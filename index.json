[
{
	"uri": "/connection_reset/",
	"title": "Connection Reset",
	"tags": [],
	"description": "",
	"content": " 에러로그에서 exception 나오는 부분의 코드를 보면, socketRead 하다가 ConnectionResetException이 발생했다. socketRead 메서드 안의 socketRead0 메서드는 native라서 자바코드로는 더이상 디버깅할 수 없다. 정리해보면 예외가 발생했고 resetState가 CONNECTION_RESET_PENDING이 되고 곧 CONNECTION_RESET이 된다. 그리고 최종적으로 throw new SocketException(\u0026quot;Connection reset\u0026quot;); 이 수행된다.\nclass SocketInputStream extends FileInputStream { ... int read(byte b[], int off, int length, int timeout) throws IOException { ... boolean gotReset = false; // acquire file descriptor and do the read  FileDescriptor fd = impl.acquireFD(); try { n = socketRead(fd, b, off, length, timeout); if (n \u0026gt; 0) { return n; } } catch (ConnectionResetException rstExc) { gotReset = true; } finally { impl.releaseFD(); } /* * We receive a \u0026#34;connection reset\u0026#34; but there may be bytes still * buffered on the socket */ if (gotReset) { impl.setConnectionResetPending(); impl.acquireFD(); try { n = socketRead(fd, b, off, length, timeout); if (n \u0026gt; 0) { return n; } } catch (ConnectionResetException rstExc) { } finally { impl.releaseFD(); } } /* * If we get here we are at EOF, the socket has been closed, * or the connection has been reset. */ if (impl.isClosedOrPending()) { throw new SocketException(\u0026#34;Socket closed\u0026#34;); } if (impl.isConnectionResetPending()) { impl.setConnectionReset(); } if (impl.isConnectionReset()) { throw new SocketException(\u0026#34;Connection reset\u0026#34;); } } ... } 대처 정확한 원인 파악이 쉽지 않아 retryHandler를 등록해서 Connection Reset이 발생되면 최대 두번까지 재전송하도록 했다.\nhttpClient = HttpClients.custom() .setRetryHandler(retryHandler()) .setConnectionManager(connectionManager) .setDefaultConnectionConfig(connectionConfig) .setDefaultRequestConfig(requestConfig) .build();private static HttpRequestRetryHandler retryHandler() { return (exception, executionCount, context) -\u0026gt; { if (executionCount \u0026gt; 2) { return false; } if (exception instanceof SocketException \u0026amp;\u0026amp; exception.getMessage().equals(\u0026#34;Connection reset\u0026#34;)) { return true; } return false; }; } 다른쪽들 정리 spring restTemplate 디폴트는 SimpleClientHttpRequest 사용\npublic abstract class HttpAccessor { /** Logger available to subclasses */ protected final Log logger = LogFactory.getLog(getClass()); private ClientHttpRequestFactory requestFactory = new SimpleClientHttpRequestFactory(); /** * Set the request factory that this accessor uses for obtaining client request handles. * \u0026lt;p\u0026gt;The default is a {@link SimpleClientHttpRequestFactory} based on the JDK\u0026#39;s own * HTTP libraries ({@link java.net.HttpURLConnection}). * \u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Note that the standard JDK HTTP library does not support the HTTP PATCH method. * Configure the Apache HttpComponents or OkHttp request factory to enable PATCH.\u0026lt;/b\u0026gt; * @see #createRequest(URI, HttpMethod) * @see org.springframework.http.client.HttpComponentsAsyncClientHttpRequestFactory * @see org.springframework.http.client.OkHttp3ClientHttpRequestFactory */ public void setRequestFactory(ClientHttpRequestFactory requestFactory) { Assert.notNull(requestFactory, \u0026#34;ClientHttpRequestFactory must not be null\u0026#34;); this.requestFactory = requestFactory; } 기본적으로 java.net.HttpURLConnection을 사용\nrestTemplate에 생성자로 requestFactory를 인자로 받아서 사용할 수 있는데, apache HttpClients를 사용하게 된다면\n// Add request retry executor, if not disabled  if (!automaticRetriesDisabled) { HttpRequestRetryHandler retryHandlerCopy = this.retryHandler; if (retryHandlerCopy == null) { retryHandlerCopy = DefaultHttpRequestRetryHandler.INSTANCE; } execChain = new RetryExec(execChain, retryHandlerCopy); } retry 설정을 disable하지 않으면 DefaultHttpRequestRetryHandler가 등록됨(디폴트 retryCount는 3)\nRST flag RST : The Reset flag indicates that the connection should be rest, and must be sent if a segment is received which is apparently not for the current connection. On receipt of a segment with the RST bit set, the receiving station will immediately aobrt the connection. Where a connection is aborted, all data in transit is considered lost, and all buffers allocated to that connection are released.\nReset flag는 connection이 reset되야 함을 나타내며, segment가 보기에 현재 connection을 위한게 아닌걸 받았을 때 보내져야 한다. RST 비트가 설정된 segment를 수신하면 즉시 연결을 중단한다. 연결이 중단된 경우, 전송 중인 모든 데이터는 손실된 것으로 간주되며 해당 연결에 할당된 모든 버퍼가 해제된다.\nRST 재설정 세그먼트 사용 예제 중복으로 SYN을 보냈을 때 TCP A가 시퀸스 번호 200으로 SYN을 보냈는데 세그먼트 전송이 지연된다.\nTCP B는 지연된 SYN 세그먼트(시퀀스 번호 90)를 받았다(line 3). TCP B는 처음 수신된 SYN이므로 ACK를 전송하고, 초기 시퀀스 번호 500을 사용할 것임을 나타낸다.\n그러나 TCP A는 TCP B에서 보낸 ACK 필드가 올바르지 않다는 것을 감지하고 SYN 세그먼트가 목적지에 도달하지 못했다고 생각해서 Reset을 전송하여 세그먼트를 거부한다(line 5). TCP A는 세그먼트를 믿을 수있게 만들기 위해이 재설정 세그먼트에서 91이라는 시퀀스 번호를 사용한다. TCP B는 Reset 플래그가 설정된 세그먼트를 받고 LISTEN 상태로 다시 들어간다.\nTCP B는 자신의 새 시퀀스 번호를 사용하여 정상적인 방식으로 ACK로 응답한다.\nTCP A는 ISN(초기 시퀀스 번호)과 연결이 설정되었음을 확인한다.\nConnection Establishment를 논의할 때, 두개의 프로세스간 정상적으로 communication할 때와 한쪽이 crash날 때 둘다 봐야한다.\n한쪽이 crash나고 다시 가동될 때, 에러 복구 메커니즘 TCP A 와 TCP B가 정상적으로 동작하다가 TCP B가 segment를 보냈는데 TCP A에서 crash가 발생했다. TCP A는 close하고 다시 three way handshake를 위한 SYN을 보낸다. TCP B는 자신이 synchronized 되어있다고 생각한다(잘 연결되어 있다고 생각). 따라서 SYN 세그먼트를 수신하면 시퀀스 번호를 확인하고 문제가 생겼다는걸 알 수 있다.(line3) TCP B는 시퀀스 번호 150을 기대한다는 ACK를 다시 전송한다(line4). TCP A는 수신 된 세그먼트가 자신이 보낸거에 맞지 않다고 생각하고(자신은 three way handshake 첫 과정인 SYN을 보냈음) Reset 세그먼트를 보낸다(line5). TCP B는 중단되고 close된다. TCP A는 이제 다시 three way handshake(line 7)로 연결을 시도 할 수 있다. 또 다른 두가지 가능한 시나리오가 있다.\nTCP A가 crash났을 때 TCP A의 이벤트를 인식하지 못한 TCP B는 데이터를 포함하는 세그먼트를 전송한다. 이 세그먼트를 수신하면 TCP A는 Reset을 전송한다(그러한 연결이 존재하는지 모르기 때문에). 위 케이스는 둘 다 LISTEN 상태에서 시작한다. 이 때 위에서 봤던 중복 SYN 문제가 발생하고, TCP A는 Reset을 보낸다. TCP B는 다시 LISTEN 상태로 돌아간다. TCP/IP ILLustrated 재설정 세그먼트(reset segment) 일반적으로 재설정은 참조 연결에 대해서 정확하지 않은 세그먼트가 도착할 때 TCP에 의해 보내진다. 참조 연결(reference connection)이라는 용어는 목적지 IP 주소와 포트 번호, 송신측 IP 주소와 포트 번호가 정의된 연결을 의미한다. RFC 793은 이것을 소켓(socket)이라고 부른다. 재설정은 정상적으로 TCP 연결의 빠른 해제의 결과다. 재설정 세그먼트 사용의 예를 보기 위해 시나리오를 구성해보자.\n존재하지 않는 포트에 대한 연결 요구 재설정 세그먼트가 생성되는 일반적 경우는, 연결 요구가 도착할 때 목적지 포트상에 프로세스가 대기하고 있지 않을 때다. 이것은 TCP에서 종종 발생한다. UDP의 경우, 사용되지 않고 있는 목적지 포트에 데이터그램이 도착하면 ICMP 목적지 접근 불가(포트 접근불가)가 생성된다. TCP는 대신에 재설정 세그먼트(reset segment)를 사용한다.\n이런 예를 발생시키는 것은 간단하다. 여기서는 텔넷 클라이언트를 사용해 목적지에서 사용되지 않고 있는 포트 번호를 지정한다.\n$ telnet localhost 9999 Trying 127.0.0.1... telnet: connect to address 127.0.0.1: Connection refused telnet: Unable to connect to remote host: Connection refused  이 오류 메세지는 텔넷 클라이언트에 의해 즉시 출력된다. 아래는 이 명령에 대한 패킷 교환을 나타내고 있다.\n1 22:15:16.348064 127.0.0.1.32803 \u0026gt; 127.0.0.1.9999: S [tcp sum ok] 3357881819:3357881819(0) win 32767 2 22:15:16.348105 127.0.0.1.9999 \u0026gt; 127.0.0.1.32803: R [tcp sum ok] 0:0(0) ack 3357881820 win 0  도착한 세그먼트의 ACK 비트는 설정돼 있지 않기 때문에 재설정의 순서 번호는 0으로 설정되고, 확인 응답 번호는 수신 ISN에 세그먼트의 데이터 바이트 수를 더한 값으로 설정돼 있다. TCP에 의해 받아들여진 재설정 세그먼트를 위해 ACK 비트 필드는 반드시 설정돼야 하고 ACK 번호 필드는 유효한 윈도우 내에 있어야 한다.\n연결 중단 위의 그림처럼 연결을 종료하는 일반적인 방법은 상대편에 FIN 신호를 보내는 것이다. FIN은 큐에서 대기하고 있는 데이터를 모두 전송한 후에 보내지고, 데이터 손실도 전혀 없기 때문에 정규 해제(orderly release)라고 부른다. 그러나 FIN 대신 RST를 보냄으로써 연결을 중단하는 경우도 있다. 이것을 중단 해제(aboritive release)라고 부른다.\n연결 중단에서는 애플리케이션에 두 가지 기능을 제공한다. (1) 대기 중인 모든 데이터를 폐기하고 즉시 재설정 신호를 전송한다. (2) RST의 수신 측은 상대방에게 일반적인 연결 폐쇄가 아닌 중단을 했다고 알릴 수 있다. 애플리케이션에 의해 사용되는 API는 정상 폐쇄 대신 중단하는 방법을 제공해야만 한다.\n소켓 API는 이 기능을 링거(linger)값 0을 가진 \u0026lsquo;linger on close\u0026rsquo;라는 소켓 옵션(SO_LINGER)을 사용해 제공한다. 링거 시간을 0으로 설정해 -L 옵션을 지정함으로써 연결이 종료될 때 일반적인 FIN 대신 중단이 보내진다.\n다음 예에서는 원격에서 대용량의 출력을 발생시키는 명령이 들어오면 사용자에 의해 취소되는 것을 볼 수 있다.\n$ ssh linux cat /user/share/dict/words Aarhus Aaron Abada Aback Abaft ... continus ... ^C Killed by signal 2.  여기서 사용자는 이 명령의 출력 중단을 결정해야 한다. 사용자가 인터럽트 문자를 입력하면 시스템은 프로세스(여기서는 ssh)가 신호 번호 2에 의해 종료됐음을 표시한다. 이 신호는 SIGINT로 부르며, 보통 이 신호가 전송되면 프로그램을 종료한다.\n$ tcpdump -vvv -s 1500 tcp 1 22:33:06.386747 192.168.10.140.2788 \u0026gt; 192.168.10.14.ssh: S [tcp sum ok] 1520364313:1520364313(0) win 65535 \u0026lt;mss 1460, nop, nop, sackOK\u0026gt; (DF) (ttl 128, id 43922, len 48) 2 22:33:06.386855 192.168.10.14.ssh \u0026gt; 192.168.10.140.2788: S [tcp sum ok] 181637276:181637276(0) ack 1520364314 win 5840 \u0026lt;mss 1460, nop, nop, sackOK\u0026gt; (DF) (ttl 64, id 0, len 48) 3 22:33:06.387676 192.168.10.140.2788 \u0026gt; 192.168.10.14.ssh: . [tcp sum ok] 1:1(0) ack 1 win 65535 (DF) (ttl 128, id 43923, len 40) (... ssh 인증 교환을 암호화하고 벌크 데이터를 전송한다 ...) 4. 22:33:13.648247 192.168.10.140.2788 \u0026gt; 192.168.10.14.ssh: R [tcp sum ok] 1343:1343(0) ack 132929 win 0 (DF) (ttl 128, id 44004, len 40)  세그먼트 1~3번은 일반적인 연결 확립을 나타내고 있다. 인터럽트 문자가 입력되면 연결은 중단된다. 재설정 세그먼트는 순서 번호와 확인 응답 번호를 포함하고 있다. 여기서 주의할 점은 재설정 세그먼트가 다른 종단으로부터 어떠한 응답도 얻지 못한다는 점이다. 이것은 전혀 확인 응답이 아니다. 재설정의 수신기는 연결을 중단하고 애플리케이션에게 연결이 재설정됐다는 것을 통보한다. 이것은 종종 Connection reset by peer 오류 표시나 유사한 메세지를 유발한다.\n절반 개방(half-open) 연결\nTCP 연결에서 한쪽 종단이 상대방의 확인 없이 자신의 연결만을 폐쇄 또는 중단할 때 절반 개방(half-open)이라고 한다. 이것은 두 호스트 중 하나가 붕괴됐을 때 발생한다. 절반 개방 연결은 데이터 전송이 행해지지 않는 동안에는 가동되고 있는 한쪽 종단이 다른 쪽 종단의 붕괴 상태를 감지할 수 없다.\n또 다른 일반적인 절반 개방이 발생하는 경우에서는 클라이언트 호스트가 애플리케이션을 종료하고 나서 클라이언트 호스트를 종료하지 않고 전력 공급을 중단한 경우다. 예를 들면 PC가 텔넷 클라이언트 상태로 동작 중일 때 사용자가 종료 시간이 돼서 PC의 전원을 꺼버린 경우를 생각 할 수 있다. 이 경우에 데이터의 전송이 없다면 서버는 클라이언트가 없어진 사실을 전혀 모르게 될 것이다. 새로운 텔넷 클라이언트를 실행하면 서버 호스트에는 새로운 서버가 동작된다. 이렇게 해서 서버 호스트상에 많은 절반 개방 TCP 연결이 생기게 된다.\n쉽게 절반 개방 연결을 만들 수 있다. 이 경우에는 서버보다 클라이언트상에서 수행한다. 10.0.0.1 상에서 텔넷 클라이언트를 실행하고, 그것을 10.0.0.7 상의 sun rpc 서버에 접속한다. 그러고 나서 한 줄의 문자열을 입력한 후 그것을 tcpdump를 통해 살펴보고, 그런 다음 서버의 호스트에 있는 이더넷 케이블을 끊고, 서버 호스트를 재가동한다. 이에 따라 서버 호스트는 충돌하게 된다(서버를 재가동 하기 전에 이더넷 케이블을 끊는 것은 TCP가 보통 시스템을 종료할 때 행하는 개방 연결에 FIN을 전송하는 것을 막기 위해서다).\n서버가 재가동된 후 케이블을 다시 접속하고, 클라이언트에서 서버로 또 다른 문자열을 전송해본다. 이때 서버의 TCP도 재실행되고, 재실행되기 전의 연결 정보는 모두 메모리에서 손실된 상태이기 때문에 데이터 세그먼트가 참조하는 연결에 대해 어떠한 정보도 알 수가 없게 된다. TCP의 규칙은 수신자가 재설정으로 응답하는 것이다.\n$ telnet 10.0.0.7 sunrpc Trying 10.0.0.7... Connected to 10.0.0.7. Escape character is '^]'. foo (이더넷 케이블이 절단되고 서버가 재부트된다) bar Connection closed by remote host  아래는 이 예의 tcpdump 출력을 보여준다.\n  TCP Dump # cd /usr/sbin # sudo ./tcpdump -i eth0 -vv -w ./dump.log tcp port 80  option\n# tcpdump -w tcpdump.log =\u0026gt; 결과를 파일로 저장, txt 가 아닌 bin 형식으로 저장됨 # tcpdump -r tcpdump.log =\u0026gt; 저장한 파일을 읽음 # tcpdump -i eth0 src 192.168.0.1 and tcp port 80 =\u0026gt; source ip 가 이것이면서 tcp port 80 인 패킷  client ip : 1.1.1.1 port : 3001 // three way handshaking 23:34:31.893798 IP (tos 0x0, ttl 64, id 60919, offset 0, flags [DF], proto TCP (6), length 60) bong.server.52986 \u0026gt; 1.1.1.1.3001: Flags [S], cksum 0xcaaa (correct), seq 1479370850, win 14600, options [mss 1460,sackOK,TS val 3970205077 ecr 0,nop,wscale 7], length 0 23:34:31.896765 IP (tos 0x0, ttl 54, id 0, offset 0, flags [DF], proto TCP (6), length 60) 1.1.1.1.3001 \u0026gt; bong.server.52986: Flags [S.], cksum 0x766b (correct), seq 3196372313, ack 1479370851, win 14480, options [mss 1460,sackOK,TS val 3970163747 ecr 3970205077,nop,wscale 7], length 0 23:34:31.896776 IP (tos 0x0, ttl 64, id 60920, offset 0, flags [DF], proto TCP (6), length 52) bong.server.52986 \u0026gt; 1.1.1.1.3001: Flags [.], cksum 0xdd51 (correct), seq 1, ack 1, win 115, options [nop,nop,TS val 3970205080 ecr 3970163747], length 0 23:34:31.896802 IP (tos 0x0, ttl 64, id 60921, offset 0, flags [DF], proto TCP (6), length 4396) bong.server.52986 \u0026gt; 1.1.1.1.3001: Flags [.], cksum 0x47ee (incorrect -\u0026gt; 0x1689), seq 1:4345, ack 1, win 115, options [nop,nop,TS val 3970205080 ecr 3970163747], length 4344 23:34:31.896810 IP (tos 0x0, ttl 64, id 60924, offset 0, flags [DF], proto TCP (6), length 1500) bong.server.52986 \u0026gt; 1.1.1.1.3001: Flags [.], cksum 0x3c9e (incorrect -\u0026gt; 0x2522), seq 4345:5793, ack 1, win 115, options [nop,nop,TS val 3970205080 ecr 3970163747], length 1448 23:34:31.896813 IP (tos 0x0, ttl 64, id 60925, offset 0, flags [DF], proto TCP (6), length 167) bong.server.52986 \u0026gt; 1.1.1.1.3001: Flags [P.], cksum 0x3769 (incorrect -\u0026gt; 0x5e2e), seq 5793:5908, ack 1, win 115, options [nop,nop,TS val 3970205080 ecr 3970163747], length 115 23:34:31.899658 IP (tos 0x0, ttl 54, id 8572, offset 0, flags [DF], proto TCP (6), length 52) 1.1.1.1.3001 \u0026gt; bong.server.52986: Flags [.], cksum 0xc626 (correct), seq 1, ack 5908, win 136, options [nop,nop,TS val 3970163750 ecr 3970205080], length 0 23:34:31.901838 IP (tos 0x0, ttl 54, id 8573, offset 0, flags [DF], proto TCP (6), length 7292) 1.1.1.1.3001 \u0026gt; bong.server.52986: Flags [.], cksum 0x533e (incorrect -\u0026gt; 0x145a), seq 1:7241, ack 5908, win 136, options [nop,nop,TS val 3970163752 ecr 3970205080], length 7240 23:34:31.901845 IP (tos 0x0, ttl 64, id 60926, offset 0, flags [DF], proto TCP (6), length 52) bong.server.52986 \u0026gt; 1.1.1.1.3001: Flags [.], cksum 0xa9d6 (correct), seq 5908, ack 7241, win 137, options [nop,nop,TS val 3970205085 ecr 3970163752], length 0 23:34:31.901850 IP (tos 0x0, ttl 54, id 8578, offset 0, flags [DF], proto TCP (6), length 1500) 1.1.1.1.3001 \u0026gt; bong.server.52986: Flags [P.], cksum 0x04d4 (correct), seq 7241:8689, ack 5908, win 136, options [nop,nop,TS val 3970163752 ecr 3970205080], length 1448 23:34:31.901854 IP (tos 0x0, ttl 64, id 60927, offset 0, flags [DF], proto TCP (6), length 52) bong.server.52986 \u0026gt; 1.1.1.1.3001: Flags [.], cksum 0xa417 (correct), seq 5908, ack 8689, win 160, options [nop,nop,TS val 3970205085 ecr 3970163752], length 0 23:34:31.901856 IP (tos 0x0, ttl 54, id 8579, offset 0, flags [DF], proto TCP (6), length 1057) 1.1.1.1.3001 \u0026gt; bong.server.52986: Flags [P.], cksum 0x6c59 (correct), seq 8689:9694, ack 5908, win 136, options [nop,nop,TS val 3970163752 ecr 3970205080], length 1005 23:34:31.901858 IP (tos 0x0, ttl 64, id 60928, offset 0, flags [DF], proto TCP (6), length 52) bong.server.52986 \u0026gt; 1.1.1.1.3001: Flags [.], cksum 0xa014 (correct), seq 5908, ack 9694, win 182, options [nop,nop,TS val 3970205085 ecr 3970163752], length 0 23:34:31.901934 IP (tos 0x0, ttl 64, id 60929, offset 0, flags [DF], proto TCP (6), length 52) bong.server.52986 \u0026gt; 1.1.1.1.3001: Flags [F.], cksum 0xa013 (correct), seq 5908, ack 9694, win 182, options [nop,nop,TS val 3970205085 ecr 3970163752], length 0 23:34:31.902096 IP (tos 0x0, ttl 54, id 8580, offset 0, flags [DF], proto TCP (6), length 52) 1.1.1.1.3001 \u0026gt; bong.server.52986: Flags [F.], cksum 0xa046 (correct), seq 9694, ack 5908, win 136, options [nop,nop,TS val 3970163752 ecr 3970205080], length 0 23:34:31.902100 IP (tos 0x0, ttl 64, id 60930, offset 0, flags [DF], proto TCP (6), length 52) bong.server.52986 \u0026gt; 1.1.1.1.3001: Flags [.], cksum 0xa012 (correct), seq 5909, ack 9695, win 182, options [nop,nop,TS val 3970205085 ecr 3970163752], length 0 23:34:31.904735 IP (tos 0x0, ttl 54, id 8581, offset 0, flags [DF], proto TCP (6), length 52) 1.1.1.1.3001 \u0026gt; bong.server.52986: Flags [.], cksum 0xa03d (correct), seq 9695, ack 5909, win 136, options [nop,nop,TS val 3970163755 ecr 3970205085], length 0  [S] - SYN (Start Connection) [.] - No Flag Set [P] - PSH (Push Data) [F] - FIN (Finish Connection) [R] - RST (Reset Connection) [.]은 ACK를 뜻하며 [F.] 은 FIN+ACK 을 가리키는 싱글 패킷  출처 : TCP/IP The Ultimate Protocol Guide\n출처 : effective tcp/ip programming 출처 : TCP/IP ILLustrated, Volume1 Second Edition 출처 : http://tech.kakao.com/2016/04/21/closewait-timewait/ 출처 : http://multifrontgarden.tistory.com/46 "
},
{
	"uri": "/effective_java/%E1%84%80%E1%85%A2%E1%86%A8%E1%84%8E%E1%85%A6%E1%84%8B%E1%85%B4_%E1%84%89%E1%85%A2%E1%86%BC%E1%84%89%E1%85%A5%E1%86%BC%E1%84%80%E1%85%AA_%E1%84%89%E1%85%A1%E1%86%A8%E1%84%8C%E1%85%A6/",
	"title": "객체의 생성과 삭제",
	"tags": [],
	"description": "",
	"content": " 객체를 만들어야하는 시점과 그 방법, 객체 생성을 피해야 하는 경우와 그 방법, 적절한 순간에 객체가 삭제되도록 보장하는 방법, 그리고 삭제 전에 반드시 이루어져야 하는 청소 작업들을 관리하는 방법을 살펴본다.\n규칙1 : 생성자 대신 정적 팩터리 메서드를 사용할 수 없는지 생각해보라(Consider static factory methods instead of consturctors) 클래스를 통해 객체를 만드는 일반적인 방법(public 생성자 이용)말고 또 다른 방법이 있다. 바로 public static factory method를 만드는 것이다.\npublic static Boolean valueOf(boolean b){ return b ? Boolean.TRUE : Boolean.FALSE; } 첫 번째 장점은, 생성자와는 달리 정적 팩토리 메서드에는 이름(name)이 있다.\n생성자에 전달되는 인자(parameter)들은 어떤 객체가 생성되는지를 설명하지 못하지만, 정적 팩토리 메서드는 이름을 잘 짓기만 한다면 사용하기 쉽고, 클라이언트 코드의 가독성도 높아진다. 예를들어, 소수일 가능성이 높은 BigInteger 객체를 생성하는 생성자 BigInteger(int, int, Random)는 BigInteger.probablePrime과 같은 이름의 정적 팩토리 메서드로 표현했으면 더 이해하기 쉬웠을 것이다.(이 메서드는 JDK 1.4 버전에 결국 추가됨)\n같은 시그너처(메서드의 형태가 같은)를 갖는 생성자를 여러 개 정의할 필요가 있을 때는 그 생성자들을 정적 팩토리 메서드로 바꾸고, 메서드 이름을 보면 차이가 명확히 드러나도록 작명에 신경쓰자.\n두 번째 장점은, 생성자와는 달리 호출할 때마다 새로운 객체를 생성할 필요가 없다.\n앞서 살펴본 Boolean.valueOf(Boolean) 메서드는 이 기법을 활용한 좋은 사례다. 결코 객체를 생성하지 않는다. 동일한 객체가 요청되는 일이 잦고, 특히 객체를 만드는 비용이 클 때 적용하면 성능을 크게 개선할 수 있다.\n세 번째 장점은, 생성자와는 달리 반환값 자료형(return type)의 하위 자료형 객체(an object of any subtype)를 반환할 수 있다\n따라서 반환되는 클래스를 선택할 수 있는 유연함(flexibility)을 제공한다. 이걸 활용하면 public으로 선언되지 않은 클래스의 객체를 반환하는 API를 만들 수 있다. 그러면 구현 세부사항을 감출 수 있으므로 아주 간결한 API가 가능하다. 이 기법은 인터페이스 기반 프레임워크(interface-based-framework) 구현에 적합한데, 이 프레임워크에서 인터페이스는 정적 팩토리 메서드의 반환값 자료형으로 이용된다. 인터페이스는 정적 메서드를 가질 수 없으므로(Prior to Java 8, interfaces couldn\u0026rsquo;t habve static methods), 관습상 반환값 자료형이 Type이라는 이름의 인터페이스인 정적 팩토리 메서드는 Types라는 이름의 객체 생성 불가능 클래스 안에 둔다.\npublic class Collections { // Suppresses default constructor, ensuring non-instantiability.  private Collections() { } ... public static \u0026lt;T\u0026gt; Collection\u0026lt;T\u0026gt; synchronizedCollection(Collection\u0026lt;T\u0026gt; c) { return new SynchronizedCollection\u0026lt;\u0026gt;(c); } static \u0026lt;T\u0026gt; Collection\u0026lt;T\u0026gt; synchronizedCollection(Collection\u0026lt;T\u0026gt; c, Object mutex) { return new SynchronizedCollection\u0026lt;\u0026gt;(c, mutex); } /** * @serial include */ static class SynchronizedCollection\u0026lt;E\u0026gt; implements Collection\u0026lt;E\u0026gt;, Serializable { private static final long serialVersionUID = 3053995032091335093L; final Collection\u0026lt;E\u0026gt; c; // Backing Collection  final Object mutex; // Object on which to synchronize  SynchronizedCollection(Collection\u0026lt;E\u0026gt; c) { this.c = Objects.requireNonNull(c); mutex = this; } ... } } 예를 들어, 자바의 컬렉션 프레임워크에는 45개의 컬렉션 인터페이스 구현체가 들어 있는데, 변경이 불가능한 컬렉션과 동기화된(synchronized) 컬렉션 등이다. 이 구현체들 거의 전부는 java.util.Collections라는 객체 생성 불가능 클래스의 정적 팩토리 메서드를 통해 이요하는데, 반환되는 객체의 실제 클래스는 public이 아니다. 구현체별로 45개의 public 클래스들을 만들었다면 컬렉션 프레임워크 API의 규모는 더 커졌을 것이다.\n인터페이스 기반 프레임워크 기법은 단순히 API 규모가 줄어든게 아니라 개념상의 무게감(conceptual weight)가 줄은 것이다. API 사용자는 반환된 객체가 인터페이스에 규정된 내용을 정확하게 따른다는 사실을 알고 있다. 또한 클라이언트가 구현된 클래스가 아닌 인터페이스를 참조해서 사용하게 되는데 일반적으로 좋은 습관이다.\n(3rd edition 추가)\nAs of Java 8, the restriction that interfaces cannot contain static methods was eliminated, so there is typically little reason to provide a noninstantiable companion class for an interface. Many public static members that would have been at home in such a class should instead be put in the interface itself. Note, however that it may still be necessary to put the bulk of the implementation code behind these static methods in a separate package-private class. This is because Java 8 requires all static members of an interface to be public. Java 9 allows private static methods, but static fields and static member classes are still required to be public.\n자바8 부터는 인터페이스에 static 메서드를 포함시킬 수 없는 제약이 사라졌다. 그래서 Collection 인터페이스를 위해 Collections 같이 noninstantiable companion class를 제공할 이유가 줄었다. 그러나 여전히 인터페이스 대신에 별도의 클래스에 구현 코드를 뒤로 두는 것은 필요하다. 자바8 인터페이스의 static 멤버들이 다 public이기 때문이다. 그리고 인터페이스에 팩토리 메서드를 추가하면, 인터페이스에서 생성된 구현 클래스를 인터페이스가 직접 의존하게 된다. 개인적으로 인터페이스가 구현 클래스를 의존하는 방식이 좋아보이지 않는다. 자바9 부터는 private static 메서드를 허용하지만 static 필드들 and static 멤버 클래스는 여전히 public이다.\nA fourth advantage of static factories is that the class of the returned object can vary from call to call as a fuction of the input parameters\n네번 째 장점은 정적 팩토리 메서드 인자에 따라 반환될 객체를 다양하게 할 수 있다. 메서드에 주어지는 인자를 이용하면 어떤 클래스의 객체를 만들지도 동적으로 결정할 수 있다. 반환될 객체의 클래스가 정적 팩토리 메서드의 반환값 자료형에 부합하기만 하면 된다. 릴리즈마다 반환되는 클래스가 달라질 수도 있다. EnumSet에는 public 생성자들이 없으며 정적 팩토리 메서드들 뿐이다.\nOpenJDK 구현체에서 enum 상수 개수에 따라 두 개 구현체 가운데 하나를 골라 해당 클래스의 객체를 만들어 반환한다. enum 상수들이 64개 이하일 경우(대부분이 그렇다) 팩토리 메서드는 RegularEnumSet 객체를 반환하는데, 이 객체는 내부적으로 long 변수 하나만을 사용한다. enum 상수들이 64개보다 많을 경우에는 JumboEnumSet 객체를 반환하는데, 이 객체는 내부적으로 long 형의 배열을 사용한다.\n클라이언트는 팩토리 메서드가 반환하는 객체의 실제 클래스를 알 수도 없고, 알 필요도 없다. 단지 EnumSet의 하위 클래스라는 사실만 중요할 뿐이다.\nA fifth advantage of static factories is that the class of the returned object need not exist when the class containing the method is written\n다섯번 째 장점은 정적 팩토리 메서드가 반환하는 객체의 클래스는 정적 팩토리 메서드가 정의된 클래스의 코드가 작성되는 순간에 존재하지 않아도 무방하다. JDBC와 같은 서비스 제공자 프레임워크의 근간을 이루는 것이 바로 유연한 정적 팩토리 메서드들이다.\nService Provider Framework는 세 가지의 핵심 컴포넌트로 구성된다. 1. service interface : Connection(서비스 제공자가 구현한다). 2. provider registration api : DriverManager.registerDriver (구현체를 시스템에 등록하여 클라이언트가 쓸수 있도록 한다). 3. service access api : DriverManager.getConnection(클라이언트에게 실제 서비스 구현체를 제공한다). 4. service provider interface(option) : Driver (서비스 제공자가 구현하고 서비스 구현체의 객체를 생성하기 위한 것이다. 서비스 제공자 인터페이스가 없는 경우 구현체는 클래스 이름으로 등록되며 자바의 리플렉션 기능을 통해 객체로 만들어진다.)\nConnection conn = null; try{ String url = \u0026#34;jdbc:mysql://localhost:3306/jdbcTest\u0026#34;; String id = \u0026#34;testid\u0026#34;; String pw = \u0026#34;testpw\u0026#34;; Class.forName(\u0026#34;com.mysql.jdbc.Driver\u0026#34;); conn = DriverManager.getConnection(url,id,pw); ...//서비스 제공자 인터페이스의 대략적인 모습  //서비스 인터페이스 ex)Connection public interface Service{ ... //서비스에 고유한 메서드들이 이 자리에 온다. } //서비스 제공자 인터페이스 ex) Driver (서비스 구현체의 객체를 생성하기 위한것) public interface Provider{ Service newService(); } //서비스 등록과 접근에 사용되는 객체 생성 불가능 클래스 ex) DriverManager public class Services{ private Services() {} //서비스 이름과 서비스 간 대응관계 보관  private static final Map\u0026lt;String, Provider\u0026gt; providers = new ConcurrentHashMap\u0026lt;String, Provider\u0026gt;(); public static final String DEFAULT_PROVIDER_NAME = \u0026#34;\u0026lt;def\u0026gt;\u0026#34;; //제공자 등록 API ex) DriverManager.registerDriver  public static void registerDefaultProvider(Provider p){ registerProvider(DEFAULT_PROVIDER_NAME, p); } public static void registerProvider(String name, Provider p){ providers.put(name,p); } //서비스 접근 API ex) DriverManager.getConnection  public static Service newInstance(){ return newInstance(DEFAULT_PROVIDER_NAME); } public static Service newInstance(String name){ Provider p = providers.get(name); if(p == null){ throw new IllegalArgumentException(\u0026#34;No provider registered with name: \u0026#34;+name); } return p.newService(); } } 자바6부터 service provider framework를 지원하는 ServiceLoader가 지원된다. 그래서 직접 만들 필요는 없다. JDBC는 ServiceLoader보다 먼저 존재했기 때문에 ServiceLoader를 사용하지 않는다.\n정적 팩토리 메서드만 있는 클래스를 만들면 생기는 가장 큰 문제는, public이나 protected로 선언된 생성자가 없으므로 하위 클래스를 만들 수 없다는 것이다.\n예를 들어, java.util.Collections에 구현된 클래스들을 편하게 쓰기 위한 하위 클래스를 만들 수 없다. 그런데 이건 틀림없이 축복이 될 수 있다. 왜냐하면 상속보다는 구성(to use composition instead of inheritance)이 더 좋기 때문이다.\n두 번째 단점은 정적 팩토리 메서드가 다른 정적 메서드와 확연히 구분되지 않는다.\n지금으로선 클래스나 인터페이스 주석을 통해 정적 팩토리 메서드임을 널리 알리거나, 이름을 지을 때 조심하는 수밖에 없다. 보통 정적 팩토리 메서드의 이름으로는 다음과 같은 것들을 사용한다.\nfrom(3rd edition 추가) : A type-conversion method that takes a single parameter and returns a corresponding instance of this type\nDate d = Date.from(instant); valueOf : 형변환 메서드.\nBigInteger prime = BigInteger.valueOf(Integer.MAX_VALUE); of : valueOf를 더 간단하게 쓴것이다. EnumSet 덕분에 인기를 모은 이름이다.\nSet\u0026lt;Rank\u0026gt; faceCards = EnumSet.of(JACK, QUEEN, KING); getInstance : 인자에 기술된 객체를 반환하지만, 인자와 같은 값을 갖지 않을 수도 있다. 싱글톤일 경우, 이 메서드는 인자 없이 항상 같은 객체를 반환한다.\nStackWalker luke = StackWalker.getInstance(options); newInstance : getInstance와 같지만 호출할 때마다 다른 객체를 반환한다.\nObject newArray = Array.newInstance(classObject, arrayLen); getType : getInstance와 같지만, 반환될 객체의 클래스와 다른 클래스에 팩토리 메서드가 있을 때 사용한다. Type은 팩토리 메서드가 반환할 객체의 자료형이다.\nFileStore fs = Files.getFileStore(path); newType : newInstance와 같지만, 반환될 객체의 클래스와 다른 클래스에 팩토리 메서드가 있을 때 사용한다. Type은 팩토리 메서드가 반환할 객체의 자료형이다.\nBufferedReader br = Files.newBufferedReader(path); type(3rd edition 추가) : A concise alternative to getType and newType\nList\u0026lt;Complaint\u0026gt; litany = Collections.list(legacyLitany); 요약 : 정적 팩토리 메서드와 public 생성자는 용도가 서로 다르며, 정적 팩토리 메서드를 고려해 보지도 않고 무조건 public 생성자를 만드는 것은 삼가기 바란다.\n규칙2 : 생성자 인자가 많을 때는 Builder 패턴 적용을 고려하라(Consider a builder when faced with many constructor parameters) 선택적 인자가 많은 상황에서 어떤 생성자나 정적 팩토리 메서드가 적합할까?\n점층적 생성자 패턴(telescoping constructor pattern)\n필수 인자만 받는 생성자를 하나 정의하고, 선택적 인자를 하나 받는 생성자를 추가하고 거기에 두개의 선택적 인자를 받는 생성자를 추가하는 식으로 생성자들을 쌓아 올리듯 추가하는 것이다.\npublic class NutritionFacts{ private final int servingSize; //필수  private final int servings; //필수  private final int calories //선택  private final int fat //선택  private final int sodium //선택  private final int carbohydrate //선택  public NutritionFacts(int servingSize, int servings){ this(servingSizem servings, 0); } public NutritionFacts(int servingSize, int servings, int calories){ this(servingSizem servings, calories, 0); } public NutritionFacts(int servingSize, int servings, int calories, int fat){ this(servingSizem servings, calories, fat, 0); } public NutritionFacts(int servingSize, int servings, int calories, int fat, int sodium){ this(servingSizem servings, calories, fat, sodium, 0); } public NutritionFacts(int servingSize, int servings, int calories, int fat, int sodium, int carbohydrate){ this.servingSize = servingSize; this.servings = servings; this.calories = calories; this.fat = fat; this.sodium = sodium; this.carbohydrate = carbohydrate; } } 이 방식은 인자 수가 늘어나면 클라이언트 코드를 작성하기가 어려워지고, 무엇보다 읽기 어려운 코드가 되고 만다. 대체 그 많은 인자가 무슨 값인지 알 수 없게 되고, 그 의미를 알려면 인자를 주의깊게 세어보아야 한다.\n자바빈 패턴\npublic class NutritionFacts{ //필드는 기본값으로 초기화(기본값이 있는 경우만)  private int servingSize = -1; private int servings = -1; private int calories = 0; private int fat = 0; private int sodium = 0; private int carbohydrate = 0; public NutritionFacts() {} //설정자(setter)  public void setServingSize(int val) { servingSize = val; } public void setServings(int val) { servings = val; } public void setCalories(int val) { calories = val; } public void setFat(int val) { fat = val; } public void setSodium(int val) { sodium = val; } public void setCarbohydrate(int val) { carbohydrate = val; } } 이 패턴에는 점층적 생성자 패턴에 있던 문제는 없다. 작성해야 하는 코드의 양이 조금 많아질 수는 있지만 객체를 생성하기도 쉬우며, 읽기도 좋다.\nNutritionFacts cocaCola = new NutritionFacts(); cocaCola.setServingSize(240); cocaCola.setServings(8); cocaCola.setCalories(100); cocaCola.setSodium(35); cocaCola.setCarbohydrate(27);  그러나 자바빈 패턴에는 심각한 단점이 있다. 1회의 함수 호출로 객체 생성을 끝낼 수 없으므로, 객체 일관성이 일시적으로 깨질 수 있다는 것이다. 또한 자바빈 패턴으로는 변경 불가능 클래스를 만들 수 없다는 것이다.\n빌더(Builder)패턴\n점층적 생성자 패턴의 안전성과 자바빈 패턴의 가독성을 결합한 패턴이다.\n필요한 객체를 직접 생성하는 대신, 클라이언트는 먼저 필수 인자들을 생성자에(또는 정적 팩토리 메서드에) 전부 전달하여 빌더 객체(builder object)를 만든다. 그런 다음 빌더 객체에 정의된 설정 메서드들을 호출하여 선택적 인자들을 추가해 나간다. 그리고 마지막으로 아무런 인자 없이 build 메서드를 호출하여 변경 불가능 객체를 만드는 것이다. 빌더 클래스는 빌더가 만드는 객체 클래스의 정적 멤버 클래스로 정의한다.\npublic class NutritionFacts { private final int servingSize; private final int servings; private final int calories; private final int fat; private final int sodium; private final int carbohydrate; private NutritionFacts(Builder builder) { servingSize = builder.servingSize; servings = builder.servings; calories = builder.calories; fat = builder.fat; sodium = builder.sodium; carbohydrate = builder.carbohydrate; } public static class Builder { //필수인자 \tprivate final int servingSize; private final int servings; //선택적 인자 - 기본값으로 초기화 \tprivate int calories = 0; private int fat = 0; private int carbohydrate = 0; private int sodium = 0; public Builder(int servingSize, int servings) { this.servingSize = servingSize; this.servings = servings; } public Builder calories(int val) { calories = val; return this; } public Builder fat(int val) { fat = val; return this; } public Builder carbohydrate(int val) { carbohydrate = val; return this; } public Builder sodium(int val) { sodium = val; return this; } public NutritionFacts build() { return new NutritionFacts(this); } } } NutritionFacts 객체가 변경 불가능하다는 사실, 그리고 모든 인자의 기본값이 한곳에 모여 있다는 것에 유의해라. 빌더에 정의된 설정 메서드는 빌더 객체 자신을 반환하므로, 설정 메서드를 호출하는 코드는 계속 이어서 쓸 수 있다.\nNutirtionFacts cocaCola = new NutritionFacts.Builder(240,8).calories(100) .sodium(35).carbohydrate(27).build(); 그리고 만약 빌더패턴에서 불변식을 검사한다면 아래 코드와 같이 빌더 파라미터 값을 복사 한 후에 체크해라.\npublic class NutritionFacts { private final int servingSize; private final int servings; private final int calories; private final int fat; private final int sodium; private final int carbohydrate; private NutritionFacts(Builder builder) { servingSize = builder.servingSize; if (servingSize \u0026gt; 0) { throw new IllegalArgumentException(); } ... } 3rd edition 추가된 빌더패턴 예제\nimport java.util.EnumSet; import java.util.Objects; import java.util.Set; public abstract class Pizza { public enum Topping {HAM, MUSHROOM, ONION, PEPPER, SAUSAGE} final Set\u0026lt;Topping\u0026gt; toppings; abstract static class Builder\u0026lt;T extends Builder\u0026lt;T\u0026gt;\u0026gt; { EnumSet\u0026lt;Topping\u0026gt; toppings = EnumSet.noneOf(Topping.class); public T addTopping(Topping topping) { toppings.add(Objects.requireNonNull(topping)); return self(); } abstract Pizza build(); // Subclasses must override this method to return \u0026#34;this\u0026#34;  protected abstract T self(); } Pizza(Builder\u0026lt;?\u0026gt; builder) { toppings = builder.toppings.clone(); } } Pizza 추상 클래스와 그안에 Builder 추상 클래스를 만들었다.\nimport java.util.Objects; public class NyPizza extends Pizza { public enum Size { SMALL, MEDIUM, LARGE } private final Size size; public static class Builder extends Pizza.Builder\u0026lt;Builder\u0026gt; { private final Size size; public Builder(Size size) { this.size = Objects.requireNonNull(size); } @Override NyPizza build() { return new NyPizza(this); } @Override protected Builder self() { return this; } } private NyPizza(Builder builder) { super(builder); size = builder.size; } }public class Calzone extends Pizza { private final boolean sauceInside; public static class Builder extends Pizza.Builder\u0026lt;Builder\u0026gt; { private boolean sauceInside = false; // default  public Builder sauceInside() { sauceInside = true; return this; } @Override Calzone build() { return new Calzone(this); } @Override protected Builder self() { return this; } } private Calzone(Builder builder) { super(builder); sauceInside = builder.sauceInside; } } 주목해야 될 부분은 Pizza 추상 클래스를 상속한 NyPizza, Calzone 클래스에서 오버라이딩한 build 메서드 return type이 자기 자신이다(Pizza가 아니라). 이렇게 함으로써 사용할 때 타입 캐스팅을 따로 안해줘도 된다.\npublic class BuilderMain { public static void main(String[] args) { NyPizza pizza = new NyPizza.Builder(NyPizza.Size.SMALL) .addTopping(Pizza.Topping.SAUSAGE) .addTopping(Pizza.Topping.ONION).build(); Calzone calzone = new Calzone.Builder().addTopping(Pizza.Topping.HAM).sauceInside().build(); } } 요약 : 빌더 패턴은 인자가 많은 생성자(4개 이상)나 정적 팩토리가 필요한 클래스를 설계할 때, 특히 대부분의 인자가 선택적 인자인 상황에 유용하다.\n규칙3 : private 생성자나 enum 자료형은 싱글턴 패턴을 따르도록 설계하라(Enforce the singleton property with a private constructor or an enum type) 싱글턴은 객체를 하나만 만들 수 있는 클래스다. 그런데 클래스를 싱글턴으로 만들면 클라이언트를 테스트하기가 어려워질 수가 있다. 싱글턴이 어떤 인터페이스를 구현하는 것이 아니면 가짜 구현으로 대체할 수 없기 때문이다.\nJDK 1.5 이전에는 싱글턴을 구현하는 방법이 두 가지였다. 두 방법 다 생성자는 private로 선언하고, 싱글턴 객체는 정적(static) 멤버를 통해 이용한다.\n첫 번째 방법 - 필드\npublic class Elvis { public static final Elvis INSTANCE = new Elvis(); //public 필드로 선언  private Elvis() { } public void leaveTheBuilding() { System.out.println(\u0026#34;Whoa baby, I\u0026#39;m outta here!\u0026#34;); } // This code would normally appear outside the class! \tpublic static void main(String[] args) { Elvis elvis = Elvis.INSTANCE; elvis.leaveTheBuilding(); } } 필드 방식의 장점은 클래스가 싱글턴인지 필드 선언만 봐도 바로 알 수 있다(public static field is final, so it will always contain the same object reference). 두번째 장점은 정적 팩토리 메서드 방식보다 더 간단하다.\n두 번째 방법 - 정적 팩토리 메서드\npublic class Elvis { private static final Elvis INSTANCE = new Elvis(); //private 필드로 선언  private Elvis() { } public static Elvis getInstance() { return INSTANCE; } public void leaveTheBuilding() { System.out.println(\u0026#34;Whoa baby, I\u0026#39;m outta here!\u0026#34;); } // This code would normally appear outside the class! \tpublic static void main(String[] args) { Elvis elvis = Elvis.getInstance(); elvis.leaveTheBuilding(); } } 이 방식의 장점은 API를 변경하지 않고도 싱글턴 패턴을 포기할 수 있다. 스레드마다 별도의 객체를 반환하도록 팩토리 메서드를 수정하는 것도 간단하다. 두번째 장점은 제네릭 타입을 수용하기 쉽다. 마지막 장점은(3rd edition 추가) method reference가 supplier로써 사용 될 수 있다. 예를 들어 Elvis::instance는 Supplier\u0026lt;Elvis\u0026gt;다. 이러한 장점들이 필요 없다면 pulbic 필드를 사용하는 쪽이 더 간단하다.\nprivate 생성자이기 때문에 클라이언트가 이 상태를 변경할 방법은 없지만 주의할 것이 하나 있다. AccessibleObject.setAccessible메서드의 도움을 받아 권한을 획득한 클라이언트는 리플렉션(reflection)기능을 통해 private 생성자를 호출 할 수 있다는 것이다.\nimport java.lang.relfect.Constructor; public class PrivateInvoker{ public static void main(String[] args) throws Exception{ //리플렉션과 setAccessible메서드를 통해 private로 선언된 생성자의 호출 권한을 획득한다.  Constructor\u0026lt;?\u0026gt; con = Private.class.getDeclaredConstructors()[0]; con.setAccessible(true); Private p = (Private)con.newInstance(); } } class Private{ private Private(){ System.out.println(\u0026#34;hello\u0026#34;); } } 리플렉션 기능을 이용하면 메모리에 적재된 클래스의 정보를 가져오는 프로그램을 작성할 수 있다. Class 객체가 주어지면, 해당 객체가 나타내는 클래스의 생성자, 메서드, 필드 등을 나타내는 Constructor, Method, Field 객체들을 가져올 수 있는데, 이 객체들을 사용하면 클래스의 멤버 이름이나 필드 자료형, 메서드 시그너처 등의 정보들을 얻어낼 수 있다(이런 공격을 막으려면 두번째 instance를 생성하는 요청이 올 때 생성자에서 Exception을 발생시키게 수정해야한다).\n싱글턴 클래스를 직렬화 가능(Serializable) 클래스로 만들려면 클래스 선언에 implements Serializable을 추가하는 것으로는 부족하다. 싱글턴 특성을 유지하려면 모든 필드를 transient로 선언하고 readResolve 메서드를 추가해야 한다. 그렇지 않으면 serialize된 객체가 역직렬화될 때마다 새로운 객체가 생기게 된다.\n//싱글턴 상태를 유지하기 위한 readResolve 구현 private Object readResolve(){ //동일한 Elvis 객체가 반환되도록 하는 동시에, 가짜 Elvis 객체는  //GC가 처리하도록 만든다.  return INSTANCE; } JDK 1.5부터는 싱글턴을 구현할 때 새로운 방법을 사용할 수 있다. 원소가 하나뿐인 enum 자료형을 정의하는 것이다.\npublic enum Elvis{ INSTNACE; public void leaveTheBuilding(){ ... } } public static void main(String[] args){ Elvis elvis = Elvis.INSTANCE; elvis.leaveTheBuilding(); } 기능적으로는 public 필드를 사용하는 구현법과 동등하다. 한 가지 차이는 좀 더 간결하다는 것과, 직렬화가 자동으로 처리된다는 것이다. 직렬화가 아무리 복잡하게 이루어져도 여러 객체가 생길 일이 없으며, 리플렉션을 통한 공격에도 안전하다. 원소가 하나뿐인 enum 자료형이야말로 싱글턴을 구현하기 가장 좋은 방법이다.\n규칙4 : 객체 생성을 막을 때는 private 생성자를 사용하라(Enforce noninstantiability with a private constructor) 정적 메서드나 필드만 모은 클래스를 만들고 싶을 때가 있다. 이런 클래스들은 악명이 높은데, 객체 지향적으로 생각하지 않으려는 사람들이 남용하는 경향이 있기 때문이다. 하지만 이런 클래스들도 분명 필요할 때가 있다. 자바의 기본 자료형 값(primitive value) 또는 배열에 적용되는 메서드를 한군데 모아둘 때 유용하다.\njava.lang.Math나 java.util.Arrays가 좋은 예다. 특정 인터페이스를 구현하는 객체를 만드는 팩토리 메서드 등의 정적 메서드를 모아놓을 때도 사용할 수 있다. java.util.Collections는 그 좋은 예다(자바8에서는 인터페이스에 직접 메서드를 추가할 수 있다). 마지막으로 final 클래스에 적용할 메서드들을 모아놓을 때도 활용할 수 있다. 클래스를 계승하여 메서드를 추가할 수 없으니 말이다.\n그런 유틸리티 클래스(utility class)들은 객체를 만들 목적의 클래스가 아니다. 객체를 만들면 오히려 이상하다. 하지만 생성자를 생략하면 컴파일러는 자동으로 기본 생성자를 만들어 버린다. 객체를 만들 수 없도록 하려고 클래스를 abstract로 선언해 봤자 소용없다. 하위 클래스를 정의하는 순간 객체 생성이 가능해지기 때문. 게다가 abstract 클래스니까 계승해서 사용하는 것이 맞다고 착각하는 사용자도 있을 수 있다. 이럴 때 private 생성자를 클래스에 넣어서 객체 생성을 방지하자는 것이다.\npublic class Utility { private Utility () { throw new AssertionError(); } } AssertionError는 반드시 필요한 것은 아니지만, 클래스 안에서 실수로 생성자를 호출하면 바로 알 수 있게 하기 위한 것이다.\nitem5 : Prefer dependency injection to hardwiring resources 규칙6 : 불필요한 객체는 만들지 말라(Avoid creating unneccesary objects) String s = new String(\u0026#34;abc\u0026#34;);  위의 문장은 실행될 때마다 String 객체를 만든다 만일 위의 문장이 순환문이나 자주 호출되는 메서드 안에 있다면, 수백만 개의 String 객체가 쓸데없이 만들어질 것이다.\nString s = \u0026#34;abc\u0026#34;; 이렇게 하면 실행할 때마다 객체를 만드는 대신, 동일한 String 객체를 사용한다. 게다가 같은 가상 머신에서 실행되는 모든 코드가 해당 객체를 재사용하게 된다.\nPerson 클래스는 어떤 사람이 베이비 붐 세대에 속하는지 아닌지를 알려주는 isBabyBoomer 메서드(1946년과 1964년 사이에 태어난 사람이면 참을 반환)를 갖고 있다.\npublic class Person{ private final Date birthDate; //다른 필드와 메서드, 생성자는 생략  //이렇게 하면 안된다!  public boolean isBabyBoomer(){ //생성 비용이 높은 객체를 쓸데없이 생성한다.  Calendar gtmCal = Calendar.getInstance(TimeZone.getTimeZone(\u0026#34;GMT\u0026#34;)); gmtCal.set(1946, Calendar.JANUARY, 1, 0, 0, 0); Date boomStart = gmtCal.getTime(); gmtCal.set(1965, Calendar.JANUARY, 1, 0, 0, 0); Date boomEnd = gmtCal.getTime(); return birthDate.compareTo(boomStart) \u0026gt;= 0 \u0026amp;\u0026amp; birthDate.compareTo(boomEnd) \u0026lt; 0; } } 위에 보인 isBabyBoomer 메서드는 호출될 때마다 Calendar 객체 하나, TimeZone 객체 하나, 그리고 Date 객체 두 개를 쓸데없이 만들어 댄다. 이렇게 비효율적인 코드는 정적 초기화 블록을 통해 개선하는 것이 좋다.\npublic class Person{ private final Date birthDate; //다른 필드와 메서드, 생성자는 생략  /** * 베이비 붐 시대의 시작과 끝 */ private static final Date BOOM_START; private static final Date BOOM_END; static{ Calendar gtmCal = Calendar.getInstance(TimeZone.getTimeZone(\u0026#34;GMT\u0026#34;)); gmtCal.set(1946, Calendar.JANUARY, 1, 0, 0, 0); BOOM_START = gmtCal.getTime(); gmtCal.set(1965, Calendar.JANUARY, 1, 0, 0, 0); BOOM_END = gmtCal.getTime(); } public boolean isBabyBoomer(){ return birthDate.compareTo(BOOM_START) \u0026gt;= 0 \u0026amp;\u0026amp; birthDate.compareTo(BOOM_END) \u0026lt; 0; } } 이렇게 개선된 Person 클래스는 Calendar, TimeZone 그리고 Date 객체를 클래스가 초기화 될 때 한 번만 만든다.\nJDK 1.5부터는 쓸데없이 객체를 만들 새로운 방법이 더 생겼다. autoboxing을 통해 자바의 기본 자료형과 그 객체 표현형을 섞어 사용할 수 있다. 둘 간의 변환은 자동으로 이뤄진다.\npublic static void main(String[] args){ Long sum = 0L; for(long i = 0; i\u0026lt; Integer.MAX_VALUE; i++){ sum += i; } System.out.println(sum); } sum은 long이 아니라 Long으로 선언되어 있는데 그 덕에 long i가 Long sum에 더해질때마다 하나씩 객체가 생긴다.\n규칙7 : 유효기간이 지난 객체 참조는 폐기하라(Eliminate obsolete object references) 스택이 커졌다가 줄어들면서 제거한 객체들을 GC가 처리하지 못하는 경우가 있다. 첨자 값이 size보다 작은 곳에 있는 요소들은 실제로 쓰이는 참조들이지만, 나머지 영역에 있는 참조들은 그렇지 않다. 문제는 남아있는 객체를 통해 참조되는 다른 객체들도 쓰레기 수집에서 제외된다. 이런 문제는 간단히 고칠 수 있다. 쓸 일 없는 객체 참조는 무조건 null로 만드는 것이다.\npublic Object pop(){ if(size ==0) throw new EmptyStackException(); Object result = elements[--size]; elements[size] = null //만기 참조 제거  return result; } 만기 참조를 제거하는 가장 좋은 방법은 해당 참조가 보관된 변수가 유효범위를 벗아나게 두는 것이다.\n캐시도 메모리 누수가 흔히 발생하는 장소다. 메모리 누수가 흔히 발견되는 또 한곳은 리스너 등의 역호출자(callback)다.\n규칙8 : 종료자 사용을 피하라(Avoid finalizers and cleaners) 종료자(finalizer) 사용은 예측할 수 없고 종종 위험하고 일반적으로 필요없다. 종료자를 사용하면 시스템 오류, 성능 문제, 이식성 문제가 발생할 수 있다.\nAs of Java 9, finalizers have been deprecated, but they are still being used by the Java libraries. The Java 9 replacement for finalizers is cleansers. Cleaners are less dangerous than finalizers, but still unpredictable, slow, and generally unnecessary.\n자바 9부터 finalizers는 deprecated됐지만, 여전히 자바 라이브러리들이 사용중이다. 자바 9에서는 finalizers 대신 cleaners로 대체됐다. cleaners는 finalizers보다는 덜 위험하지만, 여전히 예측할 수 없고 느리고 일반적으로 불필요하다.\nC++에서 소멸자는 객체에 배정된 자원을 반환하는 일반적인 수단이며, 생성자와 쌍으로 존재해야 한다. 하지만 자바에서는 GC가 알아서 반환하므로 프로그래머가 특별히 할 일이 없다. C++에서 소멸자는 메모리 이외의 자원을 반환하는 데도 사용되는데, 자바에서는 보통 try-with-resources 나 try-finally 블록이 그런 용도로 사용된다.\n종료자의 한 가지 단점은, 즉시 실행되리라는 보장이 전혀 없다는 것이다. 어떤 객체에 대한 모든 참조가 사라지고 나서 종료자가 실행되기까지는 긴 시간이 걸릴 수도 있다. 따라서 긴급한(time-critical) 작업을 종료자 안에서 처리하면 안 된다. 예를 들어 종료자 안에서 파일을 닫도록 하면 치명적이다. 파일 기술자(file descriptor)는 유한한 자원이기 때문이다. JVM은 종료자를 천천히 실행하므로 열린 상태의 파일이 많이 남아 있을 수 있다. 그런 상황에서 새로운 파일을 열려고 하면, 한 번에 열 수 있는 파일의 개수에 제한이 있으므로 오류가 나게 된다.\n그리고 finalizers 와 cleaners 실행 시점은 GC 알고리즘 구현에 따라 다양하다. 그래서 JVM에 따라 동작이 달라질 수 있기 때문에 이식성 문제가 발생할 수 있다. 또한 자바 언어 명세서에는 어떤 스레드가 종료자를 실행해야 하는지 아무 언급도 없으므로 이식성(portability)을 보장하면서 이 문제를 해결할 방법은 없다. 종료자 사용을 피하는 것만이 유일한 길이다.\nThere is no portable way to prevent this sort of problem other than to refrain from using finalizers. Cleaners are a bit better than finalizers in this regard because class authors have control over their own cleaner threads, but cleaners still run in the background, under the control of the garbage collector, so there can be no guarantee of prompt cleaning.\n자바 명세에서는 어느 스레드가 finalizers를 실행시키는걸 보장하지 않았다. 그래서 finalizers를 안쓰는 것 말고 portable하게 할 수 없다.Cleaners는 조금 나은데 class authors가 자신의 cleaner 스레드를 제어할 수 있기 때문이다. 하지만 cleaners는 여전히 백그라운드에서 gc 제어로 돌기 때문에 즉시 실행의 보장이 없다.\n자바 명세는 종료자가 즉시 샐행되어야 한다는 문구도 없지만, 종료자가 결국에는 반드시 실행되어야 한다는 문구도 없다. 따라서 종료자가 실행되지 않은 객체가 남은 상태로 프로그램이 끝나게 되는 일도 충분히 가능하다. 그러므로 지속성이 보장되어야 하는 중요 상태 정보(critical persistent state)는 종료자로 갱신하면 안된다.\nAs a consequence, you should never depend on a finalizer or cleaner to update persistent state. for example, depending on a finalizer or cleaner to release a persistent lock on a shared resource such as a database is a good way to bring your entire distributed system to a grinding halt.\npersistent state update는 finalizer 나 cleaner에 의존해서는 안된다. 분산시스템 전체를 먹통으로 만드는 가장 좋은 방법은, db같은 공유 자원에 대한 persistent lock을 종료자가 반환하게 구현하는 것이다.\n@Override protected void finalize() throws Throwable { super.finalize(); // 여기서 persistent lock을 반환하게 구현  } System.gc나 System.runFinalization 같은 메서드에 마음이 흔들리면 곤란하다. 이런 메서드들은 종료자가 실행될 가능성을 높여주긴 하지만 보장하진 않는다. 종료자 실행을 보장하는 메서드들은 System.runFinalizersOnExit와 Runtime.runFinalizersOnExit 뿐인데, 이들 메서드는 심각한 결함을 갖고 있어서 이미 명세에서 폐기되었다.\n또다른 문제는 종료 처리 도중에 무점검 예외가 던져지면, 해당 예외는 무시되며 종료 과정은 중단된다. 이런 예외는 객체의 상태를 망가뜨릴 수 있다. 일반적으로는 무점검 예외가 발생하면 스레드는 종료되고 스택 추적 정보가 표시되지만 종료자 안에서는 아니다. 경고 문구조차 출력되지 않는다.\n@Override protected void finalize() throws Throwable { super.finalize(); if ( ) { } else { throw new BongException(); } } Cleaners do not have this problem because a library using a cleaner has control over its thread. Cleaners는 이 문제를 갖고 있지 않은데 cleaner를 사용하는 라이브러리가 그 스레드를 제어하기 때문이다.\n그리고 종료자를 사용하면 성능이 심각하게 떨어진다. 필자의 컴퓨터에서 일반 AutoCloseable 객체를 만들고 try-with-resources를 이용해 close 시킬 때는 GC에 반환하는데 12ns가 걸렸다. finalizer를 사용하면 550ns로 증가했다. 왜냐하면 종료자가 GC 효율성을 억제시키기 때문이다.\nCleaners are comparable in speed to finalizers if you use them to clean all instances of the class (about 500 ns per instance on my machine), but cleaners are much faster if you use them only as a safety net, as discussed below. Under these circumstances, creating, cleaning, and destroying an object takes about 66 ns on my machine, which means you pay a factor of five (not fifty) for the insurance of a safety net if you don\u0026rsquo;t use it.\nCleaners는 모든 클래스 인스턴스를 clean한다고 했을 땐 약 500ns로 finalizer와 속도가 비슷하다. 하지만 안전망에서만 사용한다면 66ns로 훨씬 빨라진다.\nFinalizers have a serious security problem: they open your class up to finalizer attacks.\nFinalizer attack에 대한 설명\n이 책에서는 finalizer attack에 대한 설명이 자세하지 않아서 위에 따로 자세히 설명함.\n(2rd edition 내용)\n그렇다면 파일이나 스레드처럼 명시적으로 반환하거나 삭제해야 하는 자원을 포함하는 객체의 클래스는 어떻게 작성해야 하는 것일까?\n그냥 명시적인 종료 메서드(termination method)를 하나 정의하고, 더 이상 필요하지 않는 객체라면 클라이언트가 해당 메서드를 호출하도록 하라. 한 가지 명심할 것은 종료 여부를 객체 안에 보관해야 한다는것. 즉, 유효하지 않은 객체임을 표시하는 private 필드를 하나 두고, 모든 메서드 맨 앞에 해당 필드를 검사하는 코드를 두어 이미 종료된 객체에 메서드를 호출하면 IllegalStateException이 던져지도록 해야 한다는 것이다. 이런 명시적 종료 메서드의 예로는 OutputStream이나 InputStream, java.sql.Connection에 정의된 close 메서드가 있다.\n이런 명시적 종료 메서드는 보통 try-finally 문과 함께 쓰인다. 객체 종료를 보장하기 위해서다. 명시적 종료 메서드를 finally 문 안에서 호출하도록 해 놓으면 객체 사용 과정에서 예외가 던져져도 종료 메서드가 실행되도록 만들 수 있다.\n종료자가 적합한 곳이 두 군데 정도 있는데 하나는, 명시적 종료 메서드 호출(close)을 잊은 경우에 대비하는 안전망으로서의 역할이다. 하지만 종료자는 그런 자원을 발견하게 될 경우 반드시 경고 메시지를 로그로 남겨야 한다.\n명시적 종료 메서드 패턴을 따르는 예로 들었던 네 가지 클래스들(FileInputStream, FileOutputStream, Timer, Connection)은 종료 메서드가 호출되지 않을 경우에 대비하여 종료자 안전망을 갖추고 있다. 불행히도 이들 종료자는 경고 로그를 남기지 않는다. API가 공개된 다음에는 그런 기능을 추가하는 것이 일반적으로 불가능한데, 이미 작성된 클라이언트 코드를 깨뜨리게 될 것이기 때문이다.\n두 번째 경우는 네이티브 피어(native peer)와 연결된 객체를 다룰 때다. 네이티브 피어는 일반 자바 객체가 네이티브 메서드를 통해 기능 수행을 위임하는 네이티브 객체를 말한다. 네이티브 피어는 일반 객체가 아니므로 gc가 알 수 없을 뿐더러 자바 측 피어 객체(java peer)가 반환될 때 같이 반환할 수도 없다. 네이티브 피어가 중요한 자원을 점유하고 있지 않다고 가정한다면, 종료자는 그런 객체의 반환에 걸맞다. 네이티브 피어가 즉시 종료되어야 하는 자원을 포함하는 경우에는, 앞서 설명한 대로 명시적인 종료 메서드를 클래스에 추가해야 한다.\n위와 같이 종료자를 사용해야 하는 드문 상황에 처했다면 super.finalize 호출은 잊지 말자. \u0026ldquo;종료자 연결(finalizer chaining)\u0026ldquo;이 자동으로 이루어지지 않는다. 만일 (Object가 아닌) 어떤 클래스가 종료자를 갖고 있고 하위 클래스가 해당 메서드를 재정의하는 경우, 하위 클래스의 종료자는 상위 클래스의 종료자를 명시적으로 호출해야 한다. 이때 하위 클래스의 상태는 try 블록 안에서 종료시켜야 하고, 상위 클래스 종료자는 finally 블록 안에서 호출해야 한다. 그래야 하위 클래스의 종료 과정에서 예외가 발생해도 상위 클래스 종료자는 반드시 호출되도록 할 수 있다.\n// 수동 종료자 연결 @Override protected void finalize() throws Throwable { try { ... // 하위 클래스의 상태를 종료함  } finally { super.finalize(); } } 하위 클래스에서 상위 클래스 종료자를 재정의하면서 상위 클래스 종료자 호출을 잊으면, 상위 클래스 종료자는 절대로 호출되지 않는다. 이런 멍청한 하위 클래스 덕에 생기는 문제를 방지하는 한 가지 방법은, 종료되어야 하는 모든 객체마다 여벌의 객체를 하나 더 만드는 것이다. 종료되어야 하는 객체의 클래스 안에 종료자를 정의하는 대신, 익명 클래스안에 종료자를 정의하는 것이다. 이 익명 클래스의 목적은 해당 클래스의 객체를 포함하는 객체를 종료시키는 것이다. 이 익명 클래스로 만든 객체는 종료 보호자라고 부르는데, 종료되어야 하는 객체 안에 하나씩 넣는다. 종료 보호자의 바깥 객체에는 종료 보호자를 참조하는 private 필드가 있다. 따라서 바깥 객체에 대한 모든 참조가 사라지는 순간, 종료 보호자의 종료자도 실행 가능한 상태가 된다. 이 보호자 객체의 종료자는 필요한 종료 작업을, 마치 바깥 객체의 종료자인 것처럼 수행한다.\n// 종료 보호자 숙어 public class Foo { // 이 객체는 바깥 객체(Foo 객체)를 종료시키는 역할만 한다.  private final Object finalizerGuardian = new Object() { @Override protected void finalize() throws Throwable { ... // 바깥 Foo 객체를 종료시킴  } }; ... // 이하 생략 } public 클래스 Foo에는 종료자가 없다는 것에 유의하자(Object에서 계승된, 무시해도 좋은 finalize 메서드 말곤 없다). 따라서 하위 클래스의 종료자가 상위 클래스의 종료자를 호출하건 말건 상관 없다. 이 기법은 종료자가 있는 비-final 클래스를 구현할 때 반드시 고려해야 한다.\n(3rd edition 내용)\n그렇다면 파일이나 스레드처럼 삭제해야 하는 자원을 포함하는 객체의 클래스는 어떻게 작성해야 하는 것일까? 클래스에 AutoCloseable 인터페이스를 구현해서 더 이상 필요없을 때 close() 메서드를 호출해라 (try-with-resources를 사용하면 exception 발생에도 종료가 보장된다).\n언급할 가치가 있는 한가지 세부 사항은 인스턴스가 닫혀 있는지 여부를 추적해야한다는 것이다. close 메서드는 개체가 더 이상 유효하지 않은 필드를 기록해야 하며 다른 메서드는 이 필드를 검사하여 이미 종료된 객체에 메서드를 호출하면 IllegalStateException을 발생시켜야 한다.\n종료자가 적합한 곳이 두 군데 정도 있는데 하나는 close 메서드 호출을 잊은 경우에 대비하는 안전망으로서의 역할이다. cleaner나 finalizer가 즉시 또는 전부 실행된다는 보장은 없지만, close 메서드를 잊었을 때 아무것도 안하는 것보다는(늦어지더라도) 있는게 낫다. FileInputStream, FileOutputStream, ThreadPoolExecutor, java.sql.Connection 자바 라이브러리들은 안전망으로써 finalizer를 구현하고 있다.\n두 번째 경우는 네이티브 피어(native peer)와 연결된 객체를 다룰 때다. 네이티브 피어는 일반 자바 객체가 네이티브 메서드를 통해 기능 수행을 위임하는 네이티브 객체를 말한다. 네이티브 피어는 일반 객체가 아니므로 gc가 알 수 없을 뿐더러 자바 측 피어 객체(java peer)가 반환될 때 같이 반환할 수도 없다. 네이티브 피어가 중요한 자원을 점유하고 있지 않다고 가정한다면, 종료자는 그런 객체의 반환에 걸맞다. 네이티브 피어가 즉시 종료되어야 하는 자원을 포함하는 경우에는, 앞서 설명한 대로 close 메서드를 클래스에 추가해야 한다.\nCleaners는 사용하기가 약간 까다롭다. 아래 코드는 간단한 Room 클래스다(room이 반환되기 전에 clean 되야 한다고 가정하자). Room 클래스는 AutoCloseable 인터페이스를 구현했다. automatic cleaning safety net이 cleaner를 사용한다는 사실은 단지 구현 세부 사항이다. finalizers와 다르게 cleaners는 클래스의 public API를 오염시키지 않는다.\n// An autocloseable class using a cleaner as a safety net public class Room implements AutoCloseable { private static final Cleaner cleaner = Cleaner.create(); // Resource that requires cleaning. Must not refer to Room!  private static class State implements Runnable { int numJunkPiles; // Number of junk piles in this room  State(int numJunkPiles) { this.numJunkPiles = numJunkPiles; } // Invoked by close method or cleaner  @Override public void run() { System.out.println(\u0026#34;Cleaning room\u0026#34;); numJunkPiles = 0; } } // The state of this room, shared with our cleanable  private final State state; // Our cleanable. Cleans the room when it\u0026#39;s eligible for gc  private final Cleaner.Cleanable cleanable; public Room(int numJunkPiles) { state = new State(numJunkPiles); cleanable = cleaner.register(this, state); } @Override public void close() { cleanable.clean(); } } 중첩된 State static 클래스는 clean될 자원을 갖고 있다. 위의 경우 단순한 numJunkPiles 필드다(represents the amount of mess in the room). 좀 더 현실적이라면 native peer를 가리키는 포인터를 갖는 final long이 될것이다.\nState 클래스는 Runnable 인터페이스를 구현했고 Room 생성자에서 State 인스턴스를 등록할 때 Cleanable을 통해서 run 메서드가 한번만 호출된다. run 메서드 호출은 두가지 중 하나에 의해 트리거 된다. 보통 Room의 close 메서드에서 cleanable의 clean 메서드를 호출할 때 트리거 된다. 만약 Room 인스턴스가 GC 자격을 얻을 때까지 close 메서드가 호출되지 않는다면, cleaner는 State의 run 메서드를 호출할 것이다(hopefully).\nState 인스턴스가 Room 인스턴스를 참조하지 않는것은 크리티컬하다. 만약 참조했다면, Room 인스턴스가 GC 자격을 얻는 것을 (그리고 자동으로 clean되는) 막아주는 순환성을 생성하게 된다. 그러므로 State 클래스는 반드시 중첩된 staic 클래스여야 한다. 왜냐하면 non static 중첩 클래스는 자신을 둘러싼 클래스 인스턴스 참조를 포함하기 때문이다. it is similarly inadvisable to use a lambda beacause they can easily capture references to enclosing objects.\nRoom cleaner는 오직 안전망으로 사용되야 한다. 만약 Room 객체 생성을 try-with-resource 블록으로 감쌌다면, automatic cleaning은 절대 필요하지 않다.\npublic class Adult { public static void main(String[] args) { try (Room myRoom = new Room(7)) { System.out.println(\u0026#34;Goodbye\u0026#34;); } } } 위와 같이 실행시키면 Cleaning room 메세지와 함께 Goodbye가 출력될 것이다. 그러나 아래와 같이 실행하면 어떻게 될까?\npublic class Teenager { public static void main(String[] args) { new Room(99); System.out.println(\u0026#34;Peace out\u0026#34;); } } Cleaning room 메세지와 함께 Peace out이 출력되길 기대하겠지만, Cleaning room은 출력되지 않고 그냥 끝나버린다. 이게 전에 얘기했던 unpredictability이다. Cleaner 스펙은 System.exit 중 클리너의 동작은 구현에 따라 다르다고 말한다. cleaning action에 대한 보장이 없다. 필자가 System.gc()를 추가했더니 끝나기 전에 Cleaning room을 출력했다. 그러나 우리가 실행했을 때 그게 반드시 그렇게 된다는 보장이 없다.\nitem9 : Prefer try-with-resources to try-finally "
},
{
	"uri": "/%E1%84%8C%E1%85%A1%E1%84%87%E1%85%A1_%E1%84%89%E1%85%A5%E1%86%BC%E1%84%82%E1%85%B3%E1%86%BC_%E1%84%90%E1%85%B2%E1%84%82%E1%85%B5%E1%86%BC_%E1%84%8B%E1%85%B5%E1%84%8B%E1%85%A3%E1%84%80%E1%85%B5/%E1%84%82%E1%85%A2%E1%84%80%E1%85%A1_%E1%84%86%E1%85%A1%E1%86%AB%E1%84%83%E1%85%B3%E1%86%AB_%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%80%E1%85%B3%E1%84%85%E1%85%A2%E1%86%B7%E1%84%8B%E1%85%B4_%E1%84%89%E1%85%A9%E1%86%A8%E1%84%83%E1%85%A9%E1%84%85%E1%85%B3%E1%86%AF_%E1%84%8B%E1%85%A1%E1%86%AF%E1%84%80%E1%85%A9_%E1%84%89%E1%85%B5%E1%87%81%E1%84%83%E1%85%A1/",
	"title": "내가 만든 프로그램의 속도를 알고 싶다",
	"tags": [],
	"description": "",
	"content": " 시스템의 성능이 느릴 때 가장 먼저 해야 하는 작업은 병목 지점을 파악하는 것이다.\nSystem 클래스 모든 System 클래스의 메서드는 static으로 되어 있고, 그 안에서 생성된 in, out, err와 같은 객체들도 static으로 선언되어 있으며, 생성자도 없다(private으로 되어 있음).\nSystem 클래스에서 자주 사용하지는 않지만 알아두면 매우 유용한 메서드에는 어떤 것들이 있는지 알아보자.\nstatic void arraycopy(Object src, int srcPos, Object dest, int destPos, int length)String[] arr = new String[]{\u0026#34;AAA\u0026#34;, \u0026#34;BBB\u0026#34;, \u0026#34;CCC\u0026#34;, \u0026#34;DDD\u0026#34;, \u0026#34;EEE\u0026#34;}; String[] copiedArr = new String[3]; System.arraycopy(arr,2,copiedArr, 1, 2); 결과 : null CCC DDD 예를 들어 위와 같이 arraycopy 메서드를 사용했다면, arr 배열의 2번 인덱스부터 copiedArr 배열의 1번 인덱스 위치에 2개 복사하겠다는 뜻이다.\n자바의 JVM에서 사용할 수 있는 설정은 크게 두가지로 나뉜다. 하나는 속성(Property)값이고, 다른 하나는 환경(Environment)값이다. 속성은 JVM에서 지정된 값들이고, 환경은 장비(서버)에 지정되어 있는 값들이다. 자바에서는 영어 단어 그대로 \u0026ldquo;속성\u0026rdquo;은 Properties로, \u0026ldquo;환경\u0026rdquo;은 env로 사용한다.\n먼저 Properties를 사용하는 메서드에 대해서 알아보자.\n// 현재 자바 속성 값들을 받아 온다. static Properties getProperties() // key에 지정된 자바 속성 값을 받아 온다. static String getProperty(String key) // key에 지정된 자바 속성 값을 받아온다. def는 해당 key가 존재하지 않을 경우 지정할 기본값이다. static String getProperty(String key, String def) // props 객체에 담겨 있는 내용을 자바 속성에 지정한다. static void setProperties(Properties props) // 자바 속성에 있는 지정된 key의 값을 value 값으로 변환한다. static void setProperty(String key, String value) 이러한 자바 속성 관련 메서드를 어떻게 사용하는지 다음의 예를 통해 알아보자.\npublic class GetProperties { public static void main(String args[]) { System.setProperty(\u0026#34;JavaTuning\u0026#34;, \u0026#34;Tune Lee\u0026#34;); Properties prop = System.getProperties(); Set key = prop.keySet(); Iterator it = key.iterator(); while(it.hasNext()) { String curKey = it.next().toString(); System.out.format(\u0026#34;%s=%s \\n\u0026#34;, curKey, prop.getProperty(curKey)); } } } 이 소스는 \u0026lsquo;Java Tuning\u0026rsquo;이라는 키를 갖는 시스템 속성에 \u0026lsquo;Tune Lee\u0026rsquo;라는 값을 지정한 후, 시스템 속성 전체 값을 화면에 출력해 주는 프로그램이다. 이 프로그램을 수행하면 수십 개의 자바 시스템 속성값을 출력한다. 그 결과 중 우리가 지정한 \u0026lsquo;Java Tuning\u0026rsquo; 키를 갖고 \u0026lsquo;Tune Lee\u0026rsquo; 값을 가지는 속성이 추가되어 출력될 것이다.\n// 현재 시스템 환경 값 목록을 String 형태의 맵으로 리턴한다. static Map\u0026lt;String, String\u0026gt; getenv() // name에 지정된 환경 변수 값을 얻는다. static String getenv(String name)public class GetEnv { public static void main(String args[]) { Map\u0026lt;String, String\u0026gt; envMap = System.getenv(); Set key = envMap.keySet(); Iterator it = key.iterator(); while(it.hasNext()) { String curKey = it.next().toString(); System.out.format(\u0026#34;%s=%s \\n\u0026#34;, curKey, envMap.get(curKey)); } } } 그리고 운영중인 코드에 절대로 사용해서는 안되는 메서드가 있다.\n// 자바에서 사용하는 메모리를 명시적으로 해제하도록 GC를 수행하는 메서드다. static void gc() // 현재 수행중인 자바 VM을 멈춘다. static void exit(int status) // Object 객체에 있는 finalize()라는 메서드가 자동으로 호출되는데, GC가 알아서 해당 객체를 더 이상 참조할 필요가 없을 때 호출한다. // 하지만 이 메서드를 호출하면 참조 해제 작업을 기다리는 모든 객체의 finalize() 메서드를 수동으로 수행해야 한다. static void runFinalization() 다시 이야기하지만, 이 세 개의 메서드들은 절대 사용하면 안된다.\nSystem.currentTimeMillis와 System.nanoTime 이제 시간 관련 메서드에 대해서 본격적으로 알아보자.\n// 현재의 시간을 ms로 리턴한다(1/1,000초) static long currentTimeMillis() currentTimeMillis() 메서드에서 리턴해 주는 결과 값은 ms(밀리초)다. UTC라는 시간 표준 체계를 따르는데, 1970년 1월 1일부터의 시간을 long타입으로 리턴해 준다. 따라서 호출할 때마다 다르다.\n20 ms 0.02초 1,200 ms 1.2초 6,000,000 ms 6,000초  // 현재의 시간을 ns로 리턴한다(1/1,000,000,000초) static long nanoTime() nanoTime() 메서드는 JDK 5.0부터 추가된 메서드다. 되도록이면 nanoTime() 메서드의 결과로 판단하도록 하자.\ncf) JMH에 대한 내용은 \u0026lsquo;story04 어디에 담아야 하는지\u0026rsquo;에서 정리함\n"
},
{
	"uri": "/%E1%84%83%E1%85%A2%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%85%E1%85%A3%E1%86%BC_%E1%84%8B%E1%85%A1%E1%84%8F%E1%85%B5%E1%84%90%E1%85%A6%E1%86%A8%E1%84%8E%E1%85%A5%E1%84%8B%E1%85%AA_%E1%84%89%E1%85%A5%E1%86%BC%E1%84%82%E1%85%B3%E1%86%BC_%E1%84%90%E1%85%B2%E1%84%82%E1%85%B5%E1%86%BC/soa/",
	"title": "레퍼런스 아키텍처",
	"tags": [],
	"description": "",
	"content": " 레퍼런스 아키텍처는 아키텍처 설계를 할 때 참고할 수 있는 아키텍처다. 그 담위에 따라서 다음과 같이 3가지로 구분할 수 있다.\nCommon Architecture는 기술 중심으로, 일반적인 소프트웨어 개발에 사용할 수 있는 아키텍처 스타일이다. 특정 업무 도메인에 대한 종속성 없이 널리 적용할 수 있다. SOA(서비스 지향 아키텍처) , CBD(컴포넌트 기반 아키텍처), ROA(리소스 기반 아키텍처), EAI(엔터프라이즈 애플리케이션 통합) 등이 이에 해당한다. Industry Architecture는 업무 도메인에 대한 종속성을 갖는다. 금융, 공공, 가스/오일, 하이테크/제조, 통신 등 특정 산업 분야에 대한 레퍼런스 아키텍처다.\nEnterprise Architecture는 업무 도메인 내에서 회사 내부의 표준 아키텍처를 정의한다. SOA의 기본 개념 SOA란 기본 애플리케이션들의 기능을 비즈니스적인 의미가 있는 기능 단위로 묶고 표준화된 호출 인터페이스를 통해 ex) XML/HTTP, CORBA, SOAP, REST\n서비스라는 소프트웨어 컴포넌트 단위로 재조합한 후, 이 서비스들을 서로 조합하여 업무 기능을 구현한 애플리케이션을 만들어내는 소프트웨어 아키텍처다.\nSOA는 서비스 구축을 위한 표준 인터페이스에 대한 방안으로 제시되었던 CORBA 등의 기술 난도 가 높았으나 XML/HTTP나 SOAP 기반의 웹 서비스 기술의 등장으로 서비스의 구현 기술 난도 문제가 해결되고 각각의 업무별로 독립된 시스템의 형태로 개발되어 이에 대한 통합이 필요해지면서 주목받게 되었다.\ncf) 지금은 REST가 SOAP을 밀어내고 Web API의 실질적 표준으로 자리매김 한거같다.\nSOA 기반의 시스템을 구축하는데 필요한 기술을 이야기하면 SOAP를 많이 이야기 하는데 꼭 SOAP를 이용해서 서비스 기반 아키텍처를 만들어야 하는 것은 아니다. (REST가능)\nSOAP 과 REST 비교 http://greatkim91.tistory.com/79 여기 글 참고 SOAP\nSOAP는 웹서비스를 만들기 위한 표준들이 있다. (WSDL, WS-Security 등등) SOAP의 힘은 이런한 표준에서 나온다. 하지만 단점은 복잡성이다.(복잡도는 REST와 비교했을때) 그리고 REST에 비해 무겁다.\n장점 - 언어, 플랫폼 그리고 통신에 중립적 - 분산 컴퓨팅 환경을 다루기 위해 설계 - 웹 서비스를 위해 보급된 많은 표준(WSDL, WS-*)과 벤더에서 제공하는 도구들 - 에러 처리에 대한 내용이 기본으로 내장 - 확장성\n단점 - 개념적으로 REST 보다 어렵고 무거움 - 복잡함\nREST\nREST는 HTTP의 기본 개념에 충실히 따르는 웹서비스를 이야기한다. 이러한 웹 서비스를 Restful 웹 서비스라고 하며 단순한 HTTP 요청과 그결과를 단순한 XML,JSON등의 포맷으로 돌려주는 구조\n장점 - 언어, 플랫폼에 중립적 - SOAP보단 개발하기 단순함 - 학습곡선이 작고 도구가 거의 필요없음 - 간결함. 추가적인 메시징 계층이 없음 - 웹에 가까운 설계와 철학\n단점 - point-to-point 통신 모델을 가정함 둘 이상을 대상으로 상호작용하는 분산환경에는 유용하지 않음 - 보안, 정책 등에 대한 표준이 없음 - HTTP 통신 모델에 의존\nSOA에서 서비스의 정의 서비스란 플랫폼에 종속되지 않는 표준 인터페이스(CORBA나 웹 서비스)를 통해서 기업의 업무를 표현한 \u0026lsquo;느슨하게 연결되고 상호 조합 가능한 소프트웨어\u0026rsquo;이다.\n서비스를 말하는 데 있어서 가장 중요한 특징은 \u0026ldquo;기업의 업무를 표현한다.\u0026ldquo;라는 것이다. 다시말해 \u0026lsquo;임직원 정보 서비스\u0026rsquo;, \u0026lsquo;계좌 이체 서비스\u0026rsquo;같은 기업의 업무는 서비스로 정의할 수 있지만 \u0026lsquo;JNDI Lookup\u0026rsquo;, \u0026lsquo;SMTP 이메일 클라이언트\u0026rsquo;와 같은 비 업무성 서비스는 존재할 수 없다.\n서비스의 특징 1. 수직적 분할\n수직적 분할이란 애플리케이션을 개발 할 때 전체 애플리케이션을 여러 개의 서비스로 나누고 각각의 서비스를 독립적으로 개발하는 것을 말한다. 이전의 소프트웨어 개발은 애플리케이션을 아래와 같이 수평적으로 분리하였다. 그러나 SOA에서는 각각의 서비스가 데이터 계층, 비즈니스 로직, 뷰에 대한 모듈을 모두 가지고 있다. 그래서 각 서비스 간의 의존성이 최소화된다.\n 표준 인터페이스 기반\n서비스가 제공하는 인터페이스는 표준 기술로 구현되어야 한다. 즉, 플랫폼이나 기술에 종속되지 않아야 한다. 느슨한 결합\n각 서비스 컴포넌트들은 다른 서비스에 대해 의존성이 최소화 되어 있어서 서비스의 구현 내용을 변ㅎ경하였을 때 다른 서비스는 이에 영향을 거의 받지 않는다. 조합 가능\n서비스 컴포넌트들은 섭로 연결되어 하나의 조합된 형태의 애플리케이션을 구성해야 하기 때문에 서비스 간에 연결 및 조합이 가능해야 한다. 큰 단위의 서비스 분류\n서비스의 구성 단위나 인터페이스의 단위는 업무 단위를 기본으로 한다. 검색 가능\nSOA 시스템의 규모가 증가함에 따라 서비스의 중복이 발생되면 안된다. 그러므로 서비스에 대한 정보가 검색 가능해야 한다. 검색 내용에는 서비스의 내용과 서비스에 대한 사용 방법, 권한, 보안에 대한 정보들을 포함해야 한다.  SOA 수행 방법론 SOA 시스템은 기존의 시스템처럼 기업에 업무별로 개발 시스템이 존재하는 것이 아니다. 이러한 개별 시스템을 통합하여 하나의 거대한 IT 운영 플랫폼을 구축하는 데 있다. 기업의 전략\nIT 시스템은 기본적으로 기업 업무를 반영한다. 그래서 SOA 시스템을 통해서 제공하고자 하는 기능은 기업의 전략에서부터 파생된다. 예를 들어 기업 경영 전략이 2004년 매출 증대\n2005년 고객 만족 실현\n2006년 브랜드 이미지 관리\n와 같다면, 이를 지원하기 위한 IT 시스템의 구현 전략을 다음과 같이 될 수 있다.\n2004년 매출 내용 전산화\n2005년 CRM 도입을 통한 고객 정보 수집과 매출 내용을 기반으로 고객 패턴 추출\n2006년 수집된 고객 정보를 토대로 마케팅 집중\n기업의 IT 전략은 예전처럼 각각의 단위 시스템을 개발하는 것이 아니다. 기업의 전략을 IT화하여 구현한 구현한 SOA 시스템을 기업의 발전에 따라서 계속 반영 및 변화시켜나간다. 따라서 기본 IT 전략보다 좀 더 장기적인 전략을 필요로 한다. 비용과 집행\nSOA 시스템은 초기에 필요한 인프라 구축에 비용이 많이 소요되기 때문에 초기 투자 비용이 기존의 IT 시스템보다 높아진다. 그러나 계속해서 업무를 추가해나감에 따라 앞 단계에서 개발하였던 서비스들을 다시 사용하기 때문에 개발 비용은 지속적으로 감소하게 된다. 또한 기능이 부족한 서비스들은 계속해서 대체하며 안정적으로 유지하기 때문에 시간이 갈수록 소요 비용은 감소하게 된다.\n"
},
{
	"uri": "/toby_spring/%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%8B%E1%85%B4_ioc_di%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7_bean_%E1%84%85%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%91%E1%85%B3%E1%84%89%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%8F%E1%85%B3%E1%86%AF/",
	"title": "정의, IoC DI개념, Bean 라이프사이클",
	"tags": [],
	"description": "",
	"content": " 자바 엔터프라이즈 개발을 편하게 해주는 오픈소스 경량급 애플리케이션 프레임워크\n애플리케이션 프레임워크 : 특정 계층에서 동작하는 한가지 기술분야가 아닌 범용적인 프레임워크\n경량급 : 과거 EJB같은 과도한 엔지니어링이 적용된 기술은 무겁다. 스프링은 복잡한 EJB와 고가의 WAS를 갖추지 않고 단순 서버환경인 톰캣, 제티에서도 잘돌아간다.\n자바 엔터프라이즈 개발을 편하게 해준다 : 스프링이라는 프레임워크가 제공하는 기술이 아니라 자신이 작성하는 애플리케이션 로직에 더 많은 관심과 시간을 쏟게 해준다(초기 기본설정, 적용기술을 잘 선택하고 준비해두면 더이상 크게 신경 쓸 부분이 없다).\n자바의 근본적인 목적 : 객체지향 프로그래밍을 통해 유연하고 확장성 좋은 애플리케이션을 빠르게 만드는것.\n스프링이 만들어진 이유 : 경량급 프레임워크인 스프링을 활용해서 엔터프라이즈 개발을 편하게 해준다.\n엔터프라이즈 시스템 : 서버에서 동작하며 기업과 조직의 업무를 처리해주는 시스템이다. 그래서 많은 사용자의 요청을 동시에 처리해야한다(보안성, 안정성, 확장성 고려).\n스프링은 비침투적인 기술을 적용(IoC, DI, AOP 등)함으로써 비지니스 로직의 복잡함과 엔터프라이즈 기술의 복잡함을 분리시켜 애플리케이션 코드에서 설계와 구현 방식을 제한하지 않는다.\n기술적 복잡함을 상대하는 전략은 1. 서비스 추상화 2. AOP\n스프링의 DI/AOP는 단지 객체지향언어의 장점을 제대로 살리지 못하게 방해했던 요소를 제거하도록 도와줄뿐이다.\nIoC(Inversion of Control)제어의 역전 일반적인 자바 프로그램에서는 main() 메서드에서 시작해서 개발자가 미리 정한 순서를 따라 오브젝트가 생성되고 실행된다. 그런데 서블릿을 개발해서 서버에 배포할 수는 있지만, 그 실행을 개발자가 직접 제어할 수 있는 방법은 없다. 서블릿 안에 main() 메서드가 있어서 직접 실행시킬 수 있는 것도 아니다. 대신 서블릿에 대한 제어 권한을 가진 컨테이너가 적절한 시점에 서블릿 클래스의 오브젝트를 만들고 그 안에 메서드를 호출한다.\n템플릿 메서드 패턴에서도 제어의 역전 개념이 적용되었다. 추상 UserDao를 상속한 서브 클래스는 getConnection()을 구현한다. 하지만 이 메서드가 언제 어떻게 사용될지 자신은 모른다. 서브 클래스에서 결정되는 것이 아니다. 단지 이런 방식으로 DB 커넥션을 만든다는 기능만 구현해놓으면, 슈퍼 클래스인 UserDao의 템플릿 메서드 add(), get() 등에서 필요할 때 호출해서 사용하는 것이다. 즉, 제어권을 상위 템플릿 메서드에 넘기고 자신은 필요할 때 호출되어 사용되도록 한다는 개념이다.\n라이브러리와 프레임워크의 차이 : 라이브러리를 사용하는 애플리케이션 코드는 애플리케이션 흐름을 직접 제어한다. 단지 동작하는 중에 필요한 기능이 있을 때 능동적으로 라이브러리를 사용할 뿐이다.\n프레임워크는 거꾸로 애플리케이션 코드가 프레임워크에 의해 사용된다. 보통 프레임워크 위에 개발한 클래스를 등록해두고, 프레임워크가 흐름을 주도하는 중에 개발자가 만든 애플리케이션 코드를 사용하도록 만드는 방식이다.\ncf) 라이브러리는 기능을 제공하고 프레임워크는 방법을 제공한다.\n빈 : 스프링이 제어권을 가지고 직접 만들고 관계를 부여하는 오브젝트(제어의 역전이 허용된 오브젝트).\n빈팩토리 : 스프링의 IoC를 담당하는 핵심 컨테이너. 빈을 등록하고 생성하고 조회하고 돌려주고, 그 외에 부가적인 빈을 관리하는 기능을 담당한다.\nApplicationContext : 빈 팩토리를 상속한, 빈 팩토리를 확장한 IoC 컨테이너.\n기본적인 기능은 빈 팩토리와 동일하고 스프링이 제공하는 각종 부가 서비스를 추가로 제공한다.\n스프링 싱글톤 스프링은 여러번에 걸쳐 빈을 요청하더라도 매번 동일한 오브젝트를 돌려준다.\nApplicationContext는 싱글톤을 저장하고 관리하는 싱글톤 레지스트리다. 스프링은 별다른 설정을 하지 않으면 기본적으로 내부에서 생성하는 빈 오브젝트를 모두 싱글톤으로 만든다.\n서버 애플리케이션과 싱글톤\n싱글톤으로 빈을 만드는 이유는 스프링이 주로 적용되는 대상이 자바 엔터프라이즈 기술을 사용하는 서버 환경이기 때문이다. 대규모 엔터프라이즈 서버 환경은 서버 하나당 초당 수십에서 수백번씩 요청을 받아 처리해야 되기 때문에 요청이 올때마다 각 로직을 담당하는 오브젝트를 새로 만들어서 사용하면 부하가 심해진다.\n싱글톤 패턴 : 어떤 클래스를 애플리케이션 내에서 제한된 인스턴스 개수, 주로 하나만 존재하도록 강제하는 패턴이다. 이렇게 하나만 만들어지는 클래스의 오브젝트는 애플리케이션 내에서 전역적으로 접근이 가능하다. 단일 오브젝트만 존재해야 하고, 이를 애플리케이션의 여러 곳에서 공유하는 경우에 주로 사용한다.\npublic class UserDao{ private static UserDao userDao; private UserDao(){ //...  } public static UserDao getInstance(){ if(userDao == null) userDao = new UserDao(); retrun userDao; } } 싱글톤 방식의 문제점 :\n1.private 생성자로 인해 상속을 못한다(객체지향 특징이 적용안됌).\n2.테스트 하기 힘들다 - 테스트에서 사용될 때 목 오브젝트 등으로 대체하기 힘들다.\n3.서버 환경에서는 싱글톤이 하나만 만들어 지는 것을 보장하지 못한다.\n 서버에서 클래스 로더를 어떻게 구성하고 있는가에 따라 싱글톤 클래스임에도 하나 이상의 오브젝트가 만들어질 수 있다. 여러 개의 JVM에 분산돼 설치가 되는 경우에도, 각각 독립적으로 오브젝트가 생기기 때문에 싱글톤으로서의 가치가 떨어진다.  4.싱글톤의 사용은 전역 상태를 만들 수 있기 때문에 바람직하지 못하다.\n 아무 객체나 자유롭게 접근, 수정, 공유할 수 있는 전역상태는 객체지향 프로그래밍에서 권장되지 않는 모델이다.  스프링은 직접 싱글톤 형태의 오브젝트를 만들고 관리하는 기능을 제공한다. 싱글톤 레지스트리 (자바의 기본적인 싱글톤 패턴 구현방식에 여러가지 단점이 있기 때문에)\n스프링 컨테이너는 싱글톤을 생성하고 관리하고 공급하는 싱글톤 관리 컨테이너이기도 하다. 싱글톤 레지스트리의 장점은 static 메서드와 private 생성자를 사용해야 하는 비정상적인 클래스가 아니라 평범한 자바클래스를 싱글톤으로 활용하게 해준다.\n평범한 자바 클래스도 IoC방식의 컨테이너를 사용해서 생성, 관계 설정 등에 대한 제어권을 컨테이너에게 넘기면 쉽게 싱글톤 방식으로 만들어져 관리될 수 있다.\n싱글톤은 멀티스레드 환경이라면 여러 스레드가 동시에 접근해서 사용할 수 있다. 따라서 상태관리에 주의를 기울여야 한다.\n=\u0026gt; 상태정보를 내부에 갖고 있지 않는 무상태(stateless)방식으로 만들어져야 한다.\ncf) 읽기 전용이라면 인스턴스 변수로 생성해도 상관없다. 값이 바뀌는 정보를 담은 변수가 문제를 일으킨다.\n스프링 빈의 기본 스코프는 싱글톤이다. 그러나 싱글톤 외의 스코프를 가질 수도 있는데 웹을 통한 새로운 http요청이 생길때마다 생성되는 request 스코프 세션 스코프 등 \u0026hellip;\nDI\n스프링 IoC 기능의 대표적인 동작원리는 주로 의존관계 주입이라고 불린다.\nA는 B에 의존한다.(B가 변하면 A에 영향을 끼친다)\n모델이나 코드에서 클래스와 인터페이스를 통해 드러나는 의존관계 말고, 런타임 시에 오브젝트 사이에서 만들어지는 의존관계도 있다(런타임 의존관계, 오브젝트 의존관계). 설계 시점의 의존관계가 실체화 된것이다.\n의존관계 주입은 구체적인 의존 오브젝트와 그것을 사용할 주체, 보통 클라이언트라고 부르는 오브젝트를 런타임 시에 연결해주는 작업이다.\nDI란 다음 3가지 조건을 충족해야 한다.\n1. 클래스 모델이나 코드에는 런타임 시점의 의존관계가 드러나지 않는다. 그러기 위해서는 인터페이스에만 의존하고 있어야 한다.\n2. 런타임 시점의 의존관계는 컨테이너나 팩토리 (ApplicationContext)같은 제 3의 존재가 결정한다.\n3. 의존관계는 사용할 오브젝트에 대한 레퍼런스를 외부에서 제공해줌으로써 만들어진다.\nUserDao와 ConnectionMaker 사이에 DI가 적용되려면 UserDao도 반드시 컨테이너가 만드는 빈 오브젝트여야한다.\nDI를 원하는 오브젝트는 먼저 자기 자신이 컨테이너가 관리하는 빈이 되야 한다는 사실을 잊지 말자.\n빈 라이프사이클과 빈 범위(scope) 스프링 컨테이너는 빈 객체를 생성하고, 프로퍼티를 할당하고, 초기화를 수행하고, 사용이 끝나면 소멸시키는 일련의 과정을 관리한다. 예를 들어, 데이터베이스에 대한 커넥션풀을 제공하는 빈은 사용되기 전에 일정 개수의 커넥션을 연결해야 하고, 애플리케이션 종료 시점에는 열려 있는 커넥션을 모두 닫아야 하는데, 스프링 컨테이너는 이런 커넥션 생성과 종료 시점을 제어하게 된다.\n스프링은 InitializingBean 인터페이스를 제공하고 있으며, 빈 객체의 클래스가 InitializingBean 인터페이스를 구현하고 있으면 InitializingBean 인터페이스에 정의된 메서드를 호출해서 빈 객체가 초기화를 진행할 수 있도록 한다. 또한, 스프링 설정에서 초기화 메서드를 지정하면, 스프링은 그 메서드를 호출해서 빈이 초기화를 수행할 수 있게 한다.\n빈 라이프사이클 개요\nInitializingBean 인터페이스와 DisposableBean 인터페이스\n스프링은 객체의 초기화 및 소멸 과정을 위해 다음의 두 인터페이스를 제공하고 있다.\npublic interface InitializingBean{ void afterPropertiesSet() throws Exception; } public interface DisposableBean{ void destroy() throws Exception; } 스프링 컨테이너는 생성한 빈 객체가 InitializingBean 인터페이스를 구현하고 있으면, InitializingBean 인터페이스로 정의되어 있는 afterPropertiesSet() 메서드를 호출한다.\npublic class ConnPool implements InitializingBean, DisposableBean{ ... @Override public void afterPropertiesSet() throws Exception{ //커넥션 풀 초기화 실행: DB 커넥션을 여는 코드  } @Override public void destory() throws Excption{ //커넥션 풀 종료 실행: 연 DB 커넥션을 닫은 코드  } } 위 클래스를 스프링 빈으로 등록하면 스프링 컨테이너는 빈 생성 후 afterPropertiesSet() 메서드를 호출해서 초기화를 진행하고 destroy() 메서드를 호출해서 소멸을 진행한다.\n\u0026lt;bean id=\u0026#34;connPool\u0026#34; class=\u0026#34;jorg.springframwork.connPool\u0026#34;/\u0026gt; 이 두 인터페이스를 모두 상속해야 하는 것은 아니며, 필요한 인터페이스만 상속 받으면 된다.\n그런데 위와 같이 스프링에 종속된 인터페이스를 구현하면 빈이 스프링에 종속되므로 스프링 IoC컨테이너 외부에서 재사용하지 못한다.\n@PostConstruct와 @PreDestroy\n각각 초기화를 실행하는 메서드와 소멸을 실행하는 메서드에 애노테이션을 적용한다.\nimport javax.annotation.PostConstruct; import javax.annotation.PreDestroy; public class ConnPool2{ @PostConstruct public void initPool(){ //커넥션 풀 초기화 실행:DB 커넥션을 여는 코드  } @PreDestroy public void destroyPool(){ //커넥션 풀 종료 실행 : 연 DB 커넥션을 닫는 코드  } } 두 애노테이션이 적용된 메서드를 초기화/소멸 과정에서 실행하려면 다음과 같이 CommonAnnotationBeanPostProcessor 전처리기를 스프링 빈으로 등록해줘야 한다.\n(context:annotation-config 태크를 사용하면 CommonAnnotationBeanPostProcessor가 빈으로 등록됨)\n초기화와 소멸 과정에서 사용될 메서드는 파라미터를 가져서는 안된다.\n커스텀 init 메서드와 커스텀 destroy 메서드\n만약 외부에서 제공받는 라이브러리가 있는데, 이 라이브러리의 클래스를 스프링 빈으로 사용해야 할 수도 있다. 이 라이브러리의 클래스는 초기화를 위해 init() 메서드를 제공하고 있는데, 이 init()메서드는 @PostConstruct 애노테이션을 갖고 있지 않고 스프링의 InitializingBean 인터페이스를 상속받지도 않았다. 이때 커스텀 방식을 사용한다.\n\u0026lt;bean id=\u0026#34;pool3\u0026#34; class=\u0026#34;net.madvirus.spring4.chap03.ConnPool3\u0026#34; init-method=\u0026#34;init\u0026#34; destroy-method=\u0026#34;destroy\u0026#34;/\u0026gt; 자바 기반 설정을 사용한다면\n@Bean(initMethod = \u0026#34;init\u0026#34;, destroyMethod = \u0026#34;destroy\u0026#34;) public ConnPool3 connPool3(){ return new ConnPool3(); } 초기화와 소멸 과정에서 사용될 메서드는 파라미터를 가져서는 안된다.\nApplicationContextAware 인터페이스와 BeanNameAware 인터페이스\n빈으로 사용될 객체에서 스프링 컨테이너에 접근해야 한다거나, 빈 객체에서 로그를 기록할 때 빈의 이름을 남기고 싶다면 어떻게 해야할까? 이런 경우에 다음의 두 인터페이스를 사용하면 된다.\no.s.context.ApplicationContextAware\n이 인터페이스를 상속받은 빈 객체는 초기화 과정에서 컨테이너(ApplicationContext)를 전달받는다.\no.s.beans.factory.BeanNameAware\n이 인터페이스를 상속받은 빈 객체는 초기화 과정에서 빈 이름을 전달받는다.\n먼저 ApplicationContextAware 인터페이스는 다음과 같이 정의되어 있다.\npublic interface ApplicationContextAware extends Aware{ void setApplicationContext(ApplicationContext applicationContext) throws BeansException; } ApplicationContextAware 인터페이스를 상속받아 구현한 클래스는 setApplicationContext() 메서드를 통해서 컨테이너 객체(ApplicationContext)를 전달받는다. 따라서, 전달받은 컨테이너를 필드에 보관한 후, 이를 이용해서 다른 빈 객체를 구하거나, 컨테이너가 제공하는 기능(이벤트 발생, 메시지 구하기)을 사용할 수 있다. 아래 코드는 ApplicationContextAware 인터페이스의 구현 예시이다.\npublic class WorkScheduler implements ApplicationContextAware{ private WorkRunner workRunner; private ApplicationContext ctx; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException{ this.ctx = applicationContext; } public void makeAndRunWork(){ for(long order = 1; order\u0026lt;=10; order++){ Work work = ctx.getBean(\u0026#34;workProto\u0026#34;,Work.class); work.setOrder(order); workRunner.execute(work); } } } BeanNameAware 인터페이스는 다음과 같이 정의되어 있다.\npublic interface BeanNameAware extends Aware{ void setBeanName(String name); } BeanNameAware 인터페이스를 상속받아 구현한 클래스는 setBeanName() 메서드를 이용해서 빈의 이름을 전달받는다. 따라서, 로그 메시지에 빈의 이름을 함께 기록해야 할 때처럼 빈의 이름이 필요한 경우에 BeanNameAware 인터페이스를 사용하면 된다.\npublic class WorkRunner implements BeanNameAware{ private String beanId; @Override public void setBeanName(String name){ this.beanId = name; } public void execute(Work work){ logger.debug(String.format(\u0026#34;WorkRunner[%s] execute Work[%d]\u0026#34;,beanId,work.getOrder())); } } 빈 객체 범위(scope)\n스프링의 빈은 범위를 갖는데 주요 범위에는 싱글톤과 프로토타입이 있다. (두개의 범위 외에 요청범위, 세션범위가 존재하지만 잘 사용되지 않는다).\n1.싱글톤 범위\n\u0026lt;bean id=\u0026#34;pool1\u0026#34; class=\u0026#34;net.madvirus.chap03.ConnPool1\u0026#34;/\u0026gt; 별다른 설정을 하지 않으면 빈은 싱글톤 범위를 갖는다. 명시적으로 표기하고 싶다면\n-- XML \u0026lt;bean id=\u0026#34;pool1\u0026#34; class=\u0026#34;net.madvirus.chap03.ConnPool1\u0026#34; scope=\u0026#34;singleton\u0026#34;/\u0026gt;--Java @Bean @Scope(\u0026#34;singleton\u0026#34;) public ConnPool1 pool1(){ return new ConnPool1(); }ConnPool1 p1 = ctx.getBean(\u0026#34;pool1\u0026#34;, ConnPool1.class); ConnPool1 p2 = ctx.getBean(\u0026#34;pool1\u0026#34;, ConnPool1.class); getBean()메서드는 매번 동일한 객체를 리턴하기 때문에 p1과 p2는 동일한 객체를 참조하게 된다.\n2.프로토타입 범위\n프로토타입 범위의 빈은 객체의 원형(즉, 프로토타입)으로 사용되는 빈으로서, 프로토타입 범위 빈을 getBean()등을 이용해서 구할 경우 스프링 컨테이너는 매번 새로운 객체를 생성한다. 프로토타입 범위로 설정하기 위해서는 다음과 같이 \u0026lt;bean\u0026gt;태그의 scope 속성을 \u0026ldquo;prototype\u0026rdquo;으로 지정하면 된다.\n"
},
{
	"uri": "/%E1%84%83%E1%85%A2%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%85%E1%85%A3%E1%86%BC_%E1%84%8B%E1%85%A1%E1%84%8F%E1%85%B5%E1%84%90%E1%85%A6%E1%86%A8%E1%84%8E%E1%85%A5%E1%84%8B%E1%85%AA_%E1%84%89%E1%85%A5%E1%86%BC%E1%84%82%E1%85%B3%E1%86%BC_%E1%84%90%E1%85%B2%E1%84%82%E1%85%B5%E1%86%BC/msa/",
	"title": "마이크로 서비스 아키텍처",
	"tags": [],
	"description": "",
	"content": " 마이크로 서비스 아키텍처를 이해하려면 먼저 모노리틱 아키텍처 스타일에 대해서 이해해야 한다. 모노리틱 아키텍처 스타일은 기존의 전통적인 웹 시스템 개발 스타일로, 하나의 애클리케이션 내에 모든 로직이 들어가 있는 \u0026lsquo;통짜 구조\u0026rsquo;이다. ex)\n위와 같이 온라인 쇼핑몰이 있을 때 톰캣 서버에서 도는 WAR 파일내에 사용자 관리, 상품, 주문 관리 등 모든 컴포넌트가 들어 있고 이를 처리하는 UX로직까지 하나로 포장돼서 들어가 있는 구조이다.\n전체 애플리케이션을 하나로 처리하기 때문에 개발 도구에서 하나의 애플리케이션만 개발하면 되고 배포 역시 간편하며 테스트도 하나의 애플리케이션만 수행하면 되므로 편리하다.\n모노리틱 아키텍처 문제점\n작은 크기의 애플리케이션에서는 유용하지만, 규모가 큰 애플리케이션에서는 빌드 및 배포 시간, 서버의 기동 시간이 오래걸린다. 또한 프로젝트를 진행하는 관점에서도 한 두 사람의 실수는 전체 시스템의 빌드 실패를 유발하기 때문에 프로젝트가 커질수록 협업 개발하기가 쉽지 않다.\n그리고 시스템 컴포넌트들이 서로 로컬 콜(Call-by-Reference) 기반으로 타이트하게 연결되어 있기 때문에, 전체 시스템의 구조를 제대로 파악하지 않고 개발을 진행하면 특정 컴포넌트나 모듈에서의 성능 문제나 장애가 다른 컴포넌트에까지 영향을 주게 된다.\n마지막으로 특정 컴포넌트를 수정할 때 수정된 컴포넌트만 재배포 하는 것이 아니라 전체 애플리케이션을 재컴파일해서 전체를 다시 통으로 재배포 해야 한다. 이 때문에 잦은 배포가 있는 시스템은 불리하며 컴포넌트별로 기능 / 비기능적 특성에 맞춰서 다른 기술을 도입하고자 할때 유연하지 않다. 예를들어 전체 애플리케이션을 자바로 개발했다고 했을 때 파일 업로드/다운로드 와 같은 IO 작업이 많은 컴포넌트는 Node.js를 사용하는 것이 좋을 수 있으나, 애플리케이션이 자바로 개발되었기 때문에 다른 기술을 집어넣기가 매우 어렵다.\n마이크로 서비스 아키텍처 마이크로 서비스 아키텍처는 대용량 웹 서비스가 많아짐에 따라 정의된 아키텍처인데, 그 근간은 SOA에 두고 있다. SOA가 엔터프라이즈 시스템을 중심으로 고안된 아키텍처라면, 마이크로 서비스 아키텍처는 SOA 사상에 근간을 두고, 대용량 웹 서비스 개발에 맞는 구조로 사상이 경량화되고 대규모 개발팀의 조직 구조에 맞도록 변형된 아키텍처다.\n마이크로 서비스 아키텍처의 구조\n마이크로 서비스 아키텍처의 구조는 아래와 같은 모양을 따른다. 각 컴포넌트는 서비스라는 형태로 구현되고 API를 이용하여 타 서비스와 통신을 한다. 배포 구조 관점에서도 각 서비스는 독립된 서버로 타 컴포넌트와의 의존성 없이 독립적으로 배포된다.\n예를 들어 사용자 관리 서비스는 독립적인 war 파일로 개발되어 독립된 톰캣 인스턴스에 배치된다. 확장을 위해서 서비스가 배치된 톰캣 인스턴스는 횡적으로 스케일이 가능(스케일 아웃)하고, 앞단에 로드 밸런서를 배치하여 서비스 간의 로드를 분산시킨다.\n데이터 분리\n데이터 저장 관점에서는 중앙 집중화된 하나의 통 데이터베이스를 사용하는 것이 아니라 서비스별로 별도의 데이터베이스를 사용한다. 보통 모노리틱 서비스는 하나의 전체 데이터베이스(보통 RDBMS)를 사용하는 경우가 일반적이지만, 마이크로 서비스 아키텍처의 경우 서비스가 API에서부터 데이터베이스까지 분리되는 수직적 분할 원칙에 따라서 독립된 데이터베이스를 가진다. 데이터베이스의 종류 자체를 다른 데이터베이스로 사용할 수도 있지만, 같은 데이터베이스를 사용하더라도 DB를 나누는 방법을 사용한다. 이 경우 다른 서비스 컴포넌트에 대한 의존성 없이 서비스를 독립적으로 개발 및 배포/운영할 수 있다는 장점을 가지고 있으나, 다른 컴포넌트의 데이터를 API 통신을 통해서만 가지고 와야 하기 때문에 성능상 문제를 일으킬 수 있고, 이 기종 데이터베이스 간의 트랜잭션을 묶을 수 없다는 문제점이 있다.\nAPI Gateway\nAPI Gateway는 마치 proxy서버처럼 API들 앞에서 모든 API에 대한 엔드포인트를 통합하고 몇 가지 추가적인 기능을 제공하는 미들웨어다. (클라우드에서 작동하는 PaaS형태의 서비스로는 apigee.com이나 3scale.com 등이 있고, 설치형 제품으로는 CA사의 Layer7, Apache Service Mix, MuleSoft의 ESB 제품 그리고 WSO2의 API Platform 등이 있다.)\n마이크로 서비스 아키텍처의 문제점 중 하나는 각 서비스가 다른 서버에 분리,배포되기 때문에 API의 엔드포인트, 즉 서버의 URL이 각기 다르다는 것이다.\n사용자 컴포넌트는 http://user.server.com, 상품 컴포넌트는 http://product.server.com과 같은 분리된 URL을 사용하는데, 이는 API 사용자 경험 관점에서도 사용하기가 불편한다. 특히 마이크로 서비스 아키텍처는 될 수 있으면 컴포넌트를 업무 단위로 잘게 자르는 작은 덩어리의 서비스를 지향하기 때문에 컴포넌트의 UIRL 수는 더 많이 늘어날 수 있다.\nAPI를 사용하는 클라이언트에서 서버 간의 통신이나 API 통신은 P2P형태로 토폴리지가 복잡해지고 거미줄 모양의 서비스 컴포넌트 간 호출 구조는 향후 관리의 문제를 일으킬 수 있다. 하나의 엔드포인트를 변경하였을 때 제대로 관리가 되지 않을 경우가 있다. 이러한 토폴로지의 문제점을 해결하기 위해 중앙 서비스 버스와 같은 역할을 하는 채널을 배치 시켜서 전체 토폴로지를 P2P에서 Hub \u0026amp; Spoke 방식으로 변환시켜서 서비스 간 호출을 단순화 할 수 있다. 오케스트레이션\n마이크로 서비스 아키텍처 서비스 자체가 작은 덩어리 형태로 잘게 쪼개졌기 때문에 여러 개의 서비스를 묶어서 새로운 서비스를 API Gateway를 통해 구현할 수 있다.\n사실 오케스트레이션을 API Gateway 계층에서 하는 것은 게이트웨이 입장에서 부담되는 일이다. 과도한 오케스트레이션 로직은 전체적인 성능 문제를 유발한다.\n공통 기능 처리(Cross Cutting Function Handling)\nAPI에 대한 인증이나 로깅과 같은 공통 기능에 대해서 서비스 컴포넌트 별로 중복 개발해야 하는 비효율성을 유발할 수 있다. API Gateway에서 이러한 공통 기능을 처리하게 되면, API 자체는 비즈니스 로직에만 집중하여 개발 중에 발생할 수 있는 중복을 방지할 수 있다.\n배포\n마이크로 서비스 아키텍처의 가장 큰 장점 중의 하나가 유연한 배포 모델이다. 각 서비스가 다른 서비스와 물리적으로 완벽하게 분리되기 때문에 변경이 있는 서비스 부분만 부분 배포가 가능하다.\n확장성\n부하가 많은 특정 서비스에 대해서만 확장할 수 있어서 조금 더 유연한 확장 모델을 가질 수 있다.\n마이크로 서비스 아키텍처의 문제점 성능\n서비스 간의 호출을 API 통신을 이용하기 때문에 값을 JSON이나 XML에서 프로그래밍에서 사용하는 데이터 모델(자바 객체 등)로 변환하는 마샬링 오버헤드가 발생하고 호출을 위해서 이 메시지들이 네트워크를 통해서 전송하기 때문에 그만큼 시간이 추가로 소요된다.\n메모리\n각 서비스를 독립된 서버에 분할 배치하기 때문에 중복되는 모듈에 대해서 그만큼 메모리 사용량이 늘어난다. 예를 들어, 하나의 톰캣 인스턴스에서 사용자 관리와 상품 관리를 배포하여 운용할 경우, 하나의 톰캣을 운영하는 데 드는 메모리와 스프링 프레임워크와 같은 라이브러리를 사용하는 데 소요되는 메모리, 그리고 각각의 서비스 애플리케이션을 기동하는 메모리가 필요하다.\n그러나 마이크로 서비스 아키텍처로 서비스를 배포하면 사용자 관리 서비스 배포와 상품 관리 서비스 배포를 위한 각각의 톰캣 인스턴스를 운용해야 하고, 스프링 프레임워크와 같은 공통 라이브러리도 필요하기 때문에 배포하고자 하는 서비스의 수만큼 중복된 양의 메모리가 필요해진다.\n위의 두 문제는 반드시 발생하는 문제점이기는 하나 현대의 인프라 환경에서는 컴퓨팅 파워가 워낙 발달하였고 네트워크 인프라 역시 발전하면서 큰 문제가 되지 않는다.\n테스팅이 더 어려움\n서비스들이 분리되어 있고 다른 서비스에 대한 종속성을 가지고 있어서 특정 사용자 시나리오가 기능을 테스트하고자 할 경우 여러 서비스에 걸쳐서 테스트를 진행해야 한다. 이 때문에 테스트 환경 구축이나 문제 발생 시 분리된 여러 개의 시스템을 동시에 봐야 하기 때문에 테스팅의 복잡도가 올라간다.\n서비스 간 트랜잭션 처리\n구현상의 가장 어려운 점 중의 하나가 트랜잭션 처리다. 모노리틱 아키텍처에서는 RDBMS를 사용하면서 하나의 애플리케이션 내에서 트랜잭션이 문제가 있으면 쉽게 데이터베이스의 기능을 이용해서 롤백할 수 있었다. 여러 개의 데이터베이스를 사용하더라도 분산 트랜잭션을 지원하는 트랜잭션 코디네이터 등을 이용해서 쉽게 구현할 수 있었으나, API 기반의 여러 서비스를 하나의 트랜잭션으로 묶는 것은 불가능하다.\n마이크로 서비스 아키텍처의 경우 금융이나 제조와 같이 트랜잭션 보장이 중요한 엔터프라이즈 시스템보다는 대규모 처리가 필요한 B2C 형 서비스에 적합하기 때문에 아키텍처 스타일 자체가 트랜잭션을 중요시하는 시나리오에서는 적절하지 않다.\n그럼에도, 트랜잭션 처리가 필요할 경우 트랜잭션 실패 시 이를 애플리케이션으로 처리해 줘야 하는데, 이를 보상 트랜잭션이라고 한다. 앞의 계좌 이체 시나리오에서 말했듯이 출금하고 나서 다른 계좌로 이체하던 중 에러가 발생했을 때 명시적으로 돈을 원래 계좌로 돌려주는 에러 처리 로직을 구현해야 한다.\n"
},
{
	"uri": "/effective_java/%E1%84%86%E1%85%A9%E1%84%83%E1%85%B3%E1%86%AB_%E1%84%80%E1%85%A2%E1%86%A8%E1%84%8E%E1%85%A6%E1%84%8B%E1%85%B4_%E1%84%80%E1%85%A9%E1%86%BC%E1%84%90%E1%85%A9%E1%86%BC_%E1%84%86%E1%85%A6%E1%84%89%E1%85%A5%E1%84%83%E1%85%B3/",
	"title": "모든 객체의 공통 메서드",
	"tags": [],
	"description": "",
	"content": " Object에 정의된 비-final 메서드(equals, hashCode, toString, clone, finalize)의 명시적인 일반 규약들에 대해서 알아보자.(종료자 finalize는 제외) 추가로 Object의 메서드는 아니지만 특성이 비슷한 Comparable.compareTo도 알아보자.\n규칙10 : equals를 재정의할 때는 일반 규약을 따르라 equals를 재정의하지 않아도 되는 경우 1. 각각의 객체가 고유하다. 1. 값(value) 대신 활성 개체(active entity)를 나타내는 Thread 같은 클래스가 이 조건에 부합. 2. 클래스에 논리적 동일성 검사 방법이 있건 없건 상관없다. 1. Random 클래스는 equals 메서드가 큰 의미 없다.\n3. 상위 클래스에서 재정의한 equals가 하위 클래스에서 사용하기에도 적당하다. 4. 클래스가 private 또는 package-private로 선언되었고, equals 메서드를 호출할 일이 없다. 1. 하지만 저자는 재정의해서 throw new AssertionError();를 선언하라고 한다. 5. 최대 하나의 객체만 존재하도록 제한하는 클래스.\nequals를 재정하는 것이 바람직할 때 : 객체 동일성(object equality)이 아닌 논리적 동일성(logical equality)의 개념을 지원하는 클래스일 때, 그리고 상위 클래스의 equals가 하위 클래스의 필요를 충족하지 못할 때 재정의해야 한다.\nequals 메서드는 동치 관계를 구현한다.\n반사성: null이 아닌 참조 x가 있을 때, x.equals(x)는 true를 반환한다. 모든 객체는 자기 자신과 같아야 한다는 뜻이다.\n대칭성: null이 아닌 참조 x와 y가 있을 때, x.equals(y)는 y.equals(x)가 true일 때만 true를 반환한다. 두 객체에게 서로 같은지 물으면 같은 답이 나와야 한다는 것이다.\n//대칭성 위반 클래스!! public final class CaseInsensitiveString{ private final String s; public CaseInsensitiveString(String s){ if( s == null) throw new NullPointerException(); this.s = s; } //대칭성 위반 !!  @Override public boolean equals(Object o){ if(o instanceof CaseInsensitiveString){ return s.equalsIgnoreCase(((CaseInsensitiveString)o).s); } if(o instanceof String){ //한 방향으로만 정상 동작!  return s.equalsIgnoreCase((String)o); } return false; } }CaseInsensitiveString cis = new CaseInsensitiveString(\u0026#34;Polish\u0026#34;); String s = \u0026#34;polish\u0026#34;; cis.equals(s)는 True를 반환할 것이다. 하지만 s.equals(cis)는 false를 반환한다. 왜냐하면 String은 CaseInsensitiveString이 뭔지 모르기 때문이다.\n그러므로 이 문제를 방지하려면 CaseInsensitiveString의 equals 메서드가 String 객체와 상호작용하지 않도록 해야 한다.\n@Override public boolean equals(Object o){ return o instanceof CaseInsensitiveString \u0026amp;\u0026amp; ((CaseInsensitiveString)o).s.equalsIgnoreCase(s); } 추이성: null이 아닌 참조 x,y,z가 있을 때, x.equals(y)가 true이고 y.equals(z)가 true이면 x.equals(z)도 true이다.\n상위 클래스에 없는 새로운 값 컴포넌트를 하위 클래스에 추가하는 상황을 생각해 보자. 다시 말해 equals가 비교할 새로운 정보를 추가한다는 뜻이다.\npublic class Point{ private final int x; private final int y; public Point(int x, int y){ this.x = x; this.y = y; } @Override public boolean equals(Object o){ if(!(o instanceof Point)){ return false; } Point p = (Point)o; return p.x == x \u0026amp;\u0026amp; p.y ==y; } } 이 클래스를 계승하여, 색상 정보를 추가해보자.\npublic class ColorPoint extends Point{ private final Color color; public ColorPoint(int x, int y, Color color){ super(x, y); this.color = color; } } ColorPoint 클래스의 equals 구현은 어떻게 해야 할까? 구현을 생략한다면 Point의 equals가 그대로 상속되어서 추가된 색상 정보는 비교하지 못한다.\n//대칭성 위반 !! @Override public boolean equals(Object o){ if(!(o instanceof ColorPoint)){ return false; } return super.equals(o) \u0026amp;\u0026amp; ((ColorPoint)o).color == color; } 위와 같이 equals를 구현했다면, 아래 코드에서 대칭성이 어떻게 위반되는것이 명확하게 확인된다.\nPoint p = new Point(1,2); ColorPoint cp = new ColorPoint(1,2,Color.RED); p.equals(cp); // true 왜냐면 Pointer의 equals는 color를 비교하지 않으니까 cp.equals(p); // false 왜냐면 ColorPoint의 equals에서 color가 같을 수가 없으니까  그렇다면 ColorPoint의 equals를 수정해서 Point 객체와 비교할때는 색상 정보를 무시하도록 하면 어떻게 될까?\n//추이성 위반!! @Override public boolean equals(Object o){ if(!(o instanceof Point)) return false; //o가 Point 객체이면 색상은 비교하지 않는다.  if(!(o instanceof ColorPoint)) return o.equals(this); //o가 ColorPoint이므로 모든 정보를 비교  return super.equals(o) \u0026amp;\u0026amp; ((ColorPoint) o).color == color; } 이렇게 하면 대칭성은 보존되지만 추이성은 깨진다.\nColorPoint p1 = new ColorPoint(1, 2, Color.RED); Point p2 = new Point(1, 2); ColorPoint p3 = new ColorPoint(1, 2, Color.BLUE); p1.equals(p2)와 p2.equals(p3)는 모두 true를 반환하지만 p1.equals(p3)는 false를 반환한다.\n이 문제의 해결책은 무엇인가? 사실 이것은 객체 지향 언어에서 동치 관계를 구현할 때 발생하는 본질적 문제다. 객체 생성가능 클래스를 계승하여 새로운 값 컴포넌트를 추가하면서 equals 규악을 어기지 않을 방법은 없다.\nequals 메서드를 구현할 때 instanceof 대신 getClass 메서드를 사용하면 기존 클래스를 확장하여 새로운 값 컴포넌트를 추가하더라도 equals 규약을 준수할 수 있다?\n//리스코프 대체 원칙 위반 @Override public boolean equals(Object o){ if(o == null || o.getClass() != getClass()) return false; Point p = (Point)o; return p.x == x \u0026amp;\u0026amp; p.y == y; } 이렇게 하면 같은 클래스의 객체만 비교하게 된다. 하지만 아래의 예제를 보면 올바르지 않다는 것을 알 수 있다.\n//단위 원 상의 모든 점을 포함하도록 unitCircle 초기화 private static final Set\u0026lt;Point\u0026gt; uniCircle; static{ unitCircle = new HashSet\u0026lt;Point\u0026gt;(); unitCircle.add(new Point(1, 0)); unitCircle.add(new Point(0, 1)); unitCircle.add(new Point(-1, 0)); unitCircle.add(new Point(0, -1)); } public static boolean onUnitCircle(Point p){ return unitCircle.contatins(p); }public class CounterPoint extends Point{ private static final AtomicInteger counter = new AtomicInteger(); public CounterPoint(int x, int y){ super(x, y); counter.incrementAndGet(); } public int numberCreated() { return counter.get(); } } 리스코프 대체 원칙은 어떤 자료형의 중요한 속성은 하위 자료형에도 그대로 유지되어서, 그 자료형을 위한 메서드는 하위 자료형에도 잘 동작해야 한다는 원칙이다. 그런데 CounterPoint 객체를 onUnitCircle 메서드의 인자로 넘기는 경우를 생각해보자. Point 클래스의 equals 메서드가 getClass를 사용하고 있다면, onUnitCircle 메서드는 CounterPoint 객체의 x나 y값에 상관없이 무조건 false를 반환할 것이다.\n이는 onUnitCircle 메서드가 이용하는 HashSet 같은 컬렉션이 객체 포함여부를 판단할 때 equals를 사용하기 때문이며, CounterPoint객체는 어떤 Point객체와도 같을 수 없기 때문이다.\n객체 생성 가능 클래스를 계승해서 새로운 값 컴포넌트를 추가할 만족스러운 방법이 없긴 하지만, 문제를 깔끔하게 피할 수 있는 방법은 하나 있다. Point를 계승해서 ColorPoint를 만드는 대신, ColorPoint안에 private Point 필드를 두고, public 뷰(view) 메서드를 하나 만드는 것이다. 이 뷰 메서드는 ColorPoint가 가리키는 위치를 Point 객체로 반환한다.\n//equals 규약을 위반하지 않으면서 값 컴포넌트 추가 public class ColorPoint{ private final Point point; private final Color color; public ColorPoint(int x, int y, Color color){ if(color == null) throw new NullPointerException(); point = new Point(x, y); this.color = color; } //ColorPoint의 Point 뷰 반환  public Point asPoint(){ return point; } @Override public boolean equals(Object o){ if(!(o instanceof ColorPoint)) return false; ColorPoint cp = (ColorPoint)o; return cp.point.equals(point) \u0026amp;\u0026amp; cp.color.equals(color); } } 자바의 기본 라이브러리 가운데는 객체 생성 가능 클래스를 계승하여 값 컴포넌트를 추가한 클래스도 있다. 일례로 java.sql.Timestamp는 java.util.Date를 계승하여 nanoseconds 필드를 추가한 것이다. Timestamp 클래스의 equals 메서드는 대칭성을 위반하므로 Timestamp 객체와 Date 객체를 같은 컬렉션에 보관하거나 섞어 쓰면 문제가 생길 수 있다.\nabstract로 선언된 클래스와 값 필드를 추가하는 것은 equals 규약을 어기지 않고도 가능하다. 추상 클래스는 객체를 생성할 수 없으므로 앞서 살펴본 문제들은 생기지 않을 것이다.\n일관성: null이 아닌 참조 x와 y가 있을 때, equals를 통해 비교되는 정보에 아무 변화가 없으면, x.equals(y) 호출 결과는 호출 횟수에 상관없이 항상 같아야 한다.\n신뢰성이 보장되지 않는 자원들을 비교하는 equals를 구현하는 것을 삼가라. 예를 들어 java.net.URL의 equals 메서드는 URL에 대응되는 호스트의 IP 주소를 비교하여 equals의 반환값을 결정한다. 문제는 호스트명을 IP 주소로 변환하려면 네트워크에 접속해야 하므로, 언제나 같은 결과가 나온다는 보장이 없다는 것이다.\nNull에 대한 비 동치성: null이 아닌 참조 x에 대해서, x.equals(null)은 항상 false이다.\ninstanceof 연산자는 첫 번째 피연산자가 null이면 두 번째 피연산자의 자료형에 상관없이 무조건 false를 반환하므로 따로 null인지 검사할 필요없다.\nString클래스의 equals 메서드\npublic boolean equals(Object anObject){ if(this == anObject){ //1번  return true; } if(anObject instanceof String){ //2번  String anotherString = (String)anObject; //3번  int n = value.length; //4번  if(n == anotherString.value.length){ char v1[] = value; char v2[] = anotherString.value; int i = 0; while(n-- != 0){ if(v1[i] != v2[i]) return false; i++; } return true; } } return false; } 훌륭한 equals 메서드를 구현하기 위해 따라야 할 지침들이다.\n == 연산자를 사용하여 equals의 인자가 자기 자신인지 검사하라. instanceof 연산자를 사용하여 인자의 자료형이 정확한지 검사하라. equals의 인자를 정확한 자료형으로 변환하라. \u0026ldquo;중요\u0026rdquo; 필드 각각이 인자로 주어진 객체의 해당 필드와 일치하는지 검사한다.  규칙11 : equals를 재정의할 때는 반드시 hashCode도 재정의하라 hashCode 일반 규약 1. 응용프로그램 실행 중에 같은 객체의 hashCode를 여러 번 호출하는 경우, equals가 사용하는 정보들이 변경되지 않았다면, 언제나 동일한 정수가 반환되어야 한다. 다만 프로그램이 종료되었다가 다시 실행되어도 같은 값이 나올 필요는 없다. 2. equals(Object) 메서드가 같다고 판정한 두 객체의 hashCode 값은 같아야한다. 3. equals(Object) 메서드가 다르다고 판정한 두 객체의 hashCode 값은 꼭 다를 필요는 없지만 서로 다른 hashCode 값이 나오면 해시 테이블의 성능이 향상될 수 있다는 점은 이해해라.\n규칙12 : toString은 항상 재정의하라 가능하다면 toString 메서드는 객체 내의 중요 정보를 전부 담아 반환해야 한다.\n규칙13 : clone을 재정의할 때는 신중하라 Cloneable 인터페이스는 복제를 허용하는 객체라는 것을 알리는 목적으로 사용하는 믹스인(Mixin) 인터페이스다(Cloneable 인터페이스는 아무런 추상 메서드도 가지고 있지 않다).\n믹스인(Mixin)이란 \u0026ldquo;원래 타입\u0026rdquo;에 어떤 부가적인 행위를 추가로 구현했다는 것을 나타내는 타입. ex) Comparable 인터페이스\nCloneable 인터페이스가 하는일은 무엇인가? protected로 선언된 Object의 clone 메서드가 어떻게 동작할지 정한다. 만일 어떤 클래스가 Cloneable을 구현하면, Object의 clone 메서드는 해당 객체를 필드 단위로 복사한 객체를 반환한다. Cloneable을 구현하지 않은 클래스라면 clone 메서드는 CloneNotSupportedException을 던진다.\n인터페이스를 굉장히 괴상하게 이용한 사례로, 따라하면 곤란하다. 일반적으로 인터페이스를 구현한다는 것은 클래스가 무슨 일을 할 수 있는지 클라이언트에게 알리는 것이다. 그런데 Cloneable의 경우에는 상위 클래스의 protected 멤버가 어떻게 동작할지 규정하는 용도로 쓰이고 있다.\nprotected native Object clone() throws CloneNotSupportedException;\ncf) native 키워드는 자바가 아닌 언어(보통 C나 C++)로 구현한 후 자바에서 사용하려고 할때 이용하는 키워드이다. 자바로 구현하기 까다로운 것을 다른 언어로 구현해서, 자바에서 사용하기 위한 방법이다.\n릴리스 1.6에서도 Cloneable은 해당 인터페이스를 구현하는 클래스가 어떤 책임을 져야 하는지 상세히 밝히지 않는다. 실질적으로 Cloneable 인터페이스를 구현하는 클래스는 제대로 동작하는 public clone 메서드를 제공해야 한다.\n//Clone 사용 예시 만들어봤다. public class CloneTest implements Cloneable{ private final int a; private final int b; private final int c = 100; public CloneTest(){ a = 1; b = 2; } @Override public CloneTest clone() { try { return (CloneTest) super.clone(); } catch(CloneNotSupportedException e) { e.printStackTrace(); } return null; } //setter getter ... } 위의 clone 메서드는 Object가 아니라 CloneTest를 반환한다. 1.5버전부터는 이렇게 할 수 있을 뿐 아니라, 그렇게 하는 것이 바람직하다. 제네릭의 일부로 공변 반환형(covariant return type)이 도입되었기 때문이다. 다시 말해서, 재정의 메서드의 반환값 자료형은 재정의 되는 메서드의 반환값 자료형의 하위 클래스가 될 수 있다. 덕분에 재정의 메서드는 반환될 객체에 대한 더 많은 정보를 제공 할 수 있고, 클라이언트는 형변환을 하지 않아도 된다. 여기서 강조하고 싶은 일반 원칙 하나는, 라이브러리가 할 수 있는 일을 클라이언트에게 미루지 말라는 것이다.\n@Override protected Object clone() throws CloneNotSupportedException { return super.clone(); } 추가적으로 Object clone을 오버라이딩하면 위의 코드의 모습인데 throws CloneNotSupportedException는 생략 할 수 있다. public clone 메서드는 사실 해당 선언을 반드시 생략해야 한다. 컴파일 할 때 예외처리 여부를 검사하도록 강요하는 checked exception 메서드는 사용하기 불편하기 때문이다.\nsuper.clone()을 하지 않으면 Object의 clone 구현 동작에 의존하지 않으므로 클래스가 Cloneable을 구현할 이유가 없다. 그러니 비-final 클래스에 clone 을 재정의할 때는 반드시 super.clone()을 호출해 얻은 객체를 반환해야 한다(clone을 오버라이드하는 클래스가 final인 경우는 subclass가 만들어질 수 없으므로 이 컨벤션은 무시될 수 있다). if a class that overrides clone is final, this convention may be safely ignored, as there are no subclasses to worry about.\nNote : immutable 클래스는 불필요한 copy를 조장하기 때문에 clone 메서드를 제공하면 안된다.\n만일 복제할 객체가 변경 가능 객체에 대한 참조 필드를 가지고 있다면, 위에서 본 clone을 그대로 이용하면 끔찍한 결과를 초래한다.\npublic class Stack { private Object[] elements; private int size = 0; private static final int DEFAULT_INITIAL_CAPACITY = 16; public Stack() { this.elements = new Object[DEFAULT_INITIAL_CAPACITY]; } public void push(Object e) { ensureCapacity(); elements[size++] = e; } public Object pop() { if (size == 0) throw new EmptyStackException(); Object result = elements[--size]; elements[size] = null; // 만기 참조(obsolete reference)제거 \treturn result; } // 적어도 한 원소가들어갈 공간 확보 \tprivate void ensureCapacity() { if (elements.length == size) { elements = Arrays.copyOf(elements, 2 * size + 1); } } } 이 클래스를 복제 가능하도록 만들고 싶다고 하자. clone 메서드가 단순히 super.clone()이 반환한 객체를 그대로 반환하도록 구현한다면, 그 복사본의 size 필드는 올바른 값을 갖겠지만 elements 필드는 원래 Stack 객체와 같은 배열을 참조하게 된다. 그 상태에서 원래 객체나 복사본을 변경하면 다른 객체의 상태가 깨지게 된다.\n사실상 clone 메서드는 또 다른 형태의 생성자다. 원래 객체를 손상시키는 일이 없도록 해야 하고, 복사본의 불변식(invariant)도 제대로 만족시켜야 한다.\nStack의 clone 메서드가 제대로 동작하도록 하려면 스택의 내부 구조도 복사해야 한다. 가장 간단한 방법은 elements 배열에도 clone을 재귀적으로 호출하는 것이다.\n@Override protected Stack clone() { try { Stack result = (Stack)super.clone(); result.elements = elements.clone(); return result; } catch (CloneNotSupportedException e) { throw new AssertionError(); } } elements.clone() 호출 결과를 Object[]로 형변환 할 필요가 없음에 유의하자. 릴리스 1.5부터는 배열에 clone을 호출하면 반환되는 배열의 컴파일 시점 자료형은 복제 대상 배열의 자료형과 같다.\n그런데 위의 해법은 elements 필드가 final로 선언되어 있으면 동작하지 않는다. clone 안에서 필드에 새로운 값을 할당할 수 없기 때문이다. 이것은 clone의 근본적 문제다. clone의 아키텍처는 변경 가능한 객체를 참조하는 final 필드의 일반적 용법과 호환되지 않는다. 복제 가능한 클래스를 만들려면 필드의 final 선언을 지워야 할 수도 있다.\n그리고 clone을 재귀적으로 호출하는 것만으로 충분하지 않을 때도 있다. 예를 들어, 버킷 배열로 구성된 해시 테이블의 clone 메서드를 작성한다고 해보자. 각 버킷은 실제로는 키-값 쌍의 연결 리스트 첫 번째 원소에 대한 참조이며, 버킷이 빈 경우에는 null이다. 성능 문제 때문에 java.util.LinkedList를 사용하는 대신, 직접 구현한 경량의 단방향 연결 리스트를 사용한다고 하자.\npublic class HashTable { private Entry[] buckets = ...; private static class Entry { final Object key; Object value; Entry next; Entry(Object key, Object value, Entry next) { this.key = key; this.value = value; this.next = next; } } ... 이제 Stack에서 했던 대로 버킷 배열을 재귀적으로 복제한다고 해보자.\n// 잘못된 코드. 두 객체가 내부 상태를 공유하게 된다. \t@Override protected HashTable clone() { try { HashTable result = (HashTable)super.clone(); result.buckets = buckets.clone(); return result; } catch (CloneNotSupportedException e) { throw new AssertionError(); } } 복사본이 자신만의 버킷 배열을 갖긴 하지만, 복제된 배열의 각 원소는 원래 배열 원소와 동일한 연결 리스트를 참조하게 된다. 그래서 쉽게 비결정적 행동을 유발하게 된다. 이 문제를 수정하려면 각 버킷을 구성하는 연결 리스트까지도 복사해야 한다.\npublic class HashTable { private Entry[] buckets = ...; private static class Entry { final Object key; Object value; Entry next; Entry(Object key, Object value, Entry next) { this.key = key; this.value = value; this.next = next; } } // 이 Entry 객체가 첫 원소인 연결 리스트를 재귀적으로 복사  Entry deepCopy() { return new Entry(key, value, next == null ? null : next.deepCopy()); } } @Override protected HashTable clone() { try { HashTable result = (HashTable)super.clone(); result.buckets = new Entry[buckets.length]; for (int i = 0; i \u0026lt; buckets.length; i++) if (buckets[i] != null) result.buckets[i] = buckets[i].deepCopy(); return result; } catch (CloneNotSupportedException e) { throw new AssertionError(); } } private 클래스 HashTable.Entry가 깊은 복사(deep copy)를 지원하도록 수정했다. HashTable의 clone 메서드는 적절한 크기의 새로운 buckets 배열을 할당하고 원래 buckets 배열을 돌면서 비어있지 않은 모든 버킷에 깊은 복사를 실행한다.\n이 기법은 깔끔하고 버킷이 그리 길지 않다면 잘 동작한다. 하지만 연결 리스트를 복제하기에 좋은 방법이 아닌데, 리스트 원소마다 스택 프레임을 하나씩 사용하기 때문이다. 그러니 리스트가 길면 쉽게 스택 오버플로가 난다. 그런 상황을 방지하려면 재귀가 아니라 순환문을 사용해서 deepCopy를 구현해야 한다.\n// 이 Entry 객체가 첫 원소인 연결 리스트를 순환문으로 복사 Entry deepCopy() { Entry result = new Entry(key, value, next); for (Entry p = result; p.next != null; p = p.next) p.next = new Entry(p.next.key, p.next.value, p.next.next); return result; } 복잡한 객체를 복제하는 마지막 방법은 super.clone 호출 결과로 반환된 객체의 모든 필드를 초기 상태로 되돌려 놓은 다음에, 상위 레벨 메서드를 호출해서 객체 상태를 다시 만드는 것이다. HashTable 예제의 경우, buckets 필드는 새로운 버킷 배열로 초기화될 것이고, 지면상 생략한 put(key, value) 메서드를 원래 헤시 테이블의 모든 키-값 쌍에 호출하면 복제가 완료된다. 이 방법은 간단하지만 원래 객체와 복사본의 내부 구조를 직접 제어하는 메서드만큼 빠르게 동작하지는 않는다.\nwhile this approach is clean, it is antithetical to the whole cloneable architecture because it blindly overwrites the field-by-field object copy that forms the basis of the architecture. 이 접근 방법은 깨끗하지만 아키텍처의 기초를 형성하는 필드 별 객체 복사본을 맹목적으로 덮어 쓰므로 복제 가능 아키텍처 전체와는 정반대다.\n생성자와 마찬가지로, clone 메서드는 복사본의 비-final 메서드, 즉 재정의 가능 메서드를 복사 도중에 호출해서는 안된다. 만일 하위 클래스에서 재정의한 메서드를 clone 안에서 호출하면, 해당 메서드는 복사본의 상태가 완성되기 전에 호출될 것이며, 원래 객체와 복사본의 상태를 망가뜨리게 될 것이다. 따라서 앞 단락에서 설명한 put(key, value)는 final이거나 private 메서드여야 한다(private 메서드라면, 아마 비-final public 메서드를 위한 help method일 것이다).\n정리하자면 Cloneable을 구현하는 모든 클래스는 return type이 자기자신인 public clone 메서드를 재정의해야 한다. 그리고 맨 처음에 super.clone()을 호출해야 한다.\n개체 복제를 지원하는 좋은 방법은, 복사 생성자(copy constructor)나 복사 팩토리(copy factory)를 제공하는 것이다. 복사 생성자는 단순히 같은 클래스의 객체 하나를 인자로 받는 생성자다.\npublic Yum(Yum yum) { ... }; 복사 팩토리는 복사 생성자와 유사한 정적 팩토리 메서드다.\npublic static Yum newInstance(Yum yum); 이 접근법은 Cloneable/clone보다 좋은 점이 많다. 위험해 보이는 언어 외적(extralinguistic) 객체 생성 수단에 의존하지 않으며, 느슨한 규약에 충실할 것을 요구하지도 않고, final 필드 용법과 충돌하지 않으며, 불필요한 예외를 검사하도록 요구하지도 않고 형변환도 필요 없다. 인터페이스에 넣을 수 없다는 단점이 있지만, Cloneable도 인터페이스 구실을 못하기는 마찬가지다. clone을 public 메서드로 선언하지 않기 때문이다.\n게다가 복사 생성자나 팩토리는 해당 메서드가 정의된 클래스가 구현하는 인터페이스를 인자로 받을 수 있다. conversion constructors와 conversion factories로 더 잘 알려져 있으며, 복사본 객체의 실제 구현 클래스를 클라이언트가 자유롭게 정할 수 있다. clone을 사용한다면 원래 객체와 동일한 클래스를 받아들일 수밖에 없다.\n예를 들어 HashSet 형의 객체 s가 있고 이것을 TreeSet으로 복제하고 싶으면 new TreeSet(s)하면 된다.\npublic TreeSet(Collection\u0026lt;? extends E\u0026gt; c) { this(); addAll(c); }public ArrayList(Collection\u0026lt;? extends E\u0026gt; c) { elementData = c.toArray(); if ((size = elementData.length) != 0) { // c.toArray might (incorrectly) not return Object[] (see 6260652)  if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); } else { // replace with empty array.  this.elementData = EMPTY_ELEMENTDATA; } } 규칙14 : Comparable 구현을 고려하라 equals와 달리 compareTo는 서로 다른 클래스 객체에는 적용될 필요가 없다.(하지만 equals도 계승을 통한 다른 객체들간의 비교는 규약을 깨야만한다.)\ncompareTo 규약을 준수하지 않는 클래스는 비교연산에 기반한 클래스들을 오동작시킬 수 있다. 이런 클래스로는 TressSet이나 TreeMap 같은 정렬된 컬렉션과, Arrays와 Collections같은 유틸리티 클래스들이 있다. 탐색과 정렬 알고리즘을 포함하는 클래스들이다.\n저자의 강력한 권고사항 : (x.compareTo(y) == 0) == (x.equals(y)) 일반적으로, Comparable 인터페이스를 구현하면서 이 조건을 만족하지 않는 클래스는 반드시 그 사실을 명시해야 한다. 이렇게 적을 것을 추천한다. \u0026ldquo;주의: 이 클래스의 객체들은 equals에 부합하지 않는 자연적 순서를 따른다.\u0026rdquo;\nex) BigDecimal 클래스 이 클래스의 compareTo 메서드는 equals에 부합하지 않는다. HashSet 객체를 만들어 거기에 new BigDecimal(\u0026ldquo;1.0\u0026rdquo;)과 new BigDecimal(\u0026ldquo;1.00\u0026rdquo;)로 만든 객체들을 추가해 보자. 그러면 집합에는 두 개의 객체가 추가된다. 이 두 객체를 equals로 비교하면 서로 다르다고 판정되기 때문이다. 하지만 HashSet 대신 TreeSet을 사용하면 집합에는 하나의 객체만 삽입된다. compareTo로 비교하면 그 두 객체는 같은 객체이기 때문이다.\nCollection Comparable 퀴즈\npublic class ComparableTest { static class Item implements Comparable\u0026lt;Item\u0026gt; { private final int value; private final ZonedDateTime createdAt; private final int random = new Random().nextInt(); public Item(int value) { this.value = value; this.createdAt = ZonedDateTime.now().truncatedTo(ChronoUnit.SECONDS); } @Override public int compareTo(Item o) { return this.createdAt.compareTo(o.createdAt); } @Override public boolean equals(Object o) { if (this == o) { return true; } if (o == null || getClass() != o.getClass()) { return false; } Item item = (Item) o; if (value != item.value) { return false; } return createdAt != null ? createdAt.equals(item.createdAt) : item.createdAt == null; } @Override public int hashCode() { int result = value; result = 31 * result + (createdAt != null ? createdAt.hashCode() : 0); return result; } @Override public String toString() { return \u0026#34;Item{\u0026#34; + \u0026#34;value=\u0026#34; + value + \u0026#34;, createdAt=\u0026#34; + createdAt + \u0026#34;, random=\u0026#34; + random + \u0026#39;}\u0026#39;; } } public static void main(String... args) throws InterruptedException { Item item1 = new Item(1); Item item2 = new Item(1); Item item3 = new Item(2); Thread.sleep(1000); Item item4 = new Item(1); System.out.println(\u0026#34;item1 equals item2: \u0026#34; + item1.equals(item2)); // true \tSystem.out.println(\u0026#34;item2 equals item3: \u0026#34; + item2.equals(item3)); // false \tSystem.out.println(\u0026#34;item1 equals item4: \u0026#34; + item1.equals(item4)); // false  System.out.println(\u0026#34;item1 compareTo item2: \u0026#34; + item1.compareTo(item2)); // 0 \tSystem.out.println(\u0026#34;item2 compareTo item3: \u0026#34; + item2.compareTo(item3)); // 0 \tSystem.out.println(\u0026#34;item3 compareTo item1: \u0026#34; + item3.compareTo(item1)); // 0 \tSystem.out.println(\u0026#34;item3 compareTo item4: \u0026#34; + item3.compareTo(item4)); // -1  // item1 item2 equals true \t// item1 item2 item3 compare 0  List\u0026lt;Item\u0026gt; arrayList = new ArrayList\u0026lt;\u0026gt;(); arrayList.add(item1); arrayList.add(item2); arrayList.add(item3); arrayList.add(item4); System.out.println(\u0026#34;arrayList size: \u0026#34; + arrayList.size()); // 4 \tarrayList.forEach(i -\u0026gt; System.out.println(\u0026#34;arrayList item value: \u0026#34; + i.value)); // item1, item2, item3, item4  Set\u0026lt;Item\u0026gt; linkedHashSet = new LinkedHashSet\u0026lt;\u0026gt;(); System.out.println(\u0026#34;item1 \u0026#34; + item1); System.out.println(\u0026#34;item2 \u0026#34; + item2); linkedHashSet.add(item1); linkedHashSet.add(item2); linkedHashSet.add(item3); linkedHashSet.add(item4); System.out.println(\u0026#34;linkedHashSet size: \u0026#34; + linkedHashSet.size()); // 3 \tlinkedHashSet.forEach(i -\u0026gt; System.out.println(\u0026#34;linkedHashSet item value: \u0026#34; + i.value + i)); // item1, item3, item4  Set\u0026lt;Item\u0026gt; treeSet = new TreeSet\u0026lt;\u0026gt;(); treeSet.add(item1); treeSet.add(item2); treeSet.add(item3); treeSet.add(item4); System.out.println(\u0026#34;treeSet size: \u0026#34; + treeSet.size()); // 2 \ttreeSet.forEach(i -\u0026gt; System.out.println(\u0026#34;treeSet item value: \u0026#34; + i)); // item1, item4  Map\u0026lt;Item, String\u0026gt; linkedHashMap = new LinkedHashMap(); linkedHashMap.put(item1, \u0026#34;item1\u0026#34;); linkedHashMap.put(item3, \u0026#34;item3\u0026#34;); linkedHashMap.put(item4, \u0026#34;item4\u0026#34;); linkedHashMap.put(item2, \u0026#34;item2\u0026#34;); System.out.println(\u0026#34;linkedHashMap size: \u0026#34; + linkedHashMap.size()); // 3 \tlinkedHashMap.forEach((entry, value) -\u0026gt; System.out.println(\u0026#34;linkedHashMap value: \u0026#34; + value)); // item2, item3, item4  Map\u0026lt;Item, String\u0026gt; treeMap = new TreeMap\u0026lt;\u0026gt;(); treeMap.put(item1, \u0026#34;item1\u0026#34;); treeMap.put(item2, \u0026#34;item2\u0026#34;); treeMap.put(item3, \u0026#34;item3\u0026#34;); treeMap.put(item4, \u0026#34;item4\u0026#34;); System.out.println(\u0026#34;treeMap size: \u0026#34; + treeMap.size()); // 2 \ttreeMap.forEach((entry, value) -\u0026gt; System.out.println(\u0026#34;treeMap value: \u0026#34; + value)); // item3, item4 \t} } Item 클래스에서 equals는 value 변수와 객체 생성 시간인 createdAt(초단위)이 모두 일치하면 true로 재정의했다. compareTo는 생성 시간만 일치하도록 재정의했다.\nItem item1 = new Item(1); Item item2 = new Item(1); Item item3 = new Item(2); Thread.sleep(1000); Item item4 = new Item(1); 그랬을 때 item1, item2는 equals가 true이고 나머지는 다 false로, 즉 다르다는 결과가 나온다(item3은 value가 달라서이고 item4는 createdAt이 달라서).\nList\u0026lt;Item\u0026gt; arrayList = new ArrayList\u0026lt;\u0026gt;(); arrayList.add(item1); arrayList.add(item2); arrayList.add(item3); arrayList.add(item4); System.out.println(\u0026#34;arrayList size: \u0026#34; + arrayList.size()); // 4 arrayList.forEach(i -\u0026gt; System.out.println(\u0026#34;arrayList item value: \u0026#34; + i.value)); // item1, item2, item3, item4 ArrayList에는 모두 추가되서 size가 4다.\nSet\u0026lt;Item\u0026gt; linkedHashSet = new LinkedHashSet\u0026lt;\u0026gt;(); linkedHashSet.add(item1); linkedHashSet.add(item2); linkedHashSet.add(item3); linkedHashSet.add(item4); System.out.println(\u0026#34;linkedHashSet size: \u0026#34; + linkedHashSet.size()); // 3 linkedHashSet.forEach(i -\u0026gt; System.out.println(\u0026#34;linkedHashSet item value: \u0026#34; + i.value + i)); // item1, item3, item4 linkedHashSet은 size가 3인데 add 할 때 equals로 비교하기 때문이다.\nSet\u0026lt;Item\u0026gt; treeSet = new TreeSet\u0026lt;\u0026gt;(); treeSet.add(item1); treeSet.add(item2); treeSet.add(item3); treeSet.add(item4); System.out.println(\u0026#34;treeSet size: \u0026#34; + treeSet.size()); // 2 treeSet.forEach(i -\u0026gt; System.out.println(\u0026#34;treeSet item value: \u0026#34; + i)); // item1, item4 treeSet은 size가 2인데 add 할 때 compare로 비교하기 때문이다.\nMap\u0026lt;Item, String\u0026gt; linkedHashMap = new LinkedHashMap(); linkedHashMap.put(item1, \u0026#34;item1\u0026#34;); linkedHashMap.put(item3, \u0026#34;item3\u0026#34;); linkedHashMap.put(item4, \u0026#34;item4\u0026#34;); linkedHashMap.put(item2, \u0026#34;item2\u0026#34;); System.out.println(\u0026#34;linkedHashMap size: \u0026#34; + linkedHashMap.size()); // 3 linkedHashMap.forEach((entry, value) -\u0026gt; System.out.println(\u0026#34;linkedHashMap value: \u0026#34; + value)); // item2, item3, item4 linkedHashMap은 linkedHashSet과 같이 size가 3이지만, item1을 item2가 덮어쓴다는 차이점이 있다.\nMap\u0026lt;Item, String\u0026gt; treeMap = new TreeMap\u0026lt;\u0026gt;(); treeMap.put(item1, \u0026#34;item1\u0026#34;); treeMap.put(item2, \u0026#34;item2\u0026#34;); treeMap.put(item3, \u0026#34;item3\u0026#34;); treeMap.put(item4, \u0026#34;item4\u0026#34;); System.out.println(\u0026#34;treeMap size: \u0026#34; + treeMap.size()); // 2 treeMap.forEach((entry, value) -\u0026gt; System.out.println(\u0026#34;treeMap value: \u0026#34; + value)); // item3, item4 treeMap은 treeSet과 마찬가지로 compare로 비교해 size가 2이지만, 같은것은 덮어써져 최종적으로는 item3, item4가 담겨있다.\n"
},
{
	"uri": "/toby_spring/%E1%84%8B%E1%85%A9%E1%84%87%E1%85%B3%E1%84%8C%E1%85%A6%E1%86%A8%E1%84%90%E1%85%B3%E1%84%8B%E1%85%AA_%E1%84%8B%E1%85%B4%E1%84%8C%E1%85%A9%E1%86%AB%E1%84%80%E1%85%AA%E1%86%AB%E1%84%80%E1%85%A8/",
	"title": "오브젝트와 의존관계",
	"tags": [],
	"description": "",
	"content": " 상속을 통한 UserDao 확장 DB 커넥션 연결이라는 관심을 상속을 통해서 서브 클래스로 분리했다.\npublic abstract class UserDao{ public void add(User user) throws ClassNotFoundException, SQLException{ Connection c = getConnection(); ... } public void get(String id) throws ClassNotFoundException, SQLException{ Connection c = getConnection(); ... } //구현코드는 제거되고 추상 메서드로 바뀌었다. 메서드의 구현은 서브클래스가 담당한다.  public abstract Connection getConnection() throws ClassNotFoundException, SQLException; } public Class NUserDao extends UserDao{ public Connection getConnection() throws ClassNotFoundException, SQLException{ //N사 DB Connection 생성코드  } } public Class DUserDao extends UserDao{ public Connection getConnection() throws ClassNotFoundException, SQLException{ //D사 DB Connection 생성코드  } } 새로운 DB 연경방법을 적용해야 할 때는 UserDao를 상속을 통해 확장해주기만 하면 된다.\n하지만 이 방법은 상속을 사용했다는 단점이 있다. 상속관계는 두 가지 다른 관심사(UserDao 고유기능과 DB연결기능)에 대해 긴밀한 결합을 허용한다. 그리고 서브클래스는 슈퍼클래스의 기능을 직접 사용할 수 있다. 확장된 기능인 DB 커넥션을 생성하는 코드를 다른 DAO 클래스에 적용할 수 없다는 것도 큰 단점이다. 만약 UserDao 외의 DAO 클래스들이 계속 만들어진다면 그때는 상속을 통해서 만들어진 getConnection()의 구현 코드가 매 DAO 클래스마다 중복돼서 나타나는 심각한 문제가 발생할 것이다.\ncf) 템플릿 메서드 패턴 : 상속을 통해 슈퍼클래스의 기능을 확장할 때 사용하는 가장 대표적인 방법이다.\n팩토리 메서드 패턴 : 서브클래스에서 오브젝트 생성 방법과 클래스를 결정할 수 있도록 미리 정의해둔 메서드(오브젝트 생성 방법을 나머지 로직, 즉 슈퍼클래스의 기본 코드에서 독립시킴).\n인터페이스를 통한 관계설정 책임의 분리 public interface ConnectionMaker{ public Connection makeConnection() throws ClassNotFoundException, SQLException; } public UserDao(ConnectionMaker connectionMaker){ this.connectionMaker = connectionMaker; }  UserDao 생성자는 ConnectionMaker 인터페이스 타입으로 전달받기 때문에 ConnectionMaker 인터페이스를 구현했다면 어떤 클래스로 만든 오브젝트라도 상관없고, 관심도 없다.\npublic class UserDaoTest{ public static void main(String[] args) throws ClassNotFoundException, SQLException{ //UserDao가 사용할 ConnectionMaker구현 클래스를 결정하고 오브젝트를 만든다.  ConnectionMaker connectionMaker = new DCoomectionMaker(); UserDao dao = new UserDao(connectionMaker); } } UserDao와 특정 ConnectionMaker 구현 클래스의 오브젝트 간 관계를 맺는 책임 담당을 UserDao의 클라이언트에게 넘겼다.\npublic class UserDao{ private ConnectionMaker connectionMaker; public UserDao(){ connectionMaker = new DConnectionMaker(); //문제!!  } public void add(User user) throws ClassNotFoundException, SQLException{ Connection c = connectionMaker.makeConnection(); } public void get(String id) throws ClassNotFoundException, SQLException{ Connection c = connectionMaker.makeConnection(); } } 그럼으로써 위의 코드처럼 이전의 UserDao에서 직접 구현 클래스의 오브젝트를 결정하는 문제를 없앨 수 있게 됐다.\n개선한 UserDaoTest - UserDao - ConnectionMaker 구조를 디자인 패턴의 시각으로 본면 전략 패턴에 해당한다고 볼 수 있다.\n전략 패턴은 자신의 기능 맥락(context)에서, 필요에 따라 변경이 필요한 알고리즘을 인터페이스를 통해 통째로 외부로 분리시키고, 이를 구현한 구체적인 알고리즘 클래스를 필요에 따라 바꿔서 사용할 수 있게 하는 디자인 패턴이다.\n컨텍스트(UserDao)를 사용하는 클라이언트(UserDaoTest)는 컨텍스트가 사용할 전략(ConnectionMaker를 구현한 클래스, 예를 들어 DConnectionMaker)을 컨텍스트의 생성자 등을 통해 제공해주는 게 일반적이다.\n팩토리 : 객체 생성 방법을 결정하고 그렇게 만들어진 오브젝트를 돌려주는 일을 하는 오브젝트.\n어떻게 만들지와 어떻게 사용할지는 분명 다른 관심이다. UserDao의 생성 책임을 맡은 팩토리 클래스\npublic class DaoFactory{ public UserDao userDao(){ //팩토리의 메서드는 UserDao 타입의 오브젝트를 어떻게 만들고, 어떻게 준비시킬지 결정한다.  ConnectionMaker connectionMaker = new DConnectionMaker(); UserDao userDao = new UserDao(connectionMaker); return userDao; } } 이제 UserDaoTest는 UserDao가 어떻게 만들어지는지 어떻게 초기화되어 있는지에 신경 쓰지 않고 팩토리로부터 UserDao 오브젝트를 받아다가, 자신의 관심사인 테스트를 위해 활용하기만 하면 그만이다.\npublic class UserDaoTest{ public static void main(String[] args) throws ClassNotFoundException, SQLException{ UserDao userDao = new DaoFactory().userDao(); } } DaoFactory를 스프링에서 사용이 가능하도록 변신시켜보자.\n@Configuration //애플리케이션컨텍스트 또는 빈 팩토리가 사용할 설정정보라는 표시 public class DaoFactory{ @Bean //오브젝트 생성을 담당하는 IoC용 메서드라는 표시  public UserDao userDao(){ return new UserDao(connectionMaker()); } @Bean public ConnectionMaker connectionMaker(){ return new DConnectionMaker(); } } 자바 코드의 탈을 쓰고 있지만, 사실은 XML과 같은 스프링 전용 설정정보라고 보는 것이 좋다.\n이제 DaoFactory를 설정정보로 사용하는 애플리케이션 컨텍스트를 만들어보자.\npublic class UserDaoTest{ public static void main(String[] args) throws ClassNotFoundException, SQLException{ ApplicationContext context = new AnnotationConfigApplicationContext(DaoFactory.class); UserDao dao = context.getBean(\u0026#34;userDao\u0026#34;, UserDao.class); } } @Configuration이 붙은 자바 코드를 설정정보로 사용하려면 AnnotationConfigApplicationContext를 이용하면 된다.\n애플리케이션 컨텍스트 동작방식 DaoFactory가 UserDao를 비롯한 DAO 오브젝트를 생성하고 DB 생성 오브젝트와 관계를 맺어주는 제한적인 역할을 하는 데 반해, 애플리케이션 컨텍스트는 애플리케이션에서 IoC를 적용해서 관리할 모든 오브젝트에 대한 생성과 관계설정을 담당한다. 대신 ApplicationContext에는 DaoFactory와 달리 직접 오브젝트를 생성하고 관계를 맺어주는 코드가 없고, 그런 생성정보와 연관관계 정보를 별도의 설정정보를 통해 얻는다.\n의존관계 검색(DL) dependency lookup, 런타임 시에 의존관계를 결정한다는 점에서 DI와 비슷하지만, 의존관계를 맺는 방법이 외부로부터의 주입이 아니라 스스로 검색을 이용한다.\n의존관계 검색은 자신이 필요로하는 의존 오브젝트를 능동적으로 찾는다. 물론 자신이 어떤 클래스의 오브젝트를 이용할지 결정하지는 않는다.\npublic UserDao(){ AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(DaoFactory.class); this.connetionMaker = context.getBean(\u0026#34;connectionMaker\u0026#34;, ConnectionMaker.class); } 스프링의 IoC 컨테이너인 애플리케이션 컨텍스트는 getBean()이라는 메서드를 제공한다. 바로 이 메서드가 의존관계 검색에 사용되는 것이다. 미리 정해놓은 이름을 전달해서 그 이름에 해당하는 오브젝트를 찾는다. 따라서 이를 일종의 검색이라 볼 수 있다.\n그러나 의존관계 검색 방법은 코드 안에 오브젝트 팩토리 클래스나 스프링 API가 나타난다. 그래서 DI 방식이 훨씬 단순하고 깔끔하다. 대개는 DI를 사용하는 편이 낫다.\n그런데 의존관계 검색 방식을 사용해야 할 때가 있다. 애플리케이션의 기동 시점에서 적어도 한 번은 의존관계 검색 방식을 사용해 오브젝트를 가져와야 한다. main()에서는 DI를 이용해 오브젝트를 주입받을 방법이 없기 때문이다. 서버에서도 마찬가지다. main() 메서드와 비슷한 역할을 하는 서블릿에서 스프링 컨테이너에 담긴 오브젝트를 사용하려면 한 번은 의존관계 검색 방식을 사용해 오브젝트를 가져와야 한다. 하지만 이런 서블릿은 스프링이 미리 만들어서 제공하므로 직접 구현할 필요는 없다.\nDL 방식에서는 검색하는 오브젝트 자신이 스프링의 빈 일 필요가 없다. 반면에 DI는 자기 자신이 컨테이너가 관리하는 빈이 돼야한다.\nDI 응용 - 부가기능 추가 DAO가 DB를 얼마나 많이 연결해서 사용하는지 파악하고 싶다고 해보자. DAO 코드의 makeConnection() 메서드를 수정해서 카운터를 증가시키는건 무식한 방법이다.\n//연결횟수 카운팅 기능이 있는 클래스 public class CountingConnectionMaker implements ConnectionMaker{ int counter = 0; private ConnectionMaker realConnectionMaker; public CountingConnectionMaker(ConnectionMaker realConnectionMaker){ this.realConnectionMaker = realConnectionMaker; } public Connection makeConnection() throws ClassNotFoundException, SQLException{ this.counter++; return realConnectionMaker.makeConnection(); //다시 실제 사용할 DB 커넥션을 제공  } public int getCounter(){ return this.counter; } }//CountingConnectionMaker 의존관계가 추가된 DI 설정용 클래스 @Configuration public class CountingDaoFactory{ @Bean public UserDao(){ return new UserDao(connectionMaker()); //변경 없음  } @Bean public ConnectionMaker connectionMaker(){ return new CountingConnectionMaker(realConnectionMaker()); } @Bean public ConnectionMaker realConnectionMaker(){ return new DConnectionMaker(); } }public class UserDaoConnectionCountingTest { public static void main(String[] args) throws ClassNotFoundException, SQLException { AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(CountingDaoFactory.class); UserDao dao = context.getBean(\u0026#34;userDao\u0026#34;, UserDao.class); //DAO 사용 코드  CountingConnectionMaker ccm = context.getBean(\u0026#34;connectionMaker\u0026#34;, CountingConnectionMaker.class); System.out.println(ccm.getCounter()); } }"
},
{
	"uri": "/%E1%84%8C%E1%85%A1%E1%84%87%E1%85%A1_%E1%84%89%E1%85%A5%E1%86%BC%E1%84%82%E1%85%B3%E1%86%BC_%E1%84%90%E1%85%B2%E1%84%82%E1%85%B5%E1%86%BC_%E1%84%8B%E1%85%B5%E1%84%8B%E1%85%A3%E1%84%80%E1%85%B5/%E1%84%8B%E1%85%AB_%E1%84%8C%E1%85%A1%E1%84%81%E1%85%AE_string%E1%84%8B%E1%85%B3%E1%86%AF_%E1%84%8A%E1%85%B3%E1%84%8C%E1%85%B5_%E1%84%86%E1%85%A1%E1%86%AF%E1%84%85%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%E1%84%80%E1%85%A5%E1%84%8B%E1%85%A3/",
	"title": "왜 자꾸 String을 쓰지 말라는거야",
	"tags": [],
	"description": "",
	"content": " StringBuffer 클래스와 StringBuilder 클래스 StringBuilder 클래스는 JDK 5.0에서 새로 추가되었다. StringBuffer 클래스가 제공하는 메서드와 동일하다. StringBuffer 클래스는 스레드에 안전하게(ThreadSafe) 설계되어 있으므로, 여러 개의 스레드에서 하나의 StringBuffer 객체를 처리해도 전혀 문제가 되지 않는다. 하지만 StringBuilder는 단일 스레드에서의 안전성만 보장한다. 그렇기 때문에 여러 개의 스레드에서 하나의 StringBuilder 객체를 처리하면 문제가 발생한다.\nStringBuffer를 기준으로 생성자와 메서드를 확인하고 정리해 보자.\n// 생성자  public StringBuffer() { super(16); //기본 용량은 16개의 char다  } public StringBuffer(int capacity) { super(capacity); } public StringBuffer(String str) { super(str.length() + 16); append(str); // str 값을 갖는 StringBuffer를 생성한다  } // CharSequence를 매개변수로 받아 그 seq 값을 갖는 StringBuffer를 생성한다  public StringBuffer(CharSequence seq) { this(seq.length() + 16); append(seq); }  cf) CharSequence는 인터페이스다. 구현체로는 CharBuffer, String, StringBuffer, StringBuilder가 있으며 StringBuffer나 StringBuilder로 생성한 객체를 전달할 때 사용된다.\n@Test public void stringTest() throws Exception { StringBuilder sb = new StringBuilder(); sb.append(\u0026#34;ABCDE\u0026#34;); check(sb); } private void check(CharSequence cs) { StringBuffer sb = new StringBuffer(cs); System.out.println(sb.length()); // 5  } StringBuffer나 StringBuilder로 값을 만든 후 굳이 toString을 수행하여 필요 없는 객체를 만들어서 넘겨주기보다는 CharSequence로 받아서 처리하는 것이 메모리 효율에 더 좋다.\n주로 사용하는 메서드는 append()와 insert()다.\n@Test public void stringTest() throws Exception { StringBuffer sb = new StringBuffer(); sb.append(\u0026#34;ABC\u0026#34;); sb.insert(1,\u0026#34;123\u0026#34;); System.out.println(sb); // A123BC  } 많은 양의 문자열을 연산 할때 String을 쓰지 말아야 하는 이유는 String은 immutable 객체(생성 후 변경 불가한 객체)이기 때문이다. 그래서 연산할 때마다 새로운 String 클래스 객체가 만들어지고 이전 객체는 필요 없는 쓰레기 값이 되어 GC 대상이 된다. 이런 작업이 반복 수행되면서 메모리를 많이 사용하게 되고, 응답속도에도 많은 영향을 미치게 된다. 반면에 StringBuffer나 StringBuilder는 새로운 객체를 생성하지 않고, 기존에 있는 객체의 크기를 증가시키면서 값을 더한다.\ncf) JDK 5.0 이상을 사용하면 아래와 같이 StringBuilder로 변환된다. 개발자의 실수를 어느 정도는 피할 수 있게 된 것이다.\npublic class VersionTest { String str = \u0026#34;Here\u0026#34; + \u0026#34;is \u0026#34; + \u0026#34;a \u0026#34; + \u0026#34;sample.\u0026#34;; public VersionTest() { int i = 1; String str2 = \u0026#34;Here \u0026#34; + \u0026#34;is \u0026#34; + i + \u0026#34; sample.\u0026#34;; } } // 역 컴파일한 소스 public class VersionTest { public VersionTest() { str = \u0026#34;Here is a sample.\u0026#34;; int i = 1; String str2 = (new StringBuilder(\u0026#34;Here is \u0026#34;)) .append(i).append(\u0026#34; sample.\u0026#34;).toString(); } String str; }"
},
{
	"uri": "/tshark/",
	"title": "티샤크를 활용한 네트워크 트래픽 분석",
	"tags": [],
	"description": "",
	"content": "참고 : 티샤크를 활용한 네트워크 트래픽 분석(와이어샤크의 커맨드라인 버전 TShark)\n와이어샤크 패키지 설치\n# yum install wireshark  root권한으로 실행시키지 않고 setcap으로 필요한 기능만을 부여\n# cd /usr/sbin # sudo ./groupadd tshark # sudo ./usermod -a -G tshark yangbongsoo # sudo chgrp tshark /usr/sbin/dumpcap # sudo chmod 750 /usr/sbin/dumpcap # sudo ./setcap cap_net_raw,cap_net_admin=eip /usr/sbin/dumpcap # sudo ./getcap /usr/sbin/dumpcap /usr/sbin/dumpcap = cap_net_admin,cap_net_raw+eip  yangbongsoo 계정으로 다시 들어와서 트래픽을 캡쳐할 권한이 있는지 확인\n$ ./tshark -i eth0 -c 1 -q Capturing on eth0 1 packet captured  와이어샤크와 마찬가지로 티샤크는 덤프캡을 이용해서 데이터를 수집한다. 덤프캡에는 기본적인 패킷 캡처 기능만 구현돼있으므로, 매우 복잡해서 취약점이 존재할 확률이 높은 와이어샤크나 티샤크 대신 덤프캡에 루트 권한을 주는게 훨씬 더 안전하다.\n$ ./tshark -V tcp port 80 -R \u0026quot;http.request || http.response\u0026quot; \u0026amp; $ pstree -pa 'yangbongsoo' nginx,155263 ├─nginx,155264 ├─nginx,155265 ├─nginx,155266 └─nginx,155267 bash,109967 ├─pstree,110571 -pa yangbongsoo └─tshark,110535 -V tcp port 80 -R http.request\\040||\\040http.response └─dumpcap,110538 -n -i eth0 -f tcp\\040port\\04080 -Z none  위의 pstree 결과로 티샤크가 데이터를 캡처하기 위해 덤프캡을 자식 프로세스로 생성하는 것을 볼 수 있다.\n$ ./tshark -D 1. eth0 2. nflog (Linux netfilter log (NFLOG) interface) 3. nfqueue (Linux netfilter queue (NFQUEUE) interface) 4. any (Pseudo-device that captures on all interfaces) 5. lo  옵션 -D를 이용하면 시스템에서 이용 가능한 네트워크 인터페이스를 나열할 수 있고 -i를 이용하면 트래픽을 캡처할 리스닝 인터페이스를 지정할 수 있다. 티샤크는 수신된 패킷마다 기본 요약 정보를 출력한다.\n$ ./tshark -i eth0 -c 2 Capturing on eth0 0.000000000 10.xxx.xxx.xxx -\u0026gt; 10.xxx.xxx.xxx TCP 1012 45850 \u0026gt; biimenu [PSH, ACK] Seq=1 Ack=1 Win=501 Len=946 TSval=1734909355 TSecr=856327483 0.002694435 10.xxx.xxx.xxx -\u0026gt; 10.xxx.xxx.xxx TCP 66 biimenu \u0026gt; 45850 [ACK] Seq=1 Ack=947 Win=501 Len=0 TSval=856417489 TSecr=1734909355 2 packets captured  네크워크 카드에 패킷이 도달하고, 수신 데이터는 커널에 정의된 메모리 블록으로 복사된다. 패킷 필터는 사용자가 지정한 패킷만 필터링해서 버퍼에 저장한다. 저장된 패킷은 사용자 공간에서 실행 중인 덤프캡으로 전송되며 덤프캡은 이 패킷을 libpcap 파일 형식으로 기록한다. 끝으로 티샤크는 덤프캡이 작성한 캡처 파일을 읽고 처리한다.\n커널은 수신된 패킷을 반드시 커널 공간에서 사용자 공간으로 복사해야 한다는 사실을 알아두자. 이와 같은 컨텍스트 스위칭은 CPU 시간을 소모하므로 네트워크 카드를 통과하는 모든 데이터 흐름을 캡처하면 시스템 전체의 성능이 저하될 수 있다. 바로 이때문에 캡처 필터가 필요하다. 캡처 필터를 사용하면 커널 공간에서 불필요한 패킷은 제외시키고 사용자가 관심 있는 패킷만 허용함으로써 성능 저하를 최소화할 수 있다.\n필터는 -f 옵션을 사용해서 지정할 수 있다.\n$ ./tshark -f \u0026quot;tcp port 80\u0026quot; -i eth0  캡처 필터를 티샤크의 핵심인 디스플레이(또는 리드) 필터와 혼동하면 안된다. 디스플레이 필터는 이미 캡처된 패킷을 필터링하는 데 사용된다. 이 필터를 사용하면 프로토콜의 각 필드를 디코딩 및 해석하는 디섹터의 활용도를 극대화할 수 있다.\n디스플레이 필터는 -R 옵션으로 지정할 수 있다.\n$ ./tshark -f \u0026quot;tcp port 80\u0026quot; -i eth0 -R \u0026quot;http.request || http.response\u0026quot; -V  -V 옵션은 add output of packet tree(Packet Details)\n$ ./tshark -f \u0026quot;tcp port 80\u0026quot; -i eth0 -R \u0026quot;http.request || http.response\u0026quot; -V | grep \u0026quot;Hypertext Transfer Protocol\u0026quot; -A 21  grep 해서 필요한부분만 추출할수도 있다.\n-- Hypertext Transfer Protocol GET /api/static/real.js HTTP/1.1\\r\\n [Expert Info (Chat/Sequence): GET /api/static/real.js HTTP/1.1\\r\\n] [Message: GET /api/static/real.js HTTP/1.1\\r\\n] [Severity level: Chat] [Group: Sequence] Request Method: GET Request URI: /api/static/real.js Request Version: HTTP/1.1 CHECK: check\\r\\n Host: 10.xxx.xxx.xxx\\r\\n Connection: close\\r\\n Pragma: no-cache\\r\\n Cache-Control: no-cache\\r\\n Upgrade-Insecure-Requests: 1\\r\\n User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36\\r\\n Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\\r\\n Accept-Encoding: gzip, deflate\\r\\n Accept-Language: ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7\\r\\n \\r\\n [Full request URI: http://10.xxx.xxx.xxx/api/static/real.js] -- Hypertext Transfer Protocol HTTP/1.1 200 OK\\r\\n [Expert Info (Chat/Sequence): HTTP/1.1 200 OK\\r\\n] [Message: HTTP/1.1 200 OK\\r\\n] [Severity level: Chat] [Group: Sequence] Request Version: HTTP/1.1 Status Code: 200 Response Phrase: OK Server: nginx\\r\\n Date: Thu, 11 Jan 2018 06:23:28 GMT\\r\\n Content-Type: application/javascript; charset=UTF-8\\r\\n Transfer-Encoding: chunked\\r\\n Connection: close\\r\\n X-Powered-By: Express\\r\\n Access-Control-Allow-Origin: http://node.test.com\\r\\n Vary: Origin\\r\\n Access-Control-Allow-Credentials: true\\r\\n Cache-Control: public, max-age=0\\r\\n Last-Modified: Thu, 21 Dec 2017 07:03:54 GMT\\r\\n ETag: W/\u0026quot;14856f-16077e2b57a\u0026quot;\\r\\n Content-Encoding: gzip\\r\\n --  tshark의 리드필터(-R 옵션)로 지정할 수 있는 HTTP 프로토콜의 필드 목록을 확인하는 방법은 아래와 같다.\n$ ./tshark -G | cut -f3 | grep \u0026quot;^http\\.\u0026quot; http.notification http.response http.request http.authbasic http.request.method http.request.uri http.request.version http.request.full_uri http.response.code http.response.phrase http.authorization http.proxy_authenticate http.proxy_authorization http.proxy_connect_host http.proxy_connect_port http.www_authenticate http.content_type http.content_length_header http.content_length http.content_encoding http.transfer_encoding http.upgrade http.user_agent http.host http.connection http.cookie http.accept http.referer http.accept_language http.accept_encoding http.date http.cache_control http.server http.location http.sec_websocket_accept http.sec_websocket_extensions http.sec_websocket_key http.sec_websocket_protocol http.sec_websocket_version http.set_cookie http.last_modified http.x_forwarded_for  cf) http2 필드는 1.12.0버전부터 가능하다.\n전체 IP 통신의 목록 구하기\n$ ./tshark -r ~/tshark-log/temp.pcap -q -z \u0026quot;conv,ip,ip.addr==10.xxx.xxx.xxx\u0026quot; -w ~/tshark-log/write.pcap ================================================================================ IPv4 Conversations Filter:ip.addr==10.xxx.xxx.xxx | \u0026lt;- | | -\u0026gt; | | Total | Rel. Start | Duration | | Frames Bytes | | Frames Bytes | | Frames Bytes | | | 10.xxx.xxx.xxx \u0026lt;-\u0026gt; 10.10.10.10 207 14144 80 371276 287 385420 4.065868087 0.0994 10.xxx.xxx.xxx \u0026lt;-\u0026gt; 10.10.10.10 44 382591 39 3071 83 385662 4.069769413 0.0772 10.10.10.10 \u0026lt;-\u0026gt; 10.xxx.xxx.xxx 8 11380 10 668 18 12048 11.738211339 0.0106 10.xxx.xxx.xxx \u0026lt;-\u0026gt; 10.10.10.10 7 595 6 11248 13 11843 11.731682788 0.0066 10.10.10.10 \u0026lt;-\u0026gt; 10.xxx.xxx.xxx 1 1012 1 66 2 1078 4.220985502 0.0028 10.xxx.xxx.xxx \u0026lt;-\u0026gt; 10.10.10.10 1 90 1 90 2 180 4.051242000 0.0008 10.xxx.xxx.xxx \u0026lt;-\u0026gt; 10.10.10.10 1 106 0 0 1 106 15.104299993 0.0000 ================================================================================  위에서 사용된 옵션들\n-q : be more quiet on stdout (e.g. when using statistics) -z \u0026lt;statistics\u0026gt; various statistics, see the man page for details -r \u0026lt;infile\u0026gt; set the filename to read from (no stdin!) -w \u0026lt;outfile|-\u0026gt; write packets to a pcap-format file named \u0026quot;outfile\u0026quot; (or to the standard output for \u0026quot;-\u0026quot;)  저장된 write.pcap 파일 읽기\n$ ./capinfos ~/tshark-log/write.pcap File name: /home/yangbongsoo/tshark-log/temp.pcap File type: Wireshark - pcapng File encapsulation: Ethernet Packet size limit: file hdr: (not set) Number of packets: 467 File size: 817148 bytes Data size: 801043 bytes Capture duration: 15 seconds Start time: Thu Jan 11 16:10:34 2018 End time: Thu Jan 11 16:10:49 2018 Data byte rate: 53034.10 bytes/sec Data bit rate: 424272.82 bits/sec Average packet size: 1715.30 bytes Average packet rate: 30.92 packets/sec SHA1: df7f85751dd2d56d8a1b64a28b93b30553df6a08 RIPEMD160: k37d0ccd2b20s81s6d9da4b44d3d168sc98s1aca MD5: 1q908e9a36cn382l768s95w4k6c8w6kb Strict time order: True  허용된 포트(HTTP, HTTPS)를 제외한 포트로의 외부 연결 파악하기\n$ ./tshark -o column.format:'\u0026quot; Source\u0026quot;,\u0026quot;%s\u0026quot;,\u0026quot;Destination\u0026quot;,\u0026quot;%d\u0026quot;, \u0026quot;dstport\u0026quot;, \u0026quot;%uD\u0026quot;, \u0026quot;Protocol\u0026quot;, \u0026quot;%p\u0026quot;' -r ~/tshark-log/temp.pcap -R \u0026quot;ip.src == 10.xxx.xxx.xxx \u0026amp;\u0026amp; ! dns \u0026amp;\u0026amp; tcp.dstport != 80 \u0026amp;\u0026amp; tcp.dstport != 443\u0026quot; | sort -u 10.xxx.xxx.xxx -\u0026gt; 10.10.10.10 9973 TCP 10.xxx.xxx.xxx -\u0026gt; 10.10.10.10 18000 TCP 10.xxx.xxx.xxx -\u0026gt; 10.10.10.10 59048 HTTP 10.xxx.xxx.xxx -\u0026gt; 10.10.10.10 59048 TCP  -o 옵션을 통해서 티샤크의 옵션을 변경할 수 있다. -o \u0026quot; \u0026lt;name\u0026gt;:\u0026lt;value\u0026gt; ... override preference setting\n"
},
{
	"uri": "/%E1%84%83%E1%85%A2%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%85%E1%85%A3%E1%86%BC_%E1%84%8B%E1%85%A1%E1%84%8F%E1%85%B5%E1%84%90%E1%85%A6%E1%86%A8%E1%84%8E%E1%85%A5%E1%84%8B%E1%85%AA_%E1%84%89%E1%85%A5%E1%86%BC%E1%84%82%E1%85%B3%E1%86%BC_%E1%84%90%E1%85%B2%E1%84%82%E1%85%B5%E1%86%BC/rest/",
	"title": "REST의 이해와 설계",
	"tags": [],
	"description": "",
	"content": " 1. REST기본 REST는 근래에 들어 HTTP와 JSON을 함께 사용하여 OPEN API를 구현하는 방법으로 주류를 이루고 있으며, 대부분의 OPEN API는 이 REST 아키텍처를 기반으로 설계 및 구현되고 있다.\nREST원리를 따르는 시스템은 Restful이란 용어로 지칭된다.\nREST는 크게 리소스, 메소드, 메세지 3가지 요소로 구성된다. ex) 이름이 Terry인 사용자를 생성한다\nHTTP POST , http://myweb/users/ { \u0026quot;users\u0026quot; : { \u0026quot;name\u0026quot; : \u0026quot;terry\u0026quot; } }  리소스 = http://myweb/users 형태의 URI HTTP POST메소드 = 생성한다\n메세지 = JSON 문서를 이용한 내용\n1.1 HTTP 메소드 HTTP에는 여러 가지 메소드가 있지만, REST에서는 CRUD(Create, Read, Update, Delete)에 해당하는 4가지의 메소드만 사용한다.\n| 메소드 | 의미 | Idempotent | | \u0026ndash; | \u0026ndash; | \u0026ndash; | | POST | Create | No | | GET | Select | Yes | | PUT | Update | Yes | | DELETE | Delete | Yes |\nIdempotent(멱등성)은 여러 번 수행해도 결과가 같은 경우를 의미한다. ex) a++은 Idempotent 하지 않다고 하지만(호출할 때마다 값이 증가하기 때문), a=4와 같은 명령은 반복적으로 수행해도 Idempotent 하다(값이 같기 때문).\nPOST 연산은 리소스를 추가하는 연산이기 때문에 Idempotent 하지 않지만, 나머지 GET, PUT, DELETE는 반복 수행해도 Idempotent하다. GET의 경우 게시물의 조회 수 카운트를 늘려준다던가 하는 기능을 같이 수행했을 때는 Idempotent 하지 않은 메소드로 정의해야 한다.\nREST는 개별 API를 상태 없이 수행하게 된다. 그래서 해당 REST API를 다른 API와 함께 호출하다가 실패하였을 경우, 트랜잭션 복구를 위해서 다시 실행해야 하는 경우가 있는데, Idempotent 하지 않은 메소드의 경우는 기존 상태를 저장했다가 다시 원상복귀해줘야 하는 문제가 있지만, Idempotent 한 메소드의 경우에는 반복적으로 다시 메소드를 수행해주면 된다. ex) 게시물 조회를 하는 API가 있을 때 조회할 때마다 조회 수를 올리는 연산을 수행한다면 이 메소드는 Idempotent 하다고 볼 수 없고 조회하다가 실패하였을 때는 올라간 조회 수를 다시 -1 해줘야 한다. 즉, Idempotent 하지 않은 메소드에 대해서는 트랜잭션에 대한 처리에 주의가 필요하다.\n1.2 REST의 리소스 REST는 리소스 지향 아키텍처 스타일이라는 정의답게 모든 것을 리소스, 즉 명사로 표현하며, 각 세부 리소스에는 ID를 붙인다.\nex) 사용자라는 리소스 타입 : http://myweb/users terry라는 ID를 갖는 리소스 : http://myweb/users/terry\nREST의 리소스가 명사의 형태를 띄우다 보니 명령(Operation) 성격의 API를 정의하는 것에서 혼동이 올 수 있다. ex) \u0026ldquo;푸시 메세지를 보낸다\u0026rdquo;를 /myweb/sendpush 형태로 잘못 정의가 될 수 있지만 \u0026ldquo;푸시 메세지 요청을 생성한다\u0026rdquo;라는 형태로 정의를 변경하면, API포맷은 POST/myweb/push 형태와 같은 명사형으로 정의할 수 있다. 모든 형태의 명령이 이런식으로 정의가 가능한 것은 아니지만, 될 수 있으면 리소스 기반의 명사 형태로 정의하는 게 REST 형태의 디자인이 된다.\n사용자 생성 HTTP POST , http://myweb/users/ { \u0026quot;name\u0026quot; : \u0026quot;terry\u0026quot;, \u0026quot;address\u0026quot; : \u0026quot;seoul\u0026quot; }  http://myweb/users라는 리소스를 이름은 terry, 주소는 seoul이라는 내용(메세지)으로 HTTP POST를 이용해서 생성하는 정의\n조회\nHTTP Get, http://myweb/users/terry  생성된 리소스 중에서 http://myweb/users라는 사용자 리소스 중에 ID가 terry인 사용자 정보를 조회해오는 방식(조회이기 때문에 HTTP GET을 사용한다)\n업데이트\nHTTP PUT, http://myweb/users/terry { \u0026quot;name\u0026quot;:\u0026quot;terry\u0026quot;, \u0026quot;address\u0026quot;:\u0026quot;suwon\u0026quot; }  http://myweb/users라는 사용자 리소스 중에 ID가 terry인 사용자 정보에 대해서 주소를 suwon으로 수정하는 방식(수정은 HTTP메소드 중에 PUT을 사용한다)\n삭제\nHTTP DELETE, http://myweb/users/terry  http://myweb/users라는 사용자 리소스 중에 ID가 terry인 사용자 정보를 삭제하는 방법\n1.3 REST 특성  유니폼 인터페이스(Uniform Interface)  REST는 HTTP 표준에만 따른다면 어떠한 기술이든지 사용할 수 있는 인터페이스 스타일이다.  무상태성(Stateless)  \u0026lsquo;상태가 있다,없다\u0026rsquo;라는 의미는 사용자나 클라이언트의 컨텍스트를 서버 쪽에서 유지하지 않는다는 의미로, 쉽게 표현하면 HTTP 세션과 같은 컨텍스트 저장소에 상태 정보를 저장하지 않는 형태를 의미한다. 상태 정보를 저장하지 않으면 각 API 서버는 들어오는 요청만을 메세지로 처리하고, 세션과 같은 컨텍스트 정보를 신경 쓸 필요가 없으므로 구현이 단순해진다.  캐시 가능(Cacheable)  REST의 큰 특징 중 하나는 HTTP라는 기존의 웹 표준을 따르기 때문에 웹에서 사용하는 기존 인프라를 그대로 활용할 수 있다는 점이다. HTTP의 리소스들을 웹 캐시 서버 등에 캐싱하는 것은 용량이나 성능 면에서 많은 장점이 있다. HTTP 프로토콜 표준에서 사용하는 Last-Modifyed태그나 E-Tag를 이용하면 캐싱을 구현할 수 있다. 다음과 같이 HTTP GET을 Last-Modified 값과 함께 보냈을 때 콘텐츠에 변화가 없으면 REST 컴포넌트는 \u0026lsquo;304 Not Modified\u0026rsquo;를 반환하면 클라이언트는 자체 캐시에 저장된 값을 사용하게 된다.  자체 표현 구조(Self-descriptiveness)  REST의 또 다른 특징 중 하나는 REST API 자체가 쉬워서 API 메세지만 보고도 이를 이해 할 수 있는 자체 표현 구조로 되어 있다는 것이다.  클라이언트 서버 구조  REST 서버는 API를 제공하고 제공된 API를 이용해서 비즈니스 로직 처리 및 저장을 책임진다. 클라이언트는 사용자 인증이나 컨텍스트(세션, 로그인 정보)를 직접 관리하고 책임지는 구조로 역할이 나누어지고 있다. 이렇게 각각의 역할이 확실하게 구분되면서 개발 관점에서 클라이언트와 서버에서 개발해야 할 내용이 명확해지고 서로의 개발에서 의존성이 줄어들게 된다.  계층형 구조  클라이언트로서는 REST API 서버만 호출한다. 그러나 서버는 다중 계층으로 구성될 수 있다. 순수 비즈니스 로직을 수행하는 API 서버와 그 앞단에 사용자 인증, 암호화, 로드 밸런싱을 하는 계층을 추가해서 구조상의 유연성을 둘 수 있는데 이는 마이크로 서비스 아키텍처의 API Gateway나 HAProxy Apache와 같은 Reverse Proxy를 이용해서 구현하는 경우가 많다.   1.4 REST 안티 패턴  GET이나 POST를 이용한 터널링 ex) http://myweb/users?method=update\u0026amp;id=terry 메소드의 실제 동작은 리소스를 업데이트 하는 내용인데, HTTP PUT을 사용하지 않고 GET에 쿼리 파라미터로 넘겨서 명시했다.\nex) Insert(Create)성 오퍼레이션이 아닌데도 불구하고 JSON body에 오퍼레이션 명을 넘기는 형태\nHTTP POST, http://myweb/users { \u0026quot;getuser\u0026quot; : { \u0026quot;id\u0026quot;:\u0026quot;terry\u0026quot; } }  Self-descriptiveness 속성을 사용하지 않음\n 자체 표현 구조를 갉아먹는 가장 대표적인 사례가 GET, POST를 이용한 터널링 구조  HTTP 응답 코드를 사용하지 않음\n 1~2개의 HTTP 응답 코드만 사용하는 문제   2. REST API 디자인 가이드 2.1 REST URI는 단순하고 직관적으로 만들자 최대 2단계 정도로 간단하게 만드는 것이 이해하기 편하다.\n/dogs/ /dogs/1234  URI에 리소스명은 동사보다는 명사를 사용한다. REST API는 리소스에 대해서 행동을 정의하는 형태를 사용한다.\nPOST /dogs  위는 /dogs라는 리소스를 생성하라는 의미로, URL은 HTTP 메소드에 의해 CRUD(생성, 읽기, 수정, 삭제)의 대상이 되는 개체(명사)라야 한다.\n잘못된 예들은 다음과 같다.\nHTTP POST: /getDogs HTTP POST: /setDogsOwner  위의 예제는 HTTP POST로 정의하지 않고 get/set 등의 행위를 URL에 붙인 경우인데, 좋지 않다. 그리고 될 수 있으면 단수형 명사(/dog) 보다는 복수형 명사(/dogs)를 사용하는 것이 의미상 표현하기가 더 좋다.\nHTTP GET: /dogs HTTP POST: /dogs/{puppy}/owner/{terry}  일반적으로 권고하는 디자인은 다음과 같다.\n| 리소스 | POST | GET | PUT | DELETE | | \u0026ndash; | \u0026ndash; | \u0026ndash; | \u0026ndash; | \u0026ndash; | | 리소 | create | read | update | delete | | /dogs | 새로운 dogs 등록 | dogs 목록을 반환 | Bulk로 여러 dogs 정보를 업데이트 | 모든 dogs 정보를 삭제 | | /dogs/baduk | 에러 | baduk이라는 이름의 dogs 정보를 반환 | baduk이라는 이름의 dogs 정보를 업데이트 | baduk이라는 이름의 dogs 정보를 삭제 |\n2.2 리소스 간의 관계를 표현하는 방법 REST 리소스 간에는 연관 관계가 있을 수 있다.예를 들어 사용자가 소유한 디바이스 목록이나 사용자가 가진 강아지들 등이 예가 될 수 있는데, 사용자-디바이스 또는 사용자-강아지 등 각각의 리소스 간의 관계를 표현하는 방법에는 여러 가지가 있다.\n옵션 1 : 서브 리소스로 표현하는 방법\n예를 들어 사용자의 휴대전화 디바이스 목록을 표현해보면 다음과 같이 /terry라는 사용자가 가진 디바이스 목록을 반환하는 방법이 있다.\n/\u0026quot;리소스명\u0026quot;/\u0026quot;리소스 id\u0026quot;/\u0026quot;관계가 있는 다른 리소스명\u0026quot; 형태 HTTP GET: /users/{userid}/devices 예)/users/terry/devices  옵션 2 : 서브 리소스에 관계를 명시하는 방법 만약에 관계명이 복잡하다면 이를 명시적으로 표현하는 방법이 있다. 예를 들어 사용자가 \u0026lsquo;좋아하는\u0026rsquo; 디바이스 목록을 표현해보면 다음은 terry라는 사용자가 좋아하는 디바이스 목록을 반환하는 방식이다.\nHTTP GET: /users/{userid}/likes/devices 예)/users/terry/likes/devices  옵션 1의 경우 일반적으로 소유 \u0026lsquo;has\u0026rsquo;의 관계를 묵시적으로 표현할 때 좋으며, 옵션 2의 경우에는 관계명이 애매하거나 구체적인 표현이 필요할 때 사용한다.\n2.3 에러 처리 에러 처리의 기본은 HTTP 응답 코드를 사용한 후 HTTP 응답 코드를 사용한 후 응답 보디(Response Body)에 에러에 대한 자세한 내용을 서술하는 것이다.\n다음과 같은 응답 코드만 사용하는 것을 권장한다. 200 - 성공 400 Bad Request - field validation 실패 시 401 Unauthorized - API 인증, 인가 실패\n404 Not found - 해당 리소스가 없음\n500 Internal Server Error - 서버 에러 에러에는 에러 내용에 대한 구체적인 내용을 HTTP 보디에 정의해서 상세한 에러의 원인을 전달하는 것이 디버깅에 유리하다. ex)\nHTTP Status Code: 401 { \u0026quot;status\u0026quot;:\u0026quot;401\u0026quot;, \u0026quot;message\u0026quot;:\u0026quot;Authenticate\u0026quot;,\u0026quot;code\u0026quot;:200003, \u0026quot;more in-fo\u0026quot;:\u0026quot;http://www.twillo.com/docs/errors/20003\u0026quot; }  에러 발생 시에 선택적으로 에러에 대한 스택 정보를 포함 시킬 수 있다. 에러 메세지에서 에러 스택 정보를 출력하는 것은 대단히 위험한 일이다. 내부적인 코드 구조와 프레임워크 구조를 외부에 노출함으로써, 해커들에게 해킹을 할 수 있는 정보를 제공하기 때문이다. 일반적인 서비스 구조에서는 에러 스택 정보를 API 에러 메세지에 포함 시키지 않는 것이 바람직하다.\n2.4 API 버전 관리 필자는 다음과 같은 형태로 정의할 것을 권장한다\n{servicename}/{version}/{REST URL} 예)api.server.com/account/v2.0/groups  이는 서비스의 배포 모델과 관계가 있는데 자바 애플리케이션의 경우 account.v1.0.war, account.v2.0.war와 같이 다른 war로 각각 배포하여 버전별로 배포 바이너리를 관리할 수 있고 앞단에 서비스명을 별도의 URL로 떼어 놓는 것은 이후에 서비스가 확장되었을 때 account 서비스만 별도의 서버로 분리해서 배포하는 경우를 대비하기 위함이다.\n외부로 제공되는 URL은 api.server.com/account/v2.0/groups로 하나의 서버를 가리키지만, 내부적으로 HAProxy 등의 Reverse Proxy를 이용해서 이런 URL을 맵핑할 수 있는데, api.server.com/account/v2.0/groups를 내부적으로 account.server.com/v2.0/groups로 맵핑하도록 하면 외부에 노출되는 URL 변경 없이 향후 확장되었을 때 서버를 물리적으로 분리해내기가 편리하다.\n2.5 페이징 페이스북 API가 직관적이기 때문에 페이스북 스타일을 사용할 것을 권장한다. ex) 100번째 레코드부터 125번째 레코드를 받는 API 정의하기\n페이스북 스타일 : /record?offset=100\u0026amp;limit=25  100번째 레코드에서부터 25개의 레코드를 출력한다는 의미이다.\n2.6 부분 응답 처리 리소스에 대한 응답 메세지에 대해서 굳이 모든 필드를 포함할 필요가 없는 경우가 있다. 예를 들어 페이스북 feed의 경우 사용자 ID, 이름, 글 내용, 날짜, 좋아요 카운트, 댓글, 사용자 사진 등 여러가지 정보를 갖는데, API를 요청하는 클라이언트의 용도에 따라 선별적으로 몇 가지 필드만이 필요할 수 있다.\n페이스북 스타일의 부분 응답을 사용할 것을 권장한다 /terry/friends?fields=id, name  2.7 검색(전역 검색과 지역 검색) 검색은 HTTP GET에서 쿼리 스트링 검색 조건을 정의하는 경우가 일반적이다\n/users?name=cho\u0026amp;region=seoul  그런데 여기에 페이징 처리를 추가하게 되면 다음과 같이 된다.\n/users?name=cho\u0026amp;region=seoul\u0026amp;offset=20\u0026amp;limit=10  페이징 처리에 정의된 offset과 limit가 검색 조건인지 아니면 페이징 조건인지 분간이 가지 않는다. 그래서 쿼리 조건은 하나의 쿼리 스트링으로 정의 하는것이 좋다.\n/user?q=name%3Dcho, region%3Dseoul\u0026amp;offset=20\u0026amp;limit=10  이런 식으로 검색 조건에 URLEncode를 써서 \u0026lsquo;q=name%3Dcho, region%3Dseoul\u0026rsquo;처럼 표현하고, 구분자를 사용하게 되면 검색 조건은 다른 쿼리 스트링과 분리된다.\n다음으로는 검색 범위인데 전역 검색은 전체 리소스에 대한 검색이고 /search와 같은 검색 URI를 사용한다.\n/search?q=id%3Dterry  반대로 특정 리소스 안에서의 검색은 다음과 같이 리소스명에 쿼리 조건을 붙이는 식으로 표현할 수 있다.\n/users?q=id%3Dterry  2.8 HATEOS를 이용한 링크 처리 HATEOS는 Hypermedia as the engine of application state의 약어로, 하이퍼미디어의 특징을 이용하여 HTTP 응답에 다음 액션이나 관계된 리소스에 대한 HTTP 링크를 함께 반환하는 것이다.\n{ [ { \u0026quot;id\u0026quot;:\u0026quot;user1\u0026quot;, \u0026quot;name\u0026quot;:\u0026quot;terry\u0026quot; }, { \u0026quot;id\u0026quot;:\u0026quot;user2\u0026quot;, \u0026quot;name\u0026quot;:\u0026quot;carry\u0026quot; } ], \u0026quot;links\u0026quot; :[ { \u0026quot;rel\u0026quot;:\u0026quot;pre_page\u0026quot;, \u0026quot;href\u0026quot;:\u0026quot;http://xxx/users?offset=6\u0026amp;limit=5\u0026quot; }, { \u0026quot;rel\u0026quot;:\u0026quot;next_page\u0026quot;, \u0026quot;href\u0026quot;:\u0026quot;http://xxx/users?offset=11\u0026amp;limit=5\u0026quot; } ] }  예를들어 앞서 설명한 페이징 처리의 경우 반환 시 전후 페이지에 대한 링크를 제공한다거나 위와 같이 표현하거나 연관된 리소스에 대한 디테일한 링크를 표시하는 것에 이용할 수 있다.\n{ \u0026quot;id\u0026quot;:\u0026quot;terry\u0026quot; \u0026quot;links\u0026quot;:[ { \u0026quot;rel\u0026quot;:\u0026quot;friends\u0026quot;, \u0026quot;href\u0026quot;:\u0026quot;http://xxx/users/terry/friends\u0026quot; } ] }  위는 사용자 정보 조회 시 친구 리스트를 조회할 수 있는 링크를 HATEOS를 이용하여 추가한 것이다.\nHATEOS를 API에 적용하게 되면 자체 표현 구조 특성이 증대되어 API에 대한 가독성이 증가하는 장점이 있지만, 응답 메세지가 다른 리소스 URI에 대한 의존성을 가지기 때문에 구현이 다소 까다롭다는 단점이 있다.\n2.9 단일 API 엔드포인트 활용 API 서비스는 물리적으로 서버가 분리되어 있더라도 단일 URL을 사용하는 것이 좋은데, 방법은 HAProxy나 nginx와 같은 Reverse Proxy를 사용하는 방법이 있다. HAProxy를 앞에 세우고 api.apiserver.com이라는 단일 URL을 구축한 후에 HAProxy 설정에서 api.apiserver.com/user는 user.apiserver.com으로 라우팅하게 하고, api.apiserver.com/car는 car.apiserver.com으로 라우팅하도록 구현하면 된다.\n3. REST의 문제점 HTTP + JSON만 쓴다고 REST가 아니다. REST 아키텍처를 제대로 사용하는 것은 리소스를 제대로 정의하고 이에 대한 CRUD를 HTTP 메소드인 POST/PUT/GET/DELETE에 대해서 맞춰 사용하며, 에러 코드에 대해서 HTTP 응답 코드를 사용해야 한다.\n3.1 표준 규약이 없다. 3.2 기존의 전통적인 RDBMS에 적용하기가 쉽지 않다. 리소스를 표현할 때 리소스는 DB의 하나의 행(Row)이 되는 경우가 많은데, DB의 경우는 기본 키가 복합 키 형태로 존재하는 경우가 많다(여러 개의 칼럼이 묶여서 하나의 PK가 되는 경우). DB에서는 유효한 설계일지 몰라도 HTTP URI는 / 에 따라서 계층 구조를 가지기 때문에 이에 대한 표현이 매우 부자연스러워진다.\n예를들어 DB의 PK가 \u0026lsquo;세대주 주민번호\u0026rsquo; + \u0026lsquo;사는 지역\u0026rsquo; + \u0026lsquo;본인 이름\u0026rsquo; 일때 DB에서는 문제없으나 REST에서 이를 userinfo/{세대주 주민번호}/{사는 지역}/{본인 이름} 식으로 표현하게 되면 다소 이상한 의미가 부여될 수 있다.\n4. REST 보안 4.1 API에 대한 인증 클라이언트 인증 추가\n추가적인 보안 강화를 위해 사용자 인증(ID, Passwd)뿐만 아니라, 클라이언트 인증 방식을 추가할 수 있다. 페이스북은 API 토큰을 발급받으려면 사용자 ID , 비밀번호 뿐만 아니라 Client ID와 Client Secret이라는 것을 같이 입력받도록 하는데, Client ID는 특정 앱에 대한 등록 ID이고 Client Secret은 특정 앱에 대한 비밀번호로, 페이스북 개발자 포털에서 앱을 등록하면 앱 별로 발급되는 일종의 비밀번호이다. API 토큰을 발급받을 때, Client ID와 Client Secret을 이용하여 클라이언트 앱을 인증하고 사용자 ID와 비밀번호를 추가로 받아서 사용자를 인증하여 API 액세스 토큰을 발급받는다. 제 3자 인증 방식(OAuth 2.0 Autorization grant type) 제 3자 인증 방식은 페이스북이나 트위터와 같은 API 서비스 제공자들이 파트너 애플리케이션에 많이 적용하는 방법으로 내 서비스를 페이스북 계정을 이용하여 인증을 하는 경우다.\ncf) sokit은 개인 웹 서비스 프로젝트 이름\n중요한 점은 서비스(Sokit)에 대해서 해당 사용자가 페이스북 유저임을 인증해주고, 서비스(Sokit)는 사용자의 비밀번호를 받지 않는다. 대신 페이스북이 사용자를 인증하고 서비스(Sokit)에 알려주는 방식이다. 즉, 서비스에는 페이스북 유저의 비밀번호가 노출되지 않는다.\n전체적인 흐름을 보면 다음과 같다. 1. 먼저 페이스북 개발자 포털에 접속하여, 페이스북 인증을 사용하고자 하는 애플리케이션 정보를 등록한다.(서비스명, 서비스 URL, 그리고 인증이 성공했을 때 인증 성공 정보를 받을 콜백 URL) 2. 페이스북 개발자 포털은 등록된 정보를 기준으로 해당 애플리케이션에 대한 client_id와 client_secret을 발급한다. 이 값은 앞에서 설명한 클라이언트 인증에 사용된다. 3. 다음으로 개발하고자 하는 애플리케이션에 이 client_id와 client_secret 등을 넣고, 페이스북 인증 페이지 정보를 넣어서 애플리케이션을 개발한다.\nSokit 웹 애플리케이션은 Javascript SDK를 적용했다. 애플리케이션이 개발돼서 실행되면 다음과 같은 흐름에 따라서 사용자 인증을 수행하게 된다.  웹 브라우저에서 사용자가 Sokit 서비스에 접근하려고 요청한다. Sokit은 사용자의 인증이 되지 않았기 때문에 페이스북 로그인 페이지 URL을 HTTP 리다이렉션으로 브라우저에 보낸다. 이때 URL로, 페이스북에게 이 로그인 요청이 Sokit에 대한 사용자 인증 요청임을 알려주고자 client_id 등의 추가 정보와 함께 페이스북의 정보 접근 권한(사용자 정보, 그룹 정보 등)을 scope라는 필드를 통해서 요청한다.  브라우저는 페이스북 로그인 페이지로 이동하여 2단계에서 받은 추가적인 정보와 함께 로그인을 요청한다. 페이스북은 사용자에게 로그인 창을 보낸다. 사용자는 로그인 창에 ID/비밀번호를 입력한다. 페이스북은 사용자를 인증하고 인증 관련 정보와 함께 브라우저로 전달하면서 Sokit의 로그인 완료 페이지로 리다이렉션을 요청한다. Sokit은 6에서 온 인증 관련 정보를 받는다. Sokit은 이 정보를 가지고 페이스북에 이 사용자가 제대로 인증을 받은 사용자인지 문의한다. 페이스북은 해당 정보를 보고 제대로 인증된 사용자임을 확인해주고 Access Token을 발급한다. Sokit은 9에서 받은 Access Token으로 페이스북 API 서비스에 접근한다.  "
},
{
	"uri": "/%E1%84%8C%E1%85%A1%E1%84%87%E1%85%A1_%E1%84%89%E1%85%A5%E1%86%BC%E1%84%82%E1%85%B3%E1%86%BC_%E1%84%90%E1%85%B2%E1%84%82%E1%85%B5%E1%86%BC_%E1%84%8B%E1%85%B5%E1%84%8B%E1%85%A3%E1%84%80%E1%85%B5/%E1%84%8B%E1%85%A5%E1%84%83%E1%85%B5%E1%84%8B%E1%85%A6_%E1%84%83%E1%85%A1%E1%86%B7%E1%84%8B%E1%85%A1%E1%84%8B%E1%85%A3_%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%E1%84%8C%E1%85%B5/",
	"title": "어디에 담아야 하는지",
	"tags": [],
	"description": "",
	"content": " JMH 설치 및 설정 방법 JMH는 JDK를 오픈 소스로 제공하는 OpenJDK에서 만든 성능 측정용 라이브러리다.\n소스 받기 먼저 Mercurial이라는 분산 저장소에 접근하는 hg라는 툴을 이용하여 소스 코드를 받는다. url : https://www.mercurial-scm.org/downloads\nhg 설치를 마쳤으면 원하는 디렉터리에서 다음 명령을 실행한다.\n$ hg clone http://hg.openjdk.java.net/code-tools/jmh/ jmh  정상적으로 코드 다운로드가 완료되었으면 다음의 명령을 사용하여 메이븐 빌드를 실행한다.\n$ cd jmh $ mvn clean install -DskipTests=true  정상적으로 프로젝트 빌드가 완료되었다면 메이븐 로컬 저장소에 JMH 라이브러리가 등록되어 있을 것이다.\n그리고 동일 디렉토리에서 벤치마크 프로젝트를 빌드한다.\n$ mvn archetype:generate -DinteractiveMode=false -DarchetypeGroupId=org.openjdk.jmh -DarchetypeArtifactId=jmh-java-benchmark-archetype -DgroupId=org.sample -DartifactId=test -Dversion=1.0  마지막으로 test 디렉토리에 있는 것을 빌드하면 기본적인 설정은 끝난다.\n$ cd test $ mvn clean install  간단한 예제\n@BenchmarkMode({Mode.AverageTime}) @OutputTimeUnit(TimeUnit.MILLISECONDS) public class MyBenchmark { @Benchmark public DummyData makeObjectWithSize() { HashMap\u0026lt;String, String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(1000000); ArrayList\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(1000000); return new DummyData(map, list); } public static void main(String[] args) throws RunnerException { Options opt = new OptionsBuilder() .include(MyBenchmark.class.getSimpleName()) .warmupIterations(5) .measurementIterations(5) .forks(1) .build(); new Runner(opt).run(); } } @Benchmark라는 애노테이션을 메서드에 선언하면 JMH에서 측정 대상 코드라고 인식한다. - 하나의 클래스에 여러 개의 메서드가 존재할 수 있다. - 애노테이션을 선언한 메서드가 끝나지 않으면 측정도 끝나지 않는다. - 예외가 발생할 경우 해당 메서드의 측정을 종료하고, 다음 측정 메서드로 이동한다.\n위의 수행 결과는 다음과 같다.\n# JMH version: 1.19 # VM version: JDK 1.8.0_60, VM 25.60-b23 # VM invoker: /Library/Java/JavaVirtualMachines/jdk1.8.0_60.jdk/Contents/Home/jre/bin/java # VM options: -Didea.launcher.port=7537 -Didea.launcher.bin.path=/Volumes/IntelliJ IDEA/IntelliJ IDEA.app/Contents/bin -Dfile.encoding=UTF-8 # Warmup: 5 iterations, 1 s each # Measurement: 5 iterations, 1 s each # Timeout: 10 min per iteration # Threads: 1 thread, will synchronize iterations # Benchmark mode: Average time, time/op # Benchmark: org.sample.MyBenchmark.makeObjectWithSize # Run progress: 0.00% complete, ETA 00:00:10 # Fork: 1 of 1 # Warmup Iteration 1: 1.608 ms/op # Warmup Iteration 2: 0.612 ms/op # Warmup Iteration 3: 0.564 ms/op # Warmup Iteration 4: 0.572 ms/op # Warmup Iteration 5: 0.553 ms/op Iteration 1: 0.571 ms/op Iteration 2: 0.555 ms/op Iteration 3: 0.558 ms/op Iteration 4: 0.557 ms/op Iteration 5: 0.557 ms/op Result \u0026quot;org.sample.MyBenchmark.makeObjectWithSize\u0026quot;: 0.560 ±(99.9%) 0.025 ms/op [Average] (min, avg, max) = (0.555, 0.560, 0.571), stdev = 0.007 CI (99.9%): [0.534, 0.585] (assumes normal distribution) # Run complete. Total time: 00:00:10 Benchmark Mode Cnt Score Error Units MyBenchmark.makeObjectWithSize avgt 5 0.560 ± 0.025 ms/op Process finished with exit code 0  Set 클래스 중 무엇이 가장 빠를까? 먼저 HashSet, TreeSet, LinkedHashSet add를 비교해보면 다음과 같다.\n@State(Scope.Thread) @BenchmarkMode({Mode.AverageTime}) @OutputTimeUnit(TimeUnit.MICROSECONDS) public class SetAdd { int LOOP_COUNT = 1000; Set\u0026lt;String\u0026gt; set; String data = \u0026#34;abcdefghijklmnopqrstuvwxyz\u0026#34;; @Benchmark public void addHashSet() { set = new HashSet\u0026lt;\u0026gt;(); for (int loop = 0; loop \u0026lt; LOOP_COUNT; loop++) { set.add(data + loop); } } @Benchmark public void addTreeSet() { set = new TreeSet\u0026lt;\u0026gt;(); for (int loop = 0; loop \u0026lt; LOOP_COUNT; loop++) { set.add(data + loop); } } @Benchmark public void addLinkedHashSet() { set = new LinkedHashSet\u0026lt;\u0026gt;(); for (int loop = 0; loop \u0026lt; LOOP_COUNT; loop++) { set.add(data + loop); } } public static void main(String[] args) throws RunnerException { Options opt = new OptionsBuilder() .include(SetAdd.class.getSimpleName()) .warmupIterations(3) .measurementIterations(5) .forks(1) .build(); new Runner(opt).run(); } } # Run complete. Total time: 00:00:25 Benchmark Mode Cnt Score Error Units SetAdd.addHashSet avgt 5 79.923 ± 7.503 us/op SetAdd.addLinkedHashSet avgt 5 84.106 ± 10.006 us/op SetAdd.addTreeSet avgt 5 297.550 ± 56.801 us/op  HashSet과 LinkedHashSet의 성능이 비슷하고, TreeSet은 성능 차이가 발생한다 TreeSet은 레드블랙 트리에 데이터를 담는다. 값에 따라서 순서가 정해진다. 데이터를 담으면서 동시에 정렬을 하기 때문에 HashSet보다 성능상 느리다.\n이번에는 Set 클래스들이 데이터를 읽을 때 얼마나 많은 차이가 발생하는지 확인해보자.\n@State(Scope.Thread) @BenchmarkMode({Mode.AverageTime}) @OutputTimeUnit(TimeUnit.MICROSECONDS) public class SetIterate { int LOOP_COUNT = 1000; Set\u0026lt;String\u0026gt; hashSet; Set\u0026lt;String\u0026gt; treeSet; Set\u0026lt;String\u0026gt; linkedHashSet; String data = \u0026#34;abcdefghijklmnopqrstuvwxyz\u0026#34;; String[] keys; String result = null; @Setup(Level.Trial) public void setUp() { hashSet = new HashSet\u0026lt;\u0026gt;(); treeSet = new TreeSet\u0026lt;\u0026gt;(); linkedHashSet = new LinkedHashSet\u0026lt;\u0026gt;(); for (int loop = 0; loop \u0026lt; LOOP_COUNT; loop++) { String tempData = data+loop; hashSet.add(tempData); treeSet.add(tempData); linkedHashSet.add(tempData); } } @Benchmark public void iterateHashSet() { Iterator\u0026lt;String\u0026gt; iter = hashSet.iterator(); while (iter.hasNext()) { result = iter.next(); } } @Benchmark public void iterateTreeSet() { Iterator\u0026lt;String\u0026gt; iter = treeSet.iterator(); while (iter.hasNext()) { result = iter.next(); } } @Benchmark public void iterateLinkedHashSet() { Iterator\u0026lt;String\u0026gt; iter = linkedHashSet.iterator(); while (iter.hasNext()) { result = iter.next(); } } public static void main(String[] args) throws RunnerException { Options opt = new OptionsBuilder() .include(SetIterate.class.getSimpleName()) .warmupIterations(3) .measurementIterations(5) .forks(1) .build(); new Runner(opt).run(); } # Run complete. Total time: 00:00:25 Benchmark Mode Cnt Score Error Units SetIterate.iterateHashSet avgt 5 8.154 ± 2.364 us/op SetIterate.iterateLinkedHashSet avgt 5 11.204 ± 0.577 us/op SetIterate.iterateTreeSet avgt 5 12.678 ± 1.558 us/op  읽기에서는 크게 차이나지 않는다. Set을 Iterator 돌려서 사용하기도 하지만, 일반적으로 Set은 여러 데이터를 넣어 두고 해당 데이터가 존재하는지를 확인하는 용도로 많이 사용된다. 따라서 데이터를 Iterator로 가져오는 것이 아니라, 랜덤하게 가져와야만 한다.\n@State(Scope.Thread) @BenchmarkMode({Mode.AverageTime}) @OutputTimeUnit(TimeUnit.MICROSECONDS) public class SetContains { int LOOP_COUNT = 1000; Set\u0026lt;String\u0026gt; hashSet; Set\u0026lt;String\u0026gt; treeSet; Set\u0026lt;String\u0026gt; linkedHashSet; String data = \u0026#34;abcdefghijklmnopqrstuvwxyz\u0026#34;; String[] keys; String result = null; @Setup(Level.Trial) public void setUp() { hashSet = new HashSet\u0026lt;\u0026gt;(); treeSet = new TreeSet\u0026lt;\u0026gt;(); linkedHashSet = new LinkedHashSet\u0026lt;\u0026gt;(); for (int loop = 0; loop \u0026lt; LOOP_COUNT; loop++) { String tempData = data+loop; hashSet.add(tempData); treeSet.add(tempData); linkedHashSet.add(tempData); } if (keys == null || keys.length != LOOP_COUNT) { keys = RandomKeyUtil.generateRandomSetKeysSwap(hashSet); } } @Benchmark public void containsHashSet() { for (String key : keys) { hashSet.contains(key); } } @Benchmark public void containsTreeSet() { for (String key : keys) { treeSet.contains(key); } } @Benchmark public void containsLinkedHashSet() { for (String key : keys) { linkedHashSet.contains(key); } } public static void main(String[] args) throws RunnerException { Options opt = new OptionsBuilder() .include(SetContains.class.getSimpleName()) .warmupIterations(3) .measurementIterations(5) .forks(1) .build(); new Runner(opt).run(); } }public class RandomKeyUtil { public static String[] generateRandomSetKeysSwap(Set\u0026lt;String\u0026gt; set) { int size = set.size(); String[] result = new String[size]; Random random = new Random(); int maxNumber = size; Iterator\u0026lt;String\u0026gt; iterator = set.iterator(); int resultPos = 0; while (iterator.hasNext()) { result[resultPos++] = iterator.next(); } for (int loop = 0; loop \u0026lt; size; loop++) { int randomNumber1 = random.nextInt(maxNumber); int randomNumber2 = random.nextInt(maxNumber); String temp = result[randomNumber2]; result[randomNumber2] = result[randomNumber1]; result[randomNumber1] = temp; } return result; } public static int[] generateRandomNumberKeysSwap(int loop_count) { int[] result = new int[loop_count]; Random random = new Random(); for (int i=0; i\u0026lt; loop_count; i++) { int randomNumber = random.nextInt(loop_count); result[i] = randomNumber; } return result; } } # Run complete. Total time: 00:00:26 Benchmark Mode Cnt Score Error Units SetContains.containsHashSet avgt 5 9.446 ± 2.284 us/op SetContains.containsLinkedHashSet avgt 5 9.875 ± 4.718 us/op SetContains.containsTreeSet avgt 5 239.340 ± 88.700 us/op  HashSet과 LinkedHashSet의 속도는 빠르지만, TreeSet의 속도는 느리다는 것을 알 수 있다. 그러면 왜 결과가 항상 느리게 나오는 TreeSet 클래스를 만들었을까?\npublic class TreeSet\u0026lt;E\u0026gt; extends AbstractSet\u0026lt;E\u0026gt; implements NavigableSet\u0026lt;E\u0026gt;, Cloneable, java.io.Serializable  TreeSet은 데이터를 저장하면서 정렬한다. 구현한 인터페이스 중에 NavigableSet이 있다. 이 인터페이스는 특정 값보다 큰 값이나 작은 값, 가장 큰 값, 가장 작은 값 등을 추출하는 메서드를 선언해 놓았으며 JDK 1.6부터 추가된 것이다. 즉, 데이터를 순서에 따라 탐색하는 작업이 필요할때는 TreeSet을 사용하는 것이 좋다는 의미다. 하지만 그럴 필요가 없을 때는 HashSet이나 LinkedHashSet을 사용하는 것을 권장한다.\nList 관련 클래스 중 무엇이 빠를까? 데이터를 넣는 속도부터 비교해보자.\n@State(Scope.Thread) @BenchmarkMode({Mode.AverageTime}) @OutputTimeUnit(TimeUnit.MICROSECONDS) public class ListAdd { int LOOP_COUNT = 1000; List\u0026lt;Integer\u0026gt; arrayList; List\u0026lt;Integer\u0026gt; vector; List\u0026lt;Integer\u0026gt; linkedList; @Benchmark public void addArrayList() { arrayList = new ArrayList\u0026lt;\u0026gt;(); for (int loop = 0; loop \u0026lt; LOOP_COUNT; loop++) { arrayList.add(loop); } } @Benchmark public void addVector() { vector = new Vector\u0026lt;\u0026gt;(); for (int loop = 0; loop \u0026lt; LOOP_COUNT; loop++) { vector.add(loop); } } @Benchmark public void addLinkedList() { linkedList = new LinkedList\u0026lt;\u0026gt;(); for (int loop = 0; loop \u0026lt; LOOP_COUNT; loop++) { linkedList.add(loop); } } public static void main(String[] args) throws RunnerException { Options opt = new OptionsBuilder() .include(ListAdd.class.getSimpleName()) .warmupIterations(3) .measurementIterations(5) .forks(1) .build(); new Runner(opt).run(); } } # Run complete. Total time: 00:00:26 Benchmark Mode Cnt Score Error Units ListAdd.addArrayList avgt 5 12.038 ± 3.928 us/op ListAdd.addLinkedList avgt 5 11.656 ± 8.859 us/op ListAdd.addVector avgt 5 12.376 ± 21.172 us/op  어떤 클래스든 큰 차이가 없다는 것을 알 수 있다.\n이번에는 데이터를 꺼내는 속도를 확인해보자.\n@State(Scope.Thread) @BenchmarkMode({Mode.AverageTime}) @OutputTimeUnit(TimeUnit.MICROSECONDS) public class ListGet { int LOOP_COUNT = 1000; List\u0026lt;Integer\u0026gt; arrayList; List\u0026lt;Integer\u0026gt; vector; List\u0026lt;Integer\u0026gt; linkedList; int result = 0; @Setup public void setUp() { arrayList = new ArrayList\u0026lt;\u0026gt;(); vector = new Vector\u0026lt;\u0026gt;(); linkedList = new LinkedList\u0026lt;\u0026gt;(); for (int loop = 0; loop \u0026lt; LOOP_COUNT; loop++) { arrayList.add(loop); vector.add(loop); linkedList.add(loop); } } @Benchmark public void getArrayList() { for (int loop = 0; loop \u0026lt; LOOP_COUNT; loop++) { result = arrayList.get(loop); } } @Benchmark public void getVector() { for (int loop = 0; loop \u0026lt; LOOP_COUNT; loop++) { result = vector.get(loop); } } @Benchmark public void getLinkedList() { for (int loop = 0; loop \u0026lt; LOOP_COUNT; loop++) { result = linkedList.get(loop); } } public static void main(String[] args) throws RunnerException { Options opt = new OptionsBuilder() .include(ListGet.class.getSimpleName()) .warmupIterations(3) .measurementIterations(5) .forks(1) .build(); new Runner(opt).run(); } } # Run complete. Total time: 00:00:26 Benchmark Mode Cnt Score Error Units ListGet.getArrayList avgt 5 1.282 ± 0.243 us/op ListGet.getLinkedList avgt 5 435.129 ± 105.285 us/op ListGet.getVector avgt 5 29.920 ± 6.519 us/op  ArrayList의 속도가 가장 빠르고, Vector와 LinkedList는 속도가 매우 느리다. LinkedList가 터무니없이 느리게 나온 이유는 LinkedList가 Queue 인터페이스를 상속받기 때문이다. 이를 수정하기 위해서는 순차적으로 결과를 받아오는 peek() 메서드를 사용해야 한다.\n@Benchmark public void getPeekLinkedList() { for (int loop = 0; loop \u0026lt; LOOP_COUNT; loop++) { result = linkedList.peek(); } } # Run complete. Total time: 00:00:34 Benchmark Mode Cnt Score Error Units ListGet.getArrayList avgt 5 1.242 ± 0.180 us/op ListGet.getLinkedList avgt 5 425.459 ± 54.941 us/op ListGet.getPeekLinkedList avgt 5 0.038 ± 0.003 us/op ListGet.getVector avgt 5 27.923 ± 0.632 us/op  LinkedList 클래스를 사용할 때는 get() 메서드가 아닌 peek()이나 poll() 메서드를 사용해야 한다. 그런데 왜 ArrayList와 Vector의 성능 차이가 이렇게 클까? ArrayList는 여러 스레드에서 접근할 경우 문제가 발생할 수 있지만, Vector는 여러 스레드에서 접근할 경우를 방지하기 위해서 get() 메서드에 synchronized가 선언되어 있다. 따라서 성능 저하가 발생할 수 밖에 없다.\n마지막으로 데이터를 삭제하는 속도를 비교해보자.\n@State(Scope.Thread) @BenchmarkMode({Mode.AverageTime}) @OutputTimeUnit(TimeUnit.MICROSECONDS) public class ListRemove { int LOOP_COUNT = 10; List\u0026lt;Integer\u0026gt; arrayList; List\u0026lt;Integer\u0026gt; vector; LinkedList\u0026lt;Integer\u0026gt; linkedList; int result = 0; @Setup(Level.Trial) public void setUp() { arrayList = new ArrayList\u0026lt;\u0026gt;(); vector = new Vector\u0026lt;\u0026gt;(); linkedList = new LinkedList\u0026lt;\u0026gt;(); for (int loop = 0; loop \u0026lt; LOOP_COUNT; loop++) { arrayList.add(loop); vector.add(loop); linkedList.add(loop); } } @Benchmark public void removeArrayListFromFirst() { ArrayList\u0026lt;Integer\u0026gt; tempList = new ArrayList\u0026lt;\u0026gt;(arrayList); for (int loop = 0; loop \u0026lt; LOOP_COUNT; loop++) { tempList.remove(0); } } @Benchmark public void removeArrayListFromLast() { ArrayList\u0026lt;Integer\u0026gt; tempList = new ArrayList\u0026lt;\u0026gt;(arrayList); for (int loop = LOOP_COUNT -1 ; loop \u0026gt;= 0; loop--) { tempList.remove(loop); } } @Benchmark public void removeVectorFromFirst() { List\u0026lt;Integer\u0026gt; tempList = new Vector\u0026lt;\u0026gt;(vector); for (int loop = 0; loop \u0026lt; LOOP_COUNT; loop++) { tempList.remove(0); } } @Benchmark public void removeVectorFromLast() { List\u0026lt;Integer\u0026gt; tempList = new Vector\u0026lt;\u0026gt;(vector); for (int loop = LOOP_COUNT -1 ; loop \u0026gt;= 0; loop--) { tempList.remove(loop); } } @Benchmark public void removeLinkedListFromFirst() { LinkedList\u0026lt;Integer\u0026gt; tempList = new LinkedList\u0026lt;\u0026gt;(linkedList); for (int loop = 0; loop \u0026lt; LOOP_COUNT; loop++) { tempList.remove(0); } } @Benchmark public void removeLinkedListFromLast() { LinkedList\u0026lt;Integer\u0026gt; tempList = new LinkedList\u0026lt;\u0026gt;(linkedList); for (int loop = LOOP_COUNT -1 ; loop \u0026gt;= 0; loop--) { tempList.remove(loop); } } public static void main(String[] args) throws RunnerException { Options opt = new OptionsBuilder() .include(ListRemove.class.getSimpleName()) .warmupIterations(3) .measurementIterations(5) .forks(1) .build(); new Runner(opt).run(); } } # Run complete. Total time: 00:00:51 Benchmark Mode Cnt Score Error Units ListRemove.removeArrayListFromFirst avgt 5 0.089 ± 0.012 us/op ListRemove.removeArrayListFromLast avgt 5 0.023 ± 0.001 us/op ListRemove.removeLinkedListFromFirst avgt 5 0.161 ± 0.094 us/op ListRemove.removeLinkedListFromLast avgt 5 0.137 ± 0.021 us/op ListRemove.removeVectorFromFirst avgt 5 0.097 ± 0.003 us/op ListRemove.removeVectorFromLast avgt 5 0.038 ± 0.007 us/op  결과를 보면 첫 번째 값을 삭제하는 메서드와 마지막 값을 삭제하는 메서드의 속도 차이는 크다. 그리고 LinkedList는 별 차이가 없다. 그 이유가뭘까? ArrayList와 Vector는 실제로 그 안에 배열을 사용하기 때문에 0번째 인덱스 값을 삭제하면 나머지를 다 옮겨야 하기 때문이다.\nMap 관련 클래스 중에서 무엇이 빠를까? @State(Scope.Thread) @BenchmarkMode({Mode.AverageTime}) @OutputTimeUnit(TimeUnit.MICROSECONDS) public class MapGet { int LOOP_COUNT = 1000; Map\u0026lt;Integer, String\u0026gt; hashMap; Map\u0026lt;Integer, String\u0026gt; hashTable; Map\u0026lt;Integer, String\u0026gt; treeMap; Map\u0026lt;Integer, String\u0026gt; linkedHashMap; int[] keys; @Setup(Level.Trial) public void setUp() { if (keys == null || keys.length != LOOP_COUNT) { hashMap = new HashMap\u0026lt;\u0026gt;(); hashTable = new Hashtable\u0026lt;\u0026gt;(); treeMap = new TreeMap\u0026lt;\u0026gt;(); linkedHashMap = new LinkedHashMap\u0026lt;\u0026gt;(); String data = \u0026#34;abcdefghijklmnopqrstuvwxyz\u0026#34;; for (int loop = 0; loop \u0026lt; LOOP_COUNT; loop++) { String tempData = data+loop; hashMap.put(loop, tempData); hashTable.put(loop, tempData); treeMap.put(loop, tempData); linkedHashMap.put(loop, tempData); } keys = RandomKeyUtil.generateRandomNumberKeysSwap(LOOP_COUNT); } } @Benchmark public void getSeqHashMap() { for (int loop = 0; loop \u0026lt; LOOP_COUNT; loop++) { hashMap.get(loop); } } @Benchmark public void getRandomHashMap() { for (int loop = 0; loop \u0026lt; LOOP_COUNT; loop++) { hashMap.get(keys[loop]); } } @Benchmark public void getSeqHashtable() { for (int loop = 0; loop \u0026lt; LOOP_COUNT; loop++) { hashTable.get(loop); } } @Benchmark public void getRandomHashtable() { for (int loop = 0; loop \u0026lt; LOOP_COUNT; loop++) { hashTable.get(keys[loop]); } } @Benchmark public void getSeqTreeMap() { for (int loop = 0; loop \u0026lt; LOOP_COUNT; loop++) { treeMap.get(loop); } } @Benchmark public void getRandomTreeMap() { for (int loop = 0; loop \u0026lt; LOOP_COUNT; loop++) { treeMap.get(keys[loop]); } } @Benchmark public void getSeqLinkedHashMap() { for (int loop = 0; loop \u0026lt; LOOP_COUNT; loop++) { linkedHashMap.get(loop); } } @Benchmark public void getRandomLinkedHashMap() { for (int loop = 0; loop \u0026lt; LOOP_COUNT; loop++) { linkedHashMap.get(keys[loop]); } } public static void main(String[] args) throws RunnerException { Options opt = new OptionsBuilder() .include(MapGet.class.getSimpleName()) .warmupIterations(3) .measurementIterations(5) .forks(1) .build(); new Runner(opt).run(); } } # Run complete. Total time: 00:01:08 Benchmark Mode Cnt Score Error Units MapGet.getRandomHashMap avgt 5 7.069 ± 0.735 us/op MapGet.getRandomHashtable avgt 5 28.774 ± 2.440 us/op MapGet.getRandomLinkedHashMap avgt 5 8.615 ± 2.757 us/op MapGet.getRandomTreeMap avgt 5 72.531 ± 3.146 us/op MapGet.getSeqHashMap avgt 5 7.663 ± 3.393 us/op MapGet.getSeqHashtable avgt 5 28.862 ± 11.409 us/op MapGet.getSeqLinkedHashMap avgt 5 5.933 ± 0.450 us/op MapGet.getSeqTreeMap avgt 5 55.169 ± 8.445 us/op  트리 형태로 처리하는 TreeMap 클래스가 가장 느린 것을 알 수 있다. 그리고 동기화처리를 하 Hashtable도 HashMap과 속도차이를 보인다.\n지금까지 Set, List, Map 관련 클래스에 어떤 것들이 있고, 각각의 성능이 얼마나 되는지 정확하게 측정해 보았다. 하지만 일반적인 웹을 개발할때는 Collection 성능 차이를 비교하는 것은 큰 의미가 없다. 각 클래스에는 사용 목적이 있기 때문에 목적에 부합하는 클래스를 선택해서 사용하는 것이 바람직하다.\n"
},
{
	"uri": "/shellscript/",
	"title": "자주쓰는 쉘 스크립트 모음",
	"tags": [],
	"description": "",
	"content": " if문 if-then 가장 기본적인 if-else 구문의 형식은 다음과 같다.\nif command then commands fi  if command; then commands fi  bash 쉘은 if문 줄에 정의된 명령을 실행한다. 이 명령의 종료 상태가 0(명령이 성공적으로 완료됨)이라면 then 아래에 있는 명령이 실행된다. 명령의 종료 상태가 0이 아니라면 then 아래에 있는 명령은 실행되지 않고, bash 쉘은 스크립트의 다른 명령으로 넘어간다.\nif-then-else if command then commands else commands fi  if문 줄의 명령이 0이 아닌 종료 상태 코드를 돌려주면 bash 쉘은 else 부분의 명령을 실행한다.\n중첩된 if문 if command1 then commands elif command2 then more commands fi  elif는 if-then 구문의 else 부분을 이어 나간다. elif 명령의 종료 상태 코드가 0이라면 bash는 두 번째 then문 부부너의 명령들(more commands)을 실행한다.\n테스트 명령 써보기 if test condition then 명령 fi  테스트 명령에 나와있는 조건이 참으로 평가되면 테스트 명령은 종료 상태 코드를 0으로 돌려준다.\nbash 쉘은 if-then 구문에서 테스트 명령을 쓰지 않고도 조건을 테스트하는 다른 방법을 제공한다.\nif [ condition ] then 명령 fi  대괄호는 테스트 조건을 정의한다. 한 가지 주의할 점이 있다. 여는 대괄호 뒤와 닫는 대괄호 앞에 각각 빈 칸이 있어야 한다. 안그러면 오류 메세지가 나타난다. 테스트 명령 및 테스트 조건은 세 가지 종류의 조건을 평가할 수 있다(파일 비교, 숫자 비교, 문자열 비교).\n파일 비교 쉘 스크립트에서 가장 강력하고 가장 많이 사용되는 비교다. 리눅스 파일 시스템에서 파일과 디렉토리의 상태를 테스트할 수 있다.\n   비교 설명     -d file 파일이 존재하고 디렉토리인지 검사한다   -e file 파일이 존재하는지 검사한다   -f file 파일이 존재하고 파일인지 검사한다   -L file 파일이 심볼릭 링크이면 참   -r file 파일이 존재하고 읽을 수 있는지 검사한다   -s file 파일이 존재하고 비어 있지 않은지 검사한다   -w file 파일이 존재하고 기록할 수 있는지 검사한다   -x file 파일이 존재하고 실행할 수 있는지 검사한다   -O file 파일이 존재하고 현재 사용자가 소유한 것인지 검사한다   -G file 파일이 존재하고 기본 그룹이 현재 사용자와 같은지 검사한다   file1 -nt file2 file1이 file2보다 새것인지 검사한다   file1 -ot file2 file1이 file2보다 오래된 것인지 검사한다    디렉토리 확인하기\n지정된 디렉토리가 시스템에 존재하는지 보려면 -d 검사를 한다. 보통은 디렉토리에 파일을 쓰거나 디렉토리의 위치를 변경하기 전에 사용하면 좋다.\njump_directory=/home/arthur if [ -d $jump_directory ] then echo \u0026quot;hi\u0026quot; fi  개체가 존재하는지 여부 검사하기\nlocation=$HOME file_name=\u0026quot;bong\u0026quot; if [ -e $location ] then # Directory does exist if [ -e $location/$file_name ] then echo \u0026quot;file does exist\u0026quot; else echo \u0026quot;file doesn't exist\u0026quot; fi else echo \u0026quot;Directory doesn't exist\u0026quot; fi  스크립트에서 파일 또는 디렉토리를 사용하기 전에 이 개채가 있는지 확인하려면 -e 비교를 사용한다(-e 비교는 파일과 디렉토리 양쪽 모두에 적용된다).\n숫자 비교    비교 설명     n1 -eq n2 n1과 n2가 같은지 검사한다   n1 -ge n2 n1이 n2보다 크거나 같은지 검사한다   n1 -gt n2 n1이 n2보다 큰지 검사한다   n1 -le n2 n1이 n2보다 작거나 같은지 검사한다   n1 -lt n2 n1이 n2보다 작은지 검사한다   n1 -ne n2 n1과 n2가 같지 않은지 검사한다    if [ $val1 -gt 1 ] then echo \u0026quot;hi\u0026quot; fi  문자열 비교    비교 설명     str1 = str2 str1이 str2와 같은지 검사한다   str1 != str2 str1이 str2와 같지 않은지 검사한다   str1 \u0026lt; str2 str1이 str2보다 작은지 검사한다   str1 \u0026gt; str2 str1이 str2보다 큰지 검사한다   -n str1 str1의 길이가 0보다 큰지(0이 아닌지) 검사한다   -z str1 str1의 길이가 0인지 검사한다    문자열이 같은가 같지 않은가 비교할 때는 모든 문장부호와 대문자도 고려된다는 점을 잊지 말자.\ntestuser=bong if [ $USER = $testuser ] then echo \u0026quot;hi\u0026quot; fi  어떤 문자열이 다른 문자열보다 큰가 작은가를 판단할 때부터 일이 복잡해진다. 문자열이 큰지의 여부를 테스트하는 기능을 사용하려고 할 때 두가지 문제가 있다.\n첫째, 부등호 기호를 이스케이프 해야 하는 것. 그렇지 않으면 쉘은 이를 리다이렉트 기호로 해석해서 문자열 값을 파일 이름으로 사용한다.\nval1=baseball val2=hockey if [ $val1 \\\u0026gt; $val2 ] then echo \u0026quot;hi\u0026quot; fi  둘째, 어느 것이 더 큰지 순서를 결정하는 논리는 sort 명령에서 쓰이는 것과 같지 않다.\n비교 테스트에서는 표준 ASCII 순서를 사용하며, 정렬 순서를 결정하기 위하여 각 문자의 ASCII 숫자 코드값을 이용한다. sort 명령은 시스템 로케일의 언어 설정에 정의된 정렬 순서를 사용한다. 영어라면 로케일 설정은 소문자를 대문자보다 앞서서 정렬하도록 지정한다.\n비어있고 초기화되지 않은 변수는 쉘 스크립트 테스트에 치명적인 영향을 미칠 수 있다. 변수의 내용이 확실하지 않으면 숫자 또는 문자열 비교를 사용하기 전에 -n 또는 -z를 사용하여 값을 포함하는지 테스트하는 것이 가장 좋다.\nval1=testing if [ -n $val1 ] then echo \u0026quot;hi\u0026quot; fi if [ -z $val2 ] then echo \u0026quot;hi\u0026quot; fi  for문 일반 for문 FILE=\u0026quot;/Users/bong\u0026quot; for state in $(ls $FILE) do echo $state done  for i in ~/bong*.sh ; do if [ -r \u0026quot;$i\u0026quot; ]; then . $i fi done  for문 돌리면서 스크립트 파일 실행\nC 스타일 for문 TEST_TRIES=7 TEST_INTERVAL_SECONDS=5 for (( TRY_COUNT = 1; TRY_COUNT \u0026lt;= $TEST_TRIES; TRY_COUNT ++ )) do sleep $TEST_INTERVAL_SECONDS echo \u0026quot;Checking HTTP port. (\u0026quot;$TRY_COUNT\u0026quot;/$TEST_TRIES)\u0026quot; HTTP_STATUS_CODE=`curl -sL -o /dev/null -I -w \u0026quot;%{http_code}\u0026quot; $TEST_URL --max-time 10` if [ $HTTP_STATUS_CODE -gt 199 ] \u0026amp;\u0026amp; [ $HTTP_STATUS_CODE -lt 300 ]; then echo \u0026quot;The Spring Boot process has started successfully.\u0026quot; break fi if [ $TRY_COUNT = $TEST_TRIES ]; then echo \u0026quot;ERROR : The Spring Boot process failed to start.\u0026quot; exit 1 fi done  while문 기본 while 형식 var1=10 while [ $var1 -gt 0 ] do echo $var1 var1=$[ $var1 - 1 ] done  getopts 명령어 사용 # -a 옵션이 있는지 플래그 변수 a_flag와 # -p 옵션의 구분자를 정의하기 a_flag=0 separator=\u0026quot;\u0026quot; while getopts \u0026quot;ap:\u0026quot; option do case $option in a) a_flag=1 ;; p) separator=\u0026quot;$OPTARG\u0026quot; ;; \\?) echo \u0026quot;Usage: getopts.sh [-a] [-p separator] target_dir\u0026quot; 1\u0026gt;\u0026amp;2 exit 1 ;; esac done  case 명령 case variable in pattern1 | pattern2) commands1;; pattern3) commands2;; *) default commands;; esac  예제\necho_host(){ host=`hostname` echo \u0026quot;[$host] $1\u0026quot; } #### Main ##### OPTION=$1 case $OPTION in \u0026quot;start\u0026quot;) start_nginx;; \u0026quot;stop\u0026quot;) stop_nginx;; \u0026quot;restart\u0026quot;) restart_nginx;; *) echo_host \u0026quot;option : $0 start|stop|restart\u0026quot;;; esac  결과\n$ ./bong.sh ttt [MyMacBook] option : ./bong.sh start|stop|restart  스크립트 종료하기 리눅스 종료 상태코드    코드 설명     0 명령이 성공적으로 완료됨   1 일반 알 수 없는 오류   2 쉘 명령을 잘못 사용함   126 명령을 실행할 수 없음(Permission denied)   127 명령을 찾을 수 없음   128 잘못된 종료 매개변수   128+x 치명적인 오류로 리눅스 신호 x를 포함   130 Ctrl+C로 명령이 종료됨   255 범위를 벗어난 종료 상태    종료 코드 확인하는 명령어 $ echo $?  cf) 종료 상태 코드는 0 ~ 255까지 쓸 수 있다.\nexit 명령 쉘 스크립트는 마지막 명령의 종료 상태로 끝마친다. 사용자 정의 종료 상태 코드를 돌려주도록 이를 변경할 수 있다. exit 명령은 스크립트가 종료될 때 종료 상태를 지정할 수 있다.\n#!/bin/bash var1=10 var2=30 var3=$[$var1 + $var2] echo The answer is $var3 exit5 #exit $var3 처럼 exit 명령의 매개변수에 변수를 사용할 수도 있다.  결과\n$ chmod u+x test13 $ ./test13 The answer is 40 $ echo $? 5  자주쓰는 명령어 모음 쉘 스크립트 작성후 실행하기 전에 문법을 확인하는 -n 옵션\n$ sh -n script.sh  java 프로세스 PID 리스트업 해서 출력\n$ ps -ef | grep java | awk '{print $2}'  grep 하면 방금 실행한 것도 잡히기 때문에 그거 제외해주는 명령어\n$ ps -ef | grep java | grep -v grep  pid가 여러개일 때 check하는 if문 추가적으로 ps -ef | grep nginx | grep -v grep | wc -l 방법도 있다\ncheck_running() { PID=`ps -ef | grep nginx | grep -v grep | awk '{print $2}'` if [[ -n $PID ]] ; then echo \u0026quot;nginx process already started (PID:$PID)\u0026quot; exit 1 fi }  /dev/null은 어떤 데이터를 보내든 블랙홀로써 전부 버려질것이다.\n$ \u0026gt;/dev/null 2\u0026gt;\u0026amp;1  2 표준 에러를 뜻하는 파일 디스크립터다. \u0026amp; 파일 디스크립터를 뜻하는 심볼이다. 이 기호가 없으면 다음 1은 파일이름으로 간주된다. 1 표준 출력을 뜻하는 파일 디스크립터다. 결론 : 프로그램의 출력을 /dev/null로 보내고 출력을 하는데 표준에러를 표준출력으로 보내라 다른 프로세스가 사용하고 있는 포트가 아닌지 확인하기 위한 명령어\n$ netstat -an | grep 8080  control + z하면 백그라운드로 suspend되는데(다시 포그라운드로 부르는건 fg)\n예를들어 [5] + 17215 suspended node server.js\n$ kill %5  하면 죽일 수 있다.\n실수로 git add 했을 때 되돌리기\n$ git rm —cached \u0026lt;filename\u0026gt;  os 버전 확인\nOS_VERSION=$(sed 's/.*release \\([0-9]\\).*/\\1/' /etc/redhat-release)  네트워크 인터페이스명은 빼고 IP주소만 쓰고 싶을 때 사용한는 명령어\n$ LANG=C /sbin/ifconfig | awk '/inet / {split($2,arr,\u0026quot;:\u0026quot;); print arr[2]}'  현재 디렉토리에 있는 서브 디렉토리들의 디스크 사용량 조사\n$ du -h ./  디스크 용량 검사\n$ df -h  네트워크 상태 모니터링 (ESTABLISHED, CLOSE_WAIT, TIME_WAIT 등)\n$ netstat -ton  "
},
{
	"uri": "/effective_java/%E1%84%8F%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A2%E1%84%89%E1%85%B3%E1%84%8B%E1%85%AA_%E1%84%8B%E1%85%B5%E1%86%AB%E1%84%90%E1%85%A5%E1%84%91%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%89%E1%85%B3/",
	"title": "클래스와 인터페이스",
	"tags": [],
	"description": "",
	"content": " 규칙15 : 클래스와 멤버의 접근 권한은 최소화하라 각 클래스와 멤버는 가능한 한 접근 불가능하도록 만들어라. 정보은닉 또는 캡슐화는 시스템을 구성하는 모듈 사이의 의존성을 낮춰서 개발 속도 및 유지보수에 효율적이다.\n클래스나 인터페이스 또는 멤버를 패키지의 공개 API로 만들어서는 곤란하다.\n객체 필드(instance field)는 절대로 public으로 선언하면 안된다. 변경 가능 public 필드를 가진 클래스는 다중 스레드에 안전하지 않다. 변경 불가능 객체를 참조하는 final 필드라 해도 public으로 선언하면 클래스 내부 데이터 표현 형태를 유연하게 바꿀 수 없게 된다. 공개 API의 일부가 되어버리므로, 삭제하거나 수정할 수 없게 되는 것이다.\nstatic으로 선언된 필드에도 똑같이 적용되지만 한 가지 예외가 있다. 어떤 상수들이 클래스로 추상화된 결과물의 핵심적 부분을 구성한다고 판단되는 경우, 해당 상수들을 public static final 필드들로 선언하여 공개할 수 있다. (public static final 필드가 참조하는 객체는 변경 불가능 객체로 만들어라.)\n길이가 0 아닌 배열은 언제나 변경 가능하므로, public static final 배열 필드를 두거나, 배열 필드를 반환하는 접근자를 정의하면 안 된다. 그런 멤버를 두면 클라이언트가 배열 내용을 변경할 수 있게 되므로, 보안에 문제가 생긴다.\n//보안 문제를 초래할 수 있는 코드 public static final Thing[] VALUES { ... }; 이 문제를 고치는 방법 중 첫 번째는 public으로 선언되었던 배열은 private으로 바꾸고, 변경이 불가능한 public 리스트를 하나 만드는 것이다.\nprivate static final Thing[] PRIVATE_VALUES = { ... }; public static final List\u0026lt;Thing\u0026gt; VALUES = Collections.unmodifiableList(Arrays.asList(PRIVATE_VALUE)); 두 번째 방법은 배열은 private으로 선언하고, 해당 배열을 복사해서 반환하는 public 메서드를 하나 추가하는 것이다.\nprivate static final Thing[] PRIVATE_VALUES = { ... }; public static final Thing[] values(){ return PRIVATE_VALUES.clone(); } 규칙16 : public 클래스 안에는 public 필드를 두지 말고 접근자 메서드를 사용하라 cf) package-private(default) 클래스나 private 중첩클래스는 데이터 필드를 공개하더라도 잘못이라 말할 수 없다. 클래스가 추상화하려는 내용을 제대로 기술하기만 한다면 말이다.\n이 접근법은 시각적으로 깔끔해 보인다. 클라이언트 코드가 클래스의 내부 표현에 종속된다는 문제가 있긴 하지만, 클라이언트 코드가 같은 패키지 안에 있을 수밖에 없다는 점을 고려해야 한다.\n규칙17 : 변경 가능성을 최소화하라 변경 가능한 클래스로 만들 타당한 이유가 없다면, 반드시 변경 불가능 클래스로 만들어야 한다.\n자바 플랫폼 라이브러리중 String, 기본 자료형 클래스 BigInteger, BigDecimal 등은 변경 불가능 클래스여서 그 객체를 수정할 수 없다.\n변경 불가능 클래스를 만드는 이유는 설계하기 쉽고, 구현하기 쉬우며, 사용하기도 쉽다.\n변경 불가능 클래스 만드는 5가지 규칙 1. 객체 상태를 변경하는 메서드(setter 등)를 제공하지 않는다. 2. 계승할 수 없도록 한다. (계승을 금지하려면 보통 클래스를 final로 선언) 3. 모든 필드를 final로 선언한다. 4. 모든 필드를 private으로 선언한다. 5. 변경 가능 컴포넌트에 대한 독점적 접근권을 보장한다.\n다음 코드를 보자\npublic final class Complex{ private final double re; private final double im; public Complex(double re, double im){ this.re = re; this.im = im; } //수정자는 없고 접근자만 있다.  public Complex add(Complex c){ return new Complex(re + c.re, im + c.im); } public Complex subtract(Complex c){ return new Complex(re - c.re, im - c.im); } ... } 사칙연산 각각은 this 객체를 변경하는 대신 새로운 Complex 객체를 만들어 반환하도록 구현되어 있음에 유의해라. 대부분의 변경 불가능 클래스가 따르는 패턴이다.\n함수형 접근법으로도 알려져 있는데 피연산자를 변경하는 대신, 연산을 적용한 결과를 새롭게 만들어 반환하기 때문이다. 생성될 때 부여된 한 가지 상태만 갖는다. 따라서 변경 불가능 객체는 단순하다.\n또한 변경 불가능 객체는 스레드에 안전할 수 밖에 없다. 어떤 동기화도 필요 없으며, 변경 불가능한 객체는 자유롭게 공유 할 수 있다. 그렇게 하는 한 가지 쉬운 방법은, 자주 사용되는 값을 public static final 상수로 만들어 제공하는 것이다.\n한 단계 더 개선하자면, 자주 사용하는 객체를 캐시하여 정적 팩터리(규칙1)를 제공할 수 있다. 이런 정적 팩토리 메서드를 사용하면 클라이언트는 새로운 객체를 만드는 대신 기존 객체들을 공유하게 되므로 메모리 요구량과 쓰레기 수집 비용이 줄어든다.\n변경 불가능한 객체를 자유롭게 공유할 수 있다는 것은, 방어적 복사본을 만들 필요없고 clone 메서드나 복사 생성자 또한 만들 필요도 없다.\n변경 불가능 객체의 유일한 단점은 값마다 별도의 객체를 만들어야 한다는 점이다. ex) String 클래스\nString s1 = \u0026#34;a\u0026#34;; String s2 = \u0026#34;b\u0026#34;; String s3 = s1 + s2; //새로운 객체 생성 변경 가능한 public 동료 클래스를 제공하는 것이 최선이다. StringBuilder\n하위 클래스 정의가 불가능하도록 하려면 보통 클래스를 final로 선언하면 되지만, 그보다 더 유연한 방법도 있다. 모든 생성자를 private나 package-private로 선언하고 public 생성자 대신 public 정적 팩토리를 제공하는 것이다.\n//생성자 대신 정적 팩토리 메서드를 제공하는 변경 불가능 클래스 public class Complex{ private final double re; private final double im; //private 생성자  private Complex(double re, double im){ this.re = re; this.im = im; } //정적 팩토리 메서드  public static Complex valueOf(double re, double im){ return new Complex(re, im); } ... } 추가적으로 한가지 더 주의할 것은 직렬화에 관계된 부분이다. 변경 불가능 클래스가 Serializable 인터페이스를 구현하도록 했고, 해당 클래스에 변경 가능 객체를 참조하는 필드가 있다면, readObject 메서드나 readResolve 메서드를 반드시 제공해야 한다. 아니면 ObjectOutputStream.writeUnshared나 ObjectInputStream.readInshared 메서드를 반드시 사용해야 한다.\n규칙18 : Favor composition over inheritance(계승 대신 구성하라) 이 책에서 inheritance라는 용어는 extends 한다는 소리다. 어떤 클래스가 다른 인터페이스를 implements 하거나 어떤 인터페이스가 다른 인터페이스를 extends하는 경우에는 적용되지 않는다는 얘기다.\n일반적인 객체 생성 가능 클래스라면, 해당 클래스가 속한 패키지 밖에서 계승을 시도하는 것은 위험하다.\n메서드 호출과 달리, 계승은 캡슐화 원칙을 위반한다. 하위 클래스가 정상 동작하기 위해서는 상위 클래스의 구현에 의존할 수밖에 없다. 상위 클래스의 구현은 릴리즈가 거듭되면서 바뀔 수 있는데 그러다 보면 하위 클래스 코드는 수정된 적이 없어도 망가질 수 있다.\n구체적인 사례를 보자. HashSet 객체가 생성된 이후 얼마나 많은 요소가 추가 되었는지를 질의한다고 했을 때, 계승을 이용해 HashSet에 삽입된 요소의 수를 추적하는 필드와 그 필드에 대한 접근자를 갖는 클래스를 만들었다. HashSet 클래스에는 원소를 추가하는 데 쓰이는 add와 addAll이라는 메서드가 있으므로, 그 두 메서드를 재정의하였다.\n//계승을 잘못 사용한 사례 class InstrumentedHashSet\u0026lt;E\u0026gt; extends HashSet\u0026lt;E\u0026gt; { //요소를 삽입하려 한 횟수 \tprivate int addCount = 0; //생성자 \tpublic InstrumentedHashSet() { } public InstrumentedHashSet(int initCap, float loadFactor) { super(initCap, loadFactor); } @Override public boolean add(E e) { addCount++; return super.add(e); } @Override public boolean addAll(Collection\u0026lt;? extends E\u0026gt; c) { addCount += c.size(); return super.addAll(c); } public int getAddCount() { return addCount; } } public class TestMain { public static void main(String[] args) { InstrumentedHashSet\u0026lt;String\u0026gt; s = new InstrumentedHashSet\u0026lt;\u0026gt;(); s.addAll(List.of(\u0026#34;Snap\u0026#34;,\u0026#34;Crackle\u0026#34;,\u0026#34;Pop\u0026#34;)); // - third edition \t// s.addAll(Arrays.asList(\u0026#34;1\u0026#34;,\u0026#34;2\u0026#34;,\u0026#34;3\u0026#34;)); - second edition \t} } cf) Note that we create a list using the static factory method List.of, which was added in Java 9\n위 코드를 실행하면 gettAddCount 메서드는 3이 아닌 6을 반환한다. HashSet의 addAll 메서드는 add 메서드를 통해 구현되어 있기 때문이다. addAll 메서드에서 super.addAll을 호출하면, InstrumentedHashSet에서 재정의한 add 메서드를 삽입할 원소마다 호출한다. 결국 중복해서 카운트가 진행하게 되는것이다.\n@Override public boolean add(E e) { addCount++; return super.add(e); } @Override public boolean addAll(Collection\u0026lt;? extends E\u0026gt; c) { try { for (E next : c) { add(next); } return true; } catch (Exception e) { return false; } } public int getAddCount() { return addCount; } addAll 메서드가 인자에 담긴 각 원소마다 add를 호출하도록 변경하면 조금 더 낫긴 할 것이다. 그렇게 하면 HashSet의 addAll 메서드가 add를 이용하는지는 상관없이 올바른 결과가 나올 것이다. HashSet의 addAll을 호출하지 않기 때문이다.\n하지만 이 기법이 모든 문제를 해결하는 것은 아니다. 결국 자기 메서드를 호출 할 수도 있고 그렇지 않을 수도 있는 상위 클래스 메서드를 수정하는 것인데, 어려울 뿐 아니라 시간도 많이 걸리고, 오류가 나기도 쉬운 작업이다. 또한 이 기법은 항상 사용할 수 있는 것은 아니다. 어떤 메서드는 private 필드를 사용하지 않으면 구현될 수 없는 경우도 있기 때문이다(하위 클래스에서 접근 못함).\n이와 관련해서 하위 클래스 구현을 망가뜨릴 수 있는 또 한 가지 요인은, 다음 릴리스에는 상위 클래스에 새로운 메서드가 추가될 수 있다는 것이다. 새 릴리스에 추가된 상위 클래스 메서드가 재수 없게도 하위 클래스에 정의한 메서드와 같은 시그너처(signature)인데 반환값 자료형만 다를 경우, 우리가 만든 하위 클래스는 더 이상 컴파일 되지 않을 것이다.\n다행히도 지금껏 설명한 모든 문제를 피할 방법이 있다. 기존 클래스를 계승하는 대신, 새로운 클래스에 기존 클래스 객체를 참조하는 private 필드를 하나 두는 것이다. 이런 설계 기법을 구성(composition) 이라고 부르는데, 기존 클래스가 새 클래스의 일부(component)가 되기 때문이다.\nclass InstrumentedSet\u0026lt;E\u0026gt; extends ForwardingSet\u0026lt;E\u0026gt; { private int addCount = 0; public InstrumentedSet(Set\u0026lt;E\u0026gt; s) { super(s); } @Override public boolean add(E e) { addCount++; return super.add(e); } @Override public boolean addAll(Collection\u0026lt;? extends E\u0026gt; c) { addCount += c.size(); return super.addAll(c); } public int getAddCount() { return addCount; } } class ForwardingSet\u0026lt;E\u0026gt; implements Set\u0026lt;E\u0026gt; { private final Set\u0026lt;E\u0026gt; s; public ForwardingSet(Set\u0026lt;E\u0026gt; s) {this.s = s;} @Override public int size() {\treturn s.size();} @Override public boolean isEmpty() {return s.isEmpty();} @Override public boolean contains(Object o) {return s.contains(o);} @Override public Iterator\u0026lt;E\u0026gt; iterator() {return s.iterator();} @Override public Object[] toArray() {return s.toArray();} @Override public \u0026lt;T\u0026gt; T[] toArray(T[] a) {return s.toArray(a);} @Override public boolean add(E e) {return s.add(e);} @Override public boolean remove(Object o) {return s.remove(o);} @Override public boolean containsAll(Collection\u0026lt;?\u0026gt; c) {return s.containsAll(c);} @Override public boolean addAll(Collection\u0026lt;? extends E\u0026gt; c) {return s.addAll(c);} @Override public boolean retainAll(Collection\u0026lt;?\u0026gt; c) {return s.retainAll(c);} @Override public boolean removeAll(Collection\u0026lt;?\u0026gt; c) {return s.removeAll(c);} @Override public void clear() {s.clear();} } public class TestMain { public static void main(String[] args) { InstrumentedSet\u0026lt;String\u0026gt; s = new InstrumentedSet\u0026lt;\u0026gt;(new HashSet\u0026lt;\u0026gt;(10)); s.addAll(Arrays.asList(\u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34;)); System.out.println(s.getAddCount()); } } 기존 코드를 유지하고, extends만 ForwardingSet으로 바꿔주면 정상적으로 동작한다. 그런데 기존에 내가 생각했던 구성(composition)은 아래 코드다.\nclass InstrumentedSet\u0026lt;E\u0026gt; { private Set\u0026lt;E\u0026gt; set; private int addCount = 0; public InstrumentedSet(Set\u0026lt;E\u0026gt; set) { this.set = set; } public boolean add(E e) { addCount++; return set.add(e); } public boolean addAll(Collection\u0026lt;? extends E\u0026gt; c) { addCount += c.size(); return set.addAll(c); } public int getAddCount() { return addCount; } } public class TestMain { public static void main(String[] args) { InstrumentedSet\u0026lt;String\u0026gt; s = new InstrumentedSet\u0026lt;\u0026gt;(new HashSet\u0026lt;\u0026gt;(10)); s.addAll(Arrays.asList(\u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34;)); System.out.println(s.getAddCount()); } } 포장(wrapper) 클래스에는 단점이 별로 없으나, 콜백 프레임워크와 함께 사용하기에는 적합하지 않다. 콜백 프레임워크에서 객체는 자기 자신에 대한 참조를 다른 객체에 넘겨, 나중에 필요할 때 콜백하도록 요청한다. 포장된(wrapped) 객체는 포장 객체에 대해서는 모르기 때문에, 자기 자신에 대한 참조(this)를 전달할 것이다. 따라서 역호출(callback) 과정에서 포장 객체는 제외된다.\n계승은 하위 클래스가 상위 클래스의 하위 자료형(subtype)이 활실한 경우에만 바람직하다. 만일 A를 계승하고 싶다면, B는 확실히 A인가? 질문에 확실하게 그렇다고 답할 수 있어야 한다. 자바 플랫폼 라이브러리에는 이 원칙을 위반하는 사례들이 많다. 예를 들어 스택(stack)은 벡터(vector)가 아니므로 Stack은 Vector를 계승하면 안 된다. 마찬가지로 속성 리스트(property list)는 해시 테이블이 아니므로 Properties는 Hashtable을 계승하면 안 된다. 모두 구성 기법이 더 적절하다.\n구성 기법에 적절한 곳에 계승을 사용하면 구현 세부사항이 쓸데없이 노출된다. 더 심각한 이슈는 클라이언트가 내부 구현 세부사항에 접근할 수 있다는 것이다. 예를 들어 아래와 같이 Properties 객체에 대한 참조 변수 p가 있을 때\nProperties p = new Properties(); p.getProperty(\u0026#34;ybs\u0026#34;); // properties p.get(\u0026#34;ybs\u0026#34;); // hashtable 두 개의 메서드는 다른 결과를 반환할 수도 있다. p.getProperty(\u0026quot;ybs\u0026quot;);는 기본값(default)를 고려하지만, Hashtable에서 계승된 두 번째 메서드는 그렇지 않기 때문이다. 가장 심각한 문제는 클라이언트가 상위 클래스 상태를 직접 변경하여 하위 클래스의 불변식을 깰 수 있다는 것이다. 상위 클래스 Hashtable에 직접 접근해서 상태를 변경시키면 Properties 클래스의 불변식은 깨질 수 있다.\n구성 대신 계승을 사용하려 할 때 반드시 물어야 할 마지막 질문들은 이런 것이다. 계승할 클래스의 API에 문제가 있는가? 그렇다면, 그 문제들이 계속 새 API의 일부가 되어도 상관없겠는가? 계승 메커니즘은 상위클래스의 문제를 하위 클래스에 전파시킨다. 반면 구성 기법은 그런 약점을 감추는 새로운 API를 설계할 수 있도록 해 준다.\n규칙19 : 계승을 위한 설계와 문서를 갖추거나, 그럴 수 없다면 계승을 금지하라 계승을 허용하려면 첫째, 생성자는 직접적이건 간접적이건 재정의 가능 메서드를 호출해서는 안된다.\npublic class Super{ //생성자가 재정의 가능 메서드를 호출하는 잘못된 사례  public Super(){ overrideMe(); } public void overrideMe(){ } } public final class Sub extends Super{ private final Date date; Sub(){ date = new Date(); } //상위 클래스 생성자가 호출하게 되는 재정의 메서드  @Override public void overrideMe(){ System.out.println(date); } public static void main(String[] args){ Sub sub = new Sub(); sub.overrideMe(); } } 상위 클래스 생성자는 하위 클래스 생성자보다 먼저 실행되므로, 하위 클래스에서 재정의한 overrideMe 메서드는 하위 클래스 생성자가 실행되기 전에 호출될 것이다. 그러므로 하위 클래스 생성자에서 date 객체를 생성하지만 그 전에 상위 클래스 생성자에서 overrideMe 메서드를 호출했고, date 객체는 생성 전이기 때문에 null을 출력하게 된다.\n계승을 반드시 허용해야 한다고 느껴지면, 재정의 가능 메서드는 절대로 호출하지 않도록 하고 그 사실을 반드시 문서에 남겨라.\n규칙20 : 추상 클래스 대신 인터페이스를 사용하라 인터페이스는 믹스인(mixin)을 정의하는 데 이상적이다. 믹스인은 클래스가 주 자료형(primary type)이외에 추가로 구현할 수 있는 자료형으로, 어떤 선택적 기능을 제공한다는 사실을 선언하기 위해 쓰인다. 예를 들어 Comparable은 어떤 클래스가 자기 객체는 다른 객체와의 비교 결과에 따른 순서를 갖는다고 선언할 때 쓰는 믹스인 인터페이스다.\n이런 인터페이스를 믹스인이라 부르는 것은, 자료형의 주된 기능에 선택적인 기능을 \u0026ldquo;혼합(mix in)\u0026ldquo;할 수 있도록 하기 때문이다.\n추상 골격 구현 클래스를 중요 인터페이스마다 두면, 인터페이스의 장점과 추상 클래스의 장점을 결합 할 수 있다. 예를 들어, 컬렉션 프레임워크에는 인터페이스별로 골격 구현 클래스들이 하나씩 제공된다. (AbstractCollection, AbstractSet, AbstractList, AbstractMap)\n골격 구현 클래스가 있다면 해당 클래스를 사용해 인터페이스를 구현하는 것이 가장 분명한 프로그래밍 방법이다. (골격 구현 클래스는 계승 용도로 설계하는 클래스이다.)\n추상 클래스가 인터페이스보다 나은 점이 한 가지 있는데, 인터페이스는 추상 클래스가 발전시키기 쉽다는 것이다. 새로운 메서드를 추가하고 싶다면 적당한 기본 구현 코드를 담은 메서드를 언제든 추가할 수 있고 해당 추상 클래스를 계승하는 모든 클래스는 그 즉시 새로운 메서드를 제공하게 될 것이다. 일반적으로 인터페이스를 구현하는 기존 클래스를 깨뜨리지 않고 새로운 메서드를 인터페이스에 추가할 방법은 없다.(자바 1.8부터는 \u0026lsquo;default\u0026rsquo; 메서드를 통해 기존 클래스를 깨뜨리지 않고 새 메서드를 추가할 수 있다.)\nitem21 : Design interfaces for posterity 규칙22 : 인터페이스는 자료형을 정의할 때만 사용하라 인터페이스를 구현하는 클래스를 만들게 되면, 그 인터페이스는 해당 클래스의 객체를 참조할 수 있는 자료형(type) 역할을 하게 된다. 인터페이스를 구현해 클래스를 만든다는 것은, 해당 클래스의 객체로 어떤 일을 할 수 있는지 클라이언트에게 알리는 행위다. 다른 목적은 적절치 못하다. (상수 인터페이스, 메서드가 없고 static final 필드만 있는 형태)\n규칙23 : Prefer class hierarchies to tagged classes(태그 달린 클래스 대신 클래스 계층을 활용하라) 때로 우리는 두 가지 이상의 기능을 가지고 있으며, 그 중 어떤 기능을 제공하는지 표시하는 태그(tag)가 달린 클래스를 만날 때가 있다.\nclass Figure { enum Shape {RECTANGLE, CIRCLE}; // 어떤 모양인지 나타내는 태그 필드 \tfinal Shape shape; // 태그가 RECTANGLE일 때만 사용되는 필드들 \tdouble length; double width; // 태그가 CIRCLE일 때만 사용되는 필드들 \tdouble radius; // 원을 만드는 생성자 \tFigure(double radius) { shape = Shape.CIRCLE; this.radius = radius; } // 사각형을 만드는 생성자 \tFigure(double length, double width) { shape = Shape.RECTANGLE; this.length = length; this.width = width; } double area() { switch (shape) { case CIRCLE: return length * width; case RECTANGLE: return Math.PI * (radius * radius);default: throw new AssertionError(); } } } 태그 달린 클래스에는 다양한 문제가 있다. enum 선언, 태그 필드, switch 문 등의 상투적인(boilerplate) 코드가 반복되는 클래스가 만들어지며, 서로 다른 기능을 위한 코드가 한 클래스에 모여 있으니 가독성도 떨어진다.\n그래서 아래 코드와 같이 클래스 계층을 활용하면 단순 명료하며, 상투적인 코드도 없다.\nabstract class Figure { abstract double area(); } class Circle extends Figure { final double radius; public Circle(double radius) { this.radius = radius; } @Override double area() { return Math.PI * (radius * radius); } } class Rectangle extends Figure { final double length; final double width; public Rectangle(double length, double width) { this.length = length; this.width = width; } @Override double area() { return length * width; } } 클래스 계층의 또 다른 장점은 자료형 간의 자연스러운 계층 관계를 반영할 수 있어서 유연성이 높아지고 컴파일 시에 형 검사(type checking)를 하기 용이하다는 것이다. 그리고 태그 기반 클래스 대신 클래스 계층을 이용하면 정사각형이 특별한 유형의 사각형임을 표현할 수 있다(사각형과 정사각형이 전부 변경 불가능 객체를 만드는 클래스라고 가정).\nclass Square extends Rectangle { public Square(double length) { super(length, length); } @Override double area() { return length * length; } } 한 클래스에 여러 기능이 있어서 태그로써 구분하는 방법쓰지 말고 계층 형태로 분리시켜라.\n규칙24 : 멤버 클래스는 가능하면 static으로 선언하라 중첩 클래스는 다른 클래스 안에 정의된 클래스다. 1.정적(static) 멤버 클래스\n1. 정적 멤버 클래스를 제외한 나머지는 전부 내부 클래스다. 정적(static) 멤버 클래스는 어쩌다 다른 클래스 안에 선언된 일반 클래스라고 생각해도 된다. 정적 멤버 클래스는 바깥 클래스의 모든 멤버에(private로 선언된 것까지도) 접근할 수 있다. 정적 멤버 클래스를 private로 선언했다면 해당 중첩 클래스에 접근할 수 있는 것은 바깥 클래스뿐일 것이다. 2. 중첩된 클래스의 객체가 바깥 클래스 객체와 독립적으로 존재할 수 있도록 하려면 중첩 클래스는 반드시 정적 멤버 클래스로 선언해야 한다. 3. private 정적 멤버 클래스는 바깥 클래스 객체의 컴포넌트를 표현하는 데 흔히 쓰인다. 예를 들어 키와 값을 연관 짓는 Map 객체를 생각해 보자. Map을 구현하는 많은 클래스는 내부적으로 키-값 쌍을 보관하는 Entry 객체를 사용한다. 각 Entry 객체는 특정 맵에 속할 것이지만, Entry 객체의 메서드(getKey, getValue, setValue 등)는 맵 객체에 접근할 필요가 없다. 따라서 Entry를 비-정적 멤버 클래스로 표현하는 것은 낭비다. private 정적 멤버 클래스가 최선이다. 실수로 static 키워드를 빼먹어도 맵은 여전히 동작할 것이지만, 각 Entry 객체 안에는 바깥 객체, 그러니까 Map을 가리키는 참조가 생겨서 공간과 시간이 낭비될 것이다.  2.비-정적 멤버 클래스\n1. 비-정적 멤버 클래스 객체는 바깥 클래스 객체와 자동적으로 연결된다. 비-정적 멤버 클래스 안에서는 바깥 클래스의 메서드를 호출할 수도 있고, this 한정 구문을 통해 바깥 객체에 대한 참조를 획득할 수도 있다. 2. 비-정적 멤버 클래스의 객체는 바깥 클래스 객체 없이는 존재할 수 없다. 3. 비-정적 멤버 클래스 객체와 바깥 객체와의 연결은 비-정적 멤버 클래스의 객체가 만들어지는 순간에 확립되고, 그 뒤에는 변경할 수 없다. 4. 비-정적 멤버 클래스는 어댑터를 정의할 때 많이 쓰인다. 바깥 클래스 객체를 다른 클래스 객체인 것처럼 보이게 하는 용도다. 예를 들어 Map 인터페이스를 구현하는 클래스들은 비-정적 멤버 클래스를 사용해 컬렉션 뷰를 구현한다.  3.익명 클래스\n1. 멤버로 선언하지 않으며, 사용하는 순간에 선언하고 객체를 만든다. 익명 클래스는 비-정적 문맥 안에서 사용될 때만 바깥 객체를 갖는다. 그러나 정적 문맥 안에서 사용된다 해도 static 멤버를 가질 수는 없다.  4.지역 클래스\n 네 종류의 중첩 클래스 가운데 사용 빈도가 가장 낮다. 지역 변수가 선언될 수 있는 곳이라면 어디서든 선언가능하다. 익명 클래스처럼 비-정적 문맥에서 정의했을 때만 바깥 객체를 갖는다.  바깥 클래스 객체에 접근할 필요가 없는 멤버 클래스를 정의할 때는 항상 선언문 앞에 static을 붙여서 비-정적 멤버 클래스대신 정적 멤버 클래스로 만들자.\nstatic을 생략하면 모든 객체는 내부적으로 바깥 객체에 대한 참조를 유지하게 된다. 그 덕분에 시간과 공간 요구량이 늘어나며, 바깥 객체에 대한 쓰레기 수집이 힘들어진다. 비-정적 멤버 클래스객체는 바깥 객체 없이는 생성할 수 없다는 문제도 있다.\n멤버 클래스가 API 클래스의 public이나 protected 멤버인 경우에는, 정적 멤버 클래스로 만들 것인지 아니면 비-정적 멤버 클래스로 만들 것인지가 더욱 중요하다. 일단 API에 포함되고 나면, 이진 호환성을 깨지 않고는 다음 릴리스에서 비-정적 멤버 클래스를 정적 멤버 클래스로 바꿀 방법이 없다.\nitem 25 : Limit source files to a single top-level class "
},
{
	"uri": "/toby_spring/%E1%84%90%E1%85%A6%E1%84%89%E1%85%B3%E1%84%90%E1%85%B3/",
	"title": "테스트",
	"tags": [],
	"description": "",
	"content": "웹을 통한 DAO 테스트 방법의 문제점 보통 웹 프로그램에서 사용하는 DAO 테스트 방법은 다음과 같다. 서비스 계층, MVC 프레젠테이션 계층까지 포함한 모든 입출력 기능을 대충이라도 코드로 다 만든다. 이렇게 웹 화면을 통해 값을 입력하고, 기능을 수행하고, 결과를 확인하는 방법은 가장 흔히 쓰이는 방법이지만 DAO에 대한 테스트로서는 단점이 너무 많다. DAO뿐만 아니라 서비스 클래스. 컨트롤러, 뷰 등 모든 레이어의 기능을 다 만들고 나서야 테스트가 가능하다는 점이 가장 큰 문제점이다.\nJUnit 프레임워크가 요구하는 조건 두가지, 첫째는 메서드가 public으로 선언되어야 하고 두번째는 @Test 애노테이션 붙여줘야한다.(하나의 클래스에 안에 여러 개의 테스트 메서드가 들어가는 것도 허용하는데 리턴 값이 void형이고 파라미터가 없다는 조건을 지키면 된다.)\n테스트의 결과를 검증하는 if/else대신 JUnit이 제공하는 assertThat을 사용한다.\ncf) 인텔리제이 IDE에서 assertThat import 자동으로 안해준다.\nimport static org.hamcrest.CoreMatchers.is; import static org.junit.Assert.assertThat; assertThat(user2.getName(), is(user.getName())); JUnit은 특정한 테스트 메서드의 실행 순서를 보장해주지 않는다. 데스트의 결과가 테스트 실행 순서에 영향을 받는다면 테스트를 잘못 만든 것이다.\n모든 테스트는 실행 순서와 상관없이 독립적으로 항상 동일한 결과를 낼 수 있도록 해야 한다.\n예외가 반드시 발생해야 하는 경우를 테스트하고 싶을 때는 @Test 애노테이션의 expected 엘리먼트를 사용하면 된다. expected는 테스트 메서드 실행 중에 발생하리라 기대하는 예외 클래스를 넣어주면 된다.\n@Test(expected=EmptyResultDataAccessException.class) public void getUserFailure() throws SQLException{ ... dao.get(\u0026#34;unknown_id\u0026#34;); } @Before @After테스트 코드들의 공통적인 작업을 처리하는 애노테이션\n픽스처(fixture) : 테스트를 수행하는 데 필요한 정보나 오브젝트\npublic class UserDaoTest{ private UserDao dao; private User user1; private User user2; private User user3; @Before public void setUp(){ ... this.user1 = new User(\u0026#34;gyumee\u0026#34;, \u0026#34;박성철\u0026#34;, \u0026#34;springno1\u0026#34;); this.user2 = new User(\u0026#34;leegw700\u0026#34;, \u0026#34;이길원\u0026#34;, \u0026#34;springno2\u0026#34;); this.user3 = new User(\u0026#34;bumjin\u0026#34;, \u0026#34;박범진\u0026#34;, \u0026#34;springno3\u0026#34;); } ... } JUnit은 테스트 클래스 전체에 걸쳐 딱 한 번만 실행되는 @BeforeClass 스태틱 메서드를 지원한다. 하지만 스프링은 JUnit을 이용하는 테스트 컨텍스트 프레임워크를 제공한다.\n@RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(locations=\u0026#34;/applicationContext.xml\u0026#34;) public class UserDaoTest{ @Autowired private ApplicationContext context; ... @Before public void setUp(){ System.out.println(context); System.out.println(this); } ... //테스트 3개 } SpringJUnit4ClassRunner라는 JUnit용 테스트 컨텍스트 프레임워크 확장 클래스를 지정해주면 JUnit이 테스트를 진행하는 중에 테스트가 사용할 애플리케이션 컨텍스트를 만들고 관리하는 작업을 진행해준다.\n위의 코드를 실행 시켜보면 테스트 3개마다 각각 setUp 메서드가 실행되고, context값은 항상 동일 한것을 확인할 수 있다. 하지만 this, UserDaoTest 오브젝트는 테스트 마다 새롭게 생성된다. JUnit은 테스트 메서드를 실행할 때마다 새로운 테스트 오브젝트를 만들기 때문이다.\n정말 실행할때마다 새로운 테스트 오브젝트를 만드는지 테스트해보자\npublic class JUnitTest{ static Set\u0026lt;JUnitTest\u0026gt; testObjects = new HashSet\u0026lt;JUnitTest\u0026gt;(); @Test public void test1(){ assertThat(testObjects, not(hasItem(this))); testObject.add(this); } @Test public void test2(){ assertThat(testObjects, not(hasItem(this))); testObject.add(this); } @Test public void test3(){ assertThat(testObjects, not(hasItem(this))); testObject.add(this); } }"
},
{
	"uri": "/java8_in_action/",
	"title": "Java 8 in Action",
	"tags": [],
	"description": "",
	"content": " Java 8 in Action "
},
{
	"uri": "/effective_java/%E1%84%8C%E1%85%A6%E1%84%82%E1%85%A6%E1%84%85%E1%85%B5%E1%86%A8/",
	"title": "제네릭",
	"tags": [],
	"description": "",
	"content": " 규칙26 : 새 코드에는 무인자 제네릭 자료형을 사용하지 마라 List\u0026lt;String\u0026gt;는 원소 자료형이 String인 리스트를 나타내는 형인자 자료형이다.\n각 제네릭 자료형은 새로운 무인자 자료형을 정의하는데, 무인자 자료형은 실 형인자 없이 사용되는 제네릭 자료형이다. ex) List list = new ArrayList\u0026lt;\u0026gt;(); 무인자 자료형 List는 제네릭 도입 이전의 인터페이스 자료형 List와 똑같이 동작한다. 하지만 제네릭 자료형을 형인자 없이 사용하면 안된다. 무인자 자료형을 쓰면 형 안전성이 사라지고, 제네릭의 장점 중 하나인 표현력 측면에서 손해를 보게 된다.\n제네릭 자료형을 쓰고 싶으나 실제 형 인자가 무엇인지는 모르거나 신경 쓰고 싶지 않을 때는 형 인자로 \u0026lsquo;?\u0026lsquo;를 쓰면 된다. 하지만 null 이외의 어떤 원소도 넣을 수 없기 때문에 한정적 와일드 카드 자료형을 쓰면 된다. ex) \u0026lt;T extends Number\u0026gt;\n새로 만든 코드에는 무인자 자료형을 쓰면 안된다고 했지만, 그 규칙에도 사소한 예외가 두 가지 있다. 제네릭 자료형 정보가 프로그램이 실행될 때는 지워지기 때문에 생긴 예외들이다. 첫 번째는 클래스 리터럴에는 반드시 무인자 자료형을 사용해야 한다. 자바 표준에 따르면, 클래스 리터럴에는 형인자 자료형을 쓸 수 없다.(배열 자료형이나 기본 자료형은 가능) 예를 들어, List.class, String[].class, int.class는 가능하지만 List\u0026lt;String\u0026gt;.class나 List\u0026lt;?\u0026gt;.class는 사용할 수 없다는 뜻이다. 두 번째는 제네릭 자료형에 instanceof 연산자를 적용할 때는 다음과 같이 하는 것이 좋다.\n//instanceof 연산자에는 무인자 자료형을 써도 OK if(o instanceof Set){ //무인자 자료형  Set\u0026lt;?\u0026gt; m = (Set\u0026lt;?\u0026gt;) o; //와일드카드 자료형 } 규칙27 : 무점검(unchecked warning) 경고를 제거하라 제거할 수 없는 경고 메세지는 형 안전성이 확실할 때만 @SupressWarnings(\u0026quot;unchecked\u0026quot;)애노테이션을 사용해 억제해라. 개별 지역 변수 선언부터 클래스 전체에까지, 어떤 크기의 단위에도 적용할 수 있지만 가능한 한 작은 범위에 적용해라. 보통은 변수 선언이나 아주 짧은 메서드 또는 생성자에 붙인다. 절대로 클래스 전체에 SupressWarnings을 적용하지 마라. 그리고 이 애노테이션을 사용할 때마다, 왜 형 안전성을 위반하지 않는지 밝히는 주석을 반드시 붙여라.\n무점검 경고를 무시하면 프로그램 실행 도중에 CalssCastException이 발생할 가능성이 있다.\n규칙28 : 배열 대신 리스트를 써라 배열은 공변 자료형이다. Sub가 Super의 하위 자료형이라면 Sub[]도 Super[]의 하위 자료형이라는 것이다. 반면 제네릭은 불변 자료형이다. Type1과 Type2가 있을 때, List\u0026lt;Type1\u0026gt;은 List\u0026lt;Type2\u0026gt;의 상위 자료형이나 하위 자료형이 될 수 없다.\n// 실행 중에 문제를 일으킴 Object[] objectArray = new Long[1]; objectArray[0] = \u0026#34;hello\u0026#34;; // ArrayStoreException 예외 발생  // 컴파일 되지 않는 코드 List\u0026lt;Object\u0026gt; ol = new ArrayList\u0026lt;Long\u0026gt;(); //자료형 불일치 ol.add(\u0026#34;hello\u0026#34;); 배열을 쓰면 실수를 저지른 사실을 프로그램 실행 중에나 알 수 있지만 리스트를 사용하면 컴파일 할 때 알 수 있다.\n배열과 제네릭의 두 번째로 중요한 차이는, 배열은 실체화(reification) 되는 자료형이라는 것이다. 즉, 배열의 각 원소의 자료형은 실행시간(runtime)에 결정된다는 것이다. 그래서 컴파일 타임에 형 안전성을 보장하지 못한다. 반면 제네릭은 삭제 과정을 통해 구현된다. 즉, 자료형에 관계된 조건들은 컴파일 시점에만 적용되고, 그 각 원소의 자료형 정보는 프로그램이 실행될 때는 삭제된다는 것이다. 자료형 삭제 덕에, 제네릭 자료형은 제네릭을 사용하지 않고 작성된 오래된 코드와도 문제없이 연동한다.\n이런 기본적인 차이점 때문에 배열과 제네릭은 섞어 쓰기 어렵다. 예를 들어, 제네릭 자료형이나 형인자 자료형, 또는 형인자의 배열을 생성하는 것은 문법적으로 허용되지 않는다. 즉, new List\u0026lt;E\u0026gt;[], new List\u0026lt;String\u0026gt;[], new E[]는 전부 컴파일되지 않는 코드다. 컴파일 하려고 하면 제네릭 배열 생성 (generic array creation)이라는 오류가 발생할 것이다.\n제네릭 배열 생성이 허용되지 않는 이유는 형 안전성(typesafe)이 보장되지 않기 때문이다.\n// 저네릭 배열 생성이 허용되지 않는 이유 - 아래의 코드는 컴파일 되지 않는다. List\u0026lt;String\u0026gt;[] stringList = new List\u0026lt;String\u0026gt;[1]; // (1) List\u0026lt;Integer\u0026gt; inList = Arrays.asList(42); // (2) Object[] objects = stringList; // (3) objects[0] = inList; // (4) String s = stringList[0].get(0); // (5) (1)은 generic array creation 오류가 발생한다. 하지만 문제없이 컴파일 된다고 가정해보자. 그러면 제네릭 배열이 만들어질 것이다. (2)는 하나의 원소를 갖는 배열 List\u0026lt;Integer\u0026gt;를 초기화한다. (3)은 List\u0026lt;String\u0026gt; 배열을 Object 배열 변수에 대입한다. 배열은 공변 자료형이므로 가능하다. (4)에서는 List\u0026lt;Integer\u0026gt;를 Object 배열에 있는 유일한 원소에 대입한다. 제네릭이 형 삭제(erasure)를 통해 구현되므로 여기에도 하자는 없다. List\u0026lt;Integer\u0026gt; 객체의 실행시점 자료형(runtime type)은 List이며, List\u0026lt;String\u0026gt;[]의 실행시점 자료형 또한 List[]이다. 이 대입문은 ArrayStoreException을 발생시키지 않는다. 문제는 지금부터다. List\u0026lt;String\u0026gt; 객체만을 담는다고 선언한 배열에 List\u0026lt;Integer\u0026gt;를 저장한 것이다. (5)에서는 이 배열 안에 있는 유일한 원소를 꺼내는 작업을 하고 있는데, 컴파일러는 꺼낸 원소의 자료형을 자동적으로 String으로 변환할 것이다. 사실은 Integer인데 말이다. 그러니 프로그램 실행 도중에 ClassCastException이 발생하고 말 것이다. 이런 일이 생기는 것을 막으려면 (1)처럼 제네릭 배열을 만들려고 하면 컴파일 할 때 오류가 발생해야 한다.\nE, List\u0026lt;E\u0026gt;, List\u0026lt;String\u0026gt;와 같은 자료형은 실체화 불가능 자료형으로 알려져 있다. 쉽게 말하자면, 프로그램이 실행될 때 해당 자료형을 표현하는 정보의 양이 컴파일 시점에 필요한 정보의 양보다 적은 자료형이 실체화 불가능 자료형이다. 실체화 가능한 형인자 자료형은 List\u0026lt;?\u0026gt;나 Map\u0026lt;?,?\u0026gt; 같은 비한정적 와일드카드 자료형 뿐이다. 쓸 일이 별로 없긴 하지만, 비한정적 와일드카드 자료형의 배열은 문법상 허용된다.\n제네릭 배열을 만들 수 없다는 것이 짜증스럽게 느껴질 수도 있다. 예를 들자면, 제네릭 자료형에 담긴 원소들의 자료형으로 만든 배열을 반환하는 것은 일반적으로 불가능하다. 또한 제네릭 자료형을 varargs 메서드와 함께 사용하면 혼란스런 경고 메세지들을 보게된다. varargs 메서드를 호출할 때마다 varargs 인자들을 담을 배열이 생성되기 때문이다(자바 1.7부터는 이런 상황에서 발생하는 경고 메세지가 개선되었다). 이런 경고는 억제하거나, 제네릭을 varargs와 혼용하지 않도록 주의하는 것 말고는 처리할 방법이 별로 없다.\n3rd edition추가 : The SafeVarargs annotation can be used to address this issue (Item 32)\n제네릭 배열 생성 오류에 대한 가장 좋은 해결책은 보통 E[] 대신 List\u0026lt;E\u0026gt;를 쓰는 것이다. 성능이 저하되거나 코드가 길어질 수는 있겠으나, 형 안전성과 호환성은 좋아진다.\n예를 들어, 아래와 같이 생성자로 Collection을 받고 choose() 메서드로 랜덤으로 선택된 collection element를 리턴한다고 해보자. 생성자에 전달하는 컬렉션에 따라 선택기를 게임 다이, 마술 8 볼 또는 몬테카를로 시뮬레이션을위한 데이터 소스로 사용할 수 있다.\n// 제네릭을 필요로 하는 클래스 public class Chooser1 { private final Object[] choiceArray; public Chooser1(Collection choices) { this.choiceArray = choices.toArray(); } public Object choose() { Random rnd = ThreadLocalRandom.current(); int i = rnd.nextInt(choiceArray.length); Object o = choiceArray[i]; return o; } } 이 클래스를 사용하려면 메서드 호출을 사용할 때마다 Object에서 반환되는 choose 메서드의 반환 값을 원하는 형식으로 캐스팅해야하며 형식이 잘못되면 런타임에 캐스트가 실패한다. Item 29의 조언을 받아 Chooser1를 제네릭으로 만든다.\n// A first cut at making Chooser genric - won\u0026#39;t compile public class Chooser2\u0026lt;T\u0026gt; { private final T[] choiceArray; public Chooser2(Collection\u0026lt;T\u0026gt; choices) { this.choiceArray = choices.toArray(); } public Object choose() { Random rnd = ThreadLocalRandom.current(); return choiceArray[rnd.nextInt(choiceArray.length)]; } } 컴파일을 시도하면 다음과 같은 에러 메세지가 나온다.\nIncompatible types. Required: T[] Found: java.lang.Object[]  아래와 같이 수정하면 에러는 없어지지만 경고가 뜬다.\nthis.choiceArray = (T[])choices.toArray(); Unchecked cast: 'java.lang.Object[]' to 'T[]  컴파일러는 런타임에 프로그램이 어떤 유형의 T를 나타내는지 알 수 없으므로 런타임 시 캐스트의 안전성을 보장할 수 없다고 알려준다. 런타임 시 제네릭에서 요소 유형 정보가 지워진다는 것을 기억해라.\nunchecked cast warning을 지우기 위해 배열 대신 리스트를 사용해라.\npublic class Chooser3\u0026lt;T\u0026gt; { private final List\u0026lt;T\u0026gt; choiceList; public Chooser3(Collection\u0026lt;T\u0026gt; choices) { this.choiceList = new ArrayList\u0026lt;\u0026gt;(choices); } public T choose() { Random rnd = ThreadLocalRandom.current(); int size = choiceList.size(); int index = rnd.nextInt(size); return choiceList.get(index); } } 이 버전은 좀 더 길고, 다소 느린 편이지만, 런타임시 ClassCastException을 얻지 못할 것이라는 점에 마음이 편한 가치가 있다.\n요약하면 제네릭과 배열은 자료형 규칙이 다르다. 배열은 공변 자료형이자 실체화 가능 자료형이다. 제네릭은 불변 자료형이며, 실행 시간에 형인자의 정보는 삭제된다. 따라서 배열은 컴파일 시간에 형 안전성을 보장하지 못하며, 제네릭은 그 반대다. 일반적으로 배열과 제네릭은 쉽게 혼용할 수 없다. 만일 배열과 제네릭을 뒤섞어 쓰다가 컴파일 오류나 경고 메세지를 만나게 되면, 배열을 리스트로 바꿔야겠다는 생각이 본능적으로 들어야한다.\n규칙29 : 가능하면 제네릭 자료형으로 만들 것 클래스를 제네릭화하는 첫 번째 단계는 선언부에 형인자를 추가하는 것이다. public class Stack\u0026lt;E\u0026gt; 그 다음 단계는 Object를 자료형으로 사용하는 부분들을 전부 찾아서, 형인자 E로 대체하고 컴파일해 보는 것이다.\nE와 같은 실체화 불가능 자료형으로는 배열을 생성할 수 없다.\nprivate E[] elements; private static final int DEFAULT_INITIAL_CAPACITY = 16; public Stack(){ elements = new E[DEFAULT_INITIAL_CAPACITY]; //문제!! } //이렇게 해야한다 @SuppressWarnings(\u0026#34;unchecked\u0026#34;) public Stack(){ elements = (E[])new Object[DEFAULT_INITIAL_CAPACITY]; } 위의 방식이 일반적으로 형 안전성을 보장하는 방법이 아니지만(컴파일러가 프로그램의 형 안전성을 입증할 수 없어서) 개발자가 프로그램의 형 안전성을 해치지 않음을 확실히 해야 한다. 위에서 문제가 되고 있는 배열 elements는 private 필드이고 클라이언트에 반환되지 않으며 다른 어떤 메서드에도 전달되지 않는다. push 메서드에 전달되는 원소만이 배열에 저장되며, 그 타입은 전부 E다. 따라서 무점검 형변환을 해도 아무런 문제가 없다. 무점검 형변환이 안전함을 증명했다면, 경고를 억제하되 범위는 최소한으로 줄요야 한다.(규칙 24)\n규칙30 : 가능하면 제네릭 메서드로 만들 것 형인자를 선언하는 형인자 목록은 메서드의 수정자와 반환값 자료형 사이에 둔다.public static \u0026lt;E\u0026gt; Set\u0026lt;E\u0026gt; union(Set\u0026lt;E\u0026gt; s1, Set\u0026lt;E\u0026gt; s2)\n\u0026lt;T extends Comparable\u0026lt;T\u0026gt;\u0026gt; 재귀적 자료형 한정이라 한다. \u0026ldquo;자기 자신과 비교 가능한 모든 자료형 T\u0026rdquo;라는 뜻으로 읽을 수 있다.\n규칙31 : 한정적 와일드카드를 써서 API 유연성을 높여라 PECS(Produce - extends, Consumer - Super)\n//E 객체 생산자 역할을 하는 인자에 대한 와일드카드 자료형 public void pushAll(Iterable\u0026lt;? extends E\u0026gt; src){ for(E e : src) push(e); } //E의 소비자 구실을 하는 인자에 대한 와일드카드 자료형 public void popAll(Collection\u0026lt;? super E\u0026gt; dst){ while(!isEmpty()) dst.add(pop()); } Stack 예제에서 pushAll의 인자 src는 스택이 사용할 E 형의 객체를 만드는 생산자이므로 src의 자료형은 Iterable\u0026lt;? extends E\u0026gt;가 되어야 한다. popAll의 dst는 Stack에 보관된 E 객체를 소비하므로 dst의 자료형은 Collection\u0026lt;? super E\u0026gt;가 되어야 한다.\npublic static \u0026lt;E\u0026gt; Set\u0026lt;E\u0026gt; union(Set\u0026lt;? extends E\u0026gt; s1, Set\u0026lt;? extends E\u0026gt; s2) 반환값에는 와일드카드 자료형을 쓰면 안 된다. 클라이언트 코드 안에도 와일드카드 자료형을 명시해야 하기 때문이다.\n이제 규칙 27에서 다룬 max 메서드를 고쳐보자 public static \u0026lt;T extends Comparable\u0026lt;? super T\u0026gt;\u0026gt; T max(List\u0026lt;? extends T\u0026gt; list 이 리스트는 T 객체의 생산자이므로 자료형을 List\u0026lt;T\u0026gt;에서 List\u0026lt;? extends T\u0026gt;로 바꾸었다. 까다로운 부분은 형인자 T에 PECS 원칙을 적용한 과정이다. T에 대한 Comparable은 T 객체를 소비하므로(그리고 순서 관계를 나타내는 정수 값을 생산하므로) 형인자 자료형 Comparable\u0026lt;T\u0026gt;를 한정적 와일드카드 자료형 Comparable\u0026lt;? super T\u0026gt;로 바꿨다. Comparable과 Comparator는 언제나 소비자라서 \u0026lt;? super T\u0026gt;를 사용해야 한다.\n유용한 swap 방법\npublic static void swap(List\u0026lt;?\u0026gt; list, int i, int j){ //이렇게 하면 메서드에 아무 리스트나 인자로 전달하면 첨자가 가리키는 원소들을 바꿔준다.  //형인자를 신경 쓸 필요가 없어서 좋지만 문제는 list의 자료형이 List\u0026lt;?\u0026gt;라는 것이다.  //List\u0026lt;?\u0026gt;에는 null 이외에 어떤 값도 넣을 수 없다.  list.set(i, list.set(j, list.get(i))); //그래서 도움 메서드가 필요  swapHelper(list, i, j); } private static \u0026lt;E\u0026gt; void swapHelper(List\u0026lt;E\u0026gt; list, int i, int j){ list.set(i, list.set(j, list.get(i))); } swapHelper 메서드는 list가 List\u0026lt;E\u0026gt;라는 것을 안다. 따라서 해당 리스트에서 꺼낸 값의 자료형은 E다. 그리고 E 형의 값은 리스트에 넣어도 안전하다.\nitem 32 : Combine generics and varargs judiciously 규칙33 : 형 안전 다형성 컨테이너를 쓰면 어떨지 따져보라 하나의 원소만을 담는 컨테이너 대신 키(key)에 형인자를 지정하는 유연한 방법.\n//형 안전 다형성 컨테이너 패턴 - 구현 public class Favorites{ private Map\u0026lt;Class\u0026lt;?\u0026gt;, Object\u0026gt; favorites = new HashMap\u0026lt;Class\u0026lt;?\u0026gt;, Object\u0026gt;(); public \u0026lt;T\u0026gt; void putFavorite(Class\u0026lt;T\u0026gt; type, T instance){ if(type == null) throw new NullPointerException(\u0026#34;Type is null\u0026#34;); //동적 형변환으로 실행시간 형 안전성 확보  favorites.put(type, type.cast(instance)); } public \u0026lt;T\u0026gt; T getFavorite(Class\u0026lt;T\u0026gt; type){ return type.cast(favorites.get(type)); } } 비한정적 와일드카드 자료형을 사용했으니 이 맵에는 아무것도 넣을 수 없다고 생각할 수 있지만, 와일드카드 자료형이 쓰인 곳은 맵이 아니라 키다. 모든 키가 상이한 형인자 자료형을 가질 수 있다는 의미다.\n두 번째로 주의할 것은 favorites 맵의 값 자료형이 Object라는 것이다. 그래서 값의 자료형이 키가 나타내는 자료형이 되도록 보장하지 않는다. 이를 해결하기 위해 Class 객체의 cast 메서드를 사용해서, Object 형 객체 참조를 Class 객체가 나타내는 자료형으로 동적 형변환한다. cast 메서드는 자바의 형변환 연산자의 동적 버전이다. 이 메서드가 하는 일은 단순히 주어진 인자가 Class 객체가 나타내는 자료형의 객체인지를 검사하는 것이다. 맞는다면 인자로 주어진 객체를 반환하고, 그렇지 않은 경우에는 ClassCastException을 던진다. favorites.put(type, type.cast(instance)) 에서도 cast 메서드를 사용했는데 의도적으로 형 안전성을 깨뜨리는걸 방지하기 위해서다.\nFavorites 클래스의 단점은 실체화 불가능 자료형에는 쓰일 수 없다는 것이다. List\u0026lt;String\u0026gt;.class가 문법적으로 옳지 않은 표현이기 때문이다.\n"
},
{
	"uri": "/%E1%84%8C%E1%85%A1%E1%84%87%E1%85%A1_%E1%84%89%E1%85%A5%E1%86%BC%E1%84%82%E1%85%B3%E1%86%BC_%E1%84%90%E1%85%B2%E1%84%82%E1%85%B5%E1%86%BC_%E1%84%8B%E1%85%B5%E1%84%8B%E1%85%A3%E1%84%80%E1%85%B5/%E1%84%8C%E1%85%B5%E1%84%80%E1%85%B3%E1%86%B7%E1%84%81%E1%85%A1%E1%84%8C%E1%85%B5_%E1%84%89%E1%85%A1%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%92%E1%85%A1%E1%84%83%E1%85%A5%E1%86%AB_for_%E1%84%85%E1%85%AE%E1%84%91%E1%85%B3%E1%84%85%E1%85%B3%E1%86%AF_%E1%84%83%E1%85%A5_%E1%84%88%E1%85%A1%E1%84%85%E1%85%B3%E1%84%80%E1%85%A6_%E1%84%92%E1%85%A1%E1%86%AF_%E1%84%89%E1%85%AE_%E1%84%8B%E1%85%B5%E1%86%BB%E1%84%83%E1%85%A1%E1%84%80%E1%85%A9/",
	"title": "지금까지 사용하던 for루프를 더 빠르게 할 수 있다고?",
	"tags": [],
	"description": "",
	"content": " switch문은 JDK 6까지는 byte, short, char, int 이렇게 네 가지 타입을 사용한 조건 분기만 가능했지만, JDK 7부터는 String도 사용 가능하다. 일반적으로 if문에서 분기를 많이 하면 시간이 많이 소요된다고 생각한다. if문 조건 안에 들어가는 비교 구문에서 속도를 잡아먹지 않는한, if문장 자체에서는 그리 많은 시간이 소요되지 않는다.\n반복 구문에서의 속도는? JDK 5.0 이전에는 for 구문을 다음과 같이 사용하였다. 여기서 list는 값이 들어있는 ArrayList이다.\nfor (int loop = 0; loop \u0026lt; list.size(); loop++)  이렇게 코딩을 하는 습관은 좋지 않다. 매번 반복하면서 list.size() 메서드를 호출하기 때문이다. 이럴 때는 다음과 같이 수정해야 한다.\nint listSize = list.size(); for (int loop = 0; loop \u0026lt; listSize; loop++)  이렇게 하면 필요 없는 size() 메서드 반복 호출이 없어지므로 더 빠르게 처리된다. JDK 5.0부터는 다음과 같이 for-each 를 사용할 수 있다.\nArrayList\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;String\u0026gt;(); … for (String str : list)@State(Scope.Thread) @BenchmarkMode({Mode.AverageTime}) @OutputTimeUnit(TimeUnit.MICROSECONDS) public class ForLoop { int LOOP_COUNT = 100000; List\u0026lt;Integer\u0026gt; list; @Setup public void setUp() { list = new ArrayList\u0026lt;\u0026gt;(LOOP_COUNT); for (int loop = 0; loop \u0026lt; LOOP_COUNT; loop++) { list.add(loop); } } @Benchmark public void traditionalForLoop() { int listSize = list.size(); for (int loop = 0; loop \u0026lt; listSize; loop++) { resultProcess(list.get(loop)); } } @Benchmark public void traditionalSizeForLoop() { for (int loop = 0; loop \u0026lt; list.size(); loop++) { resultProcess(list.get(loop)); } } @Benchmark public void timeForEachLoop() { for (Integer loop : list) { resultProcess(loop); } } @Benchmark public void timeForEachLoopJava8() { list.forEach(this::resultProcess); } int current; public void resultProcess(int result) { current = result; } public static void main(String[] args) throws RunnerException { Options opt = new OptionsBuilder() .include(ForLoop.class.getSimpleName()) .warmupIterations(3) .measurementIterations(5) .forks(1) .build(); new Runner(opt).run(); } } # Run complete. Total time: 00:00:33 Benchmark Mode Cnt Score Error Units ForLoop.timeForEachLoop avgt 5 159.759 ± 97.272 us/op ForLoop.timeForEachLoopJava8 avgt 5 108.508 ± 11.156 us/op ForLoop.traditionalForLoop avgt 5 117.491 ± 15.692 us/op ForLoop.traditionalSizeForLoop avgt 5 131.080 ± 46.861 us/op  결과를 보면 자바8의 forEach를 사용한게 가장 빠른것으로 나오고, 일반 for-each가 가장 느리게 나온다. 그리고 for문 돌때마다 list.size() 메서드를 호출이 때문에 그렇지 않은것보다 약간 느리게 나왔다.\ncf) 중괄호 안에서 아무런 작업을 하지 않거나, resultProcess() 메서드를 호출하지 않을 경우, 자바의 JIT(Just In Time) 컴파일러는최적화를 통해 해당 코드를 무시해 버릴 수도 있다. 그래서 메서드 호출을 하도록 했다.\n반복 구문에서의 필요 없는 반복 가장 많은 실수 중 하나는 반복 구문에서 계속 필요 없는 메서드 호출을 하는 것이다. 다음 소스를 보자.\npublic void sample(DataVo data, String key) { TreeSet treeSet2 = null; treeSet2 = (TreeSet)data.get(key); if (treeSet2 != null) { for (int i=0; i\u0026lt; treeSet2.size(); i++) { DataVO2 data2 = (DataVO2)treeSet2.toArray()[i]; ... } } } TreeSet 형태의 테이터를 갖고 있는 DataVO에서 TreeSet을 하나 추출하여 처리하는 부분이다. 이 소스의 문제는 toArray() 메서드를 반복해서 수행한다는 것이다. 참고로 sample 메서드는 애플리케이션이 한 번 호출되면 40번씩 수행된다. 또한 treeSet2 객체에 256개의 데이터들이 들어가 있으므로, 결과적으로 toArray() 메서드는 10,600번씩 반복 호출된다. 그러므로 이 코드는 toArray() 메서드가 반복되지 않도록 for 문 앞으로 옮기는 것이 좋다. 게다가 이 소스의 for문을 보면 treeSet2.size() 메서드를 지속적으로 호출하도록 되어 있다. 수정한 결과는 다음과 같다.\npublic void sample(DataVo data, String key) { TreeSet treeSet2 = null; treeSet2 = (TreeSet)data.get(key); if (treeSet2 != null) { DataVO2[] dataVO2 = (DataVO2)treeSet2.toArray(); int treeSetSize = treeSet2.size(); for (int i=0; i\u0026lt; treeSetSize; i++) { DataVO2 data2 = dataVO2[i]; ... } } }"
},
{
	"uri": "/toby_spring/%E1%84%90%E1%85%A6%E1%86%B7%E1%84%91%E1%85%B3%E1%86%AF%E1%84%85%E1%85%B5%E1%86%BA/",
	"title": "템플릿",
	"tags": [],
	"description": "",
	"content": " 템플릿이란 바뀌는 성질이 다른 코드 중에서 변경이 거의 일어나지 않으며 일정한 패턴으로 유지되는 특성을 가진 부분을 자유롭게 변경되는 성질을 가진 부분으로부터 독립시켜서 효과적으로 활용할 수 있도록 하는 방법이다.\n예외처리 기능을 갖춘 DAO\npublic void deleteAll() throws SQLException{ Connection c = null; PreparedStatement ps = null; //예외가 발생할 가능성이 있는 코드를 모두 try 블록으로 묶어준다.  try{ c = dataSource.getConnection(); ps = c.prepareStatement(\u0026#34;delete from users\u0026#34;); ps.executeUpdate(); }catch(SQLException e){ throw e; }finally{//예외 발생하건 안하건 항상 실행  if(ps != null){ //ps가 null일때 close 호출하면 NullPointerException  try{ ps.close(); //close()도 예외 발생할 수 있다.  }catch(SQLException e){ } } if(c != null){ try{ c.close(); }catch(SQLException e){ } } }// finally end } close()는 만들어진 순서의 반대로 하는 것이 원칙이다.\n이제 이 deleteAll() 메서드에 담겨 있던 변하지 않는 부분, 자주 변하는 부분을 전략 패턴을 사용해 깔끔하게 분리해보자. 클라이언트 책임을 담당할 deleteAll() 메서드\npublic void deleteAll() throws SQLException{ StatementStrategy st = new DeleteAllStatement(); jdbcContextWithStatementStrategy(st); } 메서드로 분리한 try/catch/finally 컨텍스트 코드\npublic void jdbcContextWithStatementStrategy(StatementStrategy stmt) throws SQLException{ Connection c = null; PreparedStatement ps = null; try{ c = dataSource.getConnection(); ps = stmt.makePreparedStatement(c); ps.executeUpdate(); }catch(SQLException e){ throw e; }finally{ if(ps != null) { try { ps.close(); } catch (SQLException e) {} } if(c != null) { try { c.close(); } catch (SQLException e) {} } } } StatementStrategy 인터페이스\npublic interface StatementStrategy{ PreparedStatement makePreparedStatement(Connection c) throws SQLException; } deleteAll() 메서드의 기능을 구현한 StatementStrategy 전략 클래스\npublic class DeleteAllStatement implements StatementStrategy{ public PreparedStatement makePreparedStatement(Connection c) throws SQLException{ PreparedStatement ps = c.preparedStatement(\u0026#34;delete from users\u0026#34;); return ps; } } 이 방법은 두 가지 개선할 부분이 있다. 첫째는 DAO 메서드마다 새로운 StatementStrategy 구현 클래스를 만들어야 한다는 점이다. 이렇게 되면 상속을 사용하는 템플릿 메서드 패턴을 적용했을 때보다 그다지 나을게 없다. 두 번째는 add() 메서드 같은 경우, 새로운 user에 대한 부가적인 정보가 있어서 번거롭게 인스턴스 변수를 만들어야 한다는 점이다.\npublic class AddStatement implements StatementStrategy { User user; public AddStatement(User user) { this.user = user; } public PreparedStatement makePreparedStatement(Connection c) { ... ps.setString(1, user.getId()); ps.setString(2, user.getName()); ps.setString(3, user.getPassword()); ... } }public void add(User user) throws SQLException { StatementStrategy st = new AddStatement(user); jdbcContextWithStatementStrategy(st); } 이 두 가지 문제를 해결할 수 있는 방법을 생각해보자.\n로컬 클래스 StatementStrategy 전략 클래스를 매번 독립된 파일로 만들지 말고 UserDao 클래스 안에 내부 클래스로 정의해버리는 간단한 방법이 있다.\n//내부 클래스에서 외부의 변수를 사용할 때는 외부변수를 반드시 final로 선언해줘야된다. public void add(final User user) throws SQLException{ class AddStatement implements StatementStrategy{ public PreparedStatement makePreparedStatement(Connection c) throws SQLException{ PreparedStatement ps = c.prepareStatement( \u0026#34;insert into users(id, name, password) values(?,?,?)\u0026#34;); ps.setString(1, user.getId()); ps.setString(2, user.getName()); ps.setString(3, user.getPassword()); return ps; } }// class end  StatementStrategy st = new AddStatement(); // 생성자 파라미터로 user 전달하지 않아도 된다.  jdbcContextWithStatementStrategy(st); } 로컬 클래스로 만들어두니 장점이 많다. AddStatement는 복잡한 클래스가 아니므로 메서드 안에서 정의해도 그다지 복잡해 보이지 않는다. 메서드마다 추가해야 했던 클래스 파일을 하나 줄일 수 있다는 것도 장점이고, 내부 클래스의 특징을 이용해 로컬 변수를 바로 가져다 사용할 수 있다는 것도 큰 장점이다.\n익명 내부 클래스 클래스 선언과 오브젝트 생성이 결합된 형태로 만들어지며, 클래스를 재사용할 필요가 없고 구현한 인터페이스 타입으로만 사용할 경우에 유용하다.\n익명 내부 클래스는 선언과 동시에 오브젝트를 생성한다. 이름이 없기 때문에 클래스 자신의 타입을 가질 수 없고, 구현한 인터페이스 타입의 변수에만 저장할 수 있다. public void add(final User user) throws SQLExecption{ jdbcContextWithStatementStrategy( new StatementStrategy(){ public PreparedStatement makePreparedStatement(Connection c) throws SQLException{ PreparedStatement ps = c.prepareStatement( \u0026#34;insert into users(id, name, password) values(?,?,?)\u0026#34;); ps.setString(1, user.getId()); ps.setString(2, user.getName()); ps.setString(3, user.getPassword()); return ps; } } ); }public void deleteAll() throws SQLException{ jdbcContextWithStatementStrategy( new StatementStrategy(){ public PreparedStatement makePreparedStatement(Connection c) throws SQLException{ return c.preparedStatement(\u0026#34;delete from users\u0026#34;); } } ); } 컨텍스트와 DI jdbcContext의 분리 전략 패턴의 구조로 보자면 UserDao의 메서드가 클라이언트이고, 익명 내부 클래스로 만들어지는 것이 개별적인 전략이고, jdbcContextWithStatementStrategy() 메서드는 컨텍스트다. 컨텍스트 메서드는 UserDao 내의 PreparedStatement를 실행하는 기능을 가진 메서드에서 공유할 수 있다. 그런데 JDBC의 일반적인 작업 흐름을 담고 있는 jdbcContextWithStatementStrategy()는 다른 DAO에서도 사용 가능하다. 그러니 jdbcContextWithStatementStrategy()를 UserDao 클래스 밖으로 독립시켜서 모든 DAO가 사용할 수 있게 해보자.\n아래 코드는 분리해서 만든 JdbcContext 클래스다.\npublic class JdbcContext { private DataSource dataSource; public void setDataSource(DataSource dataSource) { this.dataSource = dataSource; } public void workWithStatementStrategy(StatementStrategy stmt) throws SQLException { Connection c = null; PreparedStatement ps = null; try { c = this.dataSource.getConnection(); ps = stmt.makePreparedStatement(c); ps.executeUpdate(); } catch(SQLException e) P throw e; } finally { if(ps != null) { try { ps.close(); } catch (SQLException e) {} } if(c != null) { try { c.close(); } catch (SQLException e) {} } } } } 다음은 UserDao가 분리된 JdbcContext를 DI 받아서 사용할 수 있게 만든다.\npublic class UserDao { ... private JdbcContext jdbcContext; public void setJdbcContext(JdbcContext jdbcContext) { this.jdbcContext = jdbcContext; } public void add(final User user) throws SQLException { this.jdbcContext.workWithStatementStrategy( new StatementStrategy() { ... } ); } public void deleteAll() throws SQLExcetion { this.jdbcContext.workWithStatementStrategy( new StatementStrategy() { ... } ); } } 템플릿과 콜백 전략 패턴의 기본 구조에 익명 내부 클래스를 활용한 방식을 스프링에서는 템플릿/콜백 패턴이라고 부른다. 전략 패턴의 컨텍스트를 템플릿이라 부르고, 익명 내부 클래스로 만들어지는 오브젝트를 콜백이라고 부른다.\ncf) 콜백 : 실행되는 것을 목적으로 다른 오브젝트의 메서드에 전달되는 오브젝트를 말한다. 파라미터로 전달되지만 값을 참조하기 위한 것이 아니라 특정 로직을 담은 메서드를 실행시키기 위해 사용한다. 그런데 템플릿/콜백 방식에서 한 가지 아쉬운 점이 있다. DAO 메서드에서 매번 익명 내부 클래스를 사용하기 때문에 상대적으로 코드를 작성하고 읽기가 조금 불편하다는 점이다. 그래서 이번에는 복잡한 익명 내부 클래스의 사용을 최소화할 수 있는 방법을 찾아보자.\n재사용 가능한 콜백을 템플릿 클래스 안으로 옮기자. 엄밀히 말해서 템플릿은 JdbcContext 클래스가 아니라 workWithStatementStrategy() 메서드이므로 옮긴다고 해도 문제 될 것은 없다.\npublic class JdbcContext { ... public void executeSql(final String query) throws SQLException { workWithStatementStrategy( new StatementStrategy() { public PreparedStatement makePreparedStatement(Connection c) throws SQLException { return c.prepareStatement(query); } } ); } } executeSql() 메서드가 JdbcContext로 이동했으니 UserDao의 메서드에서도 아래와 같이 jdbcContext를 통해 executeSql() 메서드를 호출하도록 수정해야 한다.\npublic void deleteAll() throws SQLExcetpion { this.jdbcContext.executeSql(\u0026#34;delete froms users\u0026#34;); } 스프링의 JdbcTemplate 스프링이 제공하는 JDBC 코드용 기본 템플릿은 JdbcTemplate이다. 앞에서 만들었던 JdbcContext와 유사하지만 훨씬 강력하고 편리한 기능을 제공해준다.\npublic class UserDao { ... private JdbcTemplate jdbcTemplate; public void setDataSource(DataSource dataSource) { this.jdbcTemplate = new JdbcTemplate(dataSource); this.dataSource = dataSource; } } 이제 템플릿을 사용할 준비가 됐다.\nupdate() deleteAll()에 먼저 적용해보자. deleteAll()에 처음 적용했던 콜백은 StatementStrategy 인터페이스의 makePreparedStatement() 메서드다. 이에 대응되는 JdbcTemplate의 콜백은 PreparedStatementCreator 인터페이스의 createPreparedStatement() 메서드다.\npublic void deleteAll() { this.jdbcTemplate.update( new PreparedStatementCreator() { public PreparedStatement createPreparedStatement(Connection con) throws SQLException { return con.prepareStatement(\u0026#34;delete from users\u0026#34;); } } ); } 앞에서 만들었던 executeSql()은 SQL 문장만 전달하면 미리 준비된 콜백을 만들어서 템플릿을 호출하는 것까지 한 번에 해주는 편리한 메서드였다. JdbcTemplate에도 기능이 비슷한 메서드가 존재한다. 콜백을 받는 update() 메서드와 이름은 동일한데 파라미터로 SQL 문장을 전달한다는 것만 다르다.\npublic void deleteAll() { this.jdbcTemplate.update(\u0026#34;delete from users\u0026#34;); } JdbcTemplate은 add() 메서드에 대한 편리한 메서드도 제공된다. 치환자를 가진 SQL로 PreparedStatement를 만들고 함께 제공하는 파라미터를 순서대로 바인딩해주는 기능을 가진 update() 메서드를 사용할 수 있다. SQL과 함께 가변인자로 선언된 파라미터를 제공해주면 된다. 현재 add() 메서드에서 만드는 콜백은 아래와 같이 PreparedStatement를 만드는 것과 파라미터를 바인딩하는 두 가지 작업을 수행한다.\nPreparedStatement ps = c.prepareStatement(\u0026#34;insert into users(id, name, password) values(?,?,?)\u0026#34;); ps.setString(1, user.getId()); ps.setString(2, user.getName()); ps.setString(3, user.getPassword()); 이를 JdbcTemplate에서 제공하는 편리한 메서드로 바꿔보면 다음과 같이 간단하게 바꿀수 있다. PreparedStatement를 만들 때 사용하는 SQL은 동일하며 바인딩할 파라미터는 순서대로 넣어주면 된다.\nthis.jdbcTemplate.update(\u0026#34;insert into users(id, name, password) values(?,?,?)\u0026#34;, user.getId(), user.getName(), user.getPassword()); queryForInt() 다음은 아직 템플릿/콜백 방식을 적용하지 않았던 getCount 메서드에 JdbcTemplate을 적용해보자.\npublic int getCount() throws SQLException { Connection c = dataSource.getConnection(); PreparedStatement ps = c.prepareStatement(\u0026#34;select count(*) from users\u0026#34;); ResultSet rs = ps.executeQuery(); rs.next(); int count = rs.getInt(1); rs.close(); ps.close(); c.close(); return count; } getCount()는 SQL 쿼리를 실행하고 ResultSet을 통해 결과 값을 가져오는 코드다. 이런 작업 흐름을 가진 코드에서 사용할 수 있는 템플릿은 PreparedStatementCreator 콜백과 ResultSetExtractor 콜백을 파라미터로 받는 query() 메서드다. ResultSetExtractor 콜백은 템플릿이 제공하는 ResultSet을 이용해 원하는 값을 추출해서 템플릿에 전달하면, 템플릿은 나머지 작업을 수행한 뒤에 그 값을 query() 메서드의 리턴 값으로 돌려준다.\npublic int getCount() { return this.jdbcTemplate.query(new PreparedStatementCreator() { public PreparedStatement createPreparedStatement(Connection con) throws SQLException { return con.prepareStatement(\u0026#34;select count(*) from users\u0026#34;); } }, new ResultSetExtractor\u0026lt;Integer\u0026gt;() { public Integer extractData(ResultSet rs) throws SQLException, DataAccessException { rs.next(); return rs.getInt(1); } } ); } 위의 콜백 오브젝트 코드는 재사용하기 좋은 구조다. SQL을 가지고 PreparedStatement를 만드는 첫 번째 콜백은 이미 재사용 방법을 알아봤다. 두 번째 콜백도 간단하다. SQL의 실행 결과가 하나의 정수 값이 되는 경우는 자주 볼 수 있다. 클라이언트에서 콜백의 작업을 위해 특별히 제공할 값도 없어서 단순하다. 손쉽게 ResultSetExtractor 콜백을 템플릿 안으로 옮겨 재활용할 수 있다. JdbcTemplate은 이런 기능을 가진 콜백을 내장하고 있는 queryForInt()라는 편리한 메서드를 제공한다. Integer 타입의 결과를 가져올 수 있는 SQL 문장만 전달해주면 된다.\npublic int getCount() { return this.jdbcTemplate.queryForInt(\u0026#34;select count(*) from users\u0026#34;); } JdbcTemplate은 스프링이 제공하는 클래스이지만 DI 컨테이너를 굳이 필요로 하지 않는다. 직접 JdbcTemplate 오브젝트를 생성하고 필요한 DataSource를 전달해주기만 하면 JdbcTemplate의 모든 기능을 자유롭게 활용할 수 있다.\nqueryForObject() 이번엔 id를 통해 User 정보를 갖고오는 get() 메서드에 JdbcTemplate을 적용해보자. 문제는 ResultSet에서 getCount()처럼 단순한 값이 아니라 복잡한 User 오브젝트로 만들어야 한다. 즉, ResultSet의 결과를 User 오브젝트를 만들어 프로퍼티에 넣어줘야 한다.\n이를 위해 getCount()에 적용했던 ResultExtractor 콜백 대신 RowMapper 콜백을 사용하겠다. ResultExtractor와 RowMapper 모두 템플릿으로부터 ResultSet을 전달받고, 필요한 정보를 추출해서 리턴하는 방식으로 동작한다. 다른 점은 ResultExtractor은 ResultSet을 한 번 전달받아 알아서 추출 작업을 모두 진행하고 최종 결과만 리턴해주면 되는 데 반해, RowMapper는 ResultSet의 로우 하나를 매핑하기 위해 사용되기 때문에 여러 번 호출될 수 있다는 점이다.\npublic User get(String id) { return this.jdbcTemplate.queryForObject(\u0026#34;select * from users where id = ?\u0026#34;, new Object[] {id}, // SQL에 바인딩할 파라미터 값  new RowMapper\u0026lt;User\u0026gt;() { public User mapRow(ResultSet rs, int rowNum) throws SQLException { User user = new User(); user.setId(rs.getString(\u0026#34;id\u0026#34;)); user.setName(rs.getString(\u0026#34;name\u0026#34;)); user.setPassword(rs.getString(\u0026#34;password\u0026#34;)); return user; } }); } 첫 번째 파라미터는 PreparedStatement를 만들기 위한 SQL이고, 두 번째는 여기에 바인딩할 값들이다. update() 에서처럼 가변인자를 사용하면 좋겠지만 뒤에 다른 파라미터가 있기 때문에 가변인자 대신 Object 타입 배열을 사용해야 한다. 배열 초기화 블록을 사용해서 SQL의 ?에 바인딩할 id 값을 전달한다. queryForObject() 내부에서 이 두 가지 파라미터를 사용하는 PreparedStatement 콜백이 만들어질 것이다.\nqueryForObject()는 SQL을 실행하면 한 개의 로우만 얻을 것이라고 기대한다. 그리고 ResultSet의 next()를 실행해서 첫 번째 로우로 이동시킨 후에 RowMapper 콜백을 호출한다. 이미 RowMapper가 호출되는 시점에서 ResultSet은 첫 번째 로우를 가리키고 있으므로 다시 rx.next()를 호출할 필요는 없다. RowMapper에서는 현재 ResultSet이 가리키고 있는 로우의 내용을 User 오브젝트에 그대로 담아서 리턴해주기만 하면 된다. RowMapper가 리턴한 User 오브젝트는 queryForObject() 메서드의 리턴 값으로 get() 메서드에 전달된다.\n이렇게만 해도 일단 User 오브젝트를 조회하는 get() 메서드의 기본 기능은 충분히 구현됐다. 하지만 get() 메서드에는 한 가지 더 고려해야 할 게 있다. queryForObject()를 이용할 때 조회 결과가 없는 예외상황을 어떻게 처리해야 할까? 이를 위해 특별히 해줄 것은 없다. 이미 queryForObject()는 SQL을 실행해서 받은 로우의 개수가 하나가 아니라면 예외를 던지도록 만들어져 있다. 이때 던져지는 예외가 바로 EmptyResultDataAccessException이다.\nquery 앞에서 사용한 queryForObject()는 쿼리의 결과가 로우 하나일 때 사용하고, query()는 여러 개의 로우가 결과로 나오는 일반적인 경우에 쓸 수 있다. query()의 리턴 타입은 List\u0026lt;T\u0026gt;다.\npublic List\u0026lt;User\u0026gt; getAll() { return this.jdbcTemplate.query(\u0026#34;select * from users order by id\u0026#34;, new RowMapper\u0026lt;User\u0026gt;() { public User mapRow(ResultSet rs, int rowNum) throws SQLException { User user = new User(); user.setId(rs.getString(\u0026#34;id\u0026#34;)); user.setName(rs.getString(\u0026#34;name\u0026#34;)); user.setPassword(rs.getString(\u0026#34;password\u0026#34;)); return user; } }); } quert()는 결과가 없을 경우에 queryForObject()처럼 예외를 던지지는 않는다. 대신 크기가 0인 List\u0026lt;T\u0026gt; 오브젝트를 돌려준다.\n중복 제거 get()과 getAll()을 보면 사용한 RowMapper의 내용이 똑같다는 사실을 알 수 있다. 사용되는 상황은 다르지만 ResultSet 로우 하나를 User 오브젝트 하나로 변환해주는 동일한 기능을 가진 콜백이다. RowMapper 콜백은 하나만 만들어서 공유하자.\npublic class UserDao { private RowMapper\u0026lt;User\u0026gt; userMapper = new RowMapper\u0026lt;User\u0026gt;() { public User mapRow(ResultSet rs, int rowNum) throws SQLException { User user = new User(); user.setId(rs.getString(\u0026#34;id\u0026#34;)); user.setName(rs.getString(\u0026#34;name\u0026#34;)); user.setPassword(rs.getString(\u0026#34;password\u0026#34;)); return user; } }; } 인스턴스 변수에 저장해둔 userMapper 콜백 오브젝트는 아래와 같이 get()과 getAll()에서 사용하면 된다.\npublic User get(String id) { return this.jdbcTemplate.queryForObject(\u0026#34;select * from users where id = ?\u0026#34;, new Object[] {id}, this.userMapper); } public List\u0026lt;User\u0026gt; getAll() { return this.jdbcTemplate.query(\u0026#34;select * from users order by id\u0026#34;, this.userMapper); }"
},
{
	"uri": "/effective_java/enum%E1%84%80%E1%85%AA_%E1%84%8B%E1%85%A5%E1%84%82%E1%85%A9%E1%84%90%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%89%E1%85%A7%E1%86%AB/",
	"title": "enum과 어노테이션",
	"tags": [],
	"description": "",
	"content": " 규칙34 : int 상수 대신 enum을 사용하라 // int를 사용한 enum 패턴 public static final int APPLE_FUJI = 0; public static final int APPLE_PIPPIN = 1; public static final int APPLE_GRANNY_SMITH = 2; public static final int ORANGE_NAVEL = 0; public static final int ORANGE_TEMPLE = 1; public static final int ORANGE_BLOOD = 2; 위의 코드는 형안전성 측면에서도 그렇고, 편의성 관점에서도 단점이 많다. String enum 패턴이라 불리는 것은 더 나쁜 패턴이다. 상수 비교를 할 때 문자열 비교를 해야 하므로 성능이 떨어질 수 있고, 사용자가 필드 이름 대신 하드코딩된 문자열 상수를 클라이언트 코드 안에 박어버릴 수 있다는 점이다. 하드코딩된 문자열 상수에 오타가 있는 경우, 컴파일 할 때는 오류를 발견할 수 없기 때문에 실행 도중에 문제가 생기게 될 것이다.\n자바 1.5부터 enum 자료형이 생겼다.\npublic enum Apple { FUJI, PIPPIN, GRANNY_SMITH } public enum Orange { NAVEL, TEMPLE, BLOOD } 다른 언어들(C, C++, C#)의 enum은 int 값이지만 자바의 enum 자료형은 완전한 기능을 갖춘 클래스다.\nenum자료형에 메서드나 필드를 추가하는 이유는 상수에 데이터를 연계시키면 좋기 때문이다. 풍부한 기능을 갖춘 enum 자료형 예제로, 태양계의 여덟 행성을 모델링하는 사례를 살펴보자.\npublic enum Planet { MERCURY(3.33, 2.22), VENUS(2.22, 3.33), MARS(6.66, 7.77), URANUS(8.88,9.99); ... private final double mass; // 킬로그램 단위  private final double radius; // 미터단위  private final double surfaceGravity; // 중력 상수  private final double G = 6.67; // 생성자  Planet(double mass, double radius) { this.mass = mass; this.radius = radius; surfaceGravity = G * mass / (radius * radius); } public double mass() {return mass;} public double radius() {return radius;} public double surfaceGravity() {return surfaceGravity;} public double surfaceWeigt(double mass){ return mass * surfaceGravity; // F = ma  } enum은 원래 변경 불가능하므로 모든 필드는 final로 선언되어야 한다. 필드는 public으로 선언할 수도 있지만, private로 선언하고 public 접근자를 두는 편이 더 낫다.\nenum 자료형에는 자동 생성된 valueOf(String) 메서드가 있는데, 이 메서드는 상수의 이름을 상수 그 자체로 변환하는 역할을 한다. enum 자료형의 toString 메서드를 재정의 할 경우에는 fromString 메서드를 작성해서 toString이 뱉어내는 문자열을 다시 enum 상수로 변환할 수단을 제공해야 할지 생각해 봐야 한다.\n// enum 자료형에 대한 fromString 메서드 구현 private static final Map\u0026lt;String, Operation\u0026gt; stringToEnum = new HashMap\u0026lt;\u0026gt;(); static { // 상수 이름을 실제 상수로 대응시키는 맵 초기화 \tfor (Operation op : values()) stringToEnum.put(op.toString(), op); } // 문자열이 주어지면 그에 대한 Operation 상수 반환. 잘못된 문자열이면 null 반환 public static Operation fromString(String symbol) { return stringToEnum.get(symbol); } Operation 상수를 stringToEnum 맵에 넣는 것은 상수가 만들어진 다음에 실행되는 static 블록 안에서 한다는 것에 주의하자. 각각의 상수가 생성자 안에서 맵에 자기 자신을 넣도록 하면 컴파일 할 때 오류가 발생한다. enum 생성자 안에서는 enum의 static 필드를 접근할 수 없다(컴파일 시점에 상수인 static 필드는 제외). 생성자가 실행될 때 static 필드는 초기화된 상태가 아니기 때문에 필요한 제약이다.\n3rd Edition에서 추가된 부분\nprivate static final Map\u0026lt;String, Operation\u0026gt; stringToEnum = Stream.of(values()).collect(toMap(Object::toString, e -\u0026gt; e)); public static Optional\u0026lt;Operation\u0026gt; fromString(String symbol) { return Optional.ofNullable(stringToEnum.get(symbol)); } 상수별 메서드 구현의 단점은 enum 상수끼리 공유하는 코드를 만들기가 어렵다는 것이다. 예를 들어, 급여 명세서에 찍히는 요일을 표현하는 enum 자료형이 있다고 하자. 이 enum 자료형 상수, 그러니까 요일을 나타내는 상수에는 직원의 시급과 해당 요일에 일한 시간을 인자로 주면 해당 요일의 급여를 계산하는 메서드가 있다. 그런데 주중에는 초과근무 시간에 대해서만 초과근무 수당을 주어야 하고, 주말에는 몇 시간을 일했건 전부 초과근무 수당으로 처리해야 한다. switch 문을 만들 때 case 레이블을 경우에 따라 잘 붙이기만 하면 쉽게 원하는 계산을 할 수 있을 것이다.\npublic enum PayrollDay { MONDAY,\tTUESDAY, WEDNESDAY,\tTHURSDAY, FRIDAY, SATURDAY,\tSUNDAY; private static final int HOURS_PER_SHIFT = 8; double pay(double hourWorked, double payRate) { double basePay = hourWorked * payRate; double overtimePay; // 초과근무수당 계산 \tswitch (this) { case SATURDAY: case SUNDAY: overtimePay = hourWorked * payRate /2; break;default: overtimePay = hourWorked \u0026lt;= HOURS_PER_SHIFT ? 0 : (hourWorked - HOURS_PER_SHIFT) * payRate / 2; } return basePay + overtimePay; } } 분명 간결한 코드다. 하지만 유지보수 관점에서는 위험한 코드다. enum에 새로운 상수를 추가한다고 하자. 아마도 휴가 등을 나타내는 특별한 값일 것이다. 그런데 switch 문에 해당 상수에 대한 case를 추가하는 것을 잊었다면? 컴파일은 되겠지만 휴가 때 일한 시간에 대해서는 같은 급여를 지급하는 프로그램이 되어버릴 것이다.\n정말 좋은 방법은 새로운 enum 상수를 추가할 때 초과근무 수당 계산 정책을 반드시 선택하도록 하는 것이다. 기본적인 아이디어는 초과근무 수당을 계산하는 부분을 private로 선언된 중첩 enum 자료형에 넣고, PayrollDay enum 생성자가 이 전략 enum 상수를 인자로 받게 하는 것이다. PayrollDay enum 상수가 초과근무 수당 계산을 이 정책 enum 상수에 위임하도록 하면 switch문이나 상수별 메서드 구현은 없앨 수 있다. 이 패턴을 적용한 코드가 switch 문을 써서 만든 코드보다는 복잡하지만 안전할 뿐더러 유연성도 높다.\npublic enum PayrollDay { MONDAY(PayType.WEEKDAY), TUESDAY(PayType.WEEKDAY), WEDNESDAY(PayType.WEEKDAY), THURSDAY(PayType.WEEKDAY), FRIDAY(PayType.WEEKDAY), SATURDAY(PayType.WEEKEND), SUNDAY(PayType.WEEKEND); private final PayType payType; //Constructor  PayrollDay(PayType payType) { this.payType = payType; } double pay(double hoursWorked, double payRate) { return payType.pay(hoursWorked, payRate); } // 정책 enum 자료형  private enum PayType { WEEKDAY { double overtimePay(double hours, double payRate) { return hours \u0026lt;= HOURS_PER_SHIFT ? 0 : (hours - HOURS_PER_SHIFT) * payRate / 2; } }, WEEKEND { double overtimePay(double hours, double payRate) { return hours * payRate / 2; } }; private static final int HOURS_PER_SHIFT = 8; abstract double overtimePay(double hrs, double payRate); double pay(double hoursWorked, double payRate) { double basePay = hoursWorked * payRate; return basePay + overtimePay(hoursWorked, payRate); } } } 규칙35 : ordinal 대신 객체 필드를 사용하라 //ordinal을 남용한 사례 public enum Ensemble{ SOLO, DUET, TRIO; public int numberOfMusicians(){ return ordinal() + 1; } } 모든 enum에는 ordinal이라는 메서드가 있는데, enum 자료형 안에서 enum 상수의 위치를 나타내는 정수값을 반환한다. 하지만 객체필드를 사용해라\npublic enum Ensemble{ SOLO(1), DUET(2), TRIO(3); private final int num; public Ensemble(int size){ this.num = size; } public int numberOfMusicians(){ return num; } } 규칙36 : 비트 필드 대신 EnumSet을 사용하라 //비트 필드 열거형 상수 - 이제는 피해야 할 구현법 public class Text{ public static final int STYLE_BOLD = 1 \u0026lt;\u0026lt; 0; //1  public static final int STYLE_ITALIC = 1 \u0026lt;\u0026lt; 1; //2  public static final int STYLE_UNDERLINE = 1 \u0026lt;\u0026lt; 2 //4  public static final int STYLE_STRIKETHROUGH = 1 \u0026lt;\u0026lt; 3; //8  //이 메서드의 인자는 STYLE_상수를 비트별 OR한 값  public void applyStyles(int styles) { ... } } text.applyStyles(STYLE_BOLD | STYLE_ITALIC); 이렇게 하면 상수들을 집합에 넣을 때 비트별 OR 연산을 사용할 수 있다. 하지만 EnumSet 이라는 더 좋은 방법이 있다.\n//EnumSet - 비트필드를 대신할 현대적 기술 public class Text{ public enum Style { BOLD, ITALIC, UNDERLINE, STRIKETHROUGH } //어떤 Set 객체도 인자로 전달할 수 있으나, EnumSet이 분명 최선  public void applyStyles(Set\u0026lt;Style\u0026gt; styles){ ... } } text.applyStyles(EnumSet.of(Style.BOLD, Style.ITALIC)); EnumSet의 단점이 하나 있는데 변경 불가능 EnumSet객체를 만들 수 없다. 그래서 EnumSet 객체를 Collections.unmodifiableSet으로 포장하면 되는데, 성능이나 코드 가독성 측면에서 좀 손해를 보게 된다.\n규칙37 : ordinal을 배열 첨자로 사용하는 대신 EnumMap을 이용하라 class Herb{ enum Type { ANNUAL, PERENNIAL, BIENNIAL } final String name; final Type type; Herb(String name, Type type){ this.name = name; this.type = type; } @Override public String toString(){ return name; } }//EnumMap을 사용해 enum 상수별 데이터를 저장하는 프로그램 Herb[] garden = …; Map\u0026lt;Herb.Type, Set\u0026lt;Herb\u0026gt;\u0026gt; herbsByType = new EnumMap\u0026lt;Herb.Type, Set\u0026lt;Herb\u0026gt;\u0026gt;(Herb.Type.class); for(Herb.Type t : Herb.Type.values()) herbsByType.put(t, new HashSet\u0026lt;Herb\u0026gt;()); for(Herb h : garden) herbsByType.get(h.type).add(h); System.out.println(herbsByType); EnumMap 생성자가 키의 자료형을 나타내는 Class 객체를 인자로 받는다는 것에 주의하자. 이런 Class 객체를 한정적 자료형 토큰이라고 부르는데, 실행시점 제네릭 자료형 정보를 제공한다.\n두 번째 예제는 상전이(phase transition) 관계를 표현하기 위해서 중첩 EnumMap을 사용했다.\n// EnumMap을 중첩해서 enum 쌍에 대응되는 데이터를 저장한다 public enum Phase{ SOLID, LIQUID, GAS; public enum Transition{ MELT(SOLID, LIQUID), FREEZE(LIQUID, SOLID), BOIL(LIQUID, GAS), CONDENSE(GAS, LIQUID), SUBLIME(SOLID, GAS), DEPOSIT(GAS, SOLID); private final Phase src; private final Phase dat; Transition(Phase src, Phase dst){ this.src = src; this.dst = dat; } //상 전이 맵 초기화 \tprivate static final Map\u0026lt;Phase, Map\u0026lt;Phase, Transition\u0026gt;\u0026gt; m = new EnumMap\u0026lt;Phase, Map\u0026lt;Phase, Transition\u0026gt;\u0026gt;(Phase.class); static{ for(Phase p : Phase.values()) m.put(p, new EnumMap\u0026lt;Phase, Transition\u0026gt;(Phase.class)); for(Transition trans : Transition.values()) m.get(trans.src).put(trans.dst, trans); } public static Transition from(Phase src, Phase dat) { return m.get(src).get(dst); } } } LIQUID쪽을 보면 액체 LIQUID에서 고체 SOLID로 변하는 것은 언다FREEZE라고 한다. 이 맵의 자료형은 Map\u0026lt;Phase, Map\u0026lt;Phase, Transition\u0026gt;\u0026gt;인데, “상전이 이전 상태를, 상전이 이후 상태와 상전이 명칭 사이의 관계를 나타내는 맵에 대응시키는 맵”이라는 뜻이다.\n규칙38 : 확장 가능한 enum을 만들어야 한다면 인터페이스를 이용하라 일반적으로 enum 자료형을 계승한다는 것은 바람직하지 않다. 확장된 자료형의 상수들이 기본 자료형의 상수가 될 수 있지만 그 반대가 될 수 없다는 것은 혼란스럽기 때문이다. 또한 기본 자료형과 그 모든 하위 자료형의 enum 상수들을 순차적으로 살펴볼 좋은 방법도 없고 설계와 구현에 관계된 많은 부분이 까다로워진다.\n하지만 열거 자료형의 확장이 가능하면 좋은 경우가 적어도 하나 있다. 연산 코드(opcode)를 만들어야 할 때다. 연산 코드는 어떤 기계에서 사용되는 연산을 표현하기 위해 쓰이는 열거 자료형이다. 기본 아이디어는 enum 자료형이 임의의 인터페이스를 구현할 수 있다는 사실을 이용하는 것이다.\n먼저 연산 코드 자료형에 대한 인터페이스를 정의한다. 그리고 해당 인터페이스를 구현하는 enum 자료형을 만든다.\n// 인터페이스를 이용해 확장 가능하게 만든 enum 자료형 public interface Operation { double apply(double x, double y); } public enum BasicOperation implements Operation { PLUS(“+”) { public double apply(double x, double y) { return x + y; } }, MINUS(“-“) { public double apply(double x, double y) { return x - y; } }, TIMES(“*“) { public double apply(double x, double y) { return x * y; } }, DIVIDE(“/“) { public double apply(double x, double y) { return x / y; } }; private final String symbol; BasicOperation(String symbol) { this.symbol = symbol; } @Override public String toString(){ return symbol; } } BasicOperation은 enum 자료형이라 계승할 수 없지만 Operation은 인터페이스가 확장이 가능하다. 따라서 이 인터페이스를 계승하는 새로운 enum 자료형을 만들면 Operation 객체가 필요한 곳에 해당 enum 자료형의 상수를 이용할 수 있게 된다.\n// 인터페이스를 이용해 기존 enum 자료형을 확장하고 테스트하는 프로그램 public static void main(String[] args) { double x = Double.parseDouble(args[0]); double y = Double.parseDouble(args[1]); // Operation을 상속한ExtendedOperation이라는 enum을 새롭게 만든껏임. P224 \ttest(ExtendedOperation.class, x, y); } private static \u0026lt;T extends Enum\u0026lt;T\u0026gt; \u0026amp; Operation\u0026gt; void test( Class\u0026lt;T\u0026gt; opSet, double x, double y){ for (Operation op : opSet.getEnumConstants()) System.out.printf(“%f %s %f = %f%n”, x, op, y, op.apply(x, y)); } 확장된 연산을 나타내는 자료형의 class 리터럴인 ExtendedOperation.class가 main에서 test로 전달되고 있음에 유의하자. 확장된 연산 집합이 무엇인지 알리기 위한 것이다. 이 class 리터럴은 한정적 자료형 토큰 구실을 한다. opSet의 형인자 T는 굉장히 복잡하게 선언되어 있는데 Class 객체가 나타내는 자료형이 enum 자료형인 동시에 Operation의 하위 자료형이 되도록 한다 라는 뜻이다. 모든 enum 상수를 순차적으로 살펴보면서 해당 상수가 나타내는 연산을 실제로 수행할 수 있으려면 반드시 그래야 한다.\n두 번째 방법은 한정적 와일드카드 자료형 Collection\u0026lt;? extends Operation\u0026gt;을 opSet 인자의 자료형으로 사용하는 것이다.\npublic static void main(String[] args) { double x = Double.parseDouble(args[0]); double y = Double.parseDouble(args[1]); test(Arrays.asList(ExtendedOperation.values()), x, y); } private static void test(Collection\u0026lt;? extends Operation\u0026gt; opSet, double x, double y){ for(Operation op : opSet) { System.out.printf(“%f %s %f = %f%n”, x, op, y, op.apply(x, y)); } } test 메서드의 인자 형태는 메서드를 호출할 때, 여러 enum 자료형에 정의한 연산들을 함께 전달할 수 있도록 하기 위한 것이다. 그러나 이렇게 하면 EnumSet이나 EnumMap을 사용할 수 없기 때문에, 여러 자료형에 정의한 연산들을 함께 전달할 수 있도록 하는 유연성이 필요 없다면, 첫 번째 방식인 한정적 자료형 토큰을 쓰는게 낫다.\n인터페이스를 사용해 확장 가능한 enum 자료형을 만드는 방법에는 한 가지 사소한 문제가 있다. enum 구현 자체는 계승할 수 없다는 것이다.\n규칙39 : (Prefer annotations to naming patterns)작명 패턴 대신 애노테이션을 사용하라 이번 예제는 Junit의 @Test 애노테이션 기능을 간단하게 직접 구현해보면서, 작명 패턴(naming pattern) 보다 애노테이션이 어떻게 더 좋은지를 설명한다.\n작명 패턴의 예로 과거 JUnit은 테스트 메서드 이름을 test로 시작해야 했다. 이러한 작명 패턴에는 몇 가지 문제점이 있는데 첫째, 오타났을 때 프로그램 상 문제가 없기 때문에 알아차리기 어렵다. 둘째, 특정한 프로그램 요소에만 적용되도록 만들 수 없다. 예를 들어 testSafetyMechanisms라는 이름의 클래스를 만들었다 해도 그 클래스의 모든 메서드를 테스트 실행시키지 않는다(클래스 이름 까지는 확인하지 않기 때문에 의미가 없다). 셋째, 프로그램 요소에 인자를 전달할 마땅한 방법이 없다. 메서드 이름에 포함된 문자열로 예외를 알려주는 방법이 있지만 보기 흉할 뿐 아니라 컴파일러가 문자열이 예외 이름인지 알 도리가 없다.\n그러므로 애노테이션을 사용하자.\n// 표식 애노테이션 자료형(markder annotation type) 선언 import java.lang.annotation.*; /** * 애노테이션이 붙은 메서드가 테스트 메서드임을 표시. * 무인자 정적 메서드(parameterless)에만 사용 가능. */ @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) public @interface BongTest { } 애노테이션 자료형 BongTest 선언부에도 Retention과 Target이라는 애노테이션이 붙어 있다. 애노테이션 자료형 선언부에 붙는 애노테이션은 메타-애노테이션이라 부른다. @Retention(RetentionPolicy.RUNTIME)은 BongTest가 실행시간(runtime)에도 유지되어야 하는 애노테이션이라는 뜻이다. 그렇지 않으면 BongTest는 테스트 도구에게는 보이지 않는다. @Target(ElementType.METHOD)은 BongTest가 메서드 선언부에만 적용할 수 있는 애노테이션이라는 뜻이다.\npublic class Sample { @BongTest public static void noParamStaticMethod() { // 성공해야함 \t} @BongTest public static void oneParamMethod() { // 실패해야함 \tthrow new RuntimeException(\u0026#34;Boom\u0026#34;); } @BongTest public void noParamMethod() { // 실패해야함 \t} @BongTest private void privateNoParamMethod() { // 실패해야함  } @BongTest public static void oneParamStaticMethod(String ii) { // 실패해야함 \t} } 위와 같이 @BongTest 애노테이션을 적용한 메서드를 Sample 클래스에 선언해 놓고 테스트 실행기를 돌려보자. @BongTest 애노테이션은 Sample 클래스가 동작하는 데 직접적 영향을 미치지 않는다. 해당 애노테이션에 관심 있는 프로그램에게 유용한 정보를 제공할 뿐이다.\npublic class RunTests { public static void main(String[] args) throws Exception { int tests = 0; int passed = 0; Class testClass = Sample.class; for (Method m : testClass.getDeclaredMethods()) { if (m.isAnnotationPresent(BongTest.class)) { tests++; try { m.invoke(null); passed++; } catch (InvocationTargetException wrappedExc) { Throwable exc = wrappedExc.getCause(); System.out.println(m + \u0026#34; failed:\u0026#34; + exc); } catch (Exception exc) { System.out.println(\u0026#34;INVALID @BongTest\u0026#34; + m); System.out.println(exc); } } } System.out.println(\u0026#34;Passed :\u0026#34; + passed); System.out.println(\u0026#34;Failed :\u0026#34; + (tests - passed)); } } 이 테스트 실행기는 Sample 클래스의 메서드들 가운데 @BongTest 애노테이션이 붙은 메서드를 전부 찾아내서 리플렉션 기능을 활용해 실행한다(Method.invoke 호출). isAnnotationPresent 메서드는 실행해야 하는 테스트 메서드를 찾는 용도로 사용되었다. 리플렉션을 통해 호출된 메서드가 예외를 발생시키면 해당 예외는 InvocationTargetException으로 wrapping된다. 이 예외가 아닌 다른 예외가 발생되었다면 그것은 컴파일 시에 발견하지 못한, 잘못 사용된 애노테이션이 있다는 뜻이다. 인스턴스 메서드나 private 메서드, 인자가 있는 메서드에 애노테이션을 붙이면 그런일이 생긴다.\n이제 특정한 예외가 발생했을 경우만 성공하는 테스트도 지원 가능하도록 고쳐보자. 새로운 애노테이션 자료형이 필요하다.\n@Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) public @interface BongTest { Class\u0026lt;? extends Exception\u0026gt; value() default BongTest.None.class; public static class None extends Exception { private None() { } } } 추가로 None 클래스를 만들어 default로 놓음으로써 애노테이션의 인자가 없을 때 컴파일 에러가 발생하는것을 막았다.\n@BongTest(ArithmeticException.class) public static void arithmeticExceptionTest() { int i = 0; i = i / i; } @BongTest(ArrayIndexOutOfBoundsException.class) public static void arrayIndexOutOfBoundsExceptionTest() { int[] a = new int[0]; int i = a[1]; } 위와 같이 발생할 예외를 인자로 보내주면 아래의 테스트 실행기에서 통과 됨을 확인할 수 있다.\npublic class RunTests { public static void main(String[] args) throws Exception { int tests = 0; int passed = 0; Class testClass = Sample.class; for (Method m : testClass.getDeclaredMethods()) { if (m.isAnnotationPresent(BongTest.class)) { tests++; try { m.invoke(null); passed++; } catch (InvocationTargetException wrappedExc) { Throwable exc = wrappedExc.getCause(); Class\u0026lt;? extends Exception\u0026gt; excType = m.getAnnotation(BongTest.class).value(); if (excType.isInstance(exc)) passed++; else System.out.println(m + \u0026#34; failed:\u0026#34; + exc); } catch (Exception exc) { System.out.println(\u0026#34;INVALID @BongTest\u0026#34; + m); System.out.println(exc); } } } System.out.println(\u0026#34;Passed :\u0026#34; + passed); System.out.println(\u0026#34;Failed :\u0026#34; + (tests - passed)); } } 좀 더 발전 시켜서 지정된 예외들 가운데 하나라도 테스트 메서드 안에서 발생하면 테스트가 통과하도록 할 수도 있다.\n@Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) public @interface BongTest { Class\u0026lt;? extends Exception\u0026gt;[] value() default BongTest.None.class; public static class None extends Exception { private None() { } } } @BongTest({IndexOutOfBoundsException.class, NullPointerException.class}) public static void doublyBad() { List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); // 자바 명세에는 아래와 같이 addAll을 호출하면 IndexOutOfBoundsException이나 NullPointerException이 발생한다고 명시되어 있다. \tlist.addAll(5, null); }public class RunTests { public static void main(String[] args) throws Exception { int tests = 0; int passed = 0; Class testClass = Sample.class; for (Method m : testClass.getDeclaredMethods()) { if (m.isAnnotationPresent(BongTest.class)) { tests++; try { m.invoke(null); passed++; } catch (InvocationTargetException wrappedExc) { Throwable exc = wrappedExc.getCause(); Class\u0026lt;? extends Exception\u0026gt;[] excTypes = m.getAnnotation(BongTest.class).value(); for (Class\u0026lt;? extends Exception\u0026gt; excType : excTypes) { if (excType.isInstance(exc)) { passed++; break; } } System.out.println(m + \u0026#34; failed:\u0026#34; + exc); } catch (Exception exc) { System.out.println(\u0026#34;INVALID @BongTest\u0026#34; + m); System.out.println(exc); } } } System.out.println(\u0026#34;Passed :\u0026#34; + passed); System.out.println(\u0026#34;Failed :\u0026#34; + (tests - passed)); } } 자바8부터 multivalued annotations 하는 또다른 방법이 있다.\n@Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) @Repeatable(BongTestContainer.class) public @interface BongTest { Class\u0026lt;? extends Exception\u0026gt; value() default BongTest.None.class; public static class None extends Exception { private None() { } } } @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) public @interface BongTestContainer { BongTest[] value(); } @BongTest(NullPointerException.class) @BongTest(IndexOutOfBoundsException.class) public static void doublyBad() { List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); list.addAll(5, null); } @Repeatable 메타 애노테이션으로 단일 요소에 반복적으로 적용할 수 있다. containing annotation type 인자를 받고 그 containing annotation type은 annotation 배열 타입을 갖는다. 주의할 점은 containing annotation type도 반드시 retention 정책과 target에 대한 메타 애노테이션이 있어야 한다. 그렇지 않으면 컴파일이 안된다.\nrepeatable annotation을 처리하려면 주의가 필요하다. getAnnotationsByType 메서드는 repeated와 non-repeated 애노테이션에 접근하는데 모두 사용될 수 있다. 그러나 isAnnotationPresent 메서드는 BongTest 타입을 검사할 때 BongTestContainer 타입은 자동으로 무시한다. 마찬가지로 BongTestContainer 타입을 검사할 때도 BongTest 타입은 무시한다. 그래서 아래와 같이 두개의 타입 모두를 검사해줘야 한다.\npublic class RunTests { public static void main(String[] args) throws Exception { int tests = 0; int passed = 0; Class testClass = Sample.class; for (Method m : testClass.getDeclaredMethods()) { if (m.isAnnotationPresent(BongTest.class) || m.isAnnotationPresent(BongTestContainer.class)) { tests++; try { m.invoke(null); passed++; } catch (InvocationTargetException wrappedExc) { Throwable exc = wrappedExc.getCause(); BongTest[] excTests = m.getAnnotationsByType(BongTest.class); for (BongTest excTest : excTests) { if (excTest.value().isInstance(exc)) { passed++; break; } } System.out.println(m + \u0026#34; failed:\u0026#34; + exc); } catch (Exception exc) { System.out.println(\u0026#34;INVALID @BongTest\u0026#34; + m); System.out.println(exc); } } } System.out.println(\u0026#34;Passed :\u0026#34; + passed); System.out.println(\u0026#34;Failed :\u0026#34; + (tests - passed)); } } Repeatable 애노테이션은 가독성을 향상시키지만, 애노테이션을 처리하는데 더 많은 상용구(boilerplate)가 있으며 처리하는데 오류를 발생시키기 쉽다.\n규칙 40 : Override 애노테이션은 일관되게 사용하라 상위 클래스에 선언된 메서드를 재정의할 때는 반드시 선언부에 Override 애노테이션을 붙여라. 그래야 실수 했을 때 컴파일러에서 검출될 수 있다.\n그런데 비-abstract 클래스에서 abstract 메서드를 재정의할 때는 Override 애노테이션을 붙이지 않아도 된다(상위 클래스 메서드를 재정의한다는 사실을 명시적으로 표현하고 싶다면 붙여도 상관 없다).\n버전 1.6 이상의 자바를 사용한다면 Override 애노테이션을 통해 찾을 수 있는 버그는 더 많다. 클래스 뿐 아니라 인터페이스에 선언된 메서드를 구현할 때도 Override를 사용할 수 있게 되었기 때문이다. 하지만 인터페이스를 구현할 때 모든 메서드에 반드시 Override를 붙여야 하는 것은 아니다. 인터페이스에 선언된 메서드를 재정의 하지 않으면 어차피 컴파일러가 오류를 내기 때문이다. (마찬가지로 특정 인터페이스 메서드를 재정의하는 메서드라는 사실을 명시적으로 알리고 싶다면 애노테이션을 붙여도 되나, 반드시 필요한 것은 아니다).\n규칙 41 : 자료형을 정의할 때 표식 인터페이스를 사용하라 표식 인터페이스(marker interface)는 아무 메서드도 선언하지 않는 인터페이스다. Serializable 인터페이스가 그 예다.\npublic interface Serializable { } 이 인터페이스를 구현하는 클래스를 만든다는 것은, 해당 클래스로 만든 객체들은 ObjectOutputStream으로 출력할 수 있다는(“직렬화”할 수 있다는) 뜻이다. 다시 말해 해당 클래스가 어떤 속성을 만족한다는 사실을 표시하는 것과 같다.\n표식 애노테이션과 비교했을 때 표식 인터페이스는 두 가지 장점이 있다. 첫 번째 장점은, 표식 인터페이스는 결국 표식 붙은 클래스가 만드는 객체들이 구현하는 자료형이라는 점이다. 표식 애노테이션은 자료형이 아니다. 표식 인터페이스는 자료형이므로, 표식 애노테이션을 쓴다면 프로그램 실행 중에나 발견하게 될 오류를 컴파일 시점에 발견할 수 있도록 한다. 표식 인터페이스 Serializable의 경우를 살펴보자. ObjectOutputStream.write(Object) 메서드는 인자가 Serializable 인터페이스를 구현하지 않은 객체면 오류를 낸다. 두 번째 장점은, 적용 범위를 좀 더 세밀하게 지정할 수 있다는 것이다. 애노테이션 자료형을 선언할 때 target을 ElementType.TYPE으로 지정하면 해당 애노테이션은 어떤 클래스나 인터페이스에도 적용 가능하다. 그런데 특정한 인터페이스를 구현한 클래스에만 적용할 수 있어야 하는 표식이 필요하다고 해 보자. 표식 인터페이스를 쓴다면, 그 특정 인터페이스를 extends 하도록 선언하기만 하면 된다.\n표식 애노테이션의 주된 장점은 프로그램 안에서 애노테이션 자료형을 쓰기 시작한 뒤에도 더 많은 정보를 추가할 수 있다는 것이다. 기본값(default)을 갖는 애노테이션 자료형 요소들을 더해 나가면 된다. 표식 인터페이스를 쓰는 경우에는 이런 진화가 불가능하다. 일단 구현이 이루어지고 난 다음에는 새로운 메서드를 추가하는 것이 일반적으로 불가능하기 때문이다(자바8부터 default 메서드를 통해 불가능하지는 않음).\n그렇다면 표식 애노테이션과 표식 인터페이스는 각각 어떤 상황에 걸맞나? 클래스나 인터페이스 이외의 프로그램 요소에 적용되어야 하는 표식은 애노테이션으로 만들어야 한다. 하지만 만약 표식이 붙은 객체만 인자로 받을 수 있는 메서드를 만든다면 표식 인터페이스를 사용해야 한다. 그러면 해당 메서드의 인자 자료형으로 해당 인터페이스를 사용할 수 있어서, 컴파일 시간에 형 검사를 진행할 수 있게 된다. 요약하자면, 표식 인터페이스와 표식 애노테이션은 쓰임새가 다르다. 새로운 메서드가 없는 자료형을 정의하고자 한다면 표식 인터페이스를 이용해야 한다. 클래스나 인터페이스 이외의 프로그램 요소에 표식을 달아야 하고, 앞으로 표식에 더 많은 정보를 추가할 가능성이 있다면, 표식 애노테이션을 사용해야 한다.\n"
},
{
	"uri": "/%E1%84%8C%E1%85%A1%E1%84%87%E1%85%A1_%E1%84%89%E1%85%A5%E1%86%BC%E1%84%82%E1%85%B3%E1%86%BC_%E1%84%90%E1%85%B2%E1%84%82%E1%85%B5%E1%86%BC_%E1%84%8B%E1%85%B5%E1%84%8B%E1%85%A3%E1%84%80%E1%85%B5/static_%E1%84%8C%E1%85%A6%E1%84%83%E1%85%A2%E1%84%85%E1%85%A9_%E1%84%92%E1%85%A1%E1%86%AB%E1%84%87%E1%85%A5%E1%86%AB_%E1%84%8A%E1%85%A5_%E1%84%87%E1%85%A9%E1%84%8C%E1%85%A1/",
	"title": "static 제대로 한번 써 보자",
	"tags": [],
	"description": "",
	"content": " 자바에서 static으로 지정했다면, 해당 메서드나 변수는 정적이다.\npublic class VariableTypes { int instance Variable; static int classVariable; public void method(int parameter) { int localVariable; } } 여기서 static으로 선언한 classVariable은 클래스 변수라고 한다. 왜냐하면 그 변수는 \u0026lsquo;객체의 변수\u0026rsquo;가 되는 것이 아니라 \u0026lsquo;클래스의 변수\u0026rsquo;가 되기 때문이다. 100개의 VariableTypes 클래스의 인스턴스를 생성하더라도, 모든 객체가 classVariable에 대해서는 동일한 주소의 값을 참조한다.\nstatic 초기화 블록에 대해서도 다시한번 알아보자.\npublic class StaticTest { static String staticVal; static { staticVal = \u0026#34;Static Value\u0026#34;; staticVal = StaticTest2.staticInt + \u0026#34;\u0026#34;; } public static void main(String[] args) { System.out.println(StaticTest.staticVal); } static { staticVal = \u0026#34;Performance is important !!!\u0026#34;; } } static 초기화 블록은 위와 같이 클래스 어느 곳에나 지정할 수 있다. 이 static 블록은 클래스가 최초 로딩될 때 수행되므로 생성자 실행과 상관없이 수행된다. 또한 여러 번 사용할 수 있으며, 이와 같이 사용했을 때 staticVal 값은 마지막에 지정한 값이 된다. static 블록은 순차적으로 읽혀진다는 의미이다.\nstatic의 특징은 다른 JVM 에서는 static이라고 선언해도 다른 주소나 다른 값을 참조하지만, 하나의 JVM이나 WAS 인스턴스에서는 같은 주소에 존재하는 값을 참조한다는 것이다. 그리고 GC의 대상도 되지 않는다. 그러므로 static을 잘 사용하면 성능을 뛰어나게 향상시킬 수 있지만, 잘못 사용하면 예기치 못한 결과를 초래하게 된다.\n특히 웹 환경에서 static을 잘못 사용하다가는 여러 쓰레드에서 하나의 변수에 접근할 수도 있기 때문에 데이터가 꼬이는 큰 일이 발생할 수도 있다.\nstatic 잘못 쓰면 이렇게 된다 public class BadQueryManager { private static String queryURL = null; public BadQueryManager(String badUrl) { queryURL = badUrl; } public static String getSql(String idSql) { try { FileReader reader = new FileReader(); HashMap\u0026lt;String, String\u0026gt; document = reader.read(queryURL); return document.get(idSql); } catch (Exception ex) { System.out.println(ex); } return null; } } 만약 어떤 화면에서 BadQueryManager의 생성자를 통해서 queryURL을 설정하고, getSql을 호출하기 전에, 다른 queryURL을 사용하는 화면의 스레드에서 BadQueryManager의 생성자를 호출하면 어떤 일이 발생할까? 그때부터는 시스템이 오류를 발생시킨다.\n"
},
{
	"uri": "/toby_spring/%E1%84%90%E1%85%A9%E1%84%87%E1%85%B5%E1%84%8B%E1%85%A8%E1%84%8B%E1%85%AC/",
	"title": "예외",
	"tags": [],
	"description": "",
	"content": " 초난감 예외처리 코드\n// 1번 try { ... } catch(SQLException e) { //예외를 잡고 아무것도 하지 않는다. } // 2번 catch(SQLException e) { System.out.println(e); // 다른 로그나 메세지에 금방 묻혀버려 놓치지 쉽상 } // 3번 catch(SQLException e) { e.printStackTract(); // 다른 로그나 메세지에 금방 묻혀버려 놓치지 쉽상 } catch 블록을 이용해 화면에 메세지를 출력한 것은 예외를 처리한 게 아니다. 예외를 처리할 때 반드시 지켜야 할 핵심 원칙은 한 가지다. 모든 예외는 적절하게 복구되든지 아니면 작업을 중단시키고 운영자 또는 개발자에게 분명하게 통보돼야 한다.\n// 그나마 나은 예외 catch(SQLException e) { e.printStackTract(); System.exit(1); } 무의미하고 무책임한 throws\ncatch 블록으로 예외를 잡아봐야 해결할 방법도 없고 처리하기 귀찮아서 throws Excpetion을 기계적으로 붙이는 경우도 있다. 이런 무책임한 throws 선언도 심각한 문제점이 있다. 자신이 사용하려고 하는 메서드 선언에서는 의미 있는 정보를 얻을 수 없다. 정말 무엇인가 실행 중에 예외적인 상황이 발생할 수 있다는 것인지, 아니면 그냥 습관적으로 복사해서 붙여 놓은 것인지 알 수 가 없다.\n일반적으로 예외라고 하면 Exception 클래스의 서브 클래스 중에서 RuntimeException을 상속하지 않은 것만을 말하는 체크 예외라고 생각해도 된다.\n예외처리 방법 예외복구 : 예외처리 코드를 강제하는 체크 예외들은 예외를 어떤 식으로든 복구할 가능성이 있는 경우에 사용한다.\n예를 들어 사용자가 요청한 파일을 읽으려고 시도했는데 해당 파일이 없다거나 다른 문제가 있어서 읽히지가 않아서 IOException 발생했다고 해보자. 이때는 사용자에게 상황을 알려주고 다른 파일을 이용하도록 안내해서 예외상황을 해결할 수 있다. 단, IOException 에러 메세지가 사용자에게 그냥 던져지는 것은 예외 복구라고 볼 수 없다.\nint maxretry = MAX_RETRY; while(maxretry-- \u0026gt; 0) { try { … return; } catch(SomeException e) { // 로그 출력. 정해진 시간만큼 대기 \t} finally { // 리소스 반납. 정리 작업 \t} } throw new RetryFailedException(); // 최대 재시도 횟수를 넘기면 직접 예외 발생 예외처리 회피 : 예외처리를 자신이 담당하지 않고 자신을 호출한 쪽으로 던져버리는 것 (throws)\n예외 전환 : 예외 회피와 비슷하게 메소드 밖으로 던지지만 발생한 예외를 그대로 넘기는게 아니라 적절한 예외로 전환해서 던진다는 특징이 있다. 예외 전환은 두가지 목적으로 사용된다. 첫째는 내부에서 발생한 예외를 그대로 던지는 것이 그 예외상황에 대한 적절한 의미를 부여해주지 못하는 경우에, 의미를 분명하게 해줄수 있는 예외로 바꿔주기 위해서다.\ncatch(SQLException e){ ... throw DuplicateUserIdException(e); } 보통 전환하는 예외에 원래 발생한 예외를 담아서 중첩 예외로 만드는 것이 좋다. 중첩 예외는 새로운 예외를 만들면서 생성자나 initCause() 메서드로 근본 원인이 되는 예외를 넣어주면 된다.\ncatch(SQLException e){ ... throw DuplicateUserIdException().initCause(e); } 두 번째 방법은 예외를 처리하기 쉽고 단순하게 만들기 위해 포장하는 것이다. 주로 예외처리를 강제하는 체크 예외를 언체크 예외인 런타임 예외로 바꾸는 경우에 사용한다.\n일반적으로 체크 예외를 계속 throws를 사용해 넘기는 건 무의미하다. 어차피 복구가 불가능한 예외라면 가능한 한 빨리 런타임 예외로 포장해 던지게 해서 다른 계층의 메서드를 작성할 때 불필요한 throws 선언이 들어가지 않도록 해줘야 한다.\n예외처리 전략 체크 예외는 복구할 가능성이 조금이라도 있는, 말 그대로 예외적인 상황이기 때문에 자바는 이를 처리하는 catch 블록이나 throws 선언을 강제하고 있다는게 문제다.\n자바가 처음 만들어질 때 많이 사용되던 애플릿이나 AWT, 스윙을 사용한 독립형 애플리케이션에서는 통제 불가능한 시스템 예외라고 할지라도 애플리케이션의 작업이 중단되지 않게 해주고 상황을 복구해야 했다. 예를 들어 워드의 파일 열기 기능에서 사용자가 입력한 이름에 해당하는 파일을 찾을 수 없다고 애플리케이션이 종료돼버리게 할 수는 없다.\n하지만 자바 엔터프라이즈 서버환경은 다르다. 수많은 사용자가 동시에 요청을 보내고 각 요청이 독립적인 작업으로 취급된다. 하나의 요청을 처리하는 중에 예외가 발생하면 해당 작업만 중단시키면 그만이다. 자바 엔터프라이즈 서버환경에서는 독립형 애플리케이션과 달리 서버의 특정 계층에서 예외가 발생했을 때 작업을 일시 중지하고 사용자와 바로 커뮤니케이션하면서 예외상황을 복구할 수 있는 방법이 없다. 차라리 프로그램의 오류나 외부 환경으로 인해 예외가 발생하는 경우라면 빨리 해당 요청의 작업을 취소하고 서버 관리자나 개발자에게 통보해주는 편이 낫다. 즉, 자바의 환경이 서버로 이동하면서 체크 예외의 활용도와 가치는 점점 떨어지고 있다. 그래서 대응이 불가능한 체크 예외라면 빨리 런타임 예외로 전환해서 던지는 게 낫다.\nadd() 메서드 예외처리\npublic void add(User user) throws DuplicateUserIdException, SQLException{ try{ // JDBC를 이용해 user 정보를 DB에 추가하는 코드 또는  // 그런 기능을 가진 다른 SQLException을 던지는 메서드를 호출하는 코드  } catch(SQLException e){ //ErrorCode가 MySQL의 \u0026#34;Duplicate Entry(1062)\u0026#34;이면 예외 전환  if(e.getErrorCode() == MysqlErrorNumbers.ER_DUP_ENTRY) throw DuplicateUserIdException(); else throw e; // 그 외의 경우는 SQLException 그대로  } } 위 코드를 보면 DuplicateUserIdException과 SQLException 두 가지의 체크 예외를 던지게 되어 있다. DuplicateUserIdException은 충분히 복구 가능한 예외이므로 add() 메서드를 사용하는 쪽에서 잡아서 대응할 수 있다. 하지만 SQLException은 대부분 복구 불가능한 예외이므로 잡아봤자 처리할 것도 없고, 결국 throws를 타고 계속 앞으로 전달되다가 애플리케이션 밖으로 던져질 것이다. 그럴 바에는 그냥 런타임 예외로 포장해 던져버려서 그 밖의 메서드들이 신경 쓰지 않게 해주는 편이 낫다.\nDuplicateUserIdException도 굳이 체크 예외로 둬야 하는 것은 아니다. DuplicateUserIdException처럼 의미 있는 예외는 add() 메서드를 바로 호출한 오브젝트 대신 더 앞단의 오브젝트에서 다룰 수 도 있다. 어디에서든 DuplicateUserIdException을 잡아서 처리할 수 있다면 굳이 체크 예외로 만들지 않고 런타임 예외로 만드는 게 낫다. 대신 add() 메서드는 명시적으로 DuplicateUserIdException을 던진다고 선언해야 한다. 그래야 add() 메서드를 사용하는 코드를 만드는 개발자에게 의미 있는 정보를 전달해줄 수 있다. 런타임 예외도 throws로 선언할 수 있으니 문제 될 것은 없다.\npublic DuplicateUserIdException extends RuntimeException{ public DuplicateUserIdException(Throwable cause){ super(cause); } } 먼저 사용자 아이디가 중복됐을 때 사용하는 DuplicateUserIdException을 만든다. 중첩 예외를 만들 수 있도록 생성자를 추가해주는 것을 잊지 말자.\npublic void add(User user) throws DuplicateUserIdException{ try{ // JDBC를 이용해 user 정보를 DB에 추가하는 코드 또는  // 그런 기능을 가진 다른 SQLException을 던지는 메서드를 호출하는 코드  } catch(SQLException e){ if(e.getErrorCode() == MysqlErrorNumbers.ER_DUP_ENTRY) throw new DuplicateUserIdException(e); //예외전환  else throw new RuntimeException(e); //예외 포장  } } 이제 이 add() 메서드를 사용하는 오브젝트는 SQLException을 처리하기 위해 불필요한 throws 선언을 할 필요는 없으면서, 필요한 경우 아이디 중복 상황을 처리하기 위해 DuplicateUserIdException을 이용할 수 있다.\n애플리케이션 예외 시스템 또는 외부의 예외상황이 원인이 아니라 애플리케이션 자체의 로직에 의해 의도적으로 발생시키고, 반드시 catch 해서 무엇인가 조치를 취하도록 요구하는 예외를 애플리케이션 예외라고 한다.\n은행계좌에서 출금하는 기능을 가진 메서드가 있다고 해보자. 이런 기능을 담은 메서드를 설계하는 방법이 두 가지 있다. 첫 번째 방법은 정상적인 출금처리를 했을 경우와 잔고 부족이 발생했을 경우에 각각 다른 종류의 리턴 값을 돌려주는 것이다. 하지만 이 방법은 정상적인 처리가 안됐을 때 전달하는 리턴값의 표준 같은게 없어서 개발자 사이의 의사소통 문제로 제대로 동작하지 않을 위험이 있다. 또 한 가지 문제는 결과 값을 확인하는 조건문이 자주 등장해서 if 블록이 범벅된 코드가 이어질지 모른다.\n두 번째 방법은 정상적인 흐름을 따르는 코드는 그대로 두고, 잔고 부족과 같은 예외 상황에서는 비지니스적인 의미를 띤 예외를 던지도록 만드는 것이다. 이때 사용하는 예외는 의도적으로 체크 예외로 만든다. 그래서 개발자가 잊지 않고 잔고 부족처럼 자주 발생 가능한 예외상황에 대한 로직을 구현하도록 강제해주는 게 좋다.\ntry { BigDecimal balance = account.withdraw(amount); … // 정상적인 처리 결과를 출력하도록 진행 } catch( InsufficientBalanceException e) { // InsufficientBalanceException에 담긴 인출 가능한 잔고금액 정보를 가져옴 \tBigDecimal availFunds = e.getAvailFunds(); … // 잔고 부족 안내 메세지를 준비하고 이를 출력하도록 진행 } 예외 전환 자바 데이터 액세스 기술은 JDBC 외에도 JDO, JPA 등이 있다. 또한 JDBC를 기반으로 하고, 성격도 비슷하지만 사용 방법과 API, 발생하는 예외가 다른 iBatis도 있다.\nDAO 인터페이스를 통해 구현을 분리시켰지만 메서드 선언에 나타나는 예외정보때문에 클라이언트가 DAO 기술에 의존적이 될 수 밖에 없다.\npulbic interface UserDao { public void add(User user) throws PersistentException; public void add(User user) throws HibernateException; public void add(User user) throws JdoException; } DAO 인터페이스를 기술에 완전히 독립적으로 만들려면 예외가 일치하지 않는 문제도 해결해야 한다. 그래서 스프링은 자바의 다양한 데이터 액세스 기술을 사용할 때 발생하는 예외들을 추상화해서 DataAccessException 계층구조 안에 정리해놓았다.\n"
},
{
	"uri": "/%E1%84%8C%E1%85%A1%E1%84%87%E1%85%A1_%E1%84%89%E1%85%A5%E1%86%BC%E1%84%82%E1%85%B3%E1%86%BC_%E1%84%90%E1%85%B2%E1%84%82%E1%85%B5%E1%86%BC_%E1%84%8B%E1%85%B5%E1%84%8B%E1%85%A3%E1%84%80%E1%85%B5/",
	"title": "자바 성능 튜닝 이야기",
	"tags": [],
	"description": "",
	"content": " 자바 성능 튜닝 이야기 "
},
{
	"uri": "/spring_%E1%84%80%E1%85%A2%E1%84%87%E1%85%A1%E1%86%AF_%E1%84%8B%E1%85%B5%E1%84%89%E1%85%B2%E1%84%86%E1%85%A9%E1%84%8B%E1%85%B3%E1%86%B7/",
	"title": "Spring 개발 이슈모음",
	"tags": [],
	"description": "",
	"content": " Spring Issue "
},
{
	"uri": "/effective_java/%E1%84%85%E1%85%A1%E1%86%B7%E1%84%83%E1%85%A1%E1%84%8B%E1%85%AA_%E1%84%89%E1%85%B3%E1%84%90%E1%85%B3%E1%84%85%E1%85%B5%E1%86%B7/",
	"title": "람다와 스트림",
	"tags": [],
	"description": "",
	"content": " item44 : 표준 함수형 인터페이스를 사용해라 Java에 람다 (lambdas)가 생겨서 API를 작성하는 모범 사례가 많이 바뀌었다. 예를 들어, 템플릿 메서드 패턴은 이제 덜 매력적이다. 동일한 효과를 얻기 위해 함수 객체를 받는 static factory나 생성자가 모던한 대체제다. 더 일반적으로, 함수 객체를 파라미터로 받는 생성자나 메서드를 작성할거다. 올바른 함수형 파라미터 타입을 선택하는것은 주의가 필요하다.\nLinkedHashMap을 생각해보자. 아래의 removeEldestEntry 메서드를 오버라이딩해서 map에 put할 때마다 호출하려고 한다.\nprotected boolean removeEldestEntry(Map.Entry\u0026lt;K,V\u0026gt; eldest) { return false; } 이 메서드가 true를 리턴하면, 맵은 eldest entry를 제거한다. 아래와 같이 오버라이드한다면 맵 사이즈가 100개를 항상 유지시킬 수 있다.\n@Override protected boolean removeEldestEntry(Map.Entry\u0026lt;K,V\u0026gt; eldest) { return size() \u0026gt; 100; } 이 기법은 올바르게 동작하지만 람다로 더 좋게 표현할 수 있다. LinkedHashMap이 오늘 작성된 경우 함수 객체를 사용하는 정적 팩토리 또는 생성자를 갖는다. removeEldestEntry 메서드 선언을 보면, 함수 객체는 Map.Entry\u0026lt;K, V\u0026gt;를 받고 boolean을 리턴해야된다고 생각할 수 있다. 그러나 그렇지 않다. removeEldestEntry 메서드 안에서 size() 메서드를 호출하는데, removeEldestEntry 메서드가 인스턴스 메서드이기 때문에 가능하다. 생성자에 전달하는 함수 객체는 인스턴스 메서드가 아니기 때문에 캡쳐를 할 수 없다(맵은 팩토리나 생성자가 호출될 때 아직 존재하지 않기 때문). 그러므로, 맵은 함수 객체에 자신을 넘기고, eldest entry도 넘겨야 한다. 함수형 인터페이스를 선언한다면 아래와 같을것이다.\n@FunctionalInterface interface EldestEntryRemovalFunction\u0026lt;K,V\u0026gt; { boolean remove(Map\u0026lt;K,V\u0026gt; map, Map.Entry\u0026lt;K,V\u0026gt; eldest); } 이 인터페이스는 잘 동작하겠지만, 새로운 인터페이스를 선언할 필요는 없다. java.util.function 패키지는 다양한 표준 함수형 인터페이스를 제공한다. 표준 함수형 인터페이스 중 하나가 작업을 수행하는 경우 일반적으로 특수 기능 인터페이스보다 우선적으로 사용해야한다. 표준 함수형 인터페이스를 사용하는 것은 개념적 표면적을 줄임으로써 API를 배우기 쉽게 만들고, 많은 표준 함수형 인터페이스가 유용한 디폴트 메서드들을 제공하므로 중요한 상호 운용성 이점을 제공한다.\n예를들어 Predicate 인터페이스는 predicates 결합하기 위한 메서드를 제공한다. LinkedHashMap 예제에서 표준 BiPredicate\u0026lt;Map\u0026lt;K,V\u0026gt; map, Map.Entry\u0026lt;K,V\u0026gt;\u0026gt; 인터페이스를 이용하는게 낫다.\n@FunctionalInterface public interface BiPredicate\u0026lt;T, U\u0026gt; { /** * Evaluates this predicate on the given arguments. * * @param t the first input argument * @param u the second input argument * @return {@code true} if the input arguments match the predicate, * otherwise {@code false} */ boolean test(T t, U u); ... } java.util.function 패키지에는 43개의 인터페이스가 있다. 모두 다 기억할 순 없지만, 기본 인터페이스 6개만 기억한다면 나머지는 필요할 때 이끌어낼수 있다. 기본 인터페이스들은 object reference types에서 동작한다.\n6개의 기본 함수형 인터페이스 요약은 아래와 같다. | Interface | Function Signature | Example | | \u0026mdash;\u0026mdash;\u0026ndash; | \u0026mdash;\u0026mdash;\u0026ndash; | \u0026mdash;\u0026mdash;\u0026ndash; | | UnaryOperator\u0026lt;T\u0026gt; | T apply(T t) | String::toLowerCase | | BinaryOperator\u0026lt;T\u0026gt; | T apply(T t1, T t2) | BigInteger::add | | Predicate\u0026lt;T\u0026gt; | boolean test(T t) | Collection::isEmpty | | Function\u0026lt;T,R\u0026gt; | R apply(T t) | Arrays::asList | | Supplier\u0026lt;T\u0026gt; | T get() | Instant::now | | Consumer\u0026lt;T\u0026gt; | void accept(T t) | System.out::println |\n또한 6개 기본 인터페이스 각각에 int, long, double 3가지 primitive type에서 동작하는 변종 인터페이스도 있다(네이밍은 기본 인터페이스 이름 prefix에 추가). 예를 들어 int를 받는 predicate는 IntPredicate이고 두개의 long 값을 받고 long을 리턴하는 binary operator는 LongBinaryOperator다. 이런 변종 인터페이스는 Function 류만 리턴 타입을 파라미터화한다. 예를 들어, LongFunction\u0026lt;int[]\u0026gt;는 int[]를 리턴한다. Function 인터페이스에는 9개의 추가적인 변종들이 있는데 result 타입이 primitive일 때 사용된다. source와 result 타입이 항상 다른데, 똑같다면 UnaryOperator 인터페이스다. 만약 source와 result 타입이 primitive이면, SrcToResult 형식으로 네이밍이 붙는다(ex LongToIntFunction) 만약 source는 primitive인데 result type이 object reference라면 \u0026lt;Src\u0026gt;ToObj 형식으로 네이밍한다(ex DoubleToObjFunction)\n3개의 기본 함수형 인터페이스에 두개인자를 갖는 버전들이 있다. BiPredicate\u0026lt;T,U\u0026gt; BiFunction\u0026lt;T,U,R\u0026gt; BiConsumer\u0026lt;T,U\u0026gt; 또한 리턴을 primitive 타입으로 하는 BiFunction 류가 있다. ToIntBiFunction\u0026lt;T,U\u0026gt; ToLongBiFunction\u0026lt;T,U\u0026gt; ToDoubleBiFunction\u0026lt;T,U\u0026gt; 그리고 하나는 object reference와 나머지 하나는 primitive 타입을 받는 Consumer 류가 있다. ObjDoubleConsumer\u0026lt;T\u0026gt; ObjIntConsumer\u0026lt;T\u0026gt; ObjLongConsumer\u0026lt;T\u0026gt; 이렇게 총 9개가 기본 인터페이스의 두개 인자받는 유형들이다.\n마지막으로 BooleanSupplier 인터페이스가 있는데, return 타입이 boolean이다. 기본 함수형 인터페이스 네이밍에서 Boolean이 명시적으로 사용되는 유일한 인터페이스이다. boolean return 타입은 Predicate와 그 변종들이 지원하고 있기 때문이다. 이전 단락에서 설명한 BooleanSupplier 인터페이스와 42개 인터페이스들은 모든 43개 표준 함수형 인터페이스들을 설명한다. 솔직히 삼켜야 될게 많지만(알아야 될게 많지만) 끔찍할 정도는 아니다. 다른 한편으로 필요한 함수형 인터페이스의 대부분은 당신을 위해 쓰여졌고 그 이름은 충분히 규칙적이어서 필요할 때 사용하기 어려움을 겪지않아야한다.\n대부분의 표준 함수형 인터페이스는 primitive 타입을 위해 제공된다. primitive 함수형 인터페이스를 사용하는것 대신에 기본 함수형 인터페이스에 boxed primitive를 함께 사용하려는 유혹을 받지 마라. 동작은 하겠지만, 규칙 61에 위배된다(Prefer primitive types to boxed primitives). 대량의 operation에서 boxed primitive의 성능은 안좋다.\n이제 일반적으로 직접 작성한 함수형 인터페이스보다 표준 함수형 인터페이스를 사용해야된다는 것을 알았을것이다. 그러나 언제 직접 작성한걸 써야할까? 당연히 표준에 없는거라면 직접 작성해 써야한다. 예를들어, 3개의 파라미터가 필요한 Predicate 라던지, checked exception을 throw 해야된다던지. 그러나 표준 인터페이스 중 하나와 구조적으로 동일한 경우에도 사용자 고유의 함수형 인터페이스를 작성해야 할 때가 있다.\nComparator\u0026lt;T\u0026gt;를 생각해보면 ToIntBiFunction\u0026lt;T,T\u0026gt;와 구조적으로 동일하지만 사용하면 안된다. 여러가지 이유가 있는데 첫째, 함수의 네이밍은 API를 사용할 때 최고의 문서로써 제공된다. 둘째, Comparator 인터페이스를 사용할 때는 각 인스턴스들을 비교하고자 하는 강한 요구사항이 있다. 셋째, 인터페이스에는 comparators를 변환하고 결합하는 유용한 default 메소드가 많이 필요하다.\n아래와 같은 Comparator 특성에 따라 신중하게 생각해서 직접 작성한 인터페이스를 사용해야한다. - 일반적으로 사용되며 설명이 포함된 이름으로 이득이 된다. - 강한 계약이 있다(it has a strong contract associated with it). - 커스텀 디폴트 메서드의 이점을 얻는다.\n만약 직접 작성하기로 했다면 그것이 인터페이스임을 명심하고 주의해서 설계해라.\nEldestEntryRemovalFunction 인터페이스에 @FunctionalInterface 애노테이션이 붙은것을 주목해라. 이 애노테이션은 @Override 정신과 유사하다. 이 애노테이션은 다음과 같은 3가지 목적의 의도를 말해준다. 첫째, 람다사용이 가능하도록 인터페이스가 설계되었다 둘째, 정확히 하나의 abstract 메서드만 있지 않는 한 컴파일 되지 않으므로 작성자가 실수하지 않는다. 셋째, 인터페이스가 진화함에 따라 유지관리자가 abstract 메서드를 추가하는 실수를 막아준다. 함수형 인터페이스에는 항상 @FunctionalInterface 애노테이션을 붙여라\n마지막 포인트는 API에서 함수형 인터페이스를 사용할때다. 클라이언트에서 가능한 모호성을 만들 수있는 경우 동일한 인수 위치에서 다른 함수형 인터페이스를 사용하는 여러 오버로드가 있는 메소드를 제공하지 마라. 이것은 단지 이론적인 문제가 아니다. ExecutorService 의 submit 메서드는 Callable\u0026lt;T\u0026gt;나 Runnable을 받을 수 있고 올바른 오버로딩을 나타내기 위해 cast가 필요한 클라이언트 프로그램을 작성하는게 가능하다.\n\u0026lt;T\u0026gt; Future\u0026lt;T\u0026gt; submit(Callable\u0026lt;T\u0026gt; task); \u0026lt;T\u0026gt; Future\u0026lt;T\u0026gt; submit(Runnable task, T result); Future\u0026lt;?\u0026gt; submit(Runnable task); 이러한 문제를 피하는 가장 쉬운 방법은 같은 인자 위치에 다른 함수형 인터페이스를 갖는 오버로딩 메서드를 작성하지 않는것이다. 규칙 52 use overloading judiciously 에서 다루는 특별한 케이스다.\n요약하면, 지금 자바는 람다가 가능하고 API를 설계하는데 람다를 생각하는걸 피할수 없다. 함수형 인터페이스 타입을 input과 output에 두는걸 받아들여라. java.util.function.Function가 제공하는 표준 인터페이스를 사용하는게 베스트다. 그러나 상대적으로 드문 케이스로 직접 작성하는 함수형 인터페이스가 더 나을 수 있으니 keep your eys open해라.\n"
},
{
	"uri": "/toby_spring/%E1%84%89%E1%85%A5%E1%84%87%E1%85%B5%E1%84%89%E1%85%B3_%E1%84%8E%E1%85%AE%E1%84%89%E1%85%A1%E1%86%BC%E1%84%92%E1%85%AA/",
	"title": "서비스 추상화",
	"tags": [],
	"description": "",
	"content": "추상화란 하위 시스템의 공통점을 뽑아내서 분리시키는 것을 말한다. 그렇게 하면 하위 시스템이 어떤 것인지 알지 못해도, 또는 하위 시스템이 바뀌더라도 일관된 방법으로 접근할 수가 있다.\n객체지향적인 코드는 다른 오브젝트의 데이터를 가져와서 작업하는 대신 데이터를 갖고 있는 다른 오브젝트에게 작업을 해달라고 요청한다. 오브젝트에게 데이터를 요구하지 말고 작업을 요청하라는 것이 객체지향 프로그래밍의 가장 기본이 되는 원리이다.\n일반적으로 서비스 추상화라고 하면 트랜잭션과 같이 기능은 유사하나 사용 방법이 다른, 로우레벨의 다양한 기술에 대해 추상 인터페이스와 일관성 있는 접근 방법을 제공해 주는 것을 말한다.\n비지니스 로직 트랜잭션 문제점 setAutoCommit(false)로 트랜잭션의 시작을 선언하고 commit()또는 rollback()으로 트랜잭션을 종료하는 작업을 트랜잭션의 경계설정이라고 한다. 트랜잭션의 경계는 하나의 Connection이 만들어지고 닫히는 범위 안에 존재한다. 이렇게 하나의 DB 커넥션 안에서 만들어지는 트랜잭션을 로컬 트랜잭션이라고도 한다.\n그런데 위의 그림과 같이 트랜잭션의 문제점이 있다. DAO를 분리해놓았을 경우에는 이처럼 DAO 메서드를 호출할 때마다 하나의 새로운 트랜잭션이 만들어지는 구조가 될 수밖에 없다. 따라서 UserService의 모든 메서드 전체를 하나의 트랜잭션으로 묶을 방법이 없게된다. 결국 비지니스 로직에 트랜잭션 경계설정을 해야하는데 그렇게되면 비지니스로직에 데이터 액세스 코드가 들어가게 되므로 단일책임원칙도 어긋나고, DB에 의존적인 코드가 돼버린다.\n이를 위해 스프링이 제안하는 방법은 독립적인 트랜잭션 동기화 방식이다. 트랜잭션 동기화란 UserService에서 트랜잭션을 시작하기 위해 만든 Connection 오브젝트를 특별한 저장소에 보관해두고, 이후에 호출되는 DAO의 메서드에서는 저장된 Connection을 가져다가 사용하게 하는 것이다. 정확히는 DAO가 사용하는 JdbcTemplate이 트랜잭션 동기화 방식을 이용하도록 하는 것이다. 그리고 트랜잭션이 모두 종료되면, 그때는 동기화를 마치면 된다. (1) UserService는 Connection을 생성하고 (2) 이를 트랜잭션 동기화 저장소에 저장해두고 Connection의 setAutoCommit(false)를 호출해 트랜잭션을 시작시킨 후에 본격적으로 DAO의 기능을 이용하기 시작한다. (3) 첫 번째 update() 메서드가 호출되고, update() 메서드 내부에서 이용하는 JdbcTemplate 메서드에서는 가장 먼저 (4) 트랜잭션 동기화 저장소에 현재 시작된 트랜잭션을 가진 Connection 오브젝트가 존재하는지 확인한다. (2) upgradeLevels() 메서드 시작 부분에서 저장해둔 Connection을 발견하고 이를 가져온다. 가져온 (5) Connection을 이용해 PreparedStatememt를 만들어 수정 SQL을 실행한다. 트랜잭션 동기화 저장소에서 DB 커넥션을 가져왔을 때는 JdbcTemplate은 Connection을 닫지 않은 채로 작업을 마친다. 이렇게 해서 트랜잭션 안에서 첫 번째 DB 작업을 마쳤다. 여전히 Connection은 열려 있고 트랜잭션은 진행 중인 채로 트랜잭션 동기화 저장소에 저장되어 있다. (6) 두 번째 update()가 호출되면 이때도 마찬가지로 (7) 트랜잭션 동기화 저장소에서 Connection을 가져와 (8) 사용한다. (9) 마지막 update()도 (10) 같은 트랜잭션을 가진 Connection을 가져와 (11) 사용한다. 트랜잭션 내의 모든 작업이 정상적으로 끝났으면 UserService는 이제 (12) Connection의 commit()을 호출해서 트랜잭션을 완료시킨다. 마지막으로 (13) 트랜잭션 저장도가 더 이상 Connection 오브젝트를 저장해두지 않도록 이를 작업한다. 어느 작업 중에라도 예외상황이 발생하면 UserService는 즉시 Connection의 rollback()을 호출하고 트랜잭션을 종료할 수 있다.\n트랜잭션 동기화 방식을 적용한 UserService\nprivate DataSource dataSource; //Connection을 생성할 때 사용할 DataSource를 DI 받도록 한다. public void setDataSource(DataSource dataSource){ this.dataSource = dataSource; } public void upgradeLevels() throws Exception{ //트랜잭션 동기화 관리자를 이용해 동기화 작업을 초기화한다.  TransactionSynchronizationManager.initSynchronization(); //DB 커넥션을 생성하고 트랜잭션을 시작한다.  //이후의 DAO 작업은 모두 여기서 시작한 트랜잭션 안에서 진행된다.  //DB 커넥션 생성과 동기화를 함께 해주는 유틸리티 메서드  Connection c = DataSourceUtils.getConnection(dataSource); c.setAutoCommit(false); try{ List\u0026lt;User\u0026gt; users = userDao.getAll(); for(User user : users){ if(canUpgradeLevel(user){ upgradeLevel(user); } } c.commit(); //정상적으로 작업을 마치면 트랜잭션 커밋  }catch(Exception e){ c.rollback(); //예외가 발생하면 롤백한다.  throw e; }finally{ //스프링 유틸리티 메서드를 이용해 DB 커넥션을 안전하게 닫는다.  DataSourceUtils.releaseConnection(c,dataSource); //동기화 작업 종료 및 정리  TransactionSynchronizationManager.unbindResource(this.dataSource); TransactionSynchronizationManager.clearSynchronization(); } } 그런데 새로운 문제가 있다. 만약 하나의 트랜잭션 안에서 여러 개의 DB에 데이터를 넣는 작업을 해야한다면 JDBC의 Connection을 이용한 트랜잭션 방식인 로컬 트랜잭션으로는 불가능하다. 왜냐하면 로컬 트랜잭션은 하나의 DB Connection에 종속되기 때문이다. 따라서 별도의 트랜잭션 관리자를 통해 트랜잭션을 관리하는 글로벌 트랜잭션 방식을 사용해야 한다.(JTA) 그리고 하이버네이트를 이용한 트랜잭션 관리코드는 JDBC나 JTA의 코드와는 또 다르다. 결국 트랜잭션의 경계설정을 담당하는 코드의 유사패턴(공통점)을 추출해 추상화 시켜야 한다.\n스프링의 트랜잭션 서비스 추상화 스프링이 제공하는 트랜잭션 추상화 방법을 UserService에 적용해보면 다음과 같다.\npublic void upgradeLevels() { PlatformTransactionManager transactionManager = new DataSourceTransactionManager(dataSource); // 트랜잭션 시작  TransactionStatus status = transactionManager.getTransaction(new DefaultTransactionDefinition()); try { List\u0026lt;User\u0026gt; users = userDao.getAll(); for (User user : users) { if (canUpgradeLevel(user)) upgradeLevel(user); } transactionManager.commit(status); } catch (RuntimeException e) { transcationManager.rollback(status); throw e; } } 스프링이 제공하는 트랜잭션 경계설정을 위한 추상 인터페이스는 PlatformTransactionManager다. JDBC의 로컬 트랜잭션을 이용한다면 DataSourceTransactionManager 구현체를 사용하면 된다.\n트랜잭션 추상화 API를 적용한 UserService 코드를 JTA를 이용하는 글로벌 트랜잭션으로 변경하려면 어떻게 해야 할까? 방법은 간단하다. PlatformTransactionManager 구현 클래스를 DataSourceTransactionManager에서 JTATransactionManager로 바꿔주기만 하면 된다. 만약 하이버네이트로 UserDao를 구현했다면 HibernateTransactionManager를, JPA를 적용했다면 JPATransactionManager를 사용하면 된다.\n하지만 어떤 트랜잭션 매니저 구현 클래스를 사용할지 UserService 코드가 알고 있는 것은 DI 원칙에 위배된다. 컨테이너를 통해 외부에서 제공받게 하는 스프링 DI의 방식으로 바꾸자.\npublic class UserService{ ... private PlatformTransactionManager transactionManager; public void setTransactionManager(PlatformTransactionManager transactionManager){ this.transactionManager = transactionManager; } public void upgradeLevels(){ TransactionStatus status = this.transactionManager.getTransaction(new DefaultTransactionDefinition()); try{ List\u0026lt;User\u0026gt; users = userDao.getAll(); for(User user : users){ if(canUpgradeLevel(user){ upgradeLevel(user); } } this.transactionManager.commit(status); }catch(RuntimeException e){ this.transactionManager.rollback(status); throw e; } } ... }\u0026lt;bean id=\u0026#34;userService\u0026#34; class=\u0026#34;springbook.user.service.UserService\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;userDao\u0026#34; ref=\u0026#34;userDao\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;transactionManager\u0026#34; ref=\u0026#34;transactionManager\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;transactionManager\u0026#34; class=\u0026#34;org.springframework.jdbc.datasource.DataSourceTransactionManager\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;dataSource\u0026#34; ref=\u0026#34;dataSource\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;transactionManager\u0026#34; class=\u0026#34;org.springframework.transaction.jta.JtaTransactionManager\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;dataSource\u0026#34; ref=\u0026#34;dataSource\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; 테스트 대역 테스트 대상이 되는 오브젝트의 기능에만 충실하게 수행하면서 빠르게, 자주 테스트를 실행할 수 있도록 사용하는 오브젝트를 통틀어서 테스트 대역(test double)이라고 부른다. 대표적인 테스트 대역은 스텁(stub)이다.\n스텁은 테스트 대상 오브젝트의 의존객체로서 존재하면서 테스트 동안에 코드가 정상적으로 수행할 수 있도록 돕는 것을 말한다.\n때론 테스트 대상 오브젝트가 의존 오브젝트에게 출력한 값에 관심이 있을 경우가 있다. 또는 의존 오브젝트를 얼마나 사용했는가 하는 커뮤니케이션 행위 자체에 관심이 있을 수 있다. 문제는 이 정보는 테스트에서는 직접 알 수가 없다는 점이다. 이때 목 객체를 만들어서 사용해야 한다.\nstatic class MockMailSender implements MailSender { private List\u0026lt;String\u0026gt; requests = new ArrayList\u0026lt;\u0026gt;(); public List\u0026lt;String\u0026gt; getRequests() { return requests; } public void send(SimpleMailMessage mailMessage) throws MailException { // 전송 요청을 받은 이메일 주소를 저장해둔다. 간단하게 첫 번째 수신자 메일 주소만 저장했다.  requests.add(mailMessage.getTo()[0]); } ... } 위 코드는 테스트 대상 오브젝트가 목 오브젝트에게 전달하는 출력정보를 저장해 두는 것이다.\n테스트 코드 @Test @DirtiesContext //컨텍스트의 DI 설정을 변경하는 테스트라는 것을 알려준다. public void upgradeLevels() trows Exception { ... MockMailSender mockMailSender = new MockMailSender(); userServce.setMailSender(mockMailSender); ... // Assertion  List\u0026lt;String\u0026gt; request = mockMailSender.getRequests(); assertThat(request.size(), is(2)); assertThat(request.get(0), is(users.get(1).getEmail()); ... } 보통의 테스트 방법으로는 검증하기가 매우 까다로운 테스트 대상 오브젝트의 내부에서 일어나는 일이나 다른오브젝트 사이에서 주고받는 정보까지 검증하는 일이 손쉽다.\n"
},
{
	"uri": "/%E1%84%8C%E1%85%A1%E1%84%87%E1%85%A1_%E1%84%89%E1%85%A5%E1%86%BC%E1%84%82%E1%85%B3%E1%86%BC_%E1%84%90%E1%85%B2%E1%84%82%E1%85%B5%E1%86%BC_%E1%84%8B%E1%85%B5%E1%84%8B%E1%85%A3%E1%84%80%E1%85%B5/%E1%84%8F%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A2%E1%84%89%E1%85%B3_%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%87%E1%85%A9_%E1%84%8B%E1%85%A5%E1%84%84%E1%85%A5%E1%87%82%E1%84%80%E1%85%A6_%E1%84%8B%E1%85%A1%E1%86%AF%E1%84%8B%E1%85%A1%E1%84%82%E1%85%A2%E1%86%AF_%E1%84%89%E1%85%AE_%E1%84%8B%E1%85%B5%E1%86%BB%E1%84%82%E1%85%A1/",
	"title": "클래스 정보, 어떻게 알아낼 수 있나?",
	"tags": [],
	"description": "",
	"content": " reflection 관련 클래스를 어떻게 사용해야 하는지 간단한 예를 통해서 살펴보자.\npublic class DemoClass { private String privateField; String field; protected String protectedField; public String publicField; public DemoClass() {} public DemoClass(String arg) {} public void publicMethod() throws IOException, Exception {} public String publicMethod(String s, int i) { return \u0026#34;s=\u0026#34;+s+ \u0026#34;i =\u0026#34;+i; } protected void protectedMethod() {} private void privateMethod() {} void method() {} public String publicRetMethod() { return null; } public InnerClass getInnerClass() { return new InnerClass(); } public class InnerClass { } }public class DemoTest { public static void main(String[] args) { DemoClass dc = new DemoClass(); // 점검 대상 클래스 객체  DemoTest dt = new DemoTest(); dt.getClassInfos(dc); } public void getClassInfos(Object clazz) { Class demoClass = clazz.getClass(); getClassInfo(demoClass); } public void getClassInfo(Class demoClass) { String className = demoClass.getName(); System.out.format(\u0026#34;Class Name : %s \\n\u0026#34;, className); String classCanonicalName = demoClass.getCanonicalName(); System.out.format(\u0026#34;Class Canonical Name : %s \\n\u0026#34;, classCanonicalName); String classSimpleName = demoClass.getSimpleName(); System.out.format(\u0026#34;Class Simple Name : %s \\n\u0026#34;, classSimpleName); String packageName = demoClass.getPackage().getName(); System.out.format(\u0026#34;Package Name : %s \\n\u0026#34;, packageName); String toString = demoClass.toString(); System.out.format(\u0026#34;toString : %s \\n\u0026#34;, toString); } } Class Name : org.sample.DemoClass Class Canonical Name : org.sample.DemoClass Class Simple Name : DemoClass Package Name : org.sample toString : class org.sample.DemoClass  이 코드는 클래스 정보만을 가져오는 부분이다. 이제 필드 정보를 읽는 부분을 보자.\npublic void getFieldInfo(Class demoClass) { Field[] field1 = demoClass.getDeclaredFields(); Field[] field2 = demoClass.getFields(); System.out.format(\u0026#34;Declared Fields : %d, Fields: %d\\n\u0026#34;, field1.length, field2.length); for (Field field : field1) { String fieldName = field.getName(); int modifier = field.getModifiers(); String modifierStr = Modifier.toString(modifier); String type = field.getType().getSimpleName(); System.out.format(\u0026#34;%s %s %s \\n\u0026#34;, modifierStr, type, fieldName); } } Declared Fields : 4, Fields: 1 private String privateField String field protected String protectedField public String publicField  여기서 가장 어려운 부분은 식별자 데이터를 가져오는 부분이다. getModifiers() 메서드에서는 int 타입으로 리턴을 하기 때문에 간단하게 변환을 하기가 어렵다. 그에 대비해서 Modifier 클래스에 static으로 선언되어 있는 Modifier.toString() 메서드가 있다. 이 메서드에 int 타입의 값을 보내면 식별자 정보를 문자열로 리턴한다.\n이제 메서드 정보를 가져오는 부분을 보자.\npublic void getMethodInfo(Class demoClass) { Method[] method1 = demoClass.getDeclaredMethods(); Method[] method2 = demoClass.getMethods(); System.out.format(\u0026#34;Declared methods : %d, Methods : %d\\n\u0026#34;, method1.length, method2.length); for (Method met1 : method1) { // method name info  String methodName = met1.getName(); // method modifier info  int modifier = met1.getModifiers(); String modifierStr = Modifier.toString(modifier); // method return type info  String returnType = met1.getReturnType().getSimpleName(); // method parameter info  Class params[] = met1.getParameterTypes(); StringBuilder paramStr = new StringBuilder(); int paramLen = params.length; if (paramLen != 0) { paramStr.append(params[0].getSimpleName()).append(\u0026#34; arg\u0026#34;); for (int loop = 1; loop \u0026lt; paramLen; loop++) { paramStr.append(\u0026#34;,\u0026#34;) .append(params[loop].getName()) .append(\u0026#34; arg\u0026#34;) .append(loop); } } // method exception info  Class exceptions[] = met1.getExceptionTypes(); StringBuilder exceptionStr = new StringBuilder(); int exceptionLen = exceptions.length; if (exceptionLen != 0) { exceptionStr.append(\u0026#34;throws\u0026#34;).append(exceptions[0].getSimpleName()); for (int loop = 1; loop \u0026lt; exceptionLen; loop++) { exceptionStr.append(\u0026#34;,\u0026#34;) .append(exceptions[loop].getSimpleName()); } } // print result  System.out.format(\u0026#34;%s %s %s(%s) %s\\n\u0026#34;, modifierStr, returnType, methodName, paramStr, exceptionStr); } } Declared methods : 7, Methods : 13 public String publicMethod(String arg,int arg1) public void publicMethod() throwsIOException,Exception protected void protectedMethod() private void privateMethod() public String publicRetMethod() public InnerClass getInnerClass() void method()  메서드 가져오는 부분에서 중요한 것은 예외와 매개변수를 처리하는 부분이다. 이 두 가지 데이터는 일반적으로 하나가 아니기 때문에 위와 같이 반복하면서 해당 부분의 정보를 읽어 와야 한다.\nreflection 클래스를 잘못 사용한 사례 public String checkClass(Object src) { if (src.getClass().getName().equals(\u0026#34;java.math.BigDecimal\u0026#34;)) { // 데이터 처리 \t} // 이하 생략 } 이렇게 사용할 경우 응답 속도에 그리 많은 영향을 주지는 않지만, 많이 사용하면 필요 없는 시간을 낭비하게 된다. getClass() 메서드를 호출할 때 Class 객체를 만들고, 그 객체의 이름을 가져오는 메서드를 수행하는 시간과 메모리를 사용한다.\npublic String checkClass(Object src) { if (src instance java.math.DigDecimal) { // 데이터 처리 \t} // 이하 생략 } 이러한 부분에서 개선이 필요할 때는 자바의 기본으로 돌아가자.\nJMH를 이용하여 얼마나 성능 차이가 있는지 비교해 보자.\n@State(Scope.Thread) @BenchmarkMode({Mode.AverageTime}) @OutputTimeUnit(TimeUnit.MICROSECONDS) public class Reflection { int LOOP_COUNT = 100; String result; @Benchmark public void withEquals() { Object src = new BigDecimal(\u0026#34;6\u0026#34;); for (int loop = 0; loop \u0026lt; LOOP_COUNT; loop++) { if (src.getClass().getName().equals(\u0026#34;java.math.BigDecimal\u0026#34;)) { result = \u0026#34;BigDecimal\u0026#34;; } } } @Benchmark public void withInstanceof() { Object src = new BigDecimal(\u0026#34;6\u0026#34;); for (int loop = 0; loop \u0026lt; LOOP_COUNT; loop++) { if (src instanceof java.math.BigDecimal) { result = \u0026#34;BigDecimal\u0026#34;; } } } public static void main(String[] args) throws RunnerException { Options opt = new OptionsBuilder() .include(Reflection.class.getSimpleName()) .warmupIterations(3) .measurementIterations(5) .forks(1) .build(); new Runner(opt).run(); } } # Run complete. Total time: 00:00:17 Benchmark Mode Cnt Score Error Units Reflection.withEquals avgt 5 0.276 ± 0.024 us/op Reflection.withInstanceof avgt 5 0.028 ± 0.006 us/op  큰 차이는 발생하지 않지만, 이런 부분이 모여 큰 차이를 만들기 때문에 작은 것부터 생각하면서 코딩하는 습관을 가지는 것이 좋다. 추가로 클래스의 메타 데이터 정보는 JVM의 Perm 영역에 저장된다는 사실을 기억해 주기 바란다. 만약 Class 클래스를 사용하여 엄청나게 많은 클래스를 동적으로 생성하는 일이 벌어지면 Perm 영역이 더 이상 사용할 수 없게 되어 OutOfMemoryError가 발생할 수도 있으니, 조심해서 사용하자.\n"
},
{
	"uri": "/toby_spring/aop/",
	"title": "AOP",
	"tags": [],
	"description": "",
	"content": " 스프링에 적용된 가장 인기 있는 AOP 적용 대상은 바로 선언적 트랜잭션 기능이다.\n1. 데코레이터 패턴을 이용한 트랜잭션 코드 분리 UserService 인터페이스를 도입해서 순수 비지니스로직을 담당하는 UserServiceImpl과 트랜잭션 처리를 담당하는 UserServiceTx로 나눈다.\npublic interface UserService { void add(User user); void upgradeLevels(); } UserServiceTx에서는 트랜잭션 경계설정을 통해 트랜잭션 작업을 수행하고 실질적인 비지니스로직은 주입받은 userServiceImpl에게 위임하는 구조다.\npublic class UserServiceTx implements UserService { UserService userService; PlatformTransactionManager transactionManager; public void setTransactionManager(PlatformTransactionManager transactionManager) { this.transactionManager = transactionManager; } public void setUserService(UserService userService) { this.userService = userService; } public void add(User user) { this.userService.add(user); } public void upgradeLevels() { TransactionStatus status = this.transactionManager.getTransaction(new DefaultTransactionDefinition()); try { userService.upgradeLevels(); this.transactionManager.commit(status); } catch(RuntimeException e) { this.transactionManager.rollback(status); throw e; } } }public class UserServiceImpl implements UserService { UserDao userDao; MailSender mailSender; public void upgradeLevels() { List\u0026lt;User\u0026gt; users = userDao.getAll(); for (User user : users) { if (canUpgradeLevel(user)) { upgradeLevel(user); } } } ... } 그리고 아래와 같이 클라이언트가 UserServiceTx 빈을 호출해서 사용하도록 만든다. 따라서 userService라는 대표적인 빈 아이디는 UserServiceTx 클래스로 정의된 빈에게 부여해준다.\n\u0026lt;bean id=\u0026#34;userService\u0026#34; class=\u0026#34;springbook.user.service.UserServiceTx\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;transactionManager\u0026#34; ref=\u0026#34;transactionManager\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;userService\u0026#34; ref=\u0026#34;userServiceImpl\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;userServiceImpl\u0026#34; class=\u0026#34;springbook.user.service.UserServiceImpl\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;userDao\u0026#34; ref=\u0026#34;userDao\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;mailSender\u0026#34; ref=\u0026#34;mailSender\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; ... cf) 프록시 패턴 vs 데코레이터 패턴\n먼저 프록시란 자신이 클라이언트가 사용하려고 하는 실제 대상인 것처럼 위장해서 클라이언트의 요청을 받아주는 것을 말한다. 그리고 프록시를 통해 최종적으로 요청을 위임받아 처리하는 실제 오브젝트를 타깃이라고 부른다.\n프록시의 특징은 타깃과 같은 인터페이스를 구현했다는 것과 프록시가 타깃을 제어할 수 있는 위치에 있다는 것이다. 프록시는 사용 목적에 따라 두 가지로 구분할 수 있다. 첫째는 클라이언트가 타깃에 접근하는 방법을 제어(프록시 패턴)하기 위해서다. 두 번째는 타깃에 부가적인 기능을 부여(데코레이터 패턴)해주기 위해서다.\n이 책에서는 타깃과 동일한 인터페이스를 구현하고 클라이언트와 타깃 사이에 존재하면서 기능의 부가 또는 접근 제어를 담당하는 오브젝트를 모두 프록시라 부른다.\n2. 다이내믹 프록시를 이용한 트랜잭션 부가기능 프록시를 이용하는 방법은 유용하지만 매번 새로운 클래스를 정의해야 하고, 만약 인터페이스의 구현해야 할 메서드가 많으면 모든 메서드를 일일히 구현해서 위임하는 코드를 넣어야하는 번거로움이 있다. 하지만 자바의 리플렉션 기능을 이용하면 손쉽게 구현할 수 있다. 다이내믹 프록시는 프록시 팩토리에 의해 런타임 시 다이내믹하게 만들어지는 오브젝트다. 다이내믹 프록시 오브젝트는 타깃의 인터페이스와 같은 타입으로 만들어진다. 클라이언트는 다이내믹 프록시 오브젝트를 타깃 인터페이스를 통해 사용할 수 있다. 이 덕분에 프록시를 만들 때 인터페이스를 모두 구현해가면서 클래스를 정의하는 수고를 덜 수 있다. 프록시 팩토리에게 인터페이스 정보만 제공해주면 해당 인터페이스를 구현한 클래스의 오브젝트를 자동으로 만들어주기 때문이다.\n다이내믹 프록시가 인터페이스 구현 클래스의 오브젝트는 만들어주지만, 프록시로서 필요한 부가기능 제공 코드는 직접 작성해야 한다. 부가기능은 프록시 오브젝트와 독립적으로 InvocationHandler를 구현한 오브젝트에 담는다. InvocationHandler 인터페이스는 다음과 같은 메서드 한 개만 가진 간단한 인터페이스다.\npublic Object invoke(Object proxy, Method method, Object[] args) invoke() 메서드는 리플렉션의 Method 인터페이스를 파라미터로 받는다. 메서드를 호출할 때 전달되는 파라미터도 args로 받는다. 다이내믹 프록시 오브젝트는 클라이언트의 모든 요청을 리플렉션 정보로 변환해서 InvocationHandler 구현 오브젝트의 invoke() 메서드로 넘기는 것이다. 타깃 인터페이스의 모든 메서드 요청이 하나의 메서드로 집중되기 때문에 중복되는 기능을 효과적으로 제공할 수 있다. 간단한 예를 통해 다시 살펴보자.\ninterface Hello { String sayHello(String name); String sayHi(String name); String sayThankYou(String name); } 위와 같은 Hello 인터페이스가 있고 이를 구현한 타깃 클래스는 다음과 같다.\npublic class HelloTarget implements Hello { public String sayHello(String name) { return \u0026#34;Hello\u0026#34; + name; } public String sayHi(String name) { return \u0026#34;Hi\u0026#34; + name; } public String sayThankYou(String name) { return \u0026#34;Thank You\u0026#34; + name; } } 이제 다이내믹 프록시를 위해 InvocationHandler 인터페이스를 구현한 부가기능 코드를 만들어보자(부가기능은 모든 글자를 대문자로 만드는 것이다).\npublic class UppercaseHandler implements InvocationHandler { Hello target; public UppercaseHandler(Hello target) { this.target = target; } public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { String ret = (String)method.invoke(target, args); return ret.toUpperCase(); } } Hello 인터페이스의 모든 메서드는 결과가 String 타입이므로 메서드 호출의 결과를 String 타입으로 변환해도 안전하다. 타깃 오브젝트의 메서드 호출이 끝났으면 프록시가 제공하려는 부가기능인 리턴 값을 대문자로 바꾸는 작업을 수행하고 결과를 리턴한다. 리턴된 값은 다이내믹 프록시가 받아서 최종적으로 클라이언트에게 전달될 것이다.\n이제 이 InvocationHandler를 사용하고 Hello 인터페이스를 구현하는 프록시를 만들어보자. 다이내믹 프록시의 생성은 Proxy 클래스의 newProxyInstance() 정적 팩토리 메서드를 이용하면 된다.\nHello proxiedHello = (Hello)Proxy.newProxyInstance( // 동적으로 생성되는 다이내믹 프록시 클래스의 로딩에 사용할 클래스 로더  getClass().getClassLoader(), // 구현할 인터페이스  new Class[] { Hello.class }, // 부가기능과 위임 코드를 담은 InvocationHandler  new UppercaseHandler(new HelloTarget()) ); 사용 방법을 자세히 살펴보자. 첫 번째 파라미터는 클래스 로더를 제공해야 한다. 다이내믹 프록시가 정의되는 클래스 로더를 지정하는 것이다. 두 번째 파라미터는 다이내믹 프록시가 구현해야 할 인터페이스다. 다이내믹 프록시는 한 번에 하나 이상의 인터페이스를 구현할 수도 있다. 따라서 인터페이스의 배열을 사용한다. 마지막 파라미터로는 부가기능과 위임 관련 코드를 담고 있는 InvocationHandler 구현 오브젝트를 제공해야 한다. Hello 타입의 타깃 오브젝트를 생성자로 받고, 모든 메서드 호출의 리턴 값을 대문자로 바꿔주는 UppercaseHandler 오브젝트를 전달했다.\n이제 이 방법을 이용해서 트랜잭션에 적용해보자.\npublic class TransactionHandler implements InvocationHandler { private Object target; private PlatformTransactionManager transactionManager; private String pattern; public void setTarget(Object target) { this.target = target; } public void setTransactionManager(PlatformTransactionManager transactionManager) { this.transactionManager = transactionManager; } public void setPattern(String pattern) { this.pattern = pattern; } public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { if (method.getName().startsWith(pattern)) { return invokeInTransaction(method, args); } else { return method.invoke(target, args); } } private Object invokeInTransaction(Method method, Object[] args) throws Throwable { TransactionStatus status = this.transactionManager.getTransaction(new DefaultTranscationDefinition()); try { Object ret = method.invoke(target, args); this.transactionManager.commit(status); return ret; } catch (InvocationTargetException e) { this.transactionManager.rollback(status); throw e.getTargetException(); } } }@Test public void upgradeAllOrNothing() throws Exception { ... TransactionHandler txHandler = new TransactionHandler(); txHandler.setTarget(testUserService); txHandler.setTransactionManager(transactionManager); txHandler.setPattern(\u0026#34;upgradeLevels\u0026#34;); UserService txUserService = (UserService)Proxy.newProxyInstance( getClass().getClassLoader(), new Class[] { UserService.class }, txHandler ); ... } 위와 같이 TransactionHandler 오브젝트를 이용해 UserService 타입의 다이내믹 프록시를 생성하면 트랜잭션 프록시가 적용된다.\n그런데 문제는 DI의 대상이 되는 다이내믹 프록시 오브젝트는 일반적인 스프링의 빈으로는 등록할 방법이 없다. 스프링의 빈은 기본적으로 클래스 이름과 프로퍼티로 정의된다. 스프링은 지정된 클래스 이름을 가지고 리플렉션을 이용해서 해당 클래스의 오브젝트를 만든다. 문제는 다이내믹 프록시 오브젝트는 이런 식으로 프록시 오브젝트가 생성되지 않는다는 점이다. 사실 다이내믹 프록시 오브젝트의 클래스가 어떤 것인지 알 수도 없다. 클래스 자체도 내부적으로 다이내믹하게 새로 정의해서 사용하기 때문이다. 따라서 사전에 프록시 오브젝트의 클래스 정보를 미리 알아내서 스프링의 빈에 정의할 방법이 없다. 다이내믹 프록시는 Proxy 클래스의 newProxyInstance() 라는 정적 팩토리 메서드를 통해서만 만들 수 있다.\n사실 스프링은 클래스 정보를 가지고 디폴트 생성자를 통해 오브젝트를 만드는 방법 외에도 빈을 만들 수 있는 여러 가지 방법을 제공한다. 대표적으로 팩토리 빈을 이용한 빈 생성 방법을 들 수 있다. 팩토리 빈이란 스프링을 대신해서 오브젝트의 생성로직을 담당하도록 만들어진 특별한 빈을 말한다.\npackage org.springframework.beans.factory; public interface FactoryBean\u0026lt;T\u0026gt; { T getObject() throws Exception; Class\u0026lt;? extends T\u0026gt; getObjectType(); boolean isSingleton(); } FactoryBean 인터페이스를 구현한 클래스를 스프링 빈으로 만들어두면 getObject()라는 메서드가 생성해주는 오브젝트가 실제 빈의 오브젝트로 대치된다. 따라서 팩토리 빈의 getObject() 메서드에 다이내믹 프록시 오브젝트를 만들어주는 코드를 넣으면 된다. 하지만 이 방식은 한 번에 여러 개의 클래스에 공통적인 부가기능을 제공하는 일이 불가능하다. 하나의 타깃 오브젝트에만 부여되는 부가기능이라면 상관없겠지만, 트랜잭션과 같이 비지니스 로직을 담은 많은 클래스의 메서드에 적용할 필요가 있다면 거의 비슷한 프록시 팩토리 빈의 설정이 중복되는 것을 막을 수 없다. 그래서 이 방식에 대해서는 더 이상 살펴보지 않고 스프링의 프록시 팩토리 빈에 대해서 자세히 알아보자.\n3. 스프링의 프록시 팩토리 빈 스프링은 트랜잭션 기술과 메일 발송 기술에 적용했던 서비스 추상화를 프록시 기술에도 동일하게 적용하고 있다. 자바에는 JDK에서 제공하는 다이내믹 프록시 외에도 편리하게 프록시를 만들 수 있도록 지원해주는 다양한 기술이 존재한다. 따라서 스프링은 일관된 방법으로 프록시를 만들 수 있게 도와주는 추상 레이어를 제공한다. 생성된 프록시는 스프링의 빈으로 등록돼야 한다. 스프링은 프록시 오브젝트를 생성해주는 기술을 추상화한 팩토리 빈을 제공해준다. 스프링의 ProxyFactoryBean은 프록시를 생성해서 빈 오브젝트로 등록하게 해주는 팩토리 빈이다. ProxyFactoryBean은 순수하게 프록시를 생성하는 작업만을 담당하고, 프록시를 통해 제공해줄 부가기능은 별도의 빈에 둘 수 있다.\nProxyFactoryBean이 생성하는 프록시에서 사용할 부가기능은 MethodInterceptor 인터페이스를 구현해서 만든다. MethodInterceptor는 InvocationHandler와 비슷하지만 한 가지 다른 점이 있다. InvocationHandler의 invoke() 메서드는 타깃 오브젝트에 대한 정보를 제공하지 않는다. 따라서 타깃은 InvocationHandler를 구현한 클래스가 직접 알고 있어야 한다. 반면에 MethodInterceptor의 invoke() 메서드는 ProxyFactoryBean으로부터 타깃 오브젝트에 대한 정보까지도 함께 제공받는다. 그 차이 덕분에 MethodInterceptor는 타깃 오브젝트에 상관없이 독립적으로 만들어질 수 있다. 따라서 MethodInterceptor 오브젝트는 타깃이 다른 여러 프록시에서 함께 사용할 수 있고, 싱글톤 빈으로 등록 가능하다.\n@Test public void proxyFactoryBean() { ProxyFactoryBean pfBean = new ProxyFactoryBean(); // 타깃 설정  pfBean.setTarget(new HelloTarget()); // 부가기능을 담은 어드바이스를 추가한다. 여러 개를 추가할 수도 있다.  pfBean.addAdvice(new UppercaseAdvice()); // FactoryBean 이므로 getObject()로 생성된 프록시를 가져온다.  Hello proxiedHello = (Hello) pfBean.getObject(); assertThat(proxiedHello.sayHi(\u0026#34;Toby\u0026#34;), is(\u0026#34;HI TOBY\u0026#34;)); } static class UppercaseAdvice implements MethodInterceptor { public Object invoke(MethodInvocation invocation) throws Throwable { // 리플렉션의 Method와 달리 메서드 실행 시 타깃 오브젝트를 전달할 필요가 없다.  // MethodInvocation은 메서드 정보와 함께 타깃 오브젝트를 알고 있기 때문이다.  String ret = (String)invocation.proceed(); return ret.toUpperCase(); } } 어드바이스 : 타깃이 필요 없는 순수한 부가기능을 담은 오브젝트\nInvocationHandler를 구현했을 때와 달리 MethodInterceptor를 구현한 UppercaseAdvice에는 타깃 오브젝트가 등장하지 않는다. MethodInterceptor로는 메서드 정보와 함께 타깃 오브젝트가 담긴 MethodInvocation 오브젝트가 전달된다. MethodInvocation은 일종의 콜백 오브젝트로, proceed() 메서드를 실행하면 타깃 오브젝트의 메서드를 내부적으로 실행해주는 기능이 있다(MethodInvocation 구현 클래스는 일종의 공유 가능한 템플릿처럼 동작).\n바로 이 점이 JDK의 다이내믹 프록시를 직접 사용하는 코드와 스프링이 제공해주는 프록시 추상화 기능인 ProxyFactoryBean을 사용하는 코드의 가장 큰 차이점이자 ProxyFactoryBean의 장점이다. ProxyFactoryBean은 작은 단위의 템플릿/콜백 구조를 응용해서 적용했기 때문에 템플릿 역할을 하는 MethodInvocation을 싱글톤으로 두고 공유할 수 있다. 마치 SQL 파라미터 정보에 종속되지 않는 JdbcTemplate이기 때문에 수많은 DAO 메서드가 하나의 JdbcTemplate 오브젝트를 공유할 수 있는 것과 마찬가지다.\n포인트컷 : 부가기능 적용 대상 메서드 선정 방법 스프링은 부가기능을 제공하는 오브젝트를 어드바이스라고 부르고, 메서드 선정 알고리즘을 담은 오브젝트를 포인트컷이라고 부른다. 어드바이스와 포인트컷은 모두 프록시에 DI로 주입돼서 사용된다. 두 가지 모두 여러 프록시에서 공유가 가능하도록 만들어지기 때문에 스프링의 싱글톤 빈으로 등록이 가능하다.\n프록시는 클라이언트로부터 요청을 받으면 먼저 포인트컷에게 부가기능을 부여할 메서드인지를 확인해달라고 요청한다. 포인트컷은 Pointcut 인터페이스를 구현해서 만들면 된다. 프록시는 포인트컷으로부터 부가기능을 적용할 대상 메서드인지 확인받으면, MethodInterceptor 타입의 어드바이스를 호출한다.\n@Test public void pointcutAdvisor() { ProxyFactoryBean pfBean = new ProxyFactoryBean(); pfBean.setTarget(new HelloTarget()); NameMatchMethodPointcut pointcut = new NameMatchMethodPointcut(); pointcut.setMappedName(\u0026#34;sayH*\u0026#34;); //포인트컷과 어드바이스를 Advisor로 묶어서 한번에 추가  pfBean.addAdvisor(new DefaultPointcutAdvisor(pointcut, new UppercaseAdvice())); Hello proxiedHello = (Hello) pfBean.getObject(); } 포인트컷이 필요 없을 때는 ProxyFactoryBean의 addAdvice() 메서드를 호출해서 어드바이스만 등록하면 됐다. 그런데 포인트컷을 함께 등록할 때는 어드바이스와 포인트컷을 Advisor 타입으로 묶어서 addAdvisor() 메서드를 호출해야 한다. 왜 굳이 별개의 오브젝트로 묶어서 등록해야 할까? 그 이유는 ProxyFactoryBean에는 여러 개의 어드바이스와 포인트컷이 추가될 수 있기 때문이다. 포인트컷과 어드바이스를 따로 등록하면 어떤 어드바이스(부가기능)에 대해 어떤 포인트컷(메서드 선정)을 적용할지 애매해지기 때문이다. 그래서 이 둘을 Advisor 타입의 오브젝트에 담아서 조합을 만들어 등록하는 것이다. 어드바이저 = 포인트컷(메서드 선정 알고리즘) + 어드바이스(부가기능)\nProxyFactoryBean을 이용해 트랜잭션 기능 적용\npublic class TransactionAdvice implements MethodInterceptor { PlatformTransactionManager transactionManager; public void setTransactionManager(PlatformTransactionManager transactionManager) { this.transactionManager = transactionManager; } public Object invoke(MethodInvocation invocation) throws Throwable { TransactionStatus status = this.transactionManager.getTransaction(new DefaultTransactionDefinition()); try { Object ret = invocation.proceed(); this.transactionManager.commit(status); return ret; } catch (RuntimeException e) { this.transactionManager.rollback(status); throw e; } } } 트랜잭션 어드바이스 빈 설정\n\u0026lt;bean id=\u0026#34;transactionAdvice\u0026#34; class=\u0026#34;xxx.xxx.service.TransactionAdvice\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;transactionManager\u0026#34; ref=\u0026#34;transactionManager\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; 포인트컷 빈 설정\n\u0026lt;bean id=\u0026#34;transactionPointcut\u0026#34; class=\u0026#34;org.springframework.aop.support.NameMatchMethodPointcut\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;mappedName\u0026#34; ref=\u0026#34;upgrade*\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; 어드바이저 빈 설정\n\u0026lt;bean id=\u0026#34;transactionAdvisor\u0026#34; class=\u0026#34;org.springframework.aop.support.DefaultPointcutAdvisor\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;advice\u0026#34; ref=\u0026#34;transactionAdvice\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;pointcut\u0026#34; ref=\u0026#34;transactionPointcut\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; 이제 ProxyFactoryBean을 등록할 차례다. 아래와 같이 프로퍼티에 타깃 빈과 어드바이저 빈을 지정해주면 된다.\n\u0026lt;bean id=\u0026#34;userService\u0026#34; class=\u0026#34;org.springframework.aop.framework.ProxyFactoryBean\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;target\u0026#34; ref=\u0026#34;userServiceImpl\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;interceptorNames\u0026#34;\u0026gt; \u0026lt;list\u0026gt; \u0026lt;value\u0026gt;transactionAdvisor\u0026lt;/value\u0026gt; \u0026lt;/list\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; 어드바이저는 interceptorNames라는 프로퍼티를 통해 넣는다. 프로퍼티 이름이 advisor가 아닌 이유는 어드바이스와 어드바이저를 혼합해서 설정할 수 있도록 하기 위해서다. 그래서 property 태그의 ref 애트리뷰트를 통한 설정 대신 list와 value 태크를 통해 여러 개의 값을 넣을 수 있도록 하고 있다. value 태그에는 어드바이스 또는 어드바이저로 설정한 빈의 아이디를 넣으면 된다. 한 개 이상을 넣을 수 있다.\n어드바이스와 포인트컷의 재사용 위의 그림은 ProxyFactoryBean을 이용해서 많은 수의 서비스 빈에게 트랜잭션 부가기능을 적용했을 때의 구조다. 트랜잭션 부가기능을 담은 TransactionAdvice는 하나만 만들어서 싱글톤 빈으로 등록해주면, DI 설정을 통해 모든 서비스에 적용이 가능하다. 메서드 선정 방식이 달라지는 경우만 포인트컷의 설정을 따로 등록하고 어드바이저로 조합해서 적용해주면 된다.\n4. 스프링 AOP 아직 한 가지 해결할 과제가 남아 있다. 부가기능의 적용이 필요한 타깃 오브젝트마다 거의 비슷한 내용의 ProxyFactoryBean 빈 설정정보를 추가해주는 부분이다. 새로운 타깃이 등장했다고 해서 코드를 손댈 필요는 없어졌지만, 설정은 매번 복사하고 붙이고 target 프로퍼티의 내용을 수정해줘야 한다. 이런 류의 중복은 어떻게 제거할까?\n빈 후처리기를 이용한 자동 프록시 생성기 스프링은 OCP의 가장 중요한 요소인 유연한 확장이라는 개념을 스프링 컨테이너 자신에게도 다양한 방법으로 적용하고 있다. 그래서 스프링은 컨테이너로서 제공하는 기능 중에서 변하지 않는 핵심적인 부분외에는 대부분 확장할 수 있는 확장 포인트를 제공해준다.\n그중에서 관심을 가질 만한 확장 포인트는 바로 BeanPostProcessor 인터페이스를 구현해서 만드는 빈 후처리기다. 빈 후처리기는 이름 그대로 스프링 빈 오브젝트로 만들어지고 난 후에, 빈 오브젝트를 다시 가공할 수 있게 해준다. 여기서는 스프링이 제공하는 빈 후처리기 중의 하나인 DefaultAdvisorAutoProxyCreator를 살펴보겠다. 이름을 보면 알 수 있듯이 DefaultAdvisorAutoProxyCreator는 어드바이저를 이용한 자동 프록시 생성기다.\n빈 후처리기를 스프링에 적용하는 방법은 간단하다. 빈 후처리기 자체를 빈으로 등록하는 것이다. 스프링은 빈 후처리기가 빈으로 등록되어 있으면 빈 오브젝트가 생성될 때마다 빈 후처리기에 보내서 후처리 작업을 요청한다. 빈 후처리기는 빈 오브젝트의 프로퍼티를 강제로 수정할 수도 있고 별도의 초기화 작업을 수행할 수도 있다. 심지어는 만들어진 빈 오브젝트 자체를 바꿔치기 할 수도 있다. 따라서 스프링이 설정을 참고해서 만든 오브젝트가 아닌 다른 오브젝트를 빈으로 등록시키는 것이 가능하다. 이를 잘 이용하면 스프링이 생성하는 빈 오브젝트의 일부를 프록시로 포장하고, 프록시를 빈으로 대신 등록할 수도 있다. 바로 이것이 자동 프록시 생성 빈 후처리기다.\n위의 그림은 빈 후처리기를 이용한 자동 프록시 생성 방법을 설명한다. DefaultAdvisorAutoProxyCreator 빈 후처리기가 등록되어 있으면 스프링은 빈 오브젝트를 만들 때마다 후처리기에게 빈을 보낸다. DefaultAdvisorAutoProxyCreator는 빈으로 등록된 모든 어드바이저 내의 포인트컷을 이용해 전달받은 빈이 프록시 적용 대상인지 확인한다. 프록시 적용 대상이면 그때는 내장된 프록시 생성기에게 현재 빈에 대한 프록시를 만들게 하고, 만들어진 프록시에 어드바이저를 연결해준다. 빈 후처리기는 프록시가 생성되면 원래 컨테이너가 전달해준 빈 오브젝트 대신 프록시 오브젝트를 컨테이너에게 돌려준다. 컨테이너는 최종적으로 빈 후처리기가 돌려준 오브젝트를 빈으로 등록하고 사용한다.\n적용할 빈을 선정하는 로직이 추가된 포인트컷이 담긴 어드바이저를 등록하고 빈 후처리기를 사용하면 일일이 ProxyFactoryBean 빈을 등록하지 않아도 타깃 오브젝트에 자동으로 프록시가 적용되게 할 수 있다. 마지막 남은 번거로운 ProxyFactoryBean 설정 문제를 말끔하게 해결해주는 놀라운 방법이다.\n확장된 포인트컷\n지금까지 포인트컷이란 타깃 오브젝트의 메서드 중에서 어떤 메서드에 부가기능을 적용할지를 선정해주는 역할을 한다고 했다. 그러나 포인트컷은 등록된 빈 중에서 어떤 빈에 프록시를 적용할지를 선택하는 기능이 또 있다.\npublic interface Pointcut { ClassFilter getClassFilter(); // 프록시를 적용할 클래스인지 확인해준다.  MethodMatcher getMethodMatcher(); // 어드바이스를 적용할 메서드인지 확인해준다. } ProxyFactoryBean에서는 굳이 클래스 레벨의 필터는 필요 없었지만, 모든 빈에 대해 프록시 자동 적용 대상을 선별해야 하는 빈 후처리기인 DefaultAdvisorAutoProxyCreator는 클래스와 메서드 선정 알고리즘을 모두 갖고 있는 포인트컷이 필요하다. 그런 포인트컷과 어드바이스가 결합되어 있는 어드바이저가 등록되어 있어야 한다.\n클래스 필터를 적용한 포인트컷 작성\n만들어야 할 클래스는 하나 뿐이다. 메서드 이름만 비교하던 포인트컷인 NameMethodPointcut을 상속해서 프로퍼티로 주어진 이름 패턴을 가지고 클래스 이름을 비교하는 ClassFilter를 추가하도록 만들 것이다.\npublic class NameMatchClassMethodPointcut extends NameMatchMethodPointcut { public void setMappedClassName(String mappedClassName) { this.setClassFilter(new SimpleClassFilter(mappedClassName)); } static class SimpleClassFilter implements ClassFilter { String mappedName; private SimpleClassFilter(String mappedName) { this.mappedName = mappedName; } public boolean matches(Class\u0026lt;?\u0026gt; clazz) { return PatternMatchUtils.simpleMatch(mappedName, clazz.getSimpleName()); } } } 어드바이저를 이용하는 자동 프록시 생성기 등록\n적용할 자동 프록시 생성기인 DefaultAdvisorAutoProxyCreator는 등록된 빈 중에서 Advisor 인터페이스를 구현한 것을 모두 찾는다. 그리고 생성되는 모든 빈에 대해 어드바이저의 포인트컷을 적용해보면서 프록시 적용 대상을 선정한다. 빈 클래스가 프록시 선정 대상이라면 프록시를 만들어 원래 빈 오브젝트와 바꿔치기한다. 원래 빈 오브젝트는 프록시 뒤에 연결돼서 프록시를 통해서만 접근 가능하게 바뀌는 것이다. 따라서 타깃 빈에 의존한다고 정의한 다른 빈들은 프록시 오브젝트를 대신 DI 받게 될 것이다. DefaultAdvisorAutoProxyCreator 등록은 다음 한 줄이면 충분하다.\n\u0026lt;bean class=\u0026#34;org.springframework.aop.framework.autoproxy.DefaultAdvisorAutoProxyCreator\u0026#34; /\u0026gt; 포인트컷 등록\n아래와 같이 기존의 포인트컷 설정을 삭제하고 새로 만든 클래스 필터 지원 포인트컷을 빈으로 등록한다. ServiceImpl로 이름이 끝나는 클래스와 upgrade로 시작하는 메서드를 선정해주는 포인트컷이다.\n\u0026lt;bean id=\u0026#34;transactionPointcut\u0026#34; class=\u0026#34;xx.xx.NameMatchClassMethodPointcut\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;mappedClassName\u0026#34; value=\u0026#34;*ServiceImpl\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;mappedName\u0026#34; value=\u0026#34;upgrade*\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; ProxyFactoryBean 제거와 서비스 빈의 원상복구\n프록시를 도입했던 때부터 아이디를 바꾸고 프록시에 DI 돼서 간접적으로 사용돼야 했던 userServiceImpl 빈의 아이디를 이제는 당당하게 userService로 되돌려놓을 수 있다. 더 이상 명시적인 프록시 팩토리 빈을 등록하지 않기 때문이다. 마지막으로 남았던 ProxyFactoryBean 타입의 빈은 삭제해버려도 좋다.\n\u0026lt;bean id=\u0026#34;userService class=\u0026#34;xx.xx.UserServiceImpl\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;userDao\u0026#34; ref=\u0026#34;userDao\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;mailSender\u0026#34; ref=\u0026#34;mailSender\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; AOP : 애스펙트 지향 프로그래밍 애스팩트란 그 자체로 애플리케이션의 핵심기능을 담고 있지는 않지만, 애플리케이션을 구성하는 중요한 한 가지 요소이고, 핵심기능에 부가되어 의미를 갖는 특별한 모듈을 가리킨다.\n애스팩트는 그 단어의 의미대로 애플리케이션을 구성하는 한 가지 측면이라고 생각 할 수 있다.\n위의 그림을 보면 왼쪽은 애스펙트로 부가기능을 분리하기 전의 상태다. 핵심기능은 깔끔한 설계를 통해서 모듈화되어 있고, 객체지향적인 장점을 잘 살릴 수 있도록 만들었지만, 부가기능이 핵심기능의 모듈에 침투해 들어가면서 설계와 코드가 모두 지저분해졌다.\n오른쪽 그림은 이렇게 핵심기능 코드 사이에 침투한 부가기능을 독립적인 모듈인 애스펙트로 구분해낸 것이다. 이렇게 애플리케이션의 핵심적인 기능에서 부가적인 기능을 분리해서 애스펙트라는 독특한 모듈로 만들어서 설계하고 개발하는 방법을 AOP라고 부른다.\nAOP 네임스페이스\n\u0026lt;aop:config\u0026gt; \u0026lt;aop:pointcut id=\u0026#34;transactionPointcut\u0026#34; expression=\u0026#34;execution(* *..*ServiceImpl.upgrade*(..))\u0026#34; /\u0026gt; \u0026lt;aop:advisor advice-reg=\u0026#34;transactionAdvice\u0026#34; pointcut-ref=\u0026#34;transactionPointcut\u0026#34; /\u0026gt; \u0026lt;/aop:config\u0026gt; \u0026lt;aop:config\u0026gt; : AspectJAdvisorAutoProxyCreator를 빈으로 등록해준다.\n\u0026lt;aop:pointcut\u0026gt; : AspectJExpressionPointcut을 빈으로 등록해준다.\n\u0026lt;aop:advisor\u0026gt; : DefaultBeanFactoryPointcutAdvisor를 빈으로 등록해준다.\n5. 트랜잭션 속성 PlatformTransactionManager로 대표되는 스프링의 트랜잭션 추상화를 설명하면서 그냥 넘어간 게 한 가지 있다. 트랜잭션 매니저에서 트랜잭션을 가져올 때 사용한 DefaultTransactionDefinition 오브젝트다.\npublic Object invoke(MethodInvocation invocation) throws Throwable { TransactionStatus status = this.transactionManager.getTransaction(new DefaultTransactionDefinition()); try { Object ret = invocation.proceed(); this.transactionManager.commit(status); return ret; } catch (RuntimeException e) { this.transactionManager.rollback(status); throw e; } } 트랜잭션을 시작한다고 하지 않고 트랜잭션을 가져온다고 하는 이유는 차차 설명하기로 하고, 일단 트랜잭션을 가져올 때 파라미터로 트랜잭션 매니저에게 전달하는 DefaultTransactionDefinition의 용도가 무엇인지 알아보자.\nDefaultTransactionDefinition이 구현하고 있는 TransactionDefinition 인터페이스는 트랜잭션의 동작방식에 영향을 줄 수 있는 네 가지 속성을 정의하고 있다.\n트랜잭션 전파\n트랜잭션의 경계에서 이미 진행 중인 트랜잭션이 있을 때 또는 없을 때, 어떻게 동작할 것인가를 결정하는 방식을 말한다.\n위 그림의 트랜잭션 전파와 같이 각각 독립적인 트랜잭션 경계를 가진 두 개의 코드가 있다고 하자. 그런데 A의 트랜잭션이 시작되고 아직 끝나지 않은 시점에서 B를 호출했다면 B의 코드는 어떤 트랜잭션 안에서 동작해야 할까? 대표적으로 다음과 같은 트랜잭션 전파 속성을 줄 수 있다.\n PROPAGATION_REQUIRED  가장 많이 사용되는 트랜잭션 전파 속성이다. 진행 중인 트랜잭션이 없으면 새로 시작하고, 이미 시작된 트랜잭션이 있으면 이에 참여한다. DefaultTransactionDefinition의 트랜잭션 전파 속성은 바로 이 PROPAGATION_REQUIRED다.\n PROPAGATION_REQUIRES_NEW  항상 새로운 트랜잭션을 시작한다. 즉, 앞에서 시작된 트랜잭션이 있든 없든 상관없이 새로운 트랜잭션을 만들어서 독자적으로 동작하게 한다. 독립적인 트랜잭션이 보장돼야 하는 코드에 적용할 수 있다.\n PROPAGATION_NOT_SUPPORTED  이 속성을 사용하면 트랜잭션 없이 동작하도록 만들 수도 있다.\n이 외에도 다양한 트랜잭션 전파 속성을 사용할 수 있다. 트랜잭션 매니저를 통해 트랜잭션을 시작하려고 할 때 getTransaction()이라는 메서드를 사용하는 이유는 바로 이 트랜잭션 전파 속성이 있기 때문이다.\n격리수준\n모든 DB 트랜잭션은 격리수준(isolation level)을 갖고 있어야 한다. 서버환경에서는 여러 개의 트랜잭션이 동시에 진행될 수 있다. 따라서 적절하게 격리수준을 조정해서 가능한 한 많은 트랜잭션을 동시에 진행시키면서도 문제가 발생하지 않게 하는 제어가 필요하다.\n제한시간\n트랜잭션을 수행하는 제한시간(timeout)을 설정할 수 있다. DefaultTransactionDefinition의 기본 설정은 제한시간이 없다는 것이다. 제한시간은 트랜잭션을 직접 시작할 수 있는 PROPAGATION_REQUIRED나 PROPAGATION_REQUIRES_NEW와 함께 사용해야만 의미가 있다.\n읽기전용\n읽기전용으로 설정해두면 트랜잭션 내에서 데이터를 조작하는 시도를 막아줄 수 있다. 또한 데이터 액세스 기술에 따라서 성능이 향상될 수도 있다.\n트랜잭션 정의를 수정하려면 어떻게 해야 할까? TransactionDefinition 오브젝트를 생성하고 사용하는 코드는 트랜잭션 경계설정 기능을 가진 TransactionAdvice다. 트랜잭션 정의를 바꾸고 싶으면 디폴트 속성을 갖고 있는 DefaultTransactionDefinition을 사용하는 대신 외부에서 정의된 TransactionDefinition 오브젝트를 DI 받아서 사용하도록 만들면 된다. TransactionDefinition 타입의 빈을 정의해두면 프로퍼티를 통해 원하는 속성을 지정해줄 수 있다. 하지만 이 방법으로 트랜잭션 속성을 변경하면 TransactionAdvice를 사용하는 모든 트랜잭션의 속성이 한꺼번에 바뀐다는 문제가 있다. 원하는 메서드만 선택해서 독자적인 트랜잭션 정의를 적용할 수 있는 방법은 없을까?\n트랜잭션 인터셉터와 트랜잭션 속성\n스프링에는 편리하게 트랜잭션 경계설정 어드바이스로 사용할 수 있도록 만들어진 TransactionInterceptor가 존재한다. TransactionInterceptor 어드바이스의 동작방식은 기존에 만들었던 TransactionAdvice와 다르지 않다. 다만 트랜잭션 정의를 메서드 이름 패턴을 이용해서 다르게 지정할 수 있는 방법을 추가로 제공해줄 뿐이다.\nTransactionInterceptor는 PlatformTransactionManager와 Properties 타입의 두 가지 프로퍼티를 갖고 있다. 트랜잭션 매니저 프로퍼티는 잘 알고 있지만 Properties 타입의 프로퍼티는 처음 보는 것이다.\nProperties 타입인 두 번째 프로퍼티 이름은 transactionAttributes로, 트랜잭션 속성을 정의한 프로퍼티다. 트랜잭션 속성은 TransactionDefinition의 네 가지 기본 항목에 rollbackOn()이라는 메서드를 하나 더 갖고 있는 TransactionAttribute 인터페이스로 정의된다. rollbackOn() 메서드는 어떤 예외가 발생하면 롤백을 할 것인가를 결정하는 메서드다. 이 TransactionAttribute를 이용하면 트랜잭션 부가기능의 동작 방식을 모두 제어할 수 있다. 위 트랜잭션 경계설정 코드를 다시 살펴보면 트랜잭션 부가기능의 동작방식을 변경할 수 있는 곳이 두 군데 있다는 사실을 알 수 있다. TransactionAdvice는 RuntimeException이 발생하는 경우에만 트랜잭션을 롤백시킨다. 하지만 런타임 예외가 아닌 경우에는 트랜잭션이 제대로 처리되지 않고 메서드를 빠져나가게 되어 있다. UserService는 런타임 예외만 던진다는 사실을 알기 때문에 일단 이렇게 정의해도 상관없지만, 체크 예외를 던지는 타깃에 사용한다면 문제가 될 수 있다. 그렇다면 런타임 예외만이 아니라 모든 종류의 예외에 대해 트랜잭션을 롤백 시키도록 해야 할까? 그래서는 안 된다. 비지니스 로직상의 예외 경우를 나타내기 위해 타깃 오브젝트가 체크 예외를 던지는 경우에는 DB 트랜잭션은 커밋시켜야 하기 때문이다. 2장에서 설명했듯이 일부 체크 예외는 정상적인 작업 흐름 안에서 사용될 수도 있다.\n스프링이 제공하는 TransactionInterceptor에는 기본적으로 두 가지 종류의 예외 처리 방식이 있다. 런타임 예외가 발생하면 트랜잭션은 롤백된다. 반면에 타깃 메서드가 런타임 예외가 아닌 체크 예외를 던지는 경우에는 이것을 예외상황으로 해석하지 않고 일종의 비지니스 로직에 따른, 의미가 있는 리턴 방식의 한 가지로 인식해서 트랜잭션을 커밋해버린다.\n그런데 TransactionInterceptor의 이러한 예외처리 기본 원칙을 따르지 않는 경우가 있을 수 있다. 그래서 TransactionAttribute는 rollbackOn()이라는 속성을 둬서 기본 원칙과 다른 예외처리가 가능하게 해준다. 이를 활용하면 특정 체크 예외의 경우는 트랜잭션을 롤백시키고, 특정 런타임 예외에 대해서는 트랜잭션을 커밋시킬 수도 있다.\nTransactionInterceptor는 이런 TransactionAttribute를 Properties라는 일종의 맵 타입 오브젝트로 전달받는다. 아래 설정은 메서드 이름 패턴과 문자열로 된 트랜잭션 속성을 이용해서 정의한 TransactionInterceptor 타입 빈의 예다. 세 가지 메서드 이름 패턴에 대한 트랜잭션 속성이 정의되어 있다. get으로 시작하는 모든 메서드에는 PROPAGATION_REQUIRED이면서 읽기전용이고 시간제한은 30초다.\ncf) readOnly나 timeout 등은 트랜잭션이 처음 시작될 때가 아니라면 적용되지 않는다.\ntx 네임스페이스를 이용한 설정 방법\n프록시 방식 AOP는 같은 타깃 오브젝트 내의 메서드를 호출할 때는 적용되지 않는다. 이건 전략이라기보다는 주의사항이다. 프록시 방식의 AOP에서는 프록시를 통한 부가기능의 적용은 클라이언트로부터 호출이 일어날 때만 가능하다. 여기서 클라이언트는 인터페이스를 통해 타깃 오브젝트를 사용하는 다른 모든 오브젝트를 말한다. 반대로 타깃 오브젝트가 자기 자신의 메서드를 호출할 때는 프록시를 통한 부가기능의 적용이 일어나지 않는다. 위 그림은 트랜잭션 프록시가 타깃에 적용되어 있는 경우의 메서드 호출 과정을 보여준다. delete()와 update()는 모두 트랜잭션 적용 대상인 메서드다. 따라서 [1]과 [3]처럼 클라이언트로부터 메서드가 호출되면 트랜잭션 프록시를 통해 타깃 메서드로 호출이 전달되므로 트랜잭션 경계설정 부가기능이 부여될 것이다.\n하지만 [2]의 경우는 다르다. 일단 타깃 오브젝트 내로 들어와서 타깃 오브젝트의 다른 메서드를 호출하는 경우에는 프록시를 거치지 않고 직접 타깃의 메서드가 호출된다. 따라서 트랜잭션 속성이 전혀 반영되지 않는다.\n만약 update() 메서드에 대해 트랜잭션 전파 속성을 REQUIRES_NEW라고 해놨더라도 같은 타깃 오브젝트에 있는 delete() 메서드를 통해 update()가 호출되면 트랜잭션 전파 속성이 적용되지 않으므로 REQUIRES_NEW는 무시되고 프록시의 delete() 메서드에서 시작한 트랜잭션에 단순하게 참여하게 될 뿐이다.\n타깃 안에서의 호출에는 프록시가 적용되지 않는 문제를 해결할 수 있는 방법은 두 가지가 있다. 하나는 스프링 API를 이용해 프록시 오브젝트에 대한 레퍼런스를 가져온 뒤에 같은 오브젝트의 메서드 호출도 프록시를 이용하도록 강제하는 방법이다. 하지만 별로 추천되지 않는다(스프링 API와 프록시 호출 코드 등장은 바람직하지 않다). 다른 방법은 AspectJ와 같은 타깃의 바이트코드를 직접 조작하는 방식의 AOP 기술을 적용하는 것이다.\n6. 애노테이션 트랜잭션 속성과 포인트컷 @Transactional // 애노테이션을 사용할 대상을 지정한다. 여기에 사용된 메서드와 타입(클래스, 인터페이스)처럼 한 개 이상의 대상을 지정할 수 있다. @Target({ElementType.METHOD, ElementType.TYPE}) // 애노테이션 정보가 언제까지 유지되는지를 지정한다. 이렇게 설정하면 런타임 때도 애노테이션 정보를 리플렉션을 통해 얻을 수 있다. @Retention(RetentionPolicy.RUNTIME) @Inherited //상속을 통해서도 애노테이션 정보를 얻을 수 있게 한다. @Documented public @interface Transactional { @AliasFor(\u0026#34;transactionManager\u0026#34;) String value() default \u0026#34;\u0026#34;; @AliasFor(\u0026#34;value\u0026#34;) String transactionManager() default \u0026#34;\u0026#34;; Propagation propagation() default Propagation.REQUIRED; Isolation isolation() default Isolation.DEFAULT; int timeout() default -1; boolean readOnly() default false; Class\u0026lt;? extends Throwable\u0026gt;[] rollbackFor() default {}; String[] rollbackForClassName() default {}; Class\u0026lt;? extends Throwable\u0026gt;[] noRollbackFor() default {}; String[] noRollbackForClassName() default {}; } @Transactional 애노테이션을 트랜잭션 속성정보로 사용하도록 지정하면 스프링은 @Transactional이 부여된 모든 오브젝트를 자동으로 타깃 오브젝트로 인식한다. 이때 사용되는 포인트컷은 TransactionAttributeSourcePointcut이다. TransactionAttributeSourcePointcut은 스스로 표현식과 같은 선정기준을 갖고 있진 않다. 대신 @Transactional이 타입 레벨이든 메서드 레벨이든 상관없이 부여된 빈 오브젝트를 모두 찾아서 포인트컷의 선정 결과로 돌려준다. @Transactional은 기본적으로 트랜잭션 속성을 정의하는 것이지만, 동시에 포인트컷의 자동등록에도 사용된다. 위의 그림은 @Transactional 애노테이션을 사용했을 때 어드바이저의 동작방식을 보여준다. TransactionInterceptor는 메서드 이름 패턴을 통해 부여되는 일괄적인 트랜잭션 속성정보 대신 @Transactional 애노테이션의 엘리먼트에서 트랜잭션 속성을 가져오는 AnnotationTransactionAttributeSource를 사용한다. @Transactional은 메서드마다 다르게 설정할 수도 있으므로 매우 유연한 트랜잭션 속성 설정이 가능해진다.\n동시에 포인트컷도 @Transactional을 통한 트랜잭션 속성정보를 참조하도록 만든다. @Transactional로 트랜잭션 속성이 부여된 오브젝트라면 포인트컷의 선정 대상이기도 하기 때문이다. 이 방식을 이용하면 포인트컷과 트랜잭션 속성을 애노테이션 하나로 지정할 수 있다. 트랜잭션 속성은 타입 레벨에 일괄적으로 부여할 수도 있지만, 메서드 단위로 세분화해서 트랜잭션 속성을 다르게 지정할 수도 있기 때문에 매우 세밀한 트랜잭션 속성 제어가 가능해진다.\n대체 정책 스프링은 @Transactional을 적용할 때 4단계의 대체(fallback)정책을 이용하게 해준다. 메서드의 속성을 확인할 때 타깃 메서드, 타깃 클래스, 선언 메서드, 선언 타입의 순서에 따라서 @Transactional이 적용됐는지 차례로 확인하고, 가장 먼저 발견되는 속성정보를 사용하게 하는 방법이다. 이런 식으로 끝까지 발견되지 않으면 트랜잭션 적용 대상이 아니라고 판단한다. 위와 같이 정의된 인터페이스와 구현 클래스가 있다고 하자. @Transactional을 부여할 수 있는 위치는 총 6개다. 스프링은 트랜잭션 기능이 부여될 위치인 타깃 오브젝트의 메서드부터 시작해서 @Transactional 애노테이션이 존재하는지 확인한다. 따라서 [5]와 [6]이 @Transactional이 위치할 수 있는 첫 번째 후보다. 여기서 애노테이션이 발견되면 바로 애노테이션의 속성을 가져다 해당 메서드의 트랜잭션 속성으로 사용한다.\n메서드에서 @Transactional을 발견하지 못하면, 다음은 타깃 클래스인 [4]에 @Transactional이 존재하는지 확인한다. 이를 통해서 @Transactional이 타입 레벨, 즉 클래스에 부여되면 해당 클래스의 모든 메서드의 공통적으로 적용되는 속성이 될 수 있다. 메서드 레벨에 @Transactional이 없다면 모두 클래스 레벨의 속성을 사용할 것이기 때문이다. 메서드가 여러 개라면 클래스 레벨에 @Transactional을 부여하는 것이 편리하다. 특정 메서드만 공통 속성을 따르지 않는다면 해당 메서드에만 추가로 @Transactional을 부여해주면 된다. 대체 정책에서 지정한 순서에 따라서 항상 메서드에 부여된 @Transactional이 가장 우선이기 때문에 @Transactional이 붙은 메서드는 클래스 레벨의 속성을 무시하고 메서드 레벨의 속성을 사용할 것이다. 반면에 @Transactional을 붙이지 않은 여타 메서드는 클래스 레벨에 부여된 공통 @Transactional을 따르게 된다.\n타깃 클래스에서도 @Transactional을 발견하지 못하면, 스프링은 메서드가 선언된 인터페이스로 넘어간다. 인터페이스에서도 먼저 메서드를 확인한다. 따라서 [2]와 [3]에 @Transactional이 부여됐는지 확인하고 있다면 이 속성을 적용한다. 인터페이스 메서드에도 없다면 마지막 단계인 인터페이스 타입 [1]의 위치에 애노테이션이 있는지 확인한다.\n기본적으로 @Transactional 적용 대상은 클라이언트가 사용하는 인터페이스가 정의한 메서드이므로 @Transactional도 타깃 클래스보다는 인터페이스에 두는 게 바람직하다. 하지만 인터페이스를 사용하는 프록시 방식의 AOP가 아닌 다른 방식으로 트랜잭션을 적용하면 인터페이스에 정의한 @Transactional은 무시되기 때문에 안전하게 타깃 클래스에 @Transactional을 두는 방법을 권장한다.\n트랜잭션 애노테이션 사용을 위한 설정\n\u0026lt;tx:annotation-driven /\u0026gt;@EnableTransactionManagement"
},
{
	"uri": "/%E1%84%8C%E1%85%A1%E1%84%87%E1%85%A1_%E1%84%89%E1%85%A5%E1%86%BC%E1%84%82%E1%85%B3%E1%86%BC_%E1%84%90%E1%85%B2%E1%84%82%E1%85%B5%E1%86%BC_%E1%84%8B%E1%85%B5%E1%84%8B%E1%85%A3%E1%84%80%E1%85%B5/%E1%84%85%E1%85%A9%E1%84%80%E1%85%B3%E1%84%82%E1%85%B3%E1%86%AB_%E1%84%87%E1%85%A1%E1%86%AB%E1%84%83%E1%85%B3%E1%84%89%E1%85%B5_%E1%84%91%E1%85%B5%E1%86%AF%E1%84%8B%E1%85%AD%E1%84%92%E1%85%A1%E1%86%AB_%E1%84%82%E1%85%A2%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%86%E1%85%A1%E1%86%AB_%E1%84%8D%E1%85%B5%E1%86%A8%E1%84%8C%E1%85%A1/",
	"title": "로그는 반드시 필요한 내용만 찍자",
	"tags": [],
	"description": "",
	"content": " System.out.println()의 문제점 대부분의 개발자들은 로그를 찍기 위해서 System.out.println() 메서드를 사용한 시스템 로그를 많이 사용한다. 가장 편하고, 확인하기 좋은 방법이지만 성능에 영향을 많이 주는 경우가 빈번히 발생한다.\n왜 성능에 영향을 많이 줄까? 파일이나 콘솔에 로그를 남길 경우를 생각해 보자. 내용이 완전히 프린트되거나 저장될 때까지, 뒤에 프린트하려는 부분은 대기 할 수밖에 없다. 특히 콘솔에 로그를 남길 경우에는 더더욱 그렇다. 그렇게 되면 애플리케이션에서는 대기 시간이 발생한다. 이 대기 시간은 시스템의 속도에 의존적이다. 만약 디스크에 로그를 남긴다면, 서버 디스크의 RPM이 높을수록 로그의 처리 속도는 빨라질 것이다.\n더 큰 문제는 System.out.println()으로 출력하는 로그가 개발할 때만 사용된다는 것이다. 운영할 때는 전혀 사용되지 않고, 볼 수도 없는 디버그용 로그를 운영 서버에서 고스란히 처리하고 있는 셈이다.\n로그를 깔금하게 처리해주는 slf4j와 LogBack 기존의 로거들은 출력을 위해서 문자열을 더해 전달해 줘야만 했다. 하지만, slf4j는 format 문자열에 중괄호를 넣고, 그 순서대로 출력하고자 하는 데이터들을 콤마로 구분하여 전달해준다.\nlogger.error(\u0026#34;message : {}\u0026#34;, e.getMessage()); 이렇게 전달해 주면 로그를 출력하지 않을 경우 필요 없는 문자열 더하기 연산이 발생하지 않는다.\n예외처리를 할 때는 아래와 같이 예외 클래스에서 원하는 스택 정보를 가공하여 메세지 처리 하는것도 좋은 방법이다.\nif (logger.isErrorEnabled()) { StackTraceElement[] ste = exception.getStackTrace(); StringBuffer str = new StringBuffer(); int lastIndex = ste.length - 1; int count = 1; for (int i = lastIndex; i\u0026gt;lastIndex-3; i--) { String className = ste[i].getClassName(); String methodName = ste[i].getMethodName(); int lineNumber = ste[i].getLineNumber(); String fileName = ste[i].getFileName(); str.append(\u0026#34;\\n\u0026#34;).append(\u0026#34;[\u0026#34; +count++ + \u0026#34;]\u0026#34;) .append(\u0026#34;className :\u0026#34;).append(className).append(\u0026#34;\\n\u0026#34;) .append(\u0026#34;methodName :\u0026#34;).append(methodName).append(\u0026#34;\\n\u0026#34;) .append(\u0026#34;fileName :\u0026#34;).append(fileName).append(\u0026#34;\\n\u0026#34;) .append(\u0026#34;lineNumber :\u0026#34;).append(lineNumber).append(\u0026#34;\\n\u0026#34;) .append(\u0026#34;message :\u0026#34;).append(exception.getMessage()).append(\u0026#34;\\n\u0026#34;) .append(\u0026#34;cause :\u0026#34;).append(exception.getCause()).append(\u0026#34;\\n\u0026#34;); } logger.error(str.toString()); } 추가적으로 정리한 내용 if (logger.isErrorEnabled())와 같은 logging guard 필요성 이슈 slf4j는 parameterized logging이라고 불리는 advanced feature를 제공한다. 그리고 parameterized logging은 로깅 성능을 크게 향상시킨다.\nlogger.debug(\u0026#34;Entry number: \u0026#34; + i + \u0026#34; is \u0026#34; + String.valueOf(entry[i])); 위와 같은 로그가 있을 때, 메세지 파라미터를 생성하는 비용(i와 entry[i]를 string으로 변환하고 다른 string들과 연결)이 발생한다. 이 작업은 메세지가 로깅되냐 안되냐에 관계없이 항상 발생한다.\n파라미터 생성 비용을 피하는 한가지 방법은 아래와 같이 logging guard로 둘러치는 것이다.\nif(logger.isDebugEnabled()) { logger.debug(\u0026#34;Entry number: \u0026#34; + i + \u0026#34; is \u0026#34; + String.valueOf(entry[i])); } 이렇게 하면 로거에 대해 디버깅이 비활성화 된 경우, 파라미터 생성 비용이 들지 않는다. 하지만 로그 레벨을 DEBUG로 하게 되면, 로거 사용 여부를 평가하는 데 드는 비용이 발생한다. 한 번은 debugEnabled에 한 번, 다른 한 번은 디버그에 사용된다.\n이것은 로거를 평가하는 데 실제로 문장을 기록하는 데 걸리는 시간의 1% 미만이기 때문에 경미한 오버헤드다.\n메세지 포맷에 따라 매우 편리한 대안이 있다. entry가 객체라고 가정하면 다음과 같이 작성할 수 있다.\nObject entry = new SomeObject(); logger.debug(\u0026#34;The entry is {}.\u0026#34;, entry); 로그 여부를 평가한 후, 그리고 결정이 긍정적일 경우에만 로거 구현에서 메시지를 포맷하고 \u0026lsquo;{}\u0026rsquo; 쌍을 입력 문자열 값으로 바꾼다. 다시말해 이 포맷은 log 문이 disabled인 경우 파라미터 생성 비용을 발생시키지 않는다.\n출처 : https://www.slf4j.org/faq.html#logging_performance\n수반되는 메시지없이 예외를 기록 할 수 있나? 답은 No\ne가 예외 인 경우 ERROR 레벨에서 예외를 기록하려면 첨부된 메시지를 추가해야한다.\nlogger.error(\u0026#34;some accompanying message\u0026#34;, e); exception/throwable이 있는 경우 로깅문을 파라미터화할 수 있나? 답은 Yes\nslf4j 1.6.0 버전부터 되고 그 아래로는 안된다.\nString s = \u0026#34;Hello world\u0026#34;; try { Integer i = Integer.valueOf(s); } catch (NumberFormatException e) { logger.error(\u0026#34;Failed to format {}\u0026#34;, s, e); } NumberFormatException stack trace가 출력될거다(1.6 이하 버전에서는 무시됨).\njcl, slf4j, logback, log4j 관계 jcl은 apache.commons.logging의 줄임말이다(아파치 재단의 자카르타 프로젝트). jcl은 엄밀히 말하면 로거가 아니다. 로깅을 하는일을 하지 않는다. 로깅 라이브러리가 아니라 로깅 추상화 라이브러리다. 로깅 라이브러리 선택권은 개발자의 것이다. 따라서 라이브러리나 프레임워크는 주로 로깅 추상화 라이브러리를 사용한다.\nimport org.apache.commons.logging.Log; import org.apache.commons.logging.LogFactory; jcl이 로깅 구현체를 찾는 방법 - 설정파일에서 찾기(그런데 설정파일 잘 안만든다) - 애플리케이션 클래스패스에서 log4j 구현체 찾아보기(다른 구현체가 있으면 그거 쓰고 없으면 java.util.logging에 있는거 씀)\n그런데 클래스 로더를 사용해서 클래스패스에 어떤 클래스가 있는지를 찾는 방법이 좋지 않음.\nslf4j는 jcl과 같은 로깅 추상화 라이브러리인데 구현체를 찾는 방법이 jcl과 다르다. 컴파일 시점에 들어있는 의존성 정보로 판단해서 찾는다. 그래서 클래스 로더나 메모리 문제가 발생하지 않는다. 대신에 의존성 설정을 잘 해야 된다.\nslf4j는 세 가지 모듈(api, binding, bridging)로 구성되어 있다.\napi는 로깅 인터페이스를 의미한다.\nimport org.slf4j.Logger; import org.slf4j.LoggerFactory; logger.debug(\u0026#34;The entry is {}.\u0026#34;, entry);\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;slf4j-api\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; binding은 api의 구현체로 연결해주는 일을 한다(어댑터 역할). 주의할점은 binding은 라이브러리나 프레임워크 개발자가 사용하는게 아니다. 애플리케이션 개발자가 사용하는거다. 그리고 여러 binding 중 반드시 한 개만 사용해야 한다.\nslf4j-log4j12-{version}.jar slf4j-jdk14-{version}.jar slf4j-nop-{version}.jar slf4j-jcl-{version}.jar logback-classic-{logback-version}.jar  마지막으로 bridging모듈은 레거시를 위한 거다. slf4j가 없었을 때는 jcl을 쓰거나 log4j를 쓰거나 다른 로거를 썼을 것이다. 그런 호출을 slf4j 호출로 바꿔주는거다. 예를 들어 jcl 호출한 코드를 slf4j가 호출한것처럼 바꿔주려면 먼저 의존성에 jcl-over-slf4j.jar를 추가한다. 그러면 jcl 호출을 받아서 slf4j api를 호출한다(jcl 인터페이스를 구현하고 있음).\n그리고 모든 로깅을 logback으로 하고 싶으면 아래 그림과 같이 설정하면 된다.\n출처 : 스프링 부트와 로깅 (백기선) https://www.youtube.com/watch?v=o2-JaRD9qQE\nlogback.xml 설정 로그레벨\n① FATAL : 가장 크리티컬한 에러가 일어 났을 때 사용\n② ERROR : 일반 에러가 일어 났을 때 사용\n③ WARN : 에러는 아니지만 주의할 필요가 있을 때 사용\n④ INFO : 일반 정보를 나타낼 때 사용\n⑤ DEBUG : 일반 정보를 상세히 나타낼 때 사용\ncf) trace도 있는데 쓰는곳은 못봄(DEBUG 아래단계)\nAppender\n로그를 출력 할 위치, 출력 형식 등을 설정\n\u0026lt;configuration\u0026gt; \u0026lt;appender name=\u0026#34;CONSOLE\u0026#34; class=\u0026#34;ch.qos.logback.core.ConsoleAppender\u0026#34;\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%d{yyyy-MM-dd HH:mm:ss.SSS} %-5level %-10contextName %logger{36} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;charset\u0026gt;utf8\u0026lt;/charset\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;appender name=\u0026#34;FILE\u0026#34; class=\u0026#34;ch.qos.logback.core.rolling.RollingFileAppender\u0026#34;\u0026gt; \u0026lt;rollingPolicy class=\u0026#34;ch.qos.logback.core.rolling.TimeBasedRollingPolicy\u0026#34;\u0026gt; \u0026lt;!-- daily rollover --\u0026gt; \u0026lt;fileNamePattern\u0026gt;/Users/yangbongsoo/logs/project/project.%d{yyyy-MM-dd}-${MYPID}.log\u0026lt;/fileNamePattern\u0026gt; \u0026lt;!-- keep 30 days\u0026#39; worth of history --\u0026gt; \u0026lt;maxHistory\u0026gt;30\u0026lt;/maxHistory\u0026gt; \u0026lt;/rollingPolicy\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%d{yyyy-MM-dd HH:mm:ss.SSS} %-5level %-10contextName %logger{36} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;charset\u0026gt;utf8\u0026lt;/charset\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;logger name=\u0026#34;net.openhft.chronicle.map.TcpReplicator\u0026#34; level=\u0026#34;DEBUG\u0026#34; \u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;logger name=\u0026#34;net.openhft.chronicle\u0026#34; level=\u0026#34;DEBUG\u0026#34; \u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;root level=\u0026#34;INFO\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;CONSOLE\u0026#34; /\u0026gt; \u0026lt;/root\u0026gt; ... \u0026lt;/configuration\u0026gt; Logback-Core 모듈을 통해 사용할 수 있는 기본적 Appender는 3가지다\nConsoleAppender : 로그를 OutputStream에 write 하여, 최종적으로 콘솔에 출력\nFileAppender : 로그의 내용을 지정된 File에 기록\nRollingFileAppender : FileAppender로 부터 상속받은 Appender로 날짜, 최대 용량 등을 설정하여 지정한 파일명 패턴에 따라 로그가 다른 파일에 기록되도록 한다. 이를 이용하여 대량의 로그를 효과적으로 기록할 수 있다.\nLogback-Core의 기본 Appender 외에도 Logback-Classic 모듈의 다양한 Appender (SSLSocketAppender, SMTPAppender, DBAppender 등)을 사용하여 로그를 원격위치에 기록 할 수도 있다. Appender들의 하위 항목으로 출력 형식(Layout Pattern)을 지정하여 각 Appender마다 원하는 내용을 출력시킬 수 있다. ex) %logger(Logger 이름), %thread(현재 스레드명), %level(로그 레벨), %msg(로그메시지), %n(new line) 등\nLogger : 실제 로그 기능을 수행하는 객체로 각 Logger마다 Name을 부여하여 사용한다. 각 Logger 마다 원하는 출력 레벨값을 설정할 수 있으며, 0개 이상의 Appender를 지정할 수 있다. 각 소스로부터 입력받은 로깅 메시지는 로그 레벨에 따라 Appender로 전달 된다. 기본적으로 최상위 로거인 Root Logger를 설정해 주어야하며, 추가로 필요한 로거에 대해 String 또는 클래스명 형식으로 Logger Name을 추가하여 사용할 수 있다. 또한 Logger의 Name은 .문자를 구분자로 사용하여 계층적으로 활용 할 수 있다.\n출처 : https://thinkwarelab.wordpress.com/2016/11/18/java%EC%97%90%EC%84%9C-logback%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EB%A1%9C%EA%B9%85logging-%EC%82%AC%EC%9A%A9%EB%B2%95/\n"
},
{
	"uri": "/effective_java/%E1%84%86%E1%85%A6%E1%84%89%E1%85%A5%E1%84%83%E1%85%B3/",
	"title": "메서드",
	"tags": [],
	"description": "",
	"content": " 이 챕터는 메서드 디자인에 대해서 다룬다. parameter와 return value를 어떻게 다뤄야하는지, 메서드 시그니처를 어떻게 디자인해야 하는지 그리고 어떻게 문서화하는지.\n규칙 49 : 파라미터 유효성을 검사하라(Check parameters for validity) 메서드나 생성자를 구현할 때는 받을 수 있는 파라미터에 제한이 있는지 따져봐야 한다(예를 들어 index값은 음수면 안되거나, 객체 참조는 null이면 안되거나). 그리고 제한이 있다면 그 사실을 문서에 남기고 메서드 앞부분에서 검사하도록 해야 한다. 오류는 가급적 빨리 탐지해야한다.\n만약 파라미터 유효성을 검사하지 않으면 몇 가지 문제가 생길 수 있다. 처리 도중에 이상한 예외를 내면서 죽어버리는 것이 그 첫 번째이고, 실행이 제대로 되는 것 같기는 한데 잘못된 결과가 나오는 것이 그 두번째다. 최고로 심각한 유형의 문제는, 메서드가 정상적으로 반환값을 내기는 하지만 어떤 객체의 상태가 비정상적으로 바뀌는 경우다. 그러면 나중에 해당 메서드와는 아무 상관도 없는 부분에서 오류가 뜨는데, 그 시간과 위치는 프로그램을 실행할 때마다 바뀐다. 다시 말해, 파라미터 검사를 안하면 규칙76 실패 원자성(failure atomicity)을 위반할 수 있다.\npublic이나 protected 메서드라면, 파라미터 유효성이 위반되었을 경우에 발생하는 예외를 Javadoc의 @throws 태그를 사용해서 문서화해라. 보통 IllegalArgumentException, IndexOutOfBoundsException, NullPointerException이 이용된다.\n/** * * @param m mod 연산을 수행할 값. 반드시 양수 * @return this mod m * @throws ArithmeticException (m \u0026lt;= 0일 때) */ public BigInteger mod(BigInteger m) { if (m.signum() \u0026lt;= 0) { throw new ArithmeticException(\u0026#34;Modulus \u0026lt;= 0: \u0026#34; + m); // 계산 수행 \t} } 여기서 doc 코멘트에 \u0026ldquo;mod 메서드는 파라미터 m이 null일 때 NullPointerException을 throw한다\u0026rdquo;라는 말이 없음에 주목해라. NullPointerException 예외는 BigInteger 클래스 doc에 코멘트되어 있다. 그러므로 클래스 레벨에 언급된 예외 코멘트를 개별 메서드에 문서화하는것을 피해라.\njava7에서 추가된 Objects.requireNonNull(m, \u0026quot;m must not be null\u0026quot;);은 유연하고 편리하다. null 체크를 수동으로 더이상 수행할 필요 없다.\njava9에서 java.util.Objects에 range-checking facility가 추가되었다. checkFromIndexSize, checkFromToIndex, checkIndex 3개의 메서드로 구성된다. 이 facility는 null-checking 메서드만큼 유연하진 않다. 사용자만의 디테일한 예외 메세지도 추가할 수 없다. 리스트 및 배열 인덱스에서만 사용되도록 설계됐다. 그리고 닫힌 범위(양쪽 끝점을 포함)는 처리하지 않는다. 그러나 그것이 필요한 것이면 도움이 된다.\npublic이 아닌 메서드라면 패키지 개발자가 메서드 호출이 이루어지는 상황을 통제할 수 있으므로 항상 유효한 파라미터가 전달될 것으로 생각할 수 있다. 따라서 일반적으로 파라미터 유효성을 검사할 때 확증문(assertion)을 이용한다.\n// 재귀적으로 정렬하는 private 도움 함수 private static void sort(long a[], int offset, int length) { assert a != null; assert offset \u0026gt;= 0 \u0026amp;\u0026amp; offset \u0026lt;= a.length; assert length \u0026gt;=0 \u0026amp;\u0026amp; length \u0026lt;= a.length - offset; … // 계산 수행 } 확증문은 클라이언트가 패키지를 어떻게 이용하건 확증 조건은 항상 참이 되어야 한다고 주장하는 것이다. 통상적인 유효성검사와는 달리, 확증문은 확증 조건이 만족되지 않으면 AssertionError를 낸다. 또한 통상의 유효성 검사와는 달리, 활성화되지 않은 확증문은 실행되지 않으므로 비용이 0이다. 확증문을 활성화시키려면 java 인터프리터에 -ea(또는 -enableassertions) 옵션을 주어야 한다.\n호출된 메서드에서 바로 이용하진 않지만 나중을 위해 보관되는 파라미터의 유효성을 검사하는 것은 특히 중요하다.\nstatic List\u0026lt;Integer\u0026gt; intArrayAsList(int[] a) { Objects.requireNonNull(a); return new AbstractList\u0026lt;Integer\u0026gt;() { @Override public Integer get(int i) { return a[i]; } @Override public Integer set(int i, Integer val) { int oldVal = a[i]; a[i] = val; return oldVal; } @Override public int size() { return a.length; } }; } intArrayAsList 메서드는 파라미터로 받은 int 배열에 대한 List view를 반환한다. 해당 메서드의 클라이언트가 null을 전달하면 해당 메서드는 NullPointerException을 발생시키는데 null인 경우를 명시적으로 검사하기 때문이다. 이 검사를 생략했다면 해당 메서드는 새롭게 만들어진 List 객체에 대한 참조를 반환했을 것이다. 그리고 클라이언트가 해당 리스트를 사용하려는 순간 NullPointerException가 일어났을 것이다. 예외가 일어났을 때, 그 List 객체가 대체 어디서 온 것인지 추적하기 어려울 것이다. 따라서 디버깅은 더욱 까다로워진다.\n생성자는 나중을 위해 보관될 파라미터의 유효성을 반드시 검사해야 한다는 원칙의 특별한 경우에 해당한다. 클래스 불변식(invariant)을 위반하는 객체가 만들어지는 것을 막으려면, 생성자에 전달되는 파라미터의 유효성을 반드시 검사해야 한다. cf) 불변 클래스는 설계, 구현이 쉽다. 객체의 상태를 변경하는 어떤 메서드도 제공안한다. 모든 필드는 fianl. 상속 불가. private 선언.\n메서드가 실제 계산을 수행하기 전에 파라미터를 반드시 검사해야 한다는 원칙에도 예외는 있다. 그 중 가장 중요한 것은 유효성 검사를 실행하는 오버헤드가 너무 크거나 비현실적이고, 계산 과정에서 유효성 검사가 자연스럽게 이루어지는 경우다. 예를 들어, Collections.sort(List)처럼 객체 리스트를 정렬하는 메서드를 생각해 보자. 리스트 내의 모든 객체는 서로 비교 가능해야 한다. 리스트를 정렬하는 과정에서 리스트 내의 모든 객체는 비교된다. 비교 가능하지 않은 객체가 포함되어 있다면 비교 도중에 ClassCastException이 발생할 것이다. 따라서 정렬 전에 모든 객체가 서로 비교 가능한지 검사하는 것은 의미가 없다. 하지만 주의할 것은, 이런 형태의 암묵적인 유효성 검사 방법에 지나치게 기대다 보면 \u0026lsquo;규칙 76의 실패 원자성\u0026rsquo;을 잃게 된다는 점이다.\n때로는 계산 과정에서 암묵적으로 유효성 검사가 이루어지기는 하는데, 검사가 실패했을 때 엉뚱한 예외가 던져지는 경우가 있다. 계산 도중에 파라미터값이 잘못되어 발생하는 예외가 메서드 문서에 명시된 예외와 다를 수 있다는 것이다. 그런 일이 생기면 예외 변환(exception translation) 숙어를 사용해서(규칙 73) 메서드 문서에 명시된 예외로 변환해야 한다.\n이번 절에서 다룬 내용을 잘못 받아들여 \u0026ldquo;파라미터에 제약을 두는 것은 바람직하다\u0026rdquo;고 믿어버리면 곤란하다. 메서드는 가능하면 일반적으로 적용될 수 있도록 설계해야 한다. 메서드가 받을 수 있는 읹에 제약이 적으면 적을수록 더 좋다.\n규칙 50 : 필요하다면 방어적 복사본을 만들라 여러분이 만드는 클래스의 클라이언트가 불변식을 망가뜨리기 위해 최선을 다할 것이라는 가정하에, 방어적으로 프로그래밍해야 한다. 아래의 클래스는 기간을 나타내는 객체에 대한 변경 불가능 클래스다.\n//변경 불가능성이 보장되지 않는 변경 불가능 클래스 public fianl class Period{ private final Date start; // 기간의 시작 지점 \tprivate final Date end; // 기간의 끝 지점. start보다 작은 값일 수 없다.  //@throws IllegalArgumentException start가 end보다 뒤면 발생 \t//@throws NullPointerException start나 end가 null이면 발생  public Period(Date start, Date end){ if(start.compareTo(end) \u0026gt; 0) throw new IllegalArgumentException(start + “after” + end); this.start = start; this.end = end; } public Date start(){ return start; } public Date end(){ return end; } … // 이하 생략 \t} 얼핏 변경이 불가능한 것으로 보이고, 기간 시작점이 기간 끝점 이후일 수 없다는 불변식도 만족되는 것처럼 보인다. 하지만 Date가 변경 가능 클래스라는 점을 이용하면 불변식을 깨트릴 수 있다.\n// Period 객체의 내부 구조를 공격 Date start = new Date(); Date end = new Date(); Period p = new Period(start, end); end.setYear(78); // p의 내부를 변경 !  따라서 Period 객체의 내부를 보호하려면 생성자로 전달되는 변경 가능 객체를 반드시 방어적으로 복사해서 그 복사본을 Period 객체의 컴포넌트로 이용해야 한다.\n// 수정된 생성자 - 인자를 방어적으로 복사함 public Period(Date start, Date end){ this.start = new Date(start.getTime()); this.end = new Date(end.getTime()); if(this.start.compareTo(this.end) \u0026gt; 0) throw new IllegalArgumentException(this.start + “after” + this.end); } 인자의 유효성을 검사하기 전에 방어적 복사본을 만들었다는 것에 유의하자. 유효성 검사는 복사본에 대해서 시행한다. 자연스러워 보이지 않을지도 모르나, 필요한 절차다. 인자를 검사한 직후 복사본이 만들어지기 직전까지의 시간, 그러니까 “취약 구간” 동안에 다른 스레드가 인자를 변경해 버리는 일을 막기 위한 것이다. (TICTOU 공격)\n방어적 복사본을 만들 때 Date의 clone 메서드를 이용하지 않았다. Date 클래스는 final 클래스가 아니므로, clone 메서드가 반드시 java.util.Date 객체를 반환할 거라는 보장이 없다. 공격을 위해 특별히 설계된 하위 클래스 객체가 반환될 수도 있다. 이런 공격을 막으려면 인자로 전달된 객체의 자료형이 제 3자가 계승할 수 있는 자료형일 경우, 방어적 복사본을 만들 때 clone을 사용하지 않도록 해야 한다.\n접근자를 통한 공격\n위의 생성자를 사용하면 생성자 인자를 통한 공격은 막을 수 있으나 접근자를 통한 공격은 막을 수 없다. 접근자를 호출하여 얻은 객체를 통해 Period 객체 내부를 변경할 수 있기 때문이다.\n// Period 객체 내부를 노린 두 번째 공격 형태 Date start = new Date(); Date end = new Date(); Period p = new Period(start, end); p.end().setYear(78); // p의 내부를 변경 !  이런 공격을 막으려면 변경 가능 내부 필드에 대한 방어적 복사본을 반환하도록 접근자를 수정해야 한다.\n// 수정된 접근자 - 내부 필드의 방어적 복사본 생성 public Date start(){ return new Date(start.getTime()); } public Date end(){ return new Date(end.getTime()); } 이렇게 수정하고 나면 Period는 진정한 변경 불가능 클래스가 된다. 객체 안에 확실히 캡슐화된 필드가 된 것이다.\n방어적 복사는 변경 불가능 클래스에서만 쓰이는 기법이 아니다. 클라이언트가 제공한 객체를 내부 자료 구조에 반영하는 생성자나 메서드에는 사용 가능하다. 예를 들어, 클라이언트가 제공한 객체 참조를 내부 Set 객체의 요소로 추가해야 하거나 내부 Map 객체의 키로 써야 하는 경우, 삽입된 객체가 나중에 변경된다면 집합이나 맵의 불변식은 깨지고 말 것이다.\n방어적 복사본을 만들도록 하면 성능에서 손해를 보기 때문에, 적절치 않을 때도 있다. 클라이언트가 같은 패키지 안에 있다거나 하는 이유로, 클라이언트가 객체의 내부 상태를 변경하려 하지 않는다는 것이 확실하다면 방어적 복사본은 만들지 않아도 될 것이다. 여기서 배워야 할 진짜 교훈은, 객체의 컴포넌트로는 가능하다면 변경 불가능 객체를 사용해야 한다는 것이다. 그래야 방어적 복사본에 대해서는 신경 쓸 필요가 없어지기 때문이다.\n규칙 51 : 메서드 시그니처는 신중하게 설계해라 메서드 이름은 신중하게 고르라.\n편의 메서드를 제공하는 데 너무 열 올리지 마라. 클래스에 메서드가 너무 많으면 학습, 사용, 테스트, 유지보수 등의 모든 측면에서 어렵다.\n인수 리스트(parameter list)를 길게 만들지 마라. 4개 이하가 되도록 애쓰라. 긴 인자 리스트를 짧게 줄이는 방법으로는 첫째, 여러 메서드로 나누는 방법이 있고 둘째, 도움 클래스를 만들어 인자들을 그룹별로 나누는 것이다. 보통 이 도움 클래스들은 static 멤버 클래스다(자주 등장하는 일련의 인자들이 어떤 별도 개체를 나타낼 때 쓰면 좋다). 셋째, 빌더 패턴이 있다.\n인자의 자료형으로는 클래스보다 인터페이스가 좋다.\n인자 자료형으로 boolean을 쓰는 것보다는, 원소가 2개인 enum 자료형을 쓰는 것이 낫다. 규칙 52 : 오버로딩할 때는 주의하라 아래의 프로그램 목적은 컬렉션을 종류별로(집합이냐, 리스트냐, 아니면 다른 종류의 컬렉션이냐) 분류하는 것이다.\n//잘못된 프로그램 public class CollectionClassifier { public static String classify(Set\u0026lt;?\u0026gt; s){ return \u0026#34;Set\u0026#34;; } public static String classify(List\u0026lt;?\u0026gt; lst){ return \u0026#34;List\u0026#34;; } public static String classify(Collection\u0026lt;?\u0026gt; lst){ return \u0026#34;Unknown Collection\u0026#34;; } public static void main(String[] args){ Collection\u0026lt;?\u0026gt;[] collections = { new HashSet\u0026lt;String\u0026gt;(), new ArrayList\u0026lt;BigInteger\u0026gt;(), new HashMap\u0026lt;String, String\u0026gt;().values() }; for(Collection\u0026lt;?\u0026gt; c : collections) System.out.println(classify(c)); } } 이 프로그램이 Set, List, Unkwon Collection을 순서대로 출력하지 않을까 기대하겠지만 실제로는 Unknown Collection을 세 번 출력한다. 그 이유는 classify 메서드가 오버로딩되어 있으며, 오버로딩된 메서드 가운데 어떤 것이 호출될지는 컴파일 시점에 결정되기 때문이다. 루프가 세 번 도는 동안, 인자의 컴파일 시점 자료형은 전부 Collection\u0026lt;?\u0026gt;으로 동일하다. 각 인자의 실행시점 자료형(runtime type)은 전부 다르지만, 선택 과정에는 영향을 끼치지 못한다. 인자의 컴파일 시점 자료형이 Collection\u0026lt;?\u0026gt;이므로 호출되는 것은 항상 classify(Collection\u0026lt;?\u0026gt;) 메서드다.\n이 예제 프로그램은 직관과는 반대로 동작한다. 오버로딩된 메서드는 정적(static)으로 선택되지만, 재정의된 메서드는 동적(dynamic)으로 선택되기 때문이다. 재정의된 메서드의 경우 선택 기준은 메서드 호출 대상 객체의 자료형이다. 객체 자료형에 따라 실행 도중에 결정되는 것이다. 그렇다면 재정의된 메서드란 무엇인가? 상위 클래스에 선언된 메서드와 같은 시그니처를 갖는 하위 클래스 메서드가 재정의된 메서드다. 하위 클래스에서 재정의한 메서드를 하위 클래스 객체에 대해 호출하면, 해당 객체의 컴파일 시점 자료형과는 상관없이, 항상 하위 클래스의 재정의 메서드가 호출된다.\nclass Wine { String name() { return \u0026#34;wine\u0026#34;;} } class SparklingWine extends Wine { @Override String name() { return \u0026#34;sparklingWine\u0026#34;; } } class Champagne extends SparklingWine{ @Override String name() { return \u0026#34;champagne\u0026#34;; } } public class Overriding { public static void main(String[] args) { Wine[] wines = { new Wine(), new SparklingWine(), new Champagne() }; for(Wine wine : wines) System.out.println(wine.name()); } } name 메서드는 Wine 클래스에 선언되어 있고, sparklingWine과 Champagne은 그 메서드를 재정의한다. 기대대로 위의 프로그램은 순서대로 출력한다. 순환문의 매 루프마다 객체의 컴파일 시점 자료형은 항상 Wine이었는데도 말이다. 재정의 메서드 가운데 하나를 선택할 때 객체의 컴파일 시점 자료형은 영향을 주지 못한다. 오버로딩에서는 반대로 실행시점 자료형이 아무 영향도 주지 못한다. 실행될 메서드는 컴파일 시에, 인자의 컴파일 시점 자료형만을 근거로 결정된다.\n오버로딩은 직관적인 예측에 반하므로 혼란스럽다. 따라서 오버로딩을 사용할 때는 혼란스럽지 않게 주의해야 한다. 혼란을 피하는 안전하고 보수적인 전략은, 같은 수의 인자를 갖는 두 개의 오버로딩 메서드를 API에 포함시키지 않는 것이다. 예를 들어 ObjectOutputStream의 경우를 생각해 보자. 이 메서드들은 writeBoolean(boolean), writeInt(int), writeLong(long) 같이 정의되어 있다. 이런 작명 패턴을 따르면 오버로딩에 비해 어떤 점이 좋을까? 각 메서드에 대응되는 read 메서드를 정의할 수 있게 된다. (readBoolean(), readInt(), readLong() 등을 정의할 수 있게 된다).\n하지만 생성자에는 다른 이름을 사용할 수 없다. 생성자가 많다면, 그 생성자들은 항상 오버로딩된다. 그게 문제라면 생성자 대신 정적 팩터리 메서드를 사용하는 옵션을 사용할 수도 있다. 하지만 같은 수의 인자를 받는 오버로딩 메서드가 많더라도, 어떤 오버로딩 메서드가 주어진 인자 집합을 처리할 것인지가 분명히 결정된다면 프로그래머는 혼란을 겪지 않을 것이다. 그 조건은, 두 개의 오버로딩 메서드를 비교했을 때 그 형식 인자 가운데 적어도 하나가 “확실히 다르다”면 만족된다. 확실히 다르다라는 것은 두 자료형을 서로 형변환 할 수 없다면 확실히 다른 것이다. 예를 들어 ArrayList에는 int를 받는 생성자와 Collection을 인자로 받는 생성자가 있다. 어떤 상황에서라도 이 두 생성자 간에 혼란의 여지가 있으리라고는 보기 어렵다.\nremove(E) vs remove(int)\n자바 1.5 이전에는 모든 기본 자료형은 참조 자료형과는 확실히 달랐다. 하지만 자동 객체화(autoboxing)라는 기능이 도입된 후 이제는 “확실히 다르다”라고 말할 수 없게 됐다.\npublic class SetList { public static void main(String[] args) { Set\u0026lt;Integer\u0026gt; set = new TreeSet\u0026lt;\u0026gt;(); List\u0026lt;Integer\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); for(int i = -3 ; i \u0026lt; 3; i++){ set.add(i); list.add(i); } for(int i =0; i\u0026lt; 3; i++){ set.remove(i); list.remove(i); } System.out.println(set + \u0026#34; \u0026#34; + list); } } 결과를 [-3, -2, -1] [-3, -2, -1] 이렇게 기대하지만 실상은 그렇지 않다. [-3, -2, -1] [-2, 0, 2] 가 출력된다. set.remove(i)는 인자의 값을 가진 모든 원소가 제거된다. 하지만 list.remove(i)는 해당 i번째 요소의 원소값을 지우게 된다. 그래서 해결을 하려면 Integer로 형변환하여 올바른 오버로딩을 하거나 Integer.valueOf를 적용해야 한다.\nfor(int i =0; i\u0026lt; 3; i++){ set.remove(i); // 인자로 들어온 값을 지우고 싶기 때문에 remove(int)가 아닌 remove(E)형태가 되야 한다.  list.remove(Integer.valueOf(i)); // 아니면 remove((Integer) i); }  이런 일이 발생하는 원인은, List\u0026lt;E\u0026gt; 인터페이스에 remove(E)와 remove(int)라는 오버로딩 메서드 두 개가 존재하기 때문이다.(remove(E)는 인자로 들어온 값을 지우는 메서드, remove(int)는 인자 position의 값을 지우는 메서드) 제네릭이 도입된 자바 1.5 이전에는 List 인터페이스에 remove(E) 대신 remove(Object)가 있었다. Object와 int는 완전히 다른 자료형이므로 문제가 될 것이 없었다. 하지만 제네릭과 자동 객체화(autoboxing)가 도입되면서, E와 int는 더 이상 완전히 다르다고 말할 수 없게 되었다.\n인자 개수가 같은 오버로딩 메서드를 추가하는 것은 일반적으로 피해야 한다. 하지만 특히 생성자에 대해서라면 이 충고를 따를 수 없을 지도 모른다. 그럴 때는, 형변환만 추가하면 같은 인자 집합으로 여러 오버로딩 메서드를 호출할 수 있는 상황은 피하는 것이 좋다.\n규칙 53 : varargs는 신중히 사용하라 자바 1.5부터 추가된 varargs 메서드는 가변 인자 메서드라고 부른다. 이 메서드는 지정된 자료형의 인자를 0개 이상 받을 수 있다. 동작 원리는 이렇다. 우선 클라이언트에서 전달한 인자 수에 맞는 배열이 자동 생성되고, 모든 인자가 해당 배열에 대입된다. 그리고 마지막으로 해당 배열이 메서드에 인자로 전달된다.\n//varargs의 간단한 사용 예 static int sum(int… args) { int sum = 0; for ( int arg : args ) sum += arg; return sum; } 그런데 때로는 0 이상이 아니라, 하나 이상의 인자가 필요할 때가 있다. 예를 들어 주어진 int 인자 가운데 최소치를 구해야 한다고 생각해 보자. 아래의 함수는 인자 없이 호출될 수 있다고 생각하면 깔끔하게 구현되지 않는다. 실행시점에 배열 길이를 검사해야만 한다.\n// 하나 이상의 인자를 받아야 하는 varargs 메서드를 잘못 구현한 사례 static int min(int … args){ if(args.length == 0) throw new IllegalArgumentException(“Too few arguments”); int min = args[0]; for(int i = 1; i \u0026lt; args.length; i++) if(args[i] \u0026lt; min ) min = args[i]; return min; } 그러나 이 방법에는 몇 가지 문제가 있다. 클라이언트가 인자 없이 메서드를 호출하는 것이 가능할 뿐 아니라, 컴파일 시점이 아니라 실행 도중에 오류가 난다는 것이다. 또 한 가지 문제는 보기 흉한 코드라는 것이다. args의 유효성을 검사하는 코드를 명시적으로 넣어야 하고, min을 Integer.MAX_VALUE로 초기화하지 않는 한 for-each 문을 사용할 수도 없다.\n다행히 더 좋은 방법이 있다. 메서드가 인자를 두 개 받도록 선언하는 것이다. 하나는 지정된 자료형을 갖는 일반 인자고, 다른 하나는 같은 자료형의 varargs 인자다. 이 해법은 앞서 살펴본 방법의 모든 문제를 해결한다.\n// 하나 이상의 인자를 받는 varargs 메서드를 제대로 구현한 사례 static int min(int firstArg, int … remainingArgs){ int min = firstArg; for (int arg : remainingArgs) if(arg \u0026lt; min) min = arg; return min; } 이 예제로 알 수 있듯, varargs는 임의 개수의 인자를 처리하는 메서드를 만들어야 할 때 효과적이다. varargs가 추가된 것은 자바 1.5부터 플랫폼에 추가된 printf 메서드와, varargs를 이용할 수 있도록 개선된 핵심 리플렉션 기능 때문이다. printf와 리플렉션은 varargs를 엄청나게 많이 이용한다.\nArrays.asList 이 메서드는 원래 여러 인자를 하나의 리스트로 합칠 목적으로 설계된 것이 아니었다. 그래서 varargs가 플랫폼에 추가되었을 때, 아래와 같은 코드를 지원할 수 있도록 Arrays.asList를 수정한 것은 좋은 생각 같았다. List\u0026lt;String\u0026gt; homophones = Arrays.asList(“to”, “too”, “two”); 하지만 배열에 직접 toString을 호출하면 쓸모없는 문자열이 출력된다.\nint[] myArr = {11, 22}; System.out.println(Arrays.asList(myArr)); // [[I@64889c4e] 이 숙어는 객체 참조 자료형에 대해서만 동작했고 기본 자료형 값의 배열에 적용하면 원하는 것과 거리가 멀고 쓸모없는 값이 나온다. (자바 1.4에서는 컴파일 조차 안됐지만 1.5에서 Arrays.asList를 varargs 메서드로 바꾼 덕분에 오류나 경고 없이 컴파일 된다.)\nint[] digits = {3,1,2,3,4,1,2,6,7,5}; System.out.println(Arrays.asList(digits)); // [[I@4678f83a]  Integer[] digits = {3,1,2,3,4,1,2,6,7,5}; System.out.println(Arrays.asList(digits)); // [3, 1, 2, 3, 4, 1, 2, 6, 7, 5] 기본 자료형에 이런 결과가 나오는 이유에 대해서 알아보자. Arrays.asList 메서드는 객체 참조를 모아 배열로 만드는데, 그 결과로 int 배열 digits에 대한 참조가 담긴 길이 1짜리 배열, 즉 배열의 배열이 만들어진다. List\u0026lt;int[]\u0026gt; 객체가 만들어지는 것이다. 이 리스트에 toString을 호출하면 다시 그 내부의 원소(int 배열)의 toString 메서드가 호출되는데, 방금 본 이상한 문자열은 그렇게 만들어지는 것이다.\n그나마 다행인 것은 Arrays.asList를 사용하여 배열을 문자열로 변환하는 숙어는 이제 폐기되었다는 것이다. 뒤이어 나온 숙어는 좀 더 안정적이다. Arrays 클래스에는 어떤 자료형의 배열이라도 문자열로 변환할 수 있도록 설계된 Arrays.toString 메서드가 구비되었다(varargs 메서드가 아니다). Arrays.asList 대신 Arrays.toString을 사용하도록 프로그램을 고치면 원하는 결과를 얻을 수 있다.\n// 배열을 출력하는 올바른 방법 System.out.println(Arrays.toString(myArr)); varargs는 정말로 임의 개수의 인자를 처리할 수 있는 메서드를 만들어야 할 때만 사용하라. 의심스런 메서드들은 아무 인자 리스트나 받을 수 있는 메서드들이다.\nReturnType1 suspect1 (Object ... args) { } \u0026lt;T\u0026gt; ReturnType2 suspect2 (T ... args) { } 규칙 54 : null 대신 empty 배열이나 컬렉션을 반환하라 아래와 같이 정의된 메서드는 어렵지 않게 만날 수 있다.\nprivate final List\u0026lt;Cheese\u0026gt; cheeseInStock = …; //@return 재고가 남은 모든 치즈를 반환. 치즈가 남지 않았을 때는 null을 반환 public List\u0026lt;Cheese\u0026gt; getCheeses() { return cheeseInStock.isEmpty() ? null : new ArrayList\u0026lt;\u0026gt;(cheeseInStock); } 그런데 치즈 재고가 없는 상황을 특별하게 처리하도록 강제하는 코드는 바람직하지 않다. 클라이언트 입장에서는 null이 반환될 때를 대비한 코드를 만들어야 하기 때문이다. 아래의 예를 보자.\nList\u0026lt;Cheese\u0026gt; cheeses = shop.getCheeses(); if(cheeses != null \u0026amp;\u0026amp; cheeses.contains(Cheese.STILTON)) System.out.println(\u0026#34;Jolly good, just the thing.\u0026#34;); 빈배열이나 컬렉션을 반환하는 대신에 null을 반환하는 메서드를 사용하면 이런 상황을 겪게 된다. 이런 메서드는 오류를 쉽게 유발한다. 클라이언트가 null 처리를 잊어버릴 수 있기 때문이다.\n배열 할당 비용을 피할 수 있으니 null을 반환해야 바람직한 것 아니냐는 주장도 있을 수 있으나, 이 주장은 두 가지 측면에서 틀렸다. 프로파일링 결과로 해당 메서드가 성능 저하의 주범이라는 것이 밝혀지지 않는 한, 그런 수준까지 성능 걱정을 하는 것은 바람직하지 않다는 것이 첫 번째다. 두 번째는 할당 없이 빈 컬렉션이나 배열을 리턴하는게 가능하다.\n아래의 코드는 빈 컬렉션을 리턴하는 일반적인 예다.\npublic List\u0026lt;Cheese\u0026gt; getCheeses() { return new ArrayList\u0026lt;\u0026gt;(cheeseInStock); } 드물 긴하지만 빈 콜렉션을 할당하면 성능에 해를 끼친다는 증거가 있다. immutable 객체가 자유롭게 공유 될 수 있기 때문에 동일한 immutable empty 컬렉션을 반복적으로 반환함으로써 할당을 피할 수있다.\n// Optimization - avoids allocating empty collections public List\u0026lt;Cheese\u0026gt; getCheeses() { return cheeseInStock.isEmpty() ? Collections.emptyList() : new ArrayList\u0026lt;\u0026gt;(cheeseInStock); } set을 반환한다면 Collections.emptySet, map을 반환해야한다면 Collections.emptyMap을 사용하면 된다.\n배열의 경우도 똑같다.\n// The right way to return a possibly empty array public Cheese[] getCheeses() { return cheeseInStock.toArray(new Cheese[0]); }// Optimization - avoids allocating empty arrays private static final Cheese[] EMPTY_CHEESE_ARRAY = new Cheese[0]; public Cheese[] getCheeses() { return cheeseInStock.toArray(EMPTY_CHEESE_ARRAY); } 최적화 버전에서 모든 toArray 호출에 동일한 빈 배열을 전달한다.이 배열은 cheesesInStock이 비어있을 때마다 getCheeses에서 반환된다. 성능 향상을 위한다고 toArray에 전달된 배열을 미리 할당하면 안된다.\n// Don\u0026#39;t do this - preallocating the array harms performance! return cheeseInStock.toArray(new Cheeses[cheeseInStock.size()]); 규칙 55 : Return optionals judiciously 규칙 56 : 모든 API 요소에 문서화 주석을 달라 좋은 API 문서를 만들려면 API에 포함된 모든 클래스, 인터페이스, 생성자, 메서드, 그리고 필드 선언에 문서화 주석을 달아야 한다. 직렬화가 가능한 클래스라면 직렬화 형식도 밝혀야 한다.\n메서드 주석 메서드에 대한 무서화 주석은 메서드와 클라이언트 사이의 규약을 간명하게 설명해야 한다. 계승을 위해 설계된 메서드가 아니라면 메서드가 무엇을 하는지를 설명해야지 어떻게 그 일을 하는지를 설명해서는 안된다. 아울러 문서화 주석에는 해당 메서드의 모든 선행조건과 후행조건을 나열해야 한다. 선행조건은 클라이언트가 메서드를 호출하려면 반드시 참이 되어야 하는 조건들이다. 후행조건은 메서드 실행이 성공적으로 끝난 다음에 만족되어야 하는 조건들이다. 보통 선행조건은 무점검 예외(unchecked exception)에 대한 @throws 태그를 통해 암묵적으로 기술한다. 관계된 인자의 @param 태그를 통해 명시할 수도 있다.\n선행조건과 후행조건 외에도, 메서드는 부작용(side effect)에 대해서도 문서화 해야한다. 예를 들어 어떤 메서드가 후면 스레드(background thread)를 실행한다면 문서에는 그 사실이 명시되어야 한다.\n관습상 @param, @return, @throws 태그 다음에 오는 구나 절에는 마침표를 찍지 않는다.\n/** * Returns the element at the specified position in this list * * \u0026lt;p\u0026gt;This method is \u0026lt;i\u0026gt;not\u0026lt;/i\u0026gt; guaranteed to run in constant time. In some implementations it may run in time proportional to the element position. * * @param index index of element to return; must be * non-negative and less than the size of this list * @return the element at the specified position in this list * @throws IndexOutOfBoundsException if the index is out of range * ({@code index \u0026lt; 0 || index \u0026gt;= this.size()}) */ E get(int indxe); 주석에 HTML 태그\u0026lt;p\u0026gt; \u0026lt;i\u0026gt;가 사용되었다는 것에 유의하자. Javadoc 유틸리티는 문서화 주석을 HTML 문서로 변환한다. @throws 절에 폼함된 코드 주변에 {@code} 태그가 사용된 것도 유의하자. 이 태그는 두 가지 일을 한다. 첫 번째는 해당 코드가 코드 서체로 표시되도록 하는 것이고 두 번째는 그 안에 포함된 모든 HTML 마크업이나 Javadoc 태그가 위력을 발휘하지 못하도록 하는 것이다. {@literal} 태그를 사용하면 그 태그 안에 포함된 HTML 마크업이나 Javadoc 태그는 전부 단순 문자로 취급된다. {@code} 태그와 유사하지만, 코드 서체로 표시되지는 않는다는 차이가 있다.\n모든 문서화 주석의 첫 번째 “문장”은, 해당 주석에 담긴 내용을 요약한 것이다. 혼란을 막기 위해, 클래스나 인터페이스의 멤버나 생성자들 가운데 요약문이 같은 것은 없어야 한다. 오버로딩을 진행할 때는 특히 주의하라. 같은 요약문을 쓰는 것이 자연스러울 때가 종종 있어서다(하지만 문서화 주석의 경우, 동일한 첫 문장은 곤란하다).\n문서화 주석의 요약문은 반드시 완벽한 문장일 필요가 없다. 메서드나 생성자의 경우, 요약문은 메서드가 무슨 일을 하는지 기술하는 완전한 동사구여야 한다. 클래스나 인터페이스의 요약문은 해당 클래스나 인터페이스로 만들어진 객체가 무엇을 나타내는지를 표현하는 명사구여야 한다. 필드의 요약문은 필드가 나타내는 것이 무엇인지를 설명하는 명사구여야 한다.\n제네릭, enum, 애노테이션 문서화 주석 제네릭 자료형이나 메서드에 주석을 달 때는 모든 자료형 인자들을 설명해야 한다.\n/** * An object that maps keys to values. A map cannot contain * duplicate keys; each key can map to at most one value. * * (중간 생략) * * @param \u0026lt;K\u0026gt; the type of keys maintained by this map * @param \u0026lt;V\u0026gt; the type of mapped values */ public interface MyMap\u0026lt;K,V\u0026gt; { } enum 자료형에 주석을 달 때는 자료형이나 public 메서드뿐 아니라 상수 각각에도 주석을 달아 주어야 한다.\n/** * 교향악단에서 쓰이는 악기 종류 */ public enum OrchestraSection { /** 플루트, 클라리넷, 오보에 관한 목관악기.*/ WOODWIND, /** 프렌치 혼이나 트럼펫 같은 금관악기. */ BRASS, /** 팀파니나 심벌즈 같은 타악기. */ PERCUSSION, /** 바이올린이나 첼로 같은 현악기. */ STRING; } 애노테이션 자료형에 주석을 달 때는 자료형뿐 아니라 모든 멤버에도 주석을 달아야 한다. 멤버에는 마치 필드인 것처럼 명사구 주석을 달라. 자료형 요약문에는 동사구를 써서, 언제 이 자료형을 애노테이션으로 붙어야 하는지 설명하라.\n/** * 지정된 예외를 반드시 발생시켜야 하는 테스트 메서드임을 명시. */ @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) public @interface ExceptionTest{ /** * 애노테이션이 붙은 테스트 메서드가 테스트를 통과하기 위해 * 반드시 발생시켜야 하는 예외. (이 Class 객체가 나타내는 자료형의 * 하위 자료형이기만 하면 어떤 예외든 상관없다.) */ Class\u0026lt;? extends Throwable\u0026gt; value(); }"
},
{
	"uri": "/toby_spring/",
	"title": "토비 스프링",
	"tags": [],
	"description": "",
	"content": " 토비 스프링 "
},
{
	"uri": "/toby_spring/%E1%84%89%E1%85%B3%E1%84%91%E1%85%B3%E1%84%85%E1%85%B5%E1%86%BC_%E1%84%92%E1%85%A2%E1%86%A8%E1%84%89%E1%85%B5%E1%86%B7_%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF%E1%84%8B%E1%85%B4_%E1%84%8B%E1%85%B3%E1%86%BC%E1%84%8B%E1%85%AD%E1%86%BC/",
	"title": "스프링 핵심 기술의 응용",
	"tags": [],
	"description": "",
	"content": " 자바 언어의 변화와 스프링 스프링이 제공하는 모든 기술의 기초가 되는 DI의 원리는 변하지 않았지만, DI가 적용된 코드를 작성할 때 사용하는 핵심 도구인 자바 언어에는 그간 적지 않은 변화가 있었다. 이런 변화들이 DI 프레임워크로서 스프링의 사용 방식에도 여러 가지 영향을 줬다. 대표적인 두 가지 변화를 살펴보자.\n애노테이션의 메타정보 활용 자바는 소스코드가 컴파일된 후 클래스 파일에 저장됐다가 JVM에 의해 메모리로 로딩되어 실행된다. 그런데 때로는 자바 코드가 실행되는 것이 목적이 아니라 다른 자바 코드에 의해 데이터처럼 취급되기도 한다. 자바 코드의 일부를 리플렉션 API 등을 이용해 어떻게 만들었는지 살펴보고 그에 따라 동작하는 기능이 점점 많이 사용되고 있다.\n원래 리플렉션 API는 자바 코드나 컴포넌트를 작성하는 데 사용되는 툴을 개발할 때 이용하도록 만들어졌는데, 언제부턴가 본래 목적보다는 자바 코드의 메타정보를 데이터로 활용하는 스타일의 프로그래밍 방식에 더 많이 활용되고 있다.\n이런 프로그래밍 방식의 절정은 자바 5에서 등장한 애노테이션일 것이다. 자바 클래스나 인터페이스, 필드, 메서드 등은 그 자체로 실행 가능하고, 상속하거나 참조하거나 호출하는 방식 등으로 직접 이용할 수 있다. 반면에 애노테이션은 기존의 자바 프로그래밍 방식으로는 활용할 수가 없다. 애노테이션은 옵션에 따라 컴파일된 클래스에 존재하거나 애플리케이션이 동작할 때 메모리에 로딩되기도 하지만 자바 코드가 실행되는 데 직접 참여하지 못한다. 복잡한 리플렉션 API를 이용해 애노테이션의 메타정보를 조회하고, 애노테이션 내에 설정된 값을 가져와 참고하는 방법이 전부다.\n그럼에도 애노테이션의 활용이 늘어난 이유는 무엇일까? 애노테이션은 애플리케이션 핵심 로직을 담은 자바 코드와 이를 지원하는 IoC 방식의 프레임워크, 그리고 프레임워크가 참조하는 메타정보라는 세 가지로 구성하는 방식에 잘 어울리기 때문일 것이다.\n애노테이션은 XML이나 여타 외부 파일과 달리 자바 코드의 일부로 사용된다 코드의 동작에 직접 영향을 주지는 못하지만 메타정보로서 활용되는 데는 XML에 비해 유리한 점이 많다.\n@Special public class MyClass { ... } 위의 코드처럼 애노테이션 하나 추가함으로써 클래스의 패키지, 클래스 이름, 접근 제한자, 상속한 클래스나 구현 인터페이스가 무엇인지 알 수 있다. 원한다면 클래스의 필드나 메서드 구성도 확인 할 수 있다.\n반면에 동일한 정보를 XML로 표현하려면 모든 내용을 명시적으로 나타내야 한다.\n\u0026lt;x:special target=\u0026quot;type\u0026quot; class=\u0026quot;com.mycompany.myproject.MyClass\u0026quot; /\u0026gt;  애노테이션 하나를 자바 코드에 넣는 것에 비해 작성할 정보의 양이 많다. 물론 애노테이션에도 단점이 있다. 자바 코드에 존재하므로 변경할 때마다 매번 클래스를 새로 컴파일 해줘야 한다.\n정책과 관례를 이용한 프로그래밍 @Transactional을 생각해보면 클래스, 인터페이스 각각의 메서드를 포함해 여러 위치에 적용이 가능하다. 이때 스프링은 우선순위를 가진 대체 정책을 정해놨다.\n프로파일 @Profile @ActiveProfiles 프로파일이 지정되어 있지 않은 빈 설정은 default 프로파일로 취급되어 항상 적용된다.\n@Profile이 붙은 설정 클래스는 @Import로 가져오든 @ContextConfiguration에 직접 명시하든 상관없이, 현재 컨테이너의 활동 프로파일 목록에 자신의 프로파일 이름이 들어 있지 않으면 무시된다.\n컨테이너의 빈 등록 정보 확인 (vol.1 p692)\n@Autowired DefaultListableBeanFactory bf; @Test public void beanTest() throws Exception { for (String s : bf.getBeanDefinitionNames()) { System.out.println(bf.getBean(s).getClass().getName()); } } 스프링 컨테이너는 모두 BeanFactory라는 인터페이스를 구현하고 있다. BeanFactory의 구현 클래스 중에 DefaultListableBeanFactory가 있는데 거의 대부분의 스프링 컨테이너는 이 클래스를 이용해 빈을 등록하고 관리한다.\n@PropertySource 스프링 3.1은 빈 설정 작업에 필요한 프로퍼티 정보를 컨테이너가 관리하고 제공해준다. 스프링 컨테이너가 지정된 정보 소스로부터 프로퍼티 값을 수집하고, 이를 빈 설정 작업 중에 사용할 수 있게 해준다. 컨테이너가 프로퍼티 값을 가져오는 대상을 프로퍼티 소스라고 한다.\n디폴트로 프로퍼티 정보를 끌어오는 프로퍼티 소스도 있고, 위치를 지정해서 사용되는 프로퍼티 소스도 있다.\n@PropertySource(\u0026#34;/database.properties\u0026#34;) public class AppContext { @PropertySource로 등록한 리소스로부터 가져오는 프로퍼티 값은 컨테이너가 관리하는 Environment 타입의 환경 오브젝트에 저장된다. 환경 오브젝트는 빈처럼 @Autowired를 통해 필드로 주입받을 수 있다 주입받은 Environment 오브젝트의 getProperty() 메서드를 이용하면 프로퍼티 값을 가져올 수 있다.\n@Autowired Environment env; @Bean public DataSource dataSource() { SimpleDriverDataSource ds = new SimpleDriverDataSource(); ds.setDriverClass((Class\u0026lt;? extends java.sql.Driver\u0026gt;)Class.forName(env.getProperty(\u0026#34;db.driverClass\u0026#34;))); ds.setUrl(env.getProperty(\u0026#34;db.url\u0026#34;)); ... } PropertySourcesPlaceholderConfigurer Environment 오브젝트 대신 프로퍼티 값을 직접 DI 받는 방법도 가능하다. @Value 애노테이션을 이용하면 된다.\n@PropertySource(\u0026#34;/database.properties\u0026#34;) public class AppContext { @Value(\u0026#34;${db.driverClass}\u0026#34;) Class\u0026lt;? extends Driver\u0026gt; driverClass; @Value(\u0026#34;${db.url}\u0026#34;) String url; ... } @Value와 치환자를 이용해 프로퍼티 값을 필드에 주입하려면 PropertySourcesPlaceholderConfigurer 빈을 선언해줘야 한다. 빈 팩토리 후처리기로 사용되는 빈을 정의해주는 것인데 이 빈 설정 메서드는 반드시 스태틱 메서드로 선언해야 한다.\n@Bean public static PropertySourcesPlaceholderConfigurer placeholderConfigurer() { return new PropertySourcesPlaceholderConfigurer(); } Enable* 애노테이션 @Component는 빈 자동등록 대상을 지정할 때 사용하는 애노테이션인데, 많은 경우 @Component를 직접 사용하기보다는 @Service, @Repository처럼 좀 더 의미있는 이름의 애노테이션을 만들어 사용한다.\n비슷한 방식으로 @Import도 다른 이름의 애노테이션으로 대체 가능하다.\n@Target({ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Documented @Import({TransactionManagementConfigurationSelector.class}) public @interface EnableTransactionManagement { @EnableTransactionManagement 애노테이션도 @Import를 메타 애노테이션으로 갖고 있다. @EnableTransactionManagement를 사용한다는 것은 결국 TransactionManagementConfigurationSelector 설정 클래스를 @Import 하는 셈이다.\n"
},
{
	"uri": "/effective_java/%E1%84%8B%E1%85%B5%E1%86%AF%E1%84%87%E1%85%A1%E1%86%AB%E1%84%8C%E1%85%A5%E1%86%A8%E1%84%8B%E1%85%B5%E1%86%AB_%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%80%E1%85%B3%E1%84%85%E1%85%A2%E1%84%86%E1%85%B5%E1%86%BC_%E1%84%8B%E1%85%AF%E1%86%AB%E1%84%8E%E1%85%B5%E1%86%A8%E1%84%83%E1%85%B3%E1%86%AF/",
	"title": "일반적인 프로그래밍 원칙들",
	"tags": [],
	"description": "",
	"content": " 규칙 57 : 지역 변수의 유효범위를 최소화하라 C와 같은 오래된 프로그래밍 언어는 지역 변수를 블록 앞부분에 선언한다. 그러나 고칠 필요가 있는 습관이다. 지역 변수의 유효범위를 최소화하는 가장 강력한 기법은, 처음으로 사용하는 곳에서 선언하는 것이다. 사용하기 전에 선언하면 프로그램의 의도를 알고자 소스 코드를 읽는 사람만 혼란스럽게 할 뿐이다. 실제로 변수가 사용될 때쯤 되면, 그 변수의 자료형과 초기값이 무엇이었는지는 잊어버리고 말 것이다.\n지역 변수를 너무 빨리 선언하면 유효범위가 너무 앞쪽으로 확장될 뿐 아니라, 너무 뒤쪽으로도 확장된다. 지역 변수의 유효범위는 선언된 지점부터 해당 블록 끝까지다. 어떤 블록 밖에서 선언된 변수는 프로그램이 해당 블록 수행을 끝내고 나서도 계속 사용 가능하다. 어떤 변수를 원래 사용하려고 했던 곳 이외의 장소에서 실수로 사용하게 되면, 끔찍한 결과가 초래될 수 있다.\n거의 모든 지역 변수 선언에는 초기값이 포함되어야 한다. 그런데 try-catch 블록이 사용 될 때는 예외적 상황이 생길 수 도 있다. 어떤 변수가 점검지정 예외(checked exception)을 던지는 메서드를 통해 초기화된다면 그 변수는 try 블록 안에서 초기되어야 할 것이다. 그런데 그 변수의 값이 try 블록 밖에서도 사용할 수 있어야 하는 값이라면 선언 위치를 try 블록 앞으로 이동시켜야 한다.\n순환문(loop)을 잘 쓰면 변수의 유효범위를 최소화할 수 있다. for문이나 for-each문의 경우, 순환문 변수라는 것을 선언할 수 있는데, 그 유효범위는 선언된 지역(즉, for 다음에 오는 순환문 괄호 ()와 순환문 몸체 {} 내부의 코드) 안으로 제한된다. 따라서 while 문보다는 for 문을 쓰는 것이 좋다. 순환문 변수의 내용은 순환문 수행이 끝난 이후에는 필요 없다는 가정하에서. 예를 들어, 컬렉션을 순회할 때는 아래와 같이 하는 것이 좋다.\n// 컬렉션을 순회할 때는 이 숙어대로 하는 것이 바람직 for (Element e : c) { doSomething(e); } 이런 for 순환문이 while 문보다 바람직한 이유는 무엇인가? 아래의 코드를 보자. while 문이 두 개 사용되었고, 버그도 하나 있다.\nIterator\u0026lt;Element\u0026gt; i = c.iterator(); while(i.hasNext()){ doSomething(i.next()); } … Iterator\u0026lt;Element\u0026gt; i2 = c2.iterator(); while(i.hasNext()){ // 버그  doSomething(i2.next()); } 두 번째 순환문에는 코드를 복붙하다보니 생긴 버그가 하나 있다. 새로운 순환문 변수 i2를 초기화 했으나 실제로는 옛날 변수 i를 써버린 것이다. i가 아직도 유효범위 안에 있는 관계로, 이 코드는 컴파일이 잘 될뿐 아니라 예외도 없이 실행되지만 이상하게 동작할 것이다. 이와 비슷한 복붙 버그가 for 문이나 for-each 문에서도 생길 수 있을까? 컴파일조차 되지 않을 것이므로 어려울 것이다. 첫 번째 순환문 안에서 사용된 요소나 반복자의 유효범위는 두 번째 순환문까지 연장될 수 없다. 아래의 예제를 보자.\nfor(Iterator\u0026lt;Element\u0026gt; i = c.iterator(); i.hasNext();){ doSomething(i.next()); } … //심볼 i를 찾을 수 없다면서 컴파일 시점에 오류 발생 for(Iterator\u0026lt;Element\u0026gt; i2 = c2.iterator(); i.hasNext();){ doSomething(i2.next()); } 더욱이 for문을 사용할 때는 순환문마다 다른 이름으 변수를 사용할 필요가 없기 때문에 복붙 버그가 발생할 가능성은 더욱 줄어든다. 각각의 for 문은 서로 의존성이 없으므로, 같은 변수명을 거듭 사용해도 상관없다. 지역 변수의 유효범위를 최소화하는 숙어를 하나 더 살펴보자.\nfor (int i = 0 , n = expensiveComputation(); i\u0026lt; n ; i++){ doSomething(i); } 여기서 주의할 것은 두 개의 순환문 변수가 사용되었다는 것이다. i와 n의 유효범위는 정확히 해당 for문 안으로 제한된다. 두번째 변수 n은 i값의 범위를 제한하는 용도로 쓰이고 있는데, 그 값을 계산하는 비용이 꽤 크다. 따라서 미리 계산해 넣어두고 사용함으로써 매번 재계산할 필요가 없도록 했다. 명심할 것은, 순환문 조건식 안에서 메서드를 호출할 경우, 해당 메서드의 호출 결과로 반환되는 값이 순환문 각 단계마다 달라지지 않는다면, 항상 이 패턴대로 코딩하라는 것이다.\n지역 변수의 유효범위를 최소화하는 마지막 전략은 메서드의 크기를 줄이고 특정한 기능에 집중하라는 것이다. 두 가지 서로 다른 기능을 한 메서드 안에 넣어두면 한 가지 기능을 수행하는 데 필요한 지역 변수의 유효범위가 다른 기능까지 확장되는 문제가 생긴다. 이런 일을 막으려면 각 기능을 나눠서 별도 메서드로 구현해야 한다.\n규칙 58 : for 문보다는 for-each 문을 사용하라 릴리스 1.5 전에는 컬렉션을 순회할 때 아래으 숙어를 따르는 것이 바람직했다.\n// 컬렉션 순회를 위해 한동안 많이 썼던 숙어 for (Iterator i = c.iterator(); i.hasNext(); ){ doSomething((Element) i.next()); // 1.5 전에는 제네릭 없었음 } 배열을 순회할 때는 이렇게 하는 것이 바람직 했다.\n// 배열 순회할 때 한동안 많이 사용한 숙어 for (int i =0; i\u0026lt; a.length; i++){ doSomething(a[i]); } 릴리스 1.5부터 도입된 for-each 문은 성가신 코드와 반복자, 첨자 변수들을 완전히 제거해서 오류 가능성을 없앤다.\n// 컬렉션이나 배열을 순회할 때는 이 숙어를 따르자 for (Element e : elements){ doSomething(e); } 위의 for-each 문에서 : \u0026ldquo;기호는 안에 있는(in)”이라고 읽는다. 따라서 위의 순환문은 “elements 안에 있는 e 각각에 대해서(for)” 라고 읽으면 된다. for-each 문의 장점은 여러 컬렉션에 중첩되는 순환문을 만들어야 할 때 더 빛난다. 두 개 컬렉션에 대한 순환문을 중첩시킬 때 흔히 저지르는 실수의 사례를 아래에 보였다.\n// 버그 있는 코드 enum Suit { CLUB, DIAMOND, HEART, SPADE } enum Rank { ACE, DEUCE, THREE, FOUR, FIVE, SIX, SEVEN, EIGHT, NINE, TEN, JACK, QUEEN, KING } … Collection\u0026lt;Suit\u0026gt; suits = Arrays.asList(Suit.values()); Collection\u0026lt;Rank\u0026gt; ranks = Arrays.asList(Rank.values()); List\u0026lt;Card\u0026gt; deck = new ArrayList\u0026lt;Card\u0026gt;(); for ( Iterator\u0026lt;Suit\u0026gt; i = suits.iterator(); i.hasNext(); ) for ( Iterator\u0026lt;Rank\u0026gt; j = rank.iterator(); j.hasNext(); ) deck.add(new Card(i.next(), j.next()));  바깥쪽 순환문 안에서 카드 종류별로 한 번만 호출되야 하는데 안쪽 순화눈에서 호출되다 보니 너무 빨리 소진되어서 결국 NoSuchElementException이 발생하고 만다. for-each 문을 중첩해서 프로그램을 짜면 이 문제는 바로 사라진다.\n// 컬렉션이나 배열에 대한 순환문을 중첩시킬 때 따라야 할 숙어 for (Suit suit : suits) for(Rand rank : ranks) deck.add(new Card(suit, rank)); for-each문으로는 컬렉션과 배열뿐 아니라 Iterable 인터페이스를 구현하는 어떤 객체도 순회 할 수 있다. Iterable 인터페이스는 메서드가 하나뿐인 아주 간단한 인터페이스다. for-each 문과 함께 플랫폼에 추가되었으며, 아래처럼 생겼다.\npublic interface Iterable\u0026lt;E\u0026gt; { // 이 Iterable 안에 있는 원소들에 대한 반복자 반환  Iterator\u0026lt;E\u0026gt; iterator(); } Iterator 인터페이스는 구현하기 어렵지 않다. 원소들의 그룹을 나타내는 자료형을 작성할 때는, Collection은 구현하지 않더라도 Iterable은 구현하도록 하라. 그러면 클라이언트는 for-each문을 통해 해당 자료형을 순회할 수 있게 될 것이므로 너무 고마워 할 것이다.\n그러나 불행히도 아래의 세 경우에 대해서는 for-each문을 적용할 수 없다. 1. 필터링 - 컬렉션을 순회하다가 특정한 원소를 삭제할 필요가 있다면, 반복자를 명시적으로 사용해야 한다. 반복자의 remove 메서드를 호출해야 하기 때문이다. 2. 변환 - 리스트나 배열을 순회하다가 그 원소 가운데 일부 또는 전부의 값을 변경해야 한다면, 원소의 값을 수정하기 위해서 리스트 반복자나 배열 첨자가 필요하다. 3. 병렬 순회 - 여러 컬렉션을 병렬적으로 순회해야 하고, 모든 반복자나 첨자 변수가 발맞춰 나아가도록 구현해야 한다면 반복자나 첨자 변수를 명시적으로 제어할 필요가 있을 것이다.\n규칙 59 : 어떤 라이브러리가 있는지 파악하고, 적절히 활용하라 무작위 정수 하나를 생성하고 싶다고 해보자. 값의 범위는 0부터 명시한 수 사이다. 아주 흔히 마주치는 문제로, 많은 프로그래머가 다음과 같은 짤막한 메서드를 만들곤 한다.\nstatic Random rnd = new Random(); static int random(int n) { return Math.abs(rnd.nextInt()) % n; } 괜찮은 듯 보여도 문제를 세 가지나 내포하고 있다. 첫 번째, n이 그리 크지 않은 2의 제곱수라면 얼마 지나지 않아 같은 수열이 반복된다. 두 번째, n이 2의 제곱수가 아니라면 몇몇 숫자가 평균적으로 더 자주 반환된다. n 값이 크면 이 현상은 더 두드러진다.\n@Test public void name() { int n =2 * (Integer.MAX_VALUE / 3); int low = 0; for (int i=0; i\u0026lt;1000000; i++) { if (random(n) \u0026lt; n/2) { low++; } } System.out.println(low); } private int random(int n) { Random rnd = new Random(); return Math.abs(rnd.nextInt()) % n; } random 메서드가 이상적으로 동작한다면 약 50만개가 출력돼야 하지만, 실제로 돌려보면 약 66만개에 가까운 값을 얻는다. 무작위로 생성된 수 중에서 2\u0026frasl;3 가량이 중간값보다 낮은 쪽으로 쏠린 것이다.\nrandom 메서드의 세 번째 결함으로, 지정한 범위 ‘바깥’의 수가 종종 튀어나올 수 있다. rnd.nextInt()가 반환한 값을 Math.abs를 이용해 음수가 아닌 정수로 매핑하기 때문이다. nextInt()가 Integer.MIN_VALUE를 반환하면 Math.abs도 Integer.MIN_VALUE를 반환하고, 나머지 연산자는 음수를 반환해버린다(n이 2의 제곱수가 아닐 때의 시나리오다). 이렇게 되면 여러분의 프로그램은 실패할 것이고, 문제를 해결하고 싶어도 현상을 재현하기가 쉽지 않을 것이다.\n이 결함을 해결하려면 Rnadom.nextInt(int)가 이미 해결해놨으니 가져다 쓰면된다. 하지만 자바 7부터는 Random을 더 이상 사용하지 않는 게 좋다. ThreadLocalRandom으로 대체하면 대부분 잘 작동한다. Random보다 더 고품질의 무작위 수를 생성할 뿐 아니라 속도도 더 빠르다. 한편, 포크-조인 풀이나 병렬 스트림에서는 SplittableRandom을 사용해라.\n다음 예제는 지정한 URL의 내용을 가져오는 명령줄 애플리케이션이다(리눅스의 curl 명령을 생각하면 된다).\npublic static void main(String[] args) throws IOException { try (InputStream in = new URL(args[0]).openStream()) { in.transferTo(System.out); } } 예전에는 작성하기가 까다로운 기능이었지만, 자바 9에서 InputStream에 추가된 transferTo 메서드를 사용하면 쉽게 구현할 수 있다.\n실제로 하려는 일과 큰 관련성도 없는 문제에 대한 해결 방법을 임의로 구현하늬라 시간을 낭비하지 않도록 하자(바퀴를 다시 발명하지 말자). 자바 프로그래머라면 java.lang, java.util, java.io와 그 하위 패키지들에는 익숙해져야 한다.\n규칙 60 : 정확한 답이 필요하다면 float와 double은 피하라 float와 double은 이진 부동 소수점 연산을 수행한다. 하지만 정확한 결과를 제공하지는 않기 때문에 정확한 결과가 필요한 곳에는 사용하면 안 된다. float와 double은 특히 돈과 관계된 계산에는 적합하지 않다. 0.1을 비롯한 10의 음의 거듭제곱 수를(10^-1, 10^-2, 10^-3 \u0026hellip;) 정확하게 나타낼 수 없기 때문이다.\nSystem.out.println(1.03 - .42); // 0.6100000000000001 System.out.println(1.00 - 9 * .10); // 0.09999999999999998  화면에 출력하기 전에 반올림하면 되지 않을까 싶기도 하겠지만, 그 방법은 항상 통하지 않는다. 예를 들어 주머니에 1달러가 있는데 10센트, 20센트, 30센트 등의 가격이 붙은 사탕들이 있다고 하자. 가장 싼 사탕부터 시작해서 차례로 더 비싼 사탕을 구입해 나갈 때, 얼마나 많은 사탕을 살 수 있는가?\ndouble funds = 1.00; int itemsBought = 0; for ( double price = .10; funds \u0026gt;= price; price += .10){ funds -= price; itemsBought++; } System.out.println(itemsBought+ \u0026#34;item bought.”); // 3item bought. System.out.println(\u0026#34;Change: $\u0026#34;+ funds); // Change: $0.3999999999999999 금전 계산을 하는 이 프로그램을 돌려 보면 살 수 있는 사탕은 세 개이고 잔돈은 $0.3999999999999999라고 출력될 것이다.\n돈 계산을 할 때는 BigDecimal,int 또는 long을 사용한다는 원칙을 지켜야 한다.\n// double 대신 BigDecimal로 바꾼 코드 final BigDecimal TEN_CENTS = new BigDecimal(\u0026#34;.10\u0026#34;); int itemsBought = 0; BigDecimal funds = new BigDecimal(\u0026#34;1.00\u0026#34;); for ( BigDecimal price = TEN_CENTS; funds.compareTo(price)\u0026gt;=0; price = price.add(TEN_CENTS)){ funds = funds.subtract(price); itemsBought++; } System.out.println(itemsBought+ \u0026#34;item bought.”); // 4item bought. System.out.println(\u0026#34;Money left over: $\u0026#34;+ funds); // Money left over: $0.00 이렇게 고치면 정확한 답이 나오지만 BigDecimal을 쓰는 방법에는 두 가지 문제가 있다. 첫 째, 기본 산술연산 자료형보다 사용이 불편하며 느리다. BigDecimal의 대안은 int나 long을 사용하는 것이다. 둘 중 어떤 자료형을 쓸 것이냐는 수의 크기, 그리고 소수점 이하 몇 자리까지를 표현할 것이냐에 따라 결정된다. 이 예제에 딱 맞는 접근법은 모든 계산을 달러 대신 센트 단위로 하는 것이다.\nint itemsBought = 0; int funds = 100; for(int price = 10; funds\u0026gt;= price; price+= 10){ funds -= price; itemsBought++; } System.out.println(itemsBought+ \u0026#34;item bought.”); // 4item bought. System.out.println(\u0026#34;Money left over: $\u0026#34;+ funds + \u0026#34; cents”); // Money left over: $0cents 결론 : 기본 자료형보다 사용하기는 불편하고 성능이 떨어져도, 소수점 이하 처리를 시스템이 알아서 해줬으면 좋겠을 때는 BigDecimal을 사용해라. BigDecimal을 쓰면 올림 연산을 어떻게 수행해야 하는지를 여덟 가지 올림 모드 가운데 하나로 지정할 수 있다(법적으로 올림 연산이 필요한 상업적인 계산을 해야 할 때 편리하다). 그러나 성능이 중요하고 소수점 아래 수를 직접 관리해도 상관없으며 계산할 수가 심하게 크지 않을 때는 int나 long을 쓰라(관계된 수치들이 십진수 9개 이하로 표현이 가능할 때는 int, 18개 이하는 long, 그 이상일 때는 BigDecial).\n규칙 61 : 객체화된 기본 자료형 대신 기본 자료형을 이용하라 자바의 자료형 시스템은 두 부분으로 나뉜다. 하나는 기본 자료형(int, double, boolean 등)이고 다른 하나는 String과 List 등의 참조 자료형(reference type)이다. 모든 자료형에는 대응되는 참조 자료형이 있는데, 이를 객체화된 기본 자료형이라 부른다. int, double, boolean의 객체화된 기본 자료형은 각각 Integer, Double, Boolean이다.\n기본 자료형과 객체화된 기본 자료형 사이에는 세 가지 큰 차이점이 있다. 1. 기본 자료형은 값만 가지지만 객체화된 기본 자료형은 값 외에도 identity를 가진다. 따라서 객체화된 기본 자료형 객체가 두 개 있을 때 그 값은 같더라도 identity는 다를 수 있다. 2. 기본 자료형에 저장되는 값은 전부 기능적으로 완전한 값이지만, 객체화된 자료형에 저장되는 값에는 그 이외에도 아무 기능도 없는 값, 즉 null이 하나 있다는 것이다. 3. 기본 자료형은 시간적이나 공간 요구량 측면에서 일반적으로 객체 표현형보다 효율적이다.\n아래의 비교자 예제를 보자.\n// 잘못된 반복자 Comparator\u0026lt;Integer\u0026gt; naturalOrder = new Comparator\u0026lt;Integer\u0026gt;(){ public int compare(Integer first, Integer second){ return first \u0026lt; second ? -1 : (first == second ? 0 : 1); } }; 표현식 fisrt \u0026lt; second는 first와 second가 참조하는 Integer 객체를 기본 자료형 값으로 자동 변환한다. 따라서 first의 int 값이 second의 int 값 보다 작다면 음수가 제대로 반환될 것이다. 하지만 first == second 표현식은 두 객체의 identity를 비교한다. 그래서 객체화된 기본 자료형에 == 연산자를 사용하는 것은 거의 항상 오류라고 봐야 한다.\n아래의 예제를 보자.\n// NullPointerException 에러 발생 public class Unbelievable { static Integer i; public static void main(String[] args) { if(i == 42) System.out.println(\u0026#34;unb\u0026#34;); } } 모든 객체 참조 필드가 그렇듯, 초기값은 null이다. 위의 프로그램이 (i == 42)를 계산할 때 비교되는 것은 Integer 객체와 int 값이다. 거의 모든 경우에, 기본 자료형과 객체화된 기본 자료형을 한 연산 안에 엮어 놓으면 객체화된 기본 자료형은 자동으로 기본 자료형으로 반환된다. 따라서 null인 객체 참조를 기본 자료형을 변환하려 시도하면 NullPointerException이 발생한다.\n무시무시할 정도로 느린 프로그램\npublic static void main(String[] args) { Long sum = 0L; for( long i = 0; i \u0026lt; Integer.MAX_VALUE; i++){ sum += i; } System.out.println(sum); } 지역 변수 sum을 long이 아니라 Long으로 선언했기 때문에 오류나 경고 없이 컴파일되는 프로그램이지만 변수가 계속해서 객체화와 비객체화를 반복하기 때문에 성능이 느려진다.\n객체화된 기본 자료형은 컬렉션의 요소, 키, 값으로 사용할 때다. 컬렉션에는 기본 자료형을 넣을 수 없으므로 객체화된 자료형을 써야 한다. 리플렉션을 통해 메서드를 호출할 때도 객체화된 기본 자료형을 사용해야 한다.\n규칙 62 : 다른 자료형이 적절하다면 문자열 사용은 피하라 문자열은 텍스트 표현과 처리에 걸맞도록 설계되었다. 이번 절에서는 문자열로 해서는 안 되는 일들을 짚어본다. 1. 문자열은 값 자료형(value type)을 대신하기에는 부족하다. 데이터가 파일이나 네트워크나 키보드를 통해서 들어올 때는 보통 문자열 형태다. 그러니 그대로 두려는 경향이 있다. 하지만 데이터가 텍스트 형태일 때나 그렇게 하는 것이 좋다. 숫자라면 int, float, BigInteger 같은 수 자료형으로 변환해야 한다. 적당한 자료형이 없다면 새로 만들어야 한다. 2. 문자열은 enum 자료형을 대신하기에는 부족하다. 3. 문자열은 혼합 자료형을 대신하기엔 부족하다. String compundKey = className + “#” + i.next();이런 접근법에는 많은 문제가 있다. 필드 구분자로 사용한 문자가 필드 안에 들어가버리면 문제가 생긴다. 게다가 각 필드를 사용하려고 하면 문자열을 파싱해야 하는데, 느릴 뿐더러 멍청하고 오류 발생 가능성도 높은 과정이다. 4. 문자열은 권한(capability)을 표현하기엔 부족하다. 때로 문자열을 사용해서 접근 권한을 표현하는 경우가 있다. 스레드 지역 변수 기능을 설계하는 경우를 예로 들어 살펴보자. 스레드마다 다른 변수를 제공하는 기능이다.\n// 문자열을 권한으로 사용하는 잘못된 예제 public class ThreadLocal { private ThreadLocal() { } // 객체를 만들 수 없다.  // 주어진 이름이 가리키는 스레드 지역 변수의 값 설정  public static void set(String key, Object value); // 주어진 이름이 가리키는 스레드 지역 변수의 값 반환  public static Object get(String key); } 이 접근법의 문제는, 문자열이 스레드 지역 변수의 전역적인 이름공간이라는 것이다. 위 접근법이 통하려면 클라이언트가 제공하는 문자열 키의 유일성이 보장되어야 한다.\n위 API의 문제는 문자열 대신 위조 불가능 키로 바꾸면 해결된다(이런 키를 때로 ‘권한’이라 부른다).\npublic class ThreadLocal { private ThreadLocal() { } // 객체를 만들 수 없다.  public static class Key { // 권한  Key() { } } // 유일성이 보장되는, 위조 불가능 키를 생성  public static Key getKey { return new Key(); } public static void set(Key key, Object value); public static Object get(Key key); } 이 방법으로 문자열 키 유일성 보장과 보안 문제도 해결하지만 아직도 개선의 여지는 있다. 정적 메서드들은 사실 더 이상 필요없다. 키의 인스턴스 메서드로 만들 수 있다. 그렇게 하고 나면 키는 더 이상 스레드 지역 변수의 키가 아니라 그것 자체가 스레드 지역 변수가 된다.\npublic final class ThreadLocal\u0026lt;T\u0026gt;{ public ThreadLocal(); public void set(T value); public T get(); } 개략적으로 이것이 바로 java.lang.ThreadLocal이 제공하는 API다.\n규칙 63 : 문자열 연결 시 성능에 주의하라 문자열 연결이 많으면 성능에 문제가 생긴다. n개의 문자열에 연결 연산자를 반복 적용해서 연결하는 데 드는 시간은 n^2에 비례한다. 문자열이 변경 불가능 하기 때문이다. 문자열 두 개를 연결할 때, 그 두 문자열의 내용은 전부 복사된다.\n// 문자열을 연결하는 잘못된 방법 - 성능이 엉망이다 public String statement() { String result = “”; for (int i =0 ; i \u0026lt; numItems(); i++){ result += lineForItem(i); } } 만족스런 성능을 얻으려면 String 대신 StringBuilder를 써서 저장해야 한다. StringBuilder 클래스는 릴리스 1.5에 추가된 것으로, StringBuffer에서 동기화 기능을 뺀 것이다. StringBuffer는 이제 지원되지 않는다.\npublic String statement() { StringBuilder b = new StringBuilder(numItems() * LINE_WIDTH); for (int i =0; i \u0026lt; numItems(); i++) b.append(lineForItem(i)); return b.toString(); } 규칙 64 : 객체를 참조할 때는 그 인터페이스를 사용하라 적당한 인터페이스 자료형이 있다면 인자나 반환값, 변수, 그리고 필드의 자료형은 클래스 대신 인터페이스로 선언하자. 객체의 실제 클래스를 사용해야 할 상황은 오직 생성자로 생성할 때 뿐이다.\n// 좋은 예 Set\u0026lt;Son\u0026gt; sonSet = new LinkedHashSet\u0026lt;\u0026gt;(); // 나쁜 예 LinkdHashSet\u0026lt;Son\u0026gt; sonSet = new LinkedHashSet\u0026lt;\u0026gt;(); 인터페이스를 자료형으로 쓰는 습관을 들이면 프로그램은 더욱 유연해진다. 단 한 가지 주의할 것이 있다. 원래의 클래스가 인터페이스의 일반 규약 이외의 특별한 기능을 제공하며, 주변 코드가 이 기능에 기대어 동작한다면 새로운 클래스도 반드시 같은 기능을 제공해야 한다. 예컨대 첫 번째 선언의 주변 코드가 LinkedHashSet이 따르는 순서 정책을 가정하고 동작하는 상황에서 이를 HashSet으로 바꾸면 문제가 될 수 있다. HashSet은 반복자의 순회 순서를 보장하지 않기 때문이다.\n적합한 인터페이스가 없다면 당연히 클래스로 참조해야 한다. 1. String과 Integer 같은 값 클래스 (값 클래스를 여러 가지로 구현될 수 있다고 생각하고 설계하는 일은 거의 없다) 2. 클래스 기반으로 작성된 프레임워크가 제공하는 객체들 ex) OutputStream 등 java.io 패키지의 여러 클래스 3. 인터페이스에는 없는 특별한 메서드를 제공하는 클래스들 PriorityQueue 클래스는 Queue 인터페이스에 없는 comparator 메서드를 제공한다.\n하지만 적합한 인터페이스가 없다면 클래스의 계층구조 중 필요한 기능을 만족하는 가장 덜 구체적인(상위의) 클래스를 타입으로 사용하자.\n규칙 65 : 리플렉션 대신 인터페이스를 이용하라 java.lang.reflect의 핵심 리플렉션 기능을 이용하면 메모리에 적재(load)된 클래스의 정보를 가져오는 프로그램을 작성할 수 있다. Class 객체가 주어지면, 해당 객체가 나타내는 클래스의 생성자, 메서드, 필드 등을 나타내는 Constructor, Method Field 객체들을 가져올 수 있는데, 이 객체들을 사용하면 클래스의 멤버 이름이나 필드 자료형, 메서드 시그니처 등의 정보들을 얻어낼 수 있다.\n게다가 Constructor, Method Field 객체를 이용하면, 거기 연결되어 있는 실제 생성자, 메서드, 필드들을 반영적으로(reflectively) 조작할 수 있다. 객체를 생성할 수도 있고, 메서드를 호출할 수도 있으며, 필드에 접근할 수도 있다. Constructor, Method Field 객체의 메서드를 통하면 된다. 예를 들어, Method.invoke를 이용하면 어떤 클래스의 어떤 객체에 정의된 어떤 메서드라도 호출할 수있다(물론 일반적인 보안 제약사항은 준수해야 한다). 또한 리플렉션을 이용하면, 소스 코드가 컴파일 될 당시에는 존재하지도 않았던 클래스를 이용할 수 있다.\n하지만 이런 능력에는 대가가 따른다. 1. 컴파일 시점에 자료형을 검사함으로써 얻을 수 있는 이점들을 포기해야 한다(예외 검사 포함). 2. 리플렉션 기능을 이용하는 코드는 가독성이 떨어진다. 3. 성능이 낮다. 리플렉션을 통한 메서드 호출 성능은 일반적인 메서드 호출에 비해 훨씬 낮다. 얼마나 낮은지 정확히 말하기는 어렵다. 고려해야 할 요건들이 다양하기 때문. 필자의 컴퓨터에서 속도 차는 2배에서 50배 가량이었다.\n명심할 것은, 일반적인 프로그램은 프로그램 실행 중에 리플렉션을 통해 객체를 이용하려 하면 안된다는 것이다. 리플렉션이 필요한 복잡한 프로그램이 몇 가지 있긴 하다. 클래스 브라우저, 객체 검사도구, 코드 분석도구 등이 그 예다. 또한 리플렉션은 스텁 컴파일러가 없는 원격 프로시저 호출(remote procedure call, RPC) 시스템을 구현하는 데 적당하다.\n리플렉션을 아주 제한적으로만 사용하면 오버헤드는 피하면서도 리플렉션의 다양한 장점을 누릴 수 있다. 컴파일 시점에는 존재하지 않는 클래스를 이용해야 하는 프로그램 가운데 상당수는, 해당 클래스 객체를 참조하는 데 사용할 수 있는 인터페이스나 상위 클래스는 컴파일 시점에 이미 갖추고 있는 경우가 많다. 그럴 때는, 객체 생성은 리플렉션으로 하고 객체 참조는 인터페이스나 상위 클래스를 통하면 된다. 호출해야 하는 생성자가 아무런 인자도 받지 않을 때는 java.lang.reflect를 이용할 필요조차 없다. Class.newInstance 메서드를 호출하는 것으로 충분하다. 예를 들어 아래의 프로그램은 명령중에 주어진 첫 번째 인자와 같은 이름의 클래스를 이용해 Set\u0026lt;String\u0026gt; 객체를 만든다. 나머지 인자들은 전부 해당 집합에 집어넣고 출력한다.\npublic class Reflection { public static void main(String[] args) { Class\u0026lt;?\u0026gt; cl = null; try{ cl = Class.forName(args[0]); }catch (ClassNotFoundException e){ System.err.println(\u0026#34;class not found\u0026#34;); System.exit(1); } //해당 클래스의 객체 생성  Set\u0026lt;String\u0026gt; s = null; try { s = (Set\u0026lt;String\u0026gt;)cl.newInstance(); } catch (InstantiationException e) { System.err.println(\u0026#34;class not instantiable\u0026#34;); System.exit(1); } catch (IllegalAccessException e) { System.err.println(\u0026#34;class not accessible\u0026#34;); System.exit(1); } // 집합 이용  s.addAll(Arrays.asList(args).subList(1,args.length)); System.out.println(s); } } 첫 번째 인자가 무엇인지에 관계없이, 이 프로그램은 나머지 인자들에서 중복을 제거한 다음에 출력한다. 하지만 출력 순서는 첫 번째 인자로 어떤 클래스를 지정했느냐에 좌우된다. java.util.HashSet을 지정했다면 무작위 순서로 출력될 것이다. java.util.TreeSet을 지정했으면 알파벳 순서대로 출력될 것이다.\n이 프로그램은 하나 이상의 객체를 공격적으로 조작하여 해당 구현이 Set의 일반 규약을 준수하는지 검증하는 일반적 집합 검사 도구로 쉽게 변경될 수 있다. 마찬가지로, 일반적 집합 성능 분석 도구로도 쉽게 바꿀 수 있다. 사실 이 기법은 완벽한 ‘서비스 제공자 프레임워크(규칙1)’를 구현할 수 있을 정도로 강력하다. 대부분의 경우, 리플렉션 기능은 이 정도만 사용해도 충분할 것이다.\n리플렉션과 특별히 관련은 없으나, 이 예제가 System.exit를 사용하고 있다는 것은 주의할 필요가 있다. 이 메서드를 호출하는 것은 대체로 바람직하지 않다. 이 메서드는 전체 VM을 종료시켜버린다.\n규칙 66 : 네이티브 메서드는 신중하게 사용하라 자바의 네이티브 인터페이스는 C나 C++ 등의 네이티브 프로그래밍 언어로 작성된 네이티브 메서드를 호출하는 데 이용되는 기능이다. 전통적으로 네이티브 메서드는 세 가지 용도로 쓰였다. 1. 레지스트리나 파일 락 같은, 특정 플랫폼에 고유한 기능을 이용할 수 있다. 2. 이미 구현되어 있는 라이브러리를 이용할 수 있으며, 그 라이브러리를 통해 기존 데이터를 활용할 수 있다. 3. 성능이 중요한 부분의 처리를 네이티브 언어에 맡길 수 있다.\n그러나 네이티브 메서드를 통해 성능을 개선하는 것은 추천하고 싶지 않다. 1.3 이전의 초기 릴리스라면 필요할 때가 자주 있었을 것이나, 현재 JVM은 훨씬 빠르다. 일례로, 릴리스 1.1에 java.math가 추가될 당시 BigInteger는 C로 작성된 다정밀 연산 라이브러리를 이용하고 있었다. 그러나 릴리즈 1.3부터 BigInteger는 완전히 자바로만 구현되었고 신중하게 최적화되었다.\n네이티브 메서드에는 심각한 문제가 있다. 네이티브 언어는 안전하지 않으므로 네이티브 메서드를 이용하는 프로그램은 메모리 훼손 문제로부터 자유로울 수 없다. 게다가 네이티브 언어는 플랫폼 종속적이므로 이식성이 낮다. 또한 디버깅하기도 훨씬 어렵다. 굳이 써야 겠다면 성능 개선 용도로만 써라. 저수준 자원이나 기존 라이브러리를 이용하기 위해 네이티브 메서드를 사용해야 한다면, 네이티브 코드는 가능하면 줄이고 광범위한 테스트를 거치기 바란다. 네이티브 코드에 있는 아주 작은 버그라도 시스템 전체를 훼손 시킬 수 있다.\n### 규칙 67 : 신중하게 최적화하라 최적화는 좋을 때보다 나쁠 때가 더 많으며, 섣불리 시도하면 더더욱 나쁘다. 성능 때문에 구조적인 원칙을 희생하지 마라. 빠른 프로그램이 아닌, 좋은 프로그램을 만들려 노력하라.\n설계를 할 때는 성능을 제약할 가능성이 있는 결정들을 피하라. 그리고 API를 설계할 때 내리는 결정들이 성능에 어떤 영향을 끼칠지 생각하라. public 자료형을 변경 가능하게 만들면 쓸데없이 방어적 복사를 많이 해야 할 수 있다. 마찬가지로, 구성(composition) 기법이 적절한 public 클래스에 계승 기법을 적용하면 해당 클래스는 영원히 상위 클래스에 묶이는데, 그 결과로 하위 클래스의 성능에 인위적인 제약이 가해질 수도 있다. 또한 인터페이스가 적당할 API에 구현 자료형을 사용해 버리면 해당 API가 특정한 구현에 종속되므로 나중에 더 빠른 구현이 나와도 개선할 수 없게 된다.\n프로그램을 신중히 설계한 결과로 명료하고 간결하며 구조가 잘 짜인 구현이 나왔다면, 바로 그때가 최적화를 고민할 시점일 것이다. 물론 그 프로그램의 성능에 만족하지 못한다는 가정하에서. 그리고 최적화를 시도할 때마다, 전후 성능을 측정하고 비교하라. 측정 결과를 보고 놀라게 될지도 모른다. 최적화 결과로 성능이 개선되지 않거나 더 나빠지는 일이 많기 때문이다. 그 주된 이유는, 프로그램이 어디에 시간을 쓰고 있는지 추측하기 어렵다는 것이다. 전통적인 정적 컴파일 언어들에 비해, 프로그래머가 작성한 코드와 CPU가 실행하는 코드 사이의 ‘의미론적 차이’가 훨씬 크기 때문에 최적화 결과로 성능이 얼마나 좋아질지 안정적으로 예측하기 어렵다.\n규칙 68 : 일반적으로 통용되는 작명 관습을 따르라 패키지 이름은 마침표를 구분점으로 사용하는 계층적 이름이어야 한다. 패키지 이름을 구성하는 각각의 컴포넌트는 알파벳 소문자로 구성하고, 숫자는 거의 사용하지 않는다. 패키지명 컴포넌트는 짧아야 하며, 보통 여덟 문자 이하로 의미가 확실한 약어를 활용하면 좋다. 즉, utilities 대신 util 이라고 하면 좋다.\nenum이나 애노테이션 자료형 이름을 비롯, 클래스나 인터페이스 이름은 하나 이상의 단어로 구성된다. 각 단어의 첫 글자는 대문자다. 그리고 약어 사용은 피해야 한다.\n메서드와 필드 이름은 클래스나 인터페이스 이름과 동일한 철자 규칙을 따른다. 다만 첫 글자는 소문자로 한다.\n상수 필드의 이름은 하나 이상의 대문자 단어로 구성되며, 단어 사이에는 밑줄 기호(_)를 둔다. VALUES나 NEGATIVE_INFINITY가 그 예다. 상수 필드는 그 값을 변경 할 수 없는(immutable) static final 필드다.\n지역 변수 이름은 멤버 이름과 같은 철자 규칙을 따르는데, 약어가 허용된다는 것만 다르다.\n자료형 인자의 이름은 보통 하나의 대문자다. 가장 널리 쓰이는 것은 다섯 가지로, 임의 자료형인 경우에 T, 컬렉션의 요소 자료형인 경우에는 E, 맵의 키와 값에 대해서는 각각 K,V 그리고 예외인 경우에는 X를 사용한다. 임의 자료형이 연속되는 경우에는 T, U, V처럼 하거나 T1, T2, T3처럼 나열한다.\n특별히 주의해야 하는 메서드 이름도 있다. 객체의 자료형을 변환하는 메서드, 다른 자료형의 독립적 객체를 반환하는 메서드에는 보통 toType 형태의 이름을 붙인다. toString, toArray 같은 이름이 그 예다. 인자로 전달받은 객체와 다른 자료형의 뷰(view) 객체를 반환하는 메서드에는 asType 형태의 이름을 붙인다. asList 같은 이름이 그 예다. 호출 대상 객체와 동일한 기본 자료형 값을 반환하는 메서드에는 typeValue와 같은 형태의 이름을 붙인다. intValue가 그 예다. 정적 팩터리 메서드에는 valueOf, of, getInstance, newInstance, getType, newType 같은 이름을 붙인다.\n"
},
{
	"uri": "/toby_spring/%E1%84%89%E1%85%B3%E1%84%91%E1%85%B3%E1%84%85%E1%85%B5%E1%86%BC_%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%8C%E1%85%A6%E1%86%A8%E1%84%90%E1%85%B3_%E1%84%89%E1%85%B5%E1%84%8C%E1%85%A1%E1%86%A8%E1%84%92%E1%85%A1%E1%84%80%E1%85%B5/",
	"title": "스프링 프로젝트 시작하기",
	"tags": [],
	"description": "",
	"content": " 계층형 아키텍처 3계층 구조(프레젠테이션 계층, 서비스 계층, 데이터 엑세스 계층)는 스프링을 사용하는 엔터프라이즈 애플리케이션에서 가장 많이 사용되는 구조다. 스프링의 주요 모듈과 기술을 살펴보면 3계층 구조에 적합하도록 설계되어 있다는 사실만 봐도 알 수 있다. 단 3계층이라는 것은 논리적이고 개념적인 구분이지 꼭 오브젝트 단위로 딱 끊어져서 만들어지는 게 아님을 염두에 둬야 한다.\n서비스 계층을 굳이 도입하지 않아도 될 만큼 비즈니스 로직이 단순한 애플리케이션이라면 서비스 계층과 데이터 액세스 계층을 통합할 수도 있다. 반대로 프레젠테이션 계층에 서비스 계층을 통합하는 방법도 가능하다. 하지만 스프링에서는 그리 권장되지 않는다.\n스프링 AOP를 이용해 트랜잭션의 경계를 설정하기가 애매하기 때문이다. DAO가 트랜잭션 경계가 되는 경우에는 트랜잭션 전파 기법을 이용해 여러 개의 DAO 처리를 하나의 트랜잭션으로 조합해서 간단히 묶을 수 있다. 반면에 프레젠테이션 계층의 오브젝트는 트랜잭션 단위로 삼기에는 너무 크고 트랜잭션 전파을 통해 조합하기가 애매해다. 그래서 굳이 이런 방식을 써야 한다면 TransactionTemplate을 이용해 코드에 의한 트랜잭션 경계설정을 해야 하는데 이는 너무 번거롭다.\n따라서 3계층을 단순화해서 2계층으로 만든다면 서비스 계층과 데이터 엑세스 계층을 통합하는 편이 낫다. 물론 이때도 논리적으로는 서비스 계층과 데이터 액세스 계층의 경계를 분명하게 하는 게 좋다.\n"
},
{
	"uri": "/effective_java/%E1%84%8B%E1%85%A8%E1%84%8B%E1%85%AC/",
	"title": "예외",
	"tags": [],
	"description": "",
	"content": " 규칙69 : 예외는 예외적 상황에만 사용하라 // 예외를 끔찍하게 남용한 사례. 이러면 곤란하다. try { int i = 0; while(true) range[i++].climb(); }catch(ArrayIndexOutOfBoundsException e){ } range 배열의 원소를 순회하는데 무한 루프를 돌다가 배열 범위 밖에 있는 첫 번째 요소를 참조하는 순간에 발생하는 ArrayIndexOutOfBoundsException 예외를 감지하고 무시하는 과정을 통해 순회를 종료시킨다. 이 코드를 다음과 같이 표준적인 관용구대로 작성했다면 모든 자바 프로그래머가 곧바로 이해했을 것이다.\nfor (Mountain m : range) { m.climb(); } 그런데 예외를 써서 루프를 종료한 이유는 뭘까? 잘못된 추론을 근거로 성능을 높여보려 한 것이다. JVM은 배열에 접근할 때마다 경계를 넘지 않는지 검사하는데, 일반적인 반복문도 배열 경계에 도달하면 종료한다. 따라서 이 검사를 반복문에도 명시하면 같은 일이 중복되므로 하나를 생략한 것이다. 하지만 세 가지 면에서 잘못된 추론이다.\n 예외는 예외 상황에 쓸 용도로 설계되었으므로 JVM 구현자 입장에서는 명확한 검사만큼 빠르게 만들어야 할 동기가 약하다(최적화에 별로 신경 쓰지 않았을 가능성이 크다). 코드를 try-catch 블록 안에 넣으면 JVM이 적용할 수 있는 최적화가 제한된다. 배열을 순회하는 표준 관용구는 앞서 걱정한 중복 검사를 수행하지 않는다. JVM이 알아서 최적화해 없애준다.  실상은 예외를 사용한 쪽이 표준 관용구보다 훨씬 느리다. 예외를 사용한 반복문의 해악은 코드를 헷갈리게 하고 성능을 떨어뜨리는데서 끝나지 않는다. 심지어 제대로 동작하지 않을 수도 있다. 반복문 안에 버그가 숨어 있다면 흐름 제어에 쓰인 예외가 이 버그를 숨겨 디버깅을 훨씬 어렵게 할 것이다. 예를 들어 위의 코드 climb 메서드에서 내부적으로 다른 배열을 사용하다가 ArrayIndexOutOfBoundsException을 일으켰다고 해보자. 표준 관용구였다면 이 버그는 예외를 잡지 않고 (stack trace 정보를 남기고) 해당 스레드를 즉각 종료시킬 것이다. 반면 예외를 사용한 반복문은 버그 때문에 발생한 엉뚱한 예외를 정상적인 반복문 종료 상황으로 오해하고 넘어간다.\n예외는 예외적인 상황에만 사용해야지, 평상시 제어 흐름에 이용해서는 안된다.\n이 원칙은 API 설계에도 적용된다. 잘 설계된 API라면 클라이언트가 정상적인 제어 흐름에서 예외를 사용할 일이 없게 해야 한다. 특정 상태에서만 호출할 수 있는 \u0026lsquo;상태 의존적\u0026rsquo; 메서드를 제공하는 클래스는 \u0026lsquo;상태 검사\u0026rsquo; 메서드도 함께 제공해야 한다. 예를 들어 Iterator 인터페이스에는 상태 의존적 메서드 next가 있고, 상태 검사 메서드 hasNext가 있다. Iterator에 hasNext 메서드가 없었다면 클라이언트는 어쩔 수 없이 아래와 같은 코드를 만들어야 했을 것이다.\n// 컬렉션을 이런 식으로 순회하지 말 것! try { Iterator\u0026lt;Foo\u0026gt; i = collection.iterator(); while(true) { Foo foo = i.next(); ... } } catch (NoSuchElementException e) { } 별도의 상태 검사 메서드 덕분에 다음과 같은 표준 for 관용구를 사용할 수 있다(for-each도 내부적으로 hasNext를 사용한다).\nfor (Iterator\u0026lt;Foo\u0026gt; i = collection.iterator(); i.hasNext();) { Foo foo = i.next(); ... } 상태 검사 메서드 대신 사용할 수 있는 선택지도 있다. 올바르지 않은 상태일 때 empty optional 혹은 null 같은 특수한 값을 반환하는 방법이다. 상태 검사 메서드, optional, 특정 값 중 하나를 선택하는 지침을 몇 개 소개하겠다.\n 외부 동기화 없이 여러 스레드가 동시에 접근할 수 있거나 외부 요인으로 상태가 변할 수 있다면 optional이나 특정 값을 사용한다. 상태 검사 메서드와 상태 의존적 메서드 호출 사이에 객체의 상태가 변할 수 있기 때문이다. 성능이 중요한 상황에서 상태 검사 메서드가 상태 의존적 메서드의 작업 일부를 중복 수행한다면 optional이나 특정 값을 선택한다. 다른 모든 경우엔 상태 검사 메서드 방식이 조금 더 낫다고 할 수 있다. 가독성이 살짝 더 좋고, 잘못 사용했을 때 발견하기가 쉽다. 상태 검사 메서드 호출을 깜빡 잊었다면 상태 의존적 메서드가 예외를 던져 버그를 확실히 드러낼 것이다. 반면 특정 값은 검사하지 않고 지나쳐도 발견하기가 어렵다(optional에는 해당하지 않는 문제다).  규칙70 : 복구 가능 상태에는 점검지정 예외를 사용하고, 프로그래밍 오류에는 실행시점 예외를 이용하라 자바는 세 가지 종류의 ‘throwable’을 제공한다. 점검지정 에외(checked exception), 실행시점 예외(runtime exception), 그리고 오류(error)다. 점검지정 예외를 사용할 것인지 아니면 무점검 예외를 사용할 것인지에 대한 가장 기본적인 규칙은, 호출자(caller) 측에서 복구할 것으로 여겨지는 상황에 대해서는 점검지정 예외를 이용해야 한다는 것이다. 점검지정 예외를 던지는 메서드를 호출한 클라이언트는 해당 예외를 catch 절 안에서 처리하든지, 아니면 계속 밖으로 던져지도록 놔두든지 해야 한다. 따라서 메서드에 선언된 점검지정 예외는 메서드를 호출하면 해당 예외와 관계된 상황이 발생할 수 있음을 API 사용자에게 알리는 구실을 한다.\n무점검(unchecked) ‘throwable’에는 실행시점 에외와 오류 두 가지가 있으며, 동작 방식은 같다. 프로그램이 무점검 예외나 오류를 던진다는 것은 복구가 불가능한 상황에 직면했다는 뜻으로, 더 진행해 봐야 득보다 실이 더 크다는 뜻이다.\n프로그래밍 오류를 표현할 때는 실행시점 예외를 사용하라 대부분의 실시점 예외는 선행조건 위반을 나타낸다. 즉, 클라이언트가 API 명세에 기술된 규약을 지키지 않았다는 뜻이다. 요약하자면 복구 가능한 상태에는 점검지정 예외를 사용하고, 프로그래밍 오류를 나타내고 싶을 때는 실행시점 예외를 사용하라.\n규칙71 : 불필요한 점검지정 예외 사용은 피하라 점검지정 예외는 프로그래머로 하여금 예외적인 상황을 처리하도록 강제함으로써 안정성을 높인다. 하지만 너무 남발하면 사용하기 불편한 API가 될 수 있다는 뜻이기도 하다.\nAPI를 제대로 이용해도 예외 상황이 벌어지는 것을 막을 수 없을 때, 그리고 API 사용자가 예외 상황에 대한 조치를 취할 수 있을 때는, 그 정도의 부담은 참을 수 있을 것이다. 하지만 이 조건 가운데 어디에도 해당되지 않을 때는 무점검 예외를 이용하는 것이 좋다.\n} catch (TheCheckedException e) { throw new AssertionError(); // 이런 에러가 생길 리 없어요 ! } 이렇게 하는 것이 최선인가? 아래 코드는 어떤가? } catch (TheCheckedException e) { e.printStrackTrace(); // 그래요. 졌습니다. \tSystem.exit(1); } API 사용자가 이보다 좋은 코드를 만들 수 없다면, 무점검 예외가 적당하다. 이 테스트를 통과하지 못하는 예외의 사례로는 CloneNotSupportedException이 있다. 이 예외는 Cloneable 인터페이스를 구현하지 않은 객체에 Object.clone 메서드를 호출하면 발생하는 예외다. 실제로는, 이 예외를 처리하는 catch 블록이 실행되었다는 것은, 확증이 실패했다는 것이나 마찬가지다. 그런 특성에 어울리지 않게 점검지정 예외로 선언되어 있다는 것이 문제인데, 프로그래머 입장에서는 반갑지 않은 일이다. 프로그램만 복잡해지기 때문이다.\n메서드가 던지는 점검지정 예외가 하나뿐일 때 프로그래머가 느끼게 되는 부담은 큰 편이다. 그 하나의 catch 블록 때문에 try 블록 안에서 메서드를 호출해야 하는 것이다. 이런 상황에 처하면, 점검지정 예외를 없앨 방법이 없을지 고민해보는 것이 좋다. 점검지정 예외를 무점검 예외로 바꾸는 한 가지 방법은, 예외를 던지는 메서드를 둘로 나눠서 첫 번째 메서드가 boolean 값을 반환하도록 만드는 것이다.\n// 예외를 점검하도록 지정된 메서드 호출 try { obj.action(args); } catch(TheCheckedException e){ // 예외적 상황 처리 \t… } 앞서 설명한 대로 메서드를 리팩토링하면 이 코드는 아래와 같이 바뀐다.\n// 상태 검사 메서드를 거쳐서 무점검 예외 메서드 호출 if (obj.actionPermitted(args)) { obj.action(args); } else { // 예외적 상황 처리 \t... } 메서드 호출 순서가 이전 방식에 비해 더 깔끔하다고 말하기는 어려우나, 더 유연한 API가 되었음은 사실이다. action 호출이 항상 성공하리라고 확신하거나, 설사 실패해서 스레드가 죽어도 상관없다면 위의 코드는 obj.action(args) 한 줄로 줄일 수 있다. 하지만 그 결과로 만들어지는 API 규칙 57에서 설명한 상태 검사 메서드와 본질적으로 같기 때문에 동일한 문제를 갖는다. 외부적인 동기화 수단 없이 병렬적으로 이용될 가능성이 있는 객체거나, 외부에서 그 상태를 바꿀 가능성이 있는 객체라면 방금 설명한 리팩토링 기법은 적용할 수 없다. actionPermitted를 호출하고 action을 미처 호출하기 전에 객체의 상태가 바뀔 수도 있기 때문이다.\n규칙72 : 표준 예외를 사용하라 가장 널리 재사용 되는 예외는 IllegalArgumentException이다. 잘못된 값을 인자로 전달했을 때 일반적으로 발생하는 예외다. 널리 쓰이는 또 다른 예외로는 IllegalStateException이 있다. 현재 객체 상태로는 호출 할 수 없는 메서드를 호출했을 때 일반적으로 발생하는 예외다. 예를 들어 아직 적절히 초기화되지 않은 객체를 사용하려고 시도하면 이 예외가 발생해야 할 것이다.\n모든 잘못된 메서드 호출은 결국 잘못된 인자나 잘못된 상태에 관계된 것이라 이해할 수 있다. 하지만 특정 부류의 잘못된 인자나 상태에 표준적으로 이용되는 예외들도 있다. null 인자를 받으면 안되는 메서드에 null을 전달한 경우, 관습적으로는 IllegalArgumentException 대신 NullPointerException이 발생해야 한다. 이와 비슷하게, 어떤 sequence의 첨자를 나타내는 인자에 참조 가능 범위를 벗어난 값이 전달되었을 때는 IndexOutOfBoundsException이 발생해야 한다.\n일반적 용도의 예외 가운데 알아둘 만한 것으로는 ConcurrentModificationException도 있다. 하나의 스레드만 사용하도록 설계된 객체나, 외부적인 동기화 수단과 함께 이용되어야 하는 객체를 여러 스레드가 동시에 변경하려 하는 경우에 발생해야 하는 예외다. 또 UnsupportedOperationException도 알아두면 좋다. 어떤 객체가 호출된 메서드를 지원하지 않을 때 발생하는 예외다. 다른 예외들에 비해 사용 빈도가 아주 낮은데, 대부분의 객체는 자기가 구현하는 메서드를 지원하는 것이 보통이기 때문이다. 이 예외는 인터페이스에 정의된 선택적 메서드 가운데 하나 이상을 구현하지 않을 경우에 사용한다.\n재사용 할 수 있는 예외라 생각된다면, 사용하도록 하라. 하지만 예외를 발생시키는 조건이 해당 예외의 문서에 기술된 것과 일치해야 한다. 마지막으로 어떤 예외를 재사용하면 좋을 지 결정하는 것은 엄밀한 과학적 절차를 따르지 않는다. 위의 표에 나열한 용례조차도 상호 배제적이지 않다.\n규칙73 : 추상화 수준에 맞는 예외를 던져라 상위 계층에서는 하위 계층에서 발생하는 예외를 반드시 받아서 상위 계층 추상화 수준에 맞는 예외로 바꿔서 던져야 한다. 이 숙어를 ‘예외 변환’이라 부른다(exception translation 토비에서는 예외 전환).\n// 예외 변환 try { // 낮은 수준의 추상화 계층 이용 \t... } catch (LowerLevelException e) { throw new HigherLevelException(…); } 토비의 스프링 exception translation 예제\npublic void add() throws DuplicateUserIdException { try { // JDBC를 이용해 user 정보를 DB에 추가하는 코드 또는 \t// 그런 기능이 있는 다른 SQLException을 던지는 메서르르 호출하는 코드 \t}catch (SQLException e){ if(e.getErrorCode() == MysqlErrorNumbers.ER_DUP_ENTRY) throw new DuplicateUserIdException(e); } } 위의 코드를 보면 예외 연결(exception chaining)도 포함되어 있다. 하위 계층에서 발생한 예제 정보가 상위 계층 예외를 발생시킨 문제를 디버깅하는 데 유용할 때 사용한다.\n// 예외 연결 try { // 낮은 수준의 추상화 계층 이용 \t... } catch (LowerLevelException cause) { throw new HigherLevelException(cause); } 상위 계층 예외 HigherLevelException의 생성자는 문제의 ‘원인’을 예외 연결을 지원하는 상위 클래스 생성자에 넘긴다. 해당 인자는 결국 Throwable의 예외 연결 지원 생성자에 전달된다.\n// 예외 연결 지원 생성자를 갖춘 예외 class HigherLevelException extends Exception { HigherLevelException (Throwable cause){ super(cause); } } 대부분의 표준 예외들은 예외 연결 지원 생성자를 구비하고 있다.\n예외 처리의 제일 좋은 방법은 하위 계층에서 예외가 생기지 않도록 하는 것이다. 하위 계층 메서드에서 예외가 발생하는 것을 막을 수 없다면 그 다음으로 좋은 방법은 하위 계층에서 생기는 문제를 상위 계층 메서드 호출자로부터 격리시키는 것이다. 하위 계층에서 발생하는 예외를 어떤 식으로든 처리해 버리는 것이다. 그래야 하는 상황이라면 java.util.logging 같은 기능을 활용해서 로그를 남기면 좋을 것이다. 클라이언트나 최종 사용자에게는 문제를 감추지만, 관리자는 나중에 분석할 수 있도록 하는 것이다.\n규칙74 : 메서드에서 던져지는 모든 예외에 대해 문서를 남겨라 점검지정 예외는 독립적으로 선언하고, 해당 예외가 발생하는 상황은 Javadoc @throws 태그를 사용해서 정확하게 밝혀라. 메서드가 던질 가능성이 있는 모든 예외를 문서로 남겨라. 점검지정 예외뿐만 아니라, 무점검 예외에도 문서를 만들라(무점검 예외는 보통 프로그래밍 오류를 나타낸다). 점검지정 예외는 메서드의 throws 절에 나열하고, 무점검 예외는 throws 절에는 적지마라.\n규칙75 : 어떤 오류인지를 드러내는 정보를 상세한 메세지에 담으라 쉽게 재현할 수 없는 오류라면, stack trace 이상의 정보를 얻기 어렵거나 불가능하다. 그래서 예외의 상세 메세지에는 원인 분석에 이용될 오류 정보가 포착되어 있어야 한다. 오류 정보를 포착해 내기 위해서는, 오류의 상세 메세지에 “예외에 관계된” 모든 인자와 필드의 값을 포함시켜야 한다.\n오류를 적절히 포착하는 정보를 상세 메세지에 담는 한 가지 방법은, 상세한 정보를 요구하는 생성자를 만드는 것이다.\npublic IndexOutOfBoundsException(int lowerBound, int upperBound, int index) { // 오류를 포착하는 상세 메세지 생성 \tsupper(lowerBound, upperBound, index); //프로그램에서 이용할 수 있도록 오류 정보 보관 \tthis.lowerBound = lowerBound; this.upperBound = upperBound; this.index = index; } 그리고 예외 객체에 오류 포착 정보를 제공하는 접근자 메서드를 두어도 좋다.\n규칙76 : 실패 원자성 달성을 위해 노력하라 일반적으로 이야기해서 호출이 정상적으로 처리되지 못한 객체의 상태는, 메서드 호출 전 상태와 동일해야 한다. 이 속성을 만족하는 메서드는 실패 원자성을 갖추었다고 한다.\n실패 원자성을 달성하는 방법은 여러 가지다. 가장 간단한 방법은 변경 불가능 객체로 설계하는 것이다. 변경 불가능한 객체의 경우, 실패 원자성은 덤이다. 변경 가능한 객체의 경우에는 실제 연산을 수행하기 전에 인자 유효성(validity)을 검사하는 것이 가장 보편적인 방법이다. 객체를 변경하는 도중에 예외가 발생하는 것을 막아준다.\npublic Object pop() { if(size == 0) throw new EmptyStackException(); Object result = elements[--size]; elements[size] = null; return result; } 위 코드를 보면, 빈 스택에서 뭔가를 뽑아내려 하면, 굳이 첫 두줄이 없어도 예외가 나긴 한다. 하지만 첫 두 줄이 없으면 size 필드의 일관성이 깨져서 음수로 바뀌게 된다. 그러니 이 메서드를 다시 호출하면 계속 문제가 생길 것이다. 게다가, 첫 두 줄이 없을 때 발생하는 예외는 해당 클래스에는 어울리지 않는다.\n이와 밀접한 관련이 있는 또 다른 접근법 하나는, 실패할 가능성이 있는 코드를 전부 객체 상태를 바꾸는 코드 앞에 배치하는 것이다. 예를 들어 TreeMap에 추가할 원소는 해당 TreeMap의 순서대로 비교가 가능한 자료형이어야 한다. 엉뚱한 자료형의 원소를 넣으려고 하면, 트리를 실제로 변경하기 전에 트리 안에서 해당 원소를 찾다가 ClassCastException이 발생할 것이다.\n사용 빈도가 훨씬 낮은 세 번째 접근법은 연산 수행 도중에 발생하는 오류를 가로채는 복구 코드를 작성하는 것이다. 이 복구 코드는 연산이 시작되기 이전 상태로 객체를 되돌린다(roll back)\n마지막 접근법은, 객체의 임시 복사본상에서 필요한 연산을 수행하고, 연산이 끝난 다음에 임시 복사본의 내용으로 객체 상태를 바꾸는 것이다. 예를 들어 Collections.sort는 원소들을 참조하는 비용을 줄이기 위해, 인자로 주어진 리스트를 정렬하기 전에 배열에 복사한다. 성능 문제 때문에 내린 조치인데, 그 덕에 정렬이 실패해도 원래 리스트에는 아무런 손상이 가지 않는다.\n실패 원자성은 일반적으로 권장되는 덕목이지만 언제나 달성할 수 있는 것은 아니다. 명심할 것은, 예외와는 달리 오류(error)는 복구가 불가능하며, 오류를 던지는 경우에는 실패 원자성을 보존하려 애쓸 필요가 없다는 점이다.\n규칙77 : 예외를 무시하지 마라 // catch 블록을 비워 놓으면 예외는 무시된다 - 심히 의심스런 코드! try { ... }catch(SomeException e){ } 빈 catch 블록은 예외를 선언한 목적, 그러니까 예외적 상황을 반드시 처리하도록 강제한다는 목적에 배치된다.\n예외를 무시해도 괜찮은 경우를 하나 예로 들자면, FileInputStream을 닫는 경우일 것이다. 파일 상태를 바꾸지 않았고 그래서 복구 작업을 할 필요도 없으며, 필요한 정보는 파일에서 모두 읽었으니 진행 중인 연산을 중단할 이유도 없다. 하지만 그렇더라도 로그는 남겨두는 것이 좋다. 그래야 예외가 자주 발생하는 것을 알았을 때 그 원인을 분석해 볼 수 있기 때문이다.\n"
},
{
	"uri": "/toby_spring/ioc_%E1%84%8F%E1%85%A5%E1%86%AB%E1%84%90%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%82%E1%85%A5%E1%84%8B%E1%85%AA_di/",
	"title": "IoC 컨테이너와 DI",
	"tags": [],
	"description": "",
	"content": " 핵심 : Singleton 빈이 주인 스프링에서는 원칙적으로 싱글톤 보다 작은 lifecycle을 가지는 빈을 DI하는 것이 의미가 없고 DL을 사용해야 한다는 것이 DI의 원칙이자 자바언어의 기본 sematics이다.\n기본적으로 스프링의 빈은 싱글톤으로 만들어진다. 애플리케이션 컨텍스트마다 빈의 오브젝트는 한 개만 만들어진다는 뜻이다. 사용자의 요청이 있을 때마다 매번 애플리케이션 로직을 담은 오브젝트를 새로 만드는 건 비효율적이기 때문이다. 하나의 빈 오브젝트에 동시에 여러 스레드가 접근하기 때문에 상태 값을 인스턴스 변수에 저장해두고 사용할 수 없다. 따라서 싱글톤의 필드에는 의존관계에 있는 빈에 대한 레퍼런스나 읽기전용 값만 저장해두고 오브젝트의 변하는 상태를 저장하는 인스턴스 변수는 두지 않는다.\n그런데 때로는 빈을 싱글톤이 아닌 다른 방법으로 만들어 사용해야 할 때가 있다. 빈 당 하나의 오브젝트만을 만드는 싱글톤 대신, 하나의 빈 설정으로 여러 개의 오브젝트를 만들어서 사용하는 경우다.\ncf) scope : 존재할 수 있는 범위를 가리키는 말이다. 빈의 스코프는 빈 오브젝트가 만들어져 존재할 수 있는 범위다. 빈 오브젝트의 생명주기는 스프링 컨테이너가 관리하기 때문에 대부분 정해진 범위(스코프)의 끝까지 존재한다. 싱글톤 스코프는 컨테이너 스코프라고 하기도 한다. 단일 컨테이너 구조에서는 컨테이너가 존재하는 범위와 싱글톤이 존재하는 범위가 일치하기 때문이다. 요청(request) 스코프는 하나의 요청이 끝날 때까지만 존재한다.\n싱글톤 스코프는 컨텍스트당 한 개의 빈 오브젝트만 만들어지게 한다. 따라서 하나의 빈을 여러 개의 빈에서 DI 하더라도 매번 동일한 오브젝트가 주입된다. DI 설정으로 자동주입하는 것 말고 컨테이너에 getBean() 메서드를 사용해 DL 하더라도 매번 같은 오브젝트가 리턴됨이 보장된다.\n프로토타입 스코프 프로토타입 스코프는 컨테이너에게 빈을 요청할 때마다 매번 새로운 오브젝트를 생성해준다. DI, DL 상관없이 매번 새로운 오브젝트가 만들어진다.\n프로토타입 빈의 생명주기와 종속성 IoC의 기본 개념은 애플리케이션을 구성하는 핵심 오브젝트를 코드가 아니라 컨테이너가 관리한다는 것이다. 그래서 스프링이 관리하는 오브젝트인 빈은 그 생성과 다른 빈에 대한 의존관계 주입, 초기화, DI와 DL을 통한 사용, 제거에 이르기까지 모든 오브젝트의 생명주기를 컨테이너가 관리한다. 빈에 대한 정보와 오브젝트에 대한 레퍼런스는 컨테이너가 계속 갖고 있고 필요할 때마다 요청해서 빈 오브젝트를 얻을 수 있다.\n그런데 프로토타입 빈은 독특하게 이 IoC의 기본 원칙을 따르지 않는다. 프로토타입 스코프를 갖는 빈은 요청이 있을 때마다 컨테이너가 생성하고 초기화하고 DI까지 해주기도 하지만 일단 빈을 제공하고 나면 컨테이너는 더 이상 빈 오브젝트를 관리하지 않는다. 따라서 프로토타입 빈 오브젝트는 한번 DL이나 DI를 통해 컨테이너 밖으로 전달 되면 그 후부터는 더 이상 스프링이 관리하는 빈이 아니게 된다. 이때부터는 DL을 통해서 오브젝트를 가져간 코드나 DI로 주입받은 다른 빈이 사실상 컨테이너가 제공한 빈 오브젝트를 관리하게 된다. 한번 만들어진 프로토타입 빈 오브젝트는 다시 컨테이너를 통해 가져올 방법이 없고, 빈이 제거되기 전에 빈이 사용한 리소스를 정리하기 위해 호출하는 메서드도 이용할 수 없다.\n프로토타입 빈은 컨테이너가 초기 생성 시에만 관여하고 DI 한 후에는 더 이상 신경 쓰지 않기 때문에 빈 오브젝트의 관리는 전적으로 DI 받은 오브젝트에 달려 있다. 그래서 프로토타입 빈은 이 빈을 주입받은 오브젝트에 종속적일 수밖에 없다. 프로토타입 빈을 주입받은 빈이 싱글톤이라면, 이 빈에 주입된 프로토타입 빈도 역시 싱글톤 생명 주기를 따라서 컨테이너가 종료될 때까지 유지될 것이다. 프로토타입 빈을 DI 받은 빈의 스코프가 더 작아서 일찍 제거돼야 한다면, DI 된 프로토타입 빈도 함께 제거될 것이다. 만약 DL 방식으로 직접 컨테이너에 getBean() 메서드를 통해서 프로토타입 빈을 요청했다면, 그 요청한 코드가 유지시켜주는 만큼 빈 오브젝트가 존재할 것이다. 메서드 안에서 사용하고 따로 저장해두지 않는다면, 메서드가 끝나면서 프로토타입 빈 오브젝트도 함께 제거된다.\n프로토타입 빈의 용도 사용자의 요청에 따라 매번 독립적인 오브젝트를 만들어야 하는데, 매번 새롭게 만들어지는 오브젝트가 컨테이너 내의 빈을 사용해야 하는 경우가 있다. DI가 필요한 오브젝트라는 뜻이다. 오브젝트에 DI를 적용하려면 컨테이너가 오브젝트를 만들게 해야 한다. 바로 이런 경우에 프로토타입 빈이 유용하다. 프로토타입 빈은 오브젝트의 생성과 DI 작업까지 마친 후에 컨테이너가 돌려준다.\n콜센터에서 고객의 A/S 신청을 받아서 접수하는 기능을 만든다고 생각해보자. 이때 등록 폼에서 고객번호를 입력받는다. 이렇게 입력받은 고객번호는 다른 입력 필드와 함께 폼 정보를 담는 오브젝트에 담겨서 서비스 계층으로 전달되어 A/S 신청 접수 기능에서 사용될 것이다.\nA/S 신청 폼 클래스 public class ServiceRequest { String customerNo; String productNo; String description; } ServiceRequest의 오브젝트는 매번 신청을 받을 때마다 새롭게 만들어지고, 폼의 정보를 담아서 서비스 계층으로 전달될 것이다. 웹 요청을 받아 처리하는 웹 컨트롤러에서는 아래와 같이 매번 new 연산자로 ServiceRequest 클래스의 오브젝트를 생성하고, 폼 요청 정보를 넣은 뒤 서비스 계층으로 전달해줘야 한다.\nServiceRequest 웹 컨트롤러 public void serviceRequestFormSubmit (HttpServletRequest request) { ServiceRequest serviceRequest = new ServiceRequest(); // 매 요청마다 새로운 객체를 생성한다.  serviceRequest.setCustomerNo(request.getParameter(\u0026#34;custno\u0026#34;)); ... this.serviceRequestService.addNewServiceRequest(serviceRequest); ... } 이 웹 컨트롤러는 매우 단순하고 원시적이다. 스프링의 웹 프레임워크를 사용하면 훨씬 세련되고 깔끔하게 만들 수 있지만, 일단은 어떤 식으로 동작하는지 설명하기 위한 코드라고 생각하고 보자. 일단 여기까지는 아무런 문제가 없다. 폼으로부터 요청이 있을 때마다 새로운 오브젝트를 만들고 폼의 필드에 입력된 고객번호를 저장하는 것은 자연스러운 일이다.\n이번엔 서비스 계층의 구현을 살펴보자. 콜 센터의 업무를 담당하는 서비스 오브젝트에서는 새로운 A/S 요청이 접수되면 접수된 내용을 DB에 저장하고 신청한 고객에게 이메일로 접수 안내 메일을 보내주도록 되어 있다. 폼에서는 단지 문자열로 된 고객번호를 받았을 뿐이지만 CustomerDao에게 요청하면 고객정보를 모두 가져올 수 있다. CustomerDao에서 가져온 고객정보는 Customer 오브젝트에 담겨 있을 것이고, 이를 이용해 이메일을 발송할 수도 있다. 서비스 계층의 ServiceRequestService 클래스에는 아래와 같은 코드가 만들어질 것이다.\nServiceRequest 서비스 계층 public void addNewServiceRequest(ServiceRequest serviceRequest) { Customer customer = this.customerDao.findCustomerByNo(serviceRequest.getCustomberNo()); ... this.serviceRequestDao.add(serviceRequest, customer); this.emailService.sendEmail(customer.getEmail(), \u0026#34;A/S 접수가 정상적으로 처리되었습니다.\u0026#34;); } 이런 코드가 자연스럽게 느껴질지도 모르겠다. ServiceRequest를 단지 폼의 정보를 전달해주는 DTO와 같은 데이터 저장용 오브젝트로 취급하고, 그 정보를 이용해 실제 비지니스 로직을 처리할 때 필요한 정보는 다시 서비스 계층의 오브젝트가 직접 찾아오게 만드는 것이다. 위 그림은 ServiceRequest가 폼의 정보를 담고 사용되는 구조를 나타낸다. 코드에서 new로 생성하는 ServiceRequest를 제외한 나머지 오브젝트는 스프링이 관리하는 싱글톤 빈이다. 이 방식의 장점은 처음 설계하고 만들기는 편하다는 것이다. 웹 페이지의 등록 폼에서 어떤 식으로 사용자 정보가 입력될지를 미리 정해두고, 그 입력 방식에 따라서 컨트롤러와 서비스 오브젝트까지 만들면 된다. 서비스 오브젝트는 폼에서 문자열로 입력된 고객번호가 ServiceRequest 오브젝트에 담겨 전달된다는 사실을 미리 알고 있다.\n문제는 폼의 고객정보 입력 방법이 모든 계층의 코드와 강하게 결합되어 있다는 점이다. 만약 고객정보를 텍스트로 입력받는 대신 AJAX를 써서 이름을 이용한 자동완성 기능을 이용한 후에 Customer 테이블의 id를 폼에서 전달하는 식으로 바뀌면 어떻게 될까? ServiceRequest의 필드와 이를 처리하는 컨트롤러는 물론이고, A/S 서비스 신청을 처리하는 서비스 오브젝트인 ServiceRequestService의 코드도 다음과 같이 id 값을 이용해 Customer 오브젝트를 가져오는 방법으로 수정돼야 할 것이다.\nCustomer customer = this.customerDao.getCustomer(serviceRequest.getCustomerId()); 이는 전형적인 데이터 중심의 아키텍처가 만들어내는 구조다. 비록 ServiceRequest 오브젝트에 폼 정보가 담겨 있긴 하지만, 도메인 모델을 반영하고 있다고 보기 힘들다. 모델 관점으로 보자면 서비스 요청 클래스인 ServiceRequest는 Customer라는 고객 클래스와 연결되어 있어야지, 폼에서 어떻게 입력받는지에 따라 달라지는 customerNo나 customerId 같은 값에 의존하고 있으면 안된다.\n그렇다면 이 구조를 좀 더 오브젝트 중심의 구조로 만들고, 좀 더 객체지향적으로 바꾸려면 어떻게 해야 할까? 일단 웹 컨트롤러는 같은 웹 프레젠테이션 계층의 뷰에서 만들어주는 폼과 밀접하게 연결되어 있는 것이 자연스럽고 별문제가 되지 않는다. 대신 서비스 계층의 ServiceRequestService는 ServiceRequest 오브젝트에 담긴 서비스 요청 내역과 함께 서비스를 신청한 고객정보를 Customer 오브젝트로 전달받아야 한다. 그래야만 프레젠테이션 계층의 입력 방식에 따라서 비지니스 로직을 담당하는 코드가 휘둘리지 않고 독립적으로 존재할 수 있다. 따라서 ServiceRequest를 다음과 같이 변경해야 한다.\npublic class ServiceRequest { Customer customer; String productNo; String description; ... } ServiceRequest는 customerNo 값 대신 Customer 오브젝트 자체를 참조하게 한다. ServiceRequest가 좀 더 도메인 모델에 가깝게 만들어졌으니, 서비스 계층의 코드는 다음과 같이 바꿀 수 있다.\n수정된 서비스 계층 코드 public void addNewServiceRequest(ServiceRequest serviceRequest) { this.serviceRequestDao.add(serviceRequest); this.emailService.sendEmail(serviceRequest.getCustomer().getEmail(), \u0026#34;A/S 접수가 정상적으로 처리되었습니다.\u0026#34;); } 폼에서 입력받은 고객번호로 고객을 찾아오는 번거로운 작업을 생략할 수 있게 됐다. serviceRequestDao에도 ServiceRequest 타입의 오브젝트만 전달하면 된다. DAO가 A/S 신청정보를 저장할 때 필요한 id와 같은 고객정보는 ServiceRequest의 customer 필드를 통해 가져올 수 있다. DAO는 물론이고 서비스 오브젝트도 폼의 입력방식에서 완전히 자유로워졌다.\n그러나 아직 해결해야 할 가장 큰 문제가 남아 있다. 폼에서는 문자열로 된 고객번호를 입력받을 텐데 그것을 어떻게 Customer 오브젝트로 바꿔서 ServiceRequest에 넣어 줄 수 있을까? 답은 간단하다. customerNo를 가지고 CustomerDao에 요청해서 Customer 오브젝트를 찾아오면 된다. 이전에는 그것을 ServiceRequestService의 메서드에서 처리했는데, 이제는 어디서 해야 할까? 일단 생각해볼 수 있는 건, 웹 컨트롤러에서 CustomerDao를 사용해 Customer를 찾은 뒤에 이를 ServiceRequest에 전달하는 것이다. 이것도 그리 나쁜 방법은 아니다. 하지만 그보다 나은 방법은 ServiceRequest 자신이 처리하는 것이다.\n만약 ServiceRequest가 CustomerDao에 접근할 수 있다면 어떨까? 그렇다면 다음과 같이 ServiceRequest 코드를 만들 수 있다.\nCustomer를 검색할 수 있는 기능을 가진 ServiceRequest public class ServiceRequest { Customer customer; ... @Autowired CustomerDao customerDao; public void setCustomerByCustomerNo(String customerNo) { this.customer = customerDao.findCustomerByNo(customerNo); } } ServiceRequest가 CustomerDao를 DI 받아서 사용할 수 있다면 문제는 간단해진다. 폼에서 고객번호를 입력받았다면 웹 컨트롤러에서는 setCustomerByCustomerNo() 메서드를 통해 ServiceRequest 오브젝트에 전달해주기만 하면 된다. 이렇게 하면 ServiceRequestService는 ServiceRequest의 customer 오브젝트가 어떻게 만들어졌는지에 대해서는 전혀 신경쓰지 않아도 된다. 단지 A/S 신청정보에는 그것을 신청한 고객정보가 도메인 모델을 따르는 오브젝트로 만들어져 있으리라 기대하고 사용할 뿐이다.\n폼에서 입력받는 것이 고객번호가 아니라 고객검색 팝업이나 AJAX를 통해 구한 고객의 ID라면, 다음과 같은 메서드를 ServiceRequest에 추가해주고 컨트롤러를 통해 id 값을 넣어주게만 하면 그만이다.\npublic void setCustomerByCustomerId(int customerId) { this.customer = this.customerDao.getCustomer(customerId); } 폼에서 고객정보를 입력받는 방법을 어떻게 변경하든 ServiceRequest를 사용하는 서비스 계층이나 DAO의 코드는 전혀 영향을 받지 않는다. 이제 남은 문제는 컨트롤러에서 new 키워드로 직접 생성하는 ServiceRequest 오브젝트에 어떻게 DI를 적용해서 CustomerDao를 주입할 것인가이다. DI를 적용하려면 결국 컨테이너에 오브젝트 생성을 맡겨야 한다. 또한 컨테이너가 만드는 빈이지만 매번 같은 오브젝트를 돌려주는 것이 아니라 new로 생성하듯이 새로운 오브젝트가 만들어지게 해야 한다. 바로 프로토타입 스코프 빈이 필요할 때다.\n@Component @Scope(\u0026#34;prototype\u0026#34;) public class ServiceRequest { ... }\u0026lt;bean id=\u0026#34;serviceRequest\u0026#34; class=\u0026#34;...ServiceRequest\u0026#34; scope=\u0026#34;prototype\u0026#34;\u0026gt; 다음으로는 컨트롤러에서 ServiceRequest 오브젝트를 new로 생성하는 대신 프로토타입으로 선언된 serviceRequest 빈을 가져오게 만들어야 한다. 프로토타입 빈은 컨테이너에 빈을 요청할 때마다 새로운 오브젝트가 생성된다고 했다. 컨테이너에 빈을 요청하는 방법이 여러 가지가 있겠지만, 일단 가장 간단하게 아래와 같이 컨트롤러에 애플리케이션 컨텍스트를 DI 받아둔 다음 getBean() 메서드로 요청하도록 만들어보자.\n컨텍스트를 이용해 프로토타입 빈을 가져오는 코드 @Autowired ApplicationContext context; public void serviceRequestFormSubmit(HttpServletRequest request) { ServiceRequest serviceRequest = this.context.getBean(ServiceRequest.class); serviceRequest.setCustomerByCustomerNo(request.getParameter(\u0026#34;custno\u0026#34;)); ... } 애플리케이션 컨텍스트에서 가져온 ServiceRequest 오브젝트는 CustomerDao가 DI된 상태이기 때문에 setCustomerByCustomerNo()가 호출되면 DAO를 이용해 Customer 오브젝트를 저장해주게 만들 수 있다.\n이번엔 EmailService에 대해서도 생각해보자. 고객의 A/S 신청이 접수된 것을 통보 해주는 방법을 ServiceRequestService 대신 ServiceRequest가 담당하면 어떨까? 고객이 가입할 때 A/S 관련 통보 방법을 지정할 수 있게 해뒀다면 Customer 정보에서 이를 확인하고, 적절한 방법으로 고객에게 메세지를 보내주는 작업을 ServiceRequest에 두는 것도 나쁘지 않다. ServiceRequest도 이제 자유롭게 DI 받을 수 있는 빈이 됐으니 EmailService를 이용할 수 있다.\npublic class ServiceRequest { Customer customer; @Autowired EmailService emailService; ... public void notifyServiceRequestRegistration() { // A/S 요청이 등록됐음을 통보해주는 기능을 가진 메서드  if (this.customer.serviceNotificationMethod == NotificationMethod.EMAIL) { this.emailService.sendEmail(customer.getEmail(), \u0026#34;A/S 접수가 정상적으로 처리되었습니다.\u0026#34;); } } } 이제 ServiceRequestService의 A/S 신청 접수를 처리하는 메서드는 아래와 같이 구체적인 통보 방식에 매이지 않고 ServiceRequest 오브젝트에게 통보를 보내라는 요청만 하는 깔끔한 코드로 만들 수 있다.\npublic void addNewServiceRequest(ServiceRequest serviceRequest) { this.serviceRequestDao.add(serviceRequest); serviceRequest.notifyServiceRequestRegistration(); // 구체적인 통보 작업은 ServiceRequest에서 알아서 담당하게 한다. } ServiceRequest를 프로토타입 빈으로 변경하면서 새롭게 바뀐 의존관계다. 이렇게 매번 새롭게 오브젝트를 만들면서 DI도 함께 적용하려고 할 때 사용할 수 있는게 바로 프로토타입 빈이다. 한번 컨테이너로부터 생성해서 가져온 이후에는 new로 직접 생성한 오브젝트처럼 평범하게 사용하면 된다. 빈으로 만들어진 오브젝트이기 때문에 DI를 통해 주입된 다른 빈을 자유롭게 이용할 수 있다.\n프로토타입 빈의 DL 전략 앞에서 ServiceRequest를 프로토타입 빈으로 만들고 컨트롤러에서 가져오도록, ApplicationContext를 이용해 getBean() 메서드를 호출하는 방식을 이용했다. 즉 DL을 사용한 것이다. 번거롭게 DL 방식을 쓰지 않고 프로토타입 빈을 직접 DI 해서 사용하는 건 어떨까? 예를 들어 아래 처럼 컨트롤러에서 ServiceRequest를 직접 DI 받게 만들고 이를 사용하면 어떻게 될까?\n@Autowired ServiceRequest serviceRequest; public void serviceRequestFormSubmit(HttpServletRequest request) { this.serviceRequest.setCustomerNo(request.getParameter(\u0026#34;custno\u0026#34;)); ... } 이 코드를 테스트해보면 일단 정상적으로 동작하는 것처럼 보이지만 운영 시스템에 적용하면 매우 심각한 문제가 발견된다. 왜 그럴까? 웹 컨트롤러도 다른 대부분의 빈처럼 싱글톤이다. 따라서 단 한 번만 만들어진다. 문제는 DI 작업은 빈 오브젝트가 처음 만들어질 때 단 한 번만 진행된다는 점이다. 따라서 아무리 ServiceRequest 빈을 프로토타입으로 만들었다고 하더라도 컨트롤러에 DI 하기 위해 컨테이너에 요청할 때 딱 한번만 오브젝트가 생성되고 더 이상 새로운 ServiceRequest 오브젝트는 만들어지지 않는다. 결국 여러 사용자가 동시에 요청을보내면 serviceRequest 오브젝트 하나가 공유되어 서로 데이터를 덮어써 버리는 문제가 발생한다.\n프로토타입 빈은 DI 될 대상이 여러 군데라면 각기 다른 오브젝트가 생성된다. 하지만 ServiceRequest 처럼 같은 컨트롤러에서도 매번 요청이 있을 때마다 새롭게 오브젝트가 만들어져야 하는 경우에는 적합하지 않다. new 키워드를 대신하기 위해 사용되는 것이 프로토타입의 용도라고 본다면, DI는 프로토타입 빈을 사용하기에 적합한 방법이 아니다. 따라서 코드 내에서 필요할 때마다 컨테이너에게 요청해서 새로운 오브젝트를 만들어야 한다. DL 방식으로 사용해야 한다는 뜻이다. 프로토타입 빈이 DI 방식으로 사용되는 경우는 매우 드물다.\n앞에서 ApplicationContext를 DI 받아둔 뒤에 코드에서 getBean() 메서드를 직접 호출하는 방법을 사용했다. 가장 단순하고 직접적인 방식이며, 사용하기도 별로 어렵지 않다. 반면에 스프링의 API가 일반 애플리케이션 코드에서 사용된다는 사실이 불편하게 느껴질 수도 있다. 게다가 단위 테스트를 작성하려면 ApplicationContext라는 거대한 인터페이스의 목 오브젝트를 만들어야 하는 부담도 뒤따른다. 스프링은 프로토타입 빈처럼 DL 방식을 코드에서 사용해야 할 경우를 위해 직접 ApplicationContext를 이용하는 것 외에도 다양한 방법을 제공하고 있다.\nApplicationContext, BeanFactory 이미 사용했던 방법이다. @Autowired나 @Resorce를 이용해 ApplicationContext 또는 BeanFactory를 DI 받은 후에 getBean() 메서드를 직접 호출해서 빈을 가져오는 방법이다.\nObjectFactory, ObjectFactoryCreatingFactoryBean 직접 애플리케이션 컨텍스트를 사용하지 않으려면 중간에 컨텍스트에 getBean()을 호출해주는 역할을 맡을 오브젝트를 두면 된다. 가장 쉽게 생각해볼 수 있는 것은 바로 팩토리다. 팩토리를 이용하는 이유는 오브젝트를 요구하면서 오브젝트를 어떻게 생성하거나 가져오는지에는 신경 쓰지 않을 수 있기 때문이다. ApplicationContext를 DI 받아서 getBean()을 호출해 원하는 프로토타입 빈을 가져오는 방식으로 동작하는 팩토리를 하나 만들어서 빈으로 등록해두고, 이 팩토리 역할을 하는 빈을 DI 받아서 필요할 때 getObject()와 같은 메서드를 호출해 빈을 가져올 수 있도록 만드는 방법이 있다.\n스프링이 제공하는 ObjectFactory 인터페이스와 ObjectFactory 인터페이스를 구현한 팩토리를 만들어주는 특별한 빈 클래스를 사용해보자. 스프링의 ObjectFactory 인터페이스는 타입 파라미터와 getObject()라는 간단한 팩토리 메서드를 갖고 있다.\nObjectFactory\u0026lt;ServiceRequest\u0026gt; factory = ...; ServiceRequest request = factory.getObject(); ObjectFactory는 비록 스프링이 제공하는 인터페이스이지만 평범하고 간단한 메서드만 갖고 있기 때문에 복잡한 ApplicationContext를 직접 사용하는 것보다 훨씬 깔끔하고 테스트하기도 편하다. ObjectFactory의 구현 클래스는 이미 스프링이 제공해주고 있다. 프로토타입처럼 컨텍스트에서 매번 빈을 가져와야 하는 구조의 팩토리를 만들 때 손쉽게 사용할 수 있도록 만들어져 있다. 클래스의 이름은 ObjectFactoryCreatingFactoryBean이다. ObjectFactory를 만들어주는 팩토리 빈이라는 뜻이다.\n사용 방법은 아래와 같이 getBean()으로 가져올 빈의 이름을 넣어서 등록해주면 된다. 이 빈은 FactoryBean이기 때문에 실제 빈의 오브젝트는 ObjectFactory 타입이 된다.\n\u0026lt;bean id=\u0026#34;serviceRequestFactory\u0026#34; class= \u0026#34;org.springframework.beans.factory.config.ObjectFactoryCreatingFactoryBean\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;targetBeanName\u0026#34; value=\u0026#34;serviceRequest\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; cf) 여기서 value는 팩토리 메서드에서 getBean()으로 가져올 빈의 이름을 넣는다.\n@Configuration public class ObjectFactoryConfig { @Bean public ObjectFactoryCreatingFactoryBean serviceRequestFactory() { ObjectFactoryCreatingFactoryBean factoryBean = new ObjectFactoryCreatingFactoryBean(); factoryBean.setTargetBeanName(\u0026#34;serviceRequest\u0026#34;); return factoryBean; } } 이제 serviceRequestFactory 빈을 ServiceRequest를 사용할 컨트롤러에 DI 해주고 아래와 같이 사용하면 된다.\n@Resource // ObjectFactory 타입은 여러개 있을 수 있으므로 이름으로 빈을 지정하는 편이 낫다. private ObjectFactory\u0026lt;ServiceRequest\u0026gt; serviceRequestFactory; public void serviceRequestFormSubmit(HttpServletRequest request) { ServiceRequest serviceRequest = this.serviceRequestFactory.getObject(); serviceRequest.setCustomerByCustomerNo(request.getParameter(\u0026#34;custno\u0026#34;)); ... } ObjectFactory는 프로토타입 빈뿐 아니라 DL을 이용해 빈을 가져와야 하는 모든 경우에 적용할 수 있다.\nServiceLocatorFactoryBean ObjectFactory가 단순하고 깔끔하지만 프레임워크의 인터페이스를 애플리케이션 코드에서 사용하는 것이 맘에 들지 않을 수 있다. 또는 기존에 만들어둔 팩토리 인터페이스를 활용하고 싶을지도 모르겠다. 이럴 땐 ObjectFactoryCreatingFactoryBean 대신 ServiceLocatorFactoryBean을 사용하면 된다.\nServiceLocatorFactoryBean은 ObjectFactory처럼 스프링이 미리 정의해둔 인터페이스를 사용하지 않아도 된다. DL 방식으로 가져올 빈을 리턴하는 임의의 이름을 가진 메서드가 정의된 인터페이스가 있으면 된다. 메서드 이름은 어떻게 지어도 상관없다.\npublic interface ServiceRequestFactory { ServiceRequest getServiceFactory(); } 이렇게 정의한 인터페이스를 이용해 스프링의 ServiceLocatorFactoryBean으로 아래와 같이 빈을 등록해주면 된다.\n\u0026lt;bean class=\u0026#34;org.springframework.beans.factory.config.ServiceLocatorFactoryBean\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;serviceLocatorInterface\u0026#34; value=\u0026#34;.. ServiceRequestFactory\u0026#34; /\u0026gt; //팩토리 인터페이스를 지정한다. 빈의 실제 타입이 된다. \u0026lt;/bean\u0026gt; 범용적으로 사용하는 ObjectFactory와 달리 ServiceRequest 전용으로 만든 인터페이스가 이 빈의 타입이 되기 때문에 @Autowired를 이용해 타입으로 가져올 수 있다. 빈을 이름으로 접근할 필요가 없을 때는 위의 빈 선언처럼 id를 생략할 수도 있다. 컨트롤러에서 사용할 때는 아래와 같이 팩토리 인터페이스 타입으로 DI 받아서 사용하면 된다. 타입 파라미터를 사용해야 하는 ObjectFactory보다 코드가 한결 깔끔하다.\n팩토리 인터페이스를 사용하는 컨트롤러 코드 @Autowired ServiceRequestFactory serviceRequestFactory; public void serviceRequestFormSubmit(HttpServletRequest request) { ServiceRequest serviceRequest = this.serviceRequestFactory.getServiceFactory(); serviceRequest.setCustomerByCustomerNo(request.getParameter(\u0026#34;custno\u0026#34;)); ... } 메서드 주입 ApplicationContext를 직접 이용하는 방법은 스프링 API에 의존적인 코드를 만드는 불편함이 있다. 반면에 ObjectFactory나 ServiceLocatorFactoryBean을 사용하면 코드는 깔끔해지지만 빈을 새로 추가해야 하는 번거로움이 있다. 이 두 가지 단점을 모두 극복할 수 있도록 스프링이 제공해주는 또 다른 DL 전략은 메서드 주입이다.\n메서드 주입은 @Autowired를 메서드에 붙여서 메서드 파라미터에 의해 DI 되게 하는 메서드를 이용한 주입 방식과 혼동하면 안된다. 메서드 주입은 메서드를 통한 주입이 아니라 메서드 코드 자체를 주입하는 것을 말한다. 메서드 주입은 일정한 규칙을 따르는 추상 메서드를 작성해두면 ApplicationContext와 getBean() 메서드를 사용해서 새로운 프로토타입 빈을 가져오는 기능을 담당하는 메서드를 런타임 시에 추가해주는 기술이다.\n컨트롤러 클래스에 아래와 같이 추상 메서드를 선언해둔다. 팩토리 역할을 하는 메서드라고 보면 된다. 그리고 이 메서드를 사용해 새로운 빈 오브젝트를 가져오도록 코드를 작성한다.\nabstract public ServiceRequest getServiceRequest(); public void serviceRequestFormSubmit(HttpServletRequest request) { ServiceRequest serviceRequest = this.getServiceFactory(); serviceRequest.setCustomerByCustomerNo(request.getParameter(\u0026#34;custno\u0026#34;)); ... } 추상 메서드를 가졌으므로 당연히 클래스도 추상 클래스로 정의돼야 한다. 이제 이 추상 클래스를 확장해서 getServiceRequest()라는 추상 메서드를 주입해주도록 스프링 빈을 다음과 같이 정의한다.\n\u0026lt;bean id=\u0026#34;serviceRequestController\u0026#34; class=\u0026#34;...ServiceRequestController\u0026#34;\u0026gt; \u0026lt;lookup-method name=\u0026#34;getServiceRequest\u0026#34; bean=\u0026#34;serviceRequest\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;lookup-method\u0026gt;라는 태그의 name이 스프링이 구현해줄 추상 메서드의 이름이고, bean 애트리뷰트는 메서드에서 getBean()으로 가져올 빈의 이름이다. 이렇게 설정해두면 스프링은 추상 클래스를 상속해서 getServiceRequest() 메서드를 완성하고 상속한 클래스를 빈으로 등록해둔다.\n메서드 주입 방식은 그 자체로 스프링 API에 의존적이 아니므로 스프링 외의 환경에 가져다 사용할 수도 있고 컨테이너의 도움 없이 단위 테스트를 할 수도 있다. 지금까지 살펴본 것중에서 가장 고급 방식이지만 불편한 점도 있다. 클래스 자체가 추상 클래스이므로 테스트에서 사용할 때 상속을 통해 추상 메서드를 오버라이드한 뒤에 사용해야 한다는 번거로움이 있다. 단위 테스트를 많이 작성할 것이라면 메서드 주입 방법은 장점보다 단점이 더 많을 수 있다.\nProvider\u0026lt;T\u0026gt; 마지막으로 살펴볼 프로토타입 빈을 DL 하는 방법은 가장 최근에 소개된 것이다. @Inject와 함께 JSR-330에 추가된 표준 인터페이스인 Provider를 이용하는 것이다. Provider는 ObjectFactory와 거의 유사하게 \u0026lt;T\u0026gt;타입 파라미터와 get()이라는 팩토리 메서드를 가진 인터페이스다. 기본 개념과 사용 방법은 ObjectFactory와 거의 유사하지만 ObjectFactoryCreatingFactoryBean을 이용해 빈을 등록해주지 않아도 되기 때문에 사용이 편리하다. Provider 인터페이스를 @Inject, @Autowired, @Resource 중의 하나를 이용해 DI 되도록 지정해주기만 하면 스프링이 자동으로 Provider를 구현한 오브젝트를 생성해서 주입해주기 때문이다. 오브젝트 팩토리 주입이라고 생각해도 좋을 것이다. 팩토리 빈을 XML이나 @Configuration 자바 코드로 정의하지 않아도 ObjectFactory처럼 동작하기 때문에 손쉽게 사용할 수 있다. Provider를 사용할 때는 아래와 같이 타입 파라미터로 생성할 빈의 타입을 넣어주기만 하면 된다.\n@Inject Provider\u0026lt;ServiceRequest\u0026gt; serviceRequestProvider; public void serviceRequestFormSubmit(HttpServletRequest request) { ServiceRequest serviceRequest = this.serviceRequestProvider.get(); serviceRequest.setCustomerByCustomerNo(request.getParameter(\u0026#34;custno\u0026#34;); ... } 빈 등록정보 조회 유틸리티 클래스 import java.util.ArrayList; import java.util.List; import org.springframework.context.support.GenericApplicationContext; public class BeanDefinitionUtils { public static void printBeanDefinitions(GenericApplicationContext gac) { List\u0026lt;List\u0026lt;String\u0026gt;\u0026gt; roleBeanInfos = new ArrayList\u0026lt;\u0026gt;(); roleBeanInfos.add(new ArrayList\u0026lt;\u0026gt;()); roleBeanInfos.add(new ArrayList\u0026lt;\u0026gt;()); roleBeanInfos.add(new ArrayList\u0026lt;\u0026gt;()); for (String name : gac.getBeanDefinitionNames()) { int role = gac.getBeanDefinition(name).getRole(); List\u0026lt;String\u0026gt; beanInfos = roleBeanInfos.get(role); beanInfos.add(role + \u0026#34;\\t\u0026#34; + name + \u0026#34;\\t\u0026#34; + gac.getBean(name).getClass().getName()); } for (List\u0026lt;String\u0026gt; beanInfos : roleBeanInfos) { for (String beanInfo : beanInfos) { System.out.println(beanInfo); } } } } 컨테이너의 빈 등록 정보 확인 (vol.1 p692)\n@Autowired DefaultListableBeanFactory bf; @Test public void beanTest() throws Exception { for (String s : bf.getBeanDefinitionNames()) { System.out.println(bf.getBean(s).getClass().getName()); } }"
},
{
	"uri": "/effective_java/%E1%84%87%E1%85%A7%E1%86%BC%E1%84%92%E1%85%A2%E1%86%BC%E1%84%89%E1%85%A5%E1%86%BC/",
	"title": "병행성",
	"tags": [],
	"description": "",
	"content": " 규칙66 : 변경 가능 공유 데이터에 대한 접근은 동기화하라 많은 프로그래머는 동기화(synchronization)를 상호 배제적인 관점, 그러니까 다른 스레드가 변경 중인 객체의 상태를 관측할 수 없어야 한다는 관점으로만 바라본다.\n이 관점에 따르면 객체는 일관된 상태를 갖도록 생성되며, 해당 객체를 접근하는 메서드는 그 객체에 락을 건다. 락을 건 메서드는 객체의 상태를 관측할 수 있으며, 선택적으로 객체 상태를 변경할 수도 있다. 하나의 일관된 상태에서 다른 일관된 상태로 전이시킬 수 있다는 것이다. 동기화 메커니즘을 적절히 사용하기만 하면, 모든 메서드가 항상 객체의 일관된 상태만 보도록 만들 수 있다.\n맞는 말이나 딱 절반만 이야기 했을 뿐이다. 동기화 없이는 한 스레드가 만든 변화를 다른 스레드가 확인할 수 없다. 동기화는 스레드가 일관성이 깨진 객체를 관측할 수 없도록 할 뿐 아니라, 동기화 메서드나 동기화 블록에 진입한 스레드가 동일한 락의 보호 아래 이루어진 모든 변경의 영향을 관측할 수 있도록 보장한다.\n자바 언어 명세에는 long이나 double이 아닌 모든 변수는 원자적으로 읽고 쓸 수 있다고 되어 있다. 다시 말해, long이나 double이 아닌 변수를 읽으면 나오는 값은 항상 어떤 스레드가 저장한 값이라는 것이다. 설사 열러 스레드가 그 변수를 동기화 없이 변경했다고 해도 말이다.\n\u0026ldquo;성능을 높이기 위해 원자적 데이터를 읽거나 쓸 때 동기화를 피해야 한다\u0026rdquo;는 아주 위험한 이야기다. 언어 명세상으로는 필드에서 읽어낸 값은 임의의 값이 될 수 없다고 되어 있으나, 그렇다고 어떤 스레드가 기록한 값을 반드시 다른 스레드가 보게 되리라는 보장은 없다. 상호 배제성뿐 아니라 스레드 간의 안정적 통신을 위해서도 동기화는 반드시 필요하다. 자바 언어 명세의 일부인 메모리 모델 때문이다. 메모리 모델은 한 스레드가 만든 변화를 다른 스레드가 볼 수 있게 되는 시점과, 그 절차를 규정한다.\n//잘못된 코드 - 이 프로그램은 얼마나 오랫동안 실행될까? public class StopThread { private static boolean stopRequested; public static void main(String[] args) throws InterruptedException { Thread backgroundThread = new Thread(new Runnable(){ public void run(){ int i = 0; while(!stopRequested) i++; } }); backgroundThread.start(); TimeUnit.SECONDS.sleep(1); stopRequested = true; } } 실행한지 1초가 지나면 main 스레드가 stopRequested의 값을 true로 바꾸므로, background thread가 실행하는 순환문도 그때 중지될 것 같지만 이 프로그램은 절대로 멈추지 않는다. 문제는 동기화 메커니즘을 적용하지 않은 탓에 main 스레드가 변경한 stopRequest의 새로운 값을 background thread가 언제쯤 보게 될지 알 수가 없다는 것이다.\nwhile(!stopRequested) i++; // 동기화가 적용되지 않은 경우, 가상 머신은 위의 코드를 아래와 같이 바꿀 수 있다. if(!stopRequested) while(true) i++; 이런 최적화를 끌어올리기(hoisting)라고 하는데, HotSpot 서버 VM이 하는 일이 바로 이런 것이다. 그 덕에 생기는 문제가 바로 생존 오류다. 살아 있기는 하나 더 진행하지는 못하는 프로그램이 되는 것이다. 이 문제를 수정하는 한 가지 방법은 stopRequested 필드를 동기화하는 것이다.\n// 적절히 동기화한 스레드 종료 예제 public class StopThread { private static boolean stopRequested; private static synchronized void requestStop(){ stopRequested = true; } private static synchronized boolean stopRequested(){ return stopRequested; } public static void main(String[] args) throws InterruptedException { Thread backgroundThread = new Thread(new Runnable(){ public void run(){ int i = 0; while(!stopRequested()) i++ } }); backgroundThread.start(); TimeUnit.SECONDS.sleep(1); requestStop(); } } 쓰기 메서드와 읽기 메서드에 동기화 메커니즘이 적용되었음을 유의하자. 읽기 연산과 쓰기 연산에 전부 동기화를 적용하지 않으면 동기화는 아무런 효과도 없다. 그런데 StopThread의 동기화 메서드가 하는 일은 동기화가 없이도 원자적이다. 다시 말해 이들 메서드에 동기화를 적용한 것은 상호 배제성을 달성하기 위해서가 아니라, 순전히 스레드 간 통신 문제를 해결하기 위해서였다는 것이다.\n비록 순환문의 각 단계마다 동기화를 실행하는 비용이 크진 않지만, 그 비용을 줄여서 좋은 성능을 내면서도 간결하기까지 한 대안이 있다. 위 코드에 사용된 boolean 필드 stopRequested를 volatile로 선언하는 것이다. 그러면 락은 없어도 된다. 비록 volatile이 상호 배제성을 실현하진 않지만, 어떤 스레드건 가장 최근에 기록된 값을 읽도록 보장한다.\n// volatile 필드를 사용해 스레드를 종료시키는 예제 public class StopThread { private static volatile boolean stopRequested; public static void main(String[] args) throws InterruptedException{ Thread backgroundThread = new Thread(new Runnable(){ public void run(){ int i = 0; while(!stopRequested) i++; } }); backgroundThread.start(); TimeUnit.SECONDS.sleep(1); stopRequested = true; } } volatile을 사용할 때는 주의해야 한다. 아래의 메서드를 보자. 일련번호를 만들어 내는 메서드다.\n// 잘못된 예제 - 동기화가 필요하다! private static volatile int nextSerialNumber = 0; public static int generateSerialNumber(){ return nextSerialNumber++; } 이 메서드의 원래 의도는, 호출 될 때마다 다른 값을 반환하는 것이었다. 이 메서드의 상태를 구성하는 것은 원자적으로 접근 가능한 필드 nextSerialNumber이며 이 필드가 가질 수 있는 값은 전부 유효하다. 따라서 불변식을 보호하기 위해 동기화 메커니즘을 사용할 필요가 없다. 그런데도 동기화 없이는 제대로 동작하지 않는다.\n문제는 증가 연산자 ++가 원자적이지 않다는 데 있다. 이 연산자는 nextSerialNumber 필드에 두 가지 연산을 순서대로 시행한다. 먼저 값을 읽고, 그 다음에 새로운 값, 즉 읽은 값 더하기 1을 필드에 쓴다. 첫 번째 스레드가 필드의 값을 읽은 후 새 값을 미처 기록하기 전에 두 번째 스레드가 필드에서 같은 값을 읽으면, 두 스레드는 같은 일련번호를 얻게 된다. 이것은 안전 오류다. 프로그램이 잘못된 결과를 계산하는 것이다.\n이 문제를 해결하는 한 가지 방법은, 메서드를 synchronized로 선언하는 것이다. 그러면 여러 스레드가 동시에 호출하더라도 서로 겹쳐 실행되지 않는 메서드가 되고, 각각의 메서드 호출은 그전에 행해진 모든 호출의 영향을 관측할 수 있게 된다. synchronized 키워드를 붙였다면, volatile 키워드는 삭제해야 한다. 더 견고한 메서드로 만들려면 int 대신 long을 쓰거나, 아니면 nextSerialNumber가 반환할 값이 다시 0으로 돌아갈 때 예외가 뜨도록 만들라.\n더 좋은 방법은 AtomicLong 클래스를 쓰는 것이다. 이 클래스는 java.util.concurrent.atomic의 일부다. 원하는 일은 해주면서도, synchronized 키워드를 사용한 해법보다 성능도 좋다.\nprivate static final AtomicLong nextSerialNum = new AtomicLong(); public static long generateSerialNumber(){ return nextSerialNum.getAndIncrement(); } 이번 절에서 설명한 문제를 피하는 가장 좋은 방법은 변경 가능 데이터를 공유하지 않는 것이다. 굳이 공유를 해야겠다면 변경 불가능 데이터를 공유하거나 그럴 필요가 없다면 아예 공유하지 마라. 다시 말해 변경 가능 데이터는 한 스레드만 이용하도록 하라는 것이다.\n규칙67 : 과도한 동기화는 피하라 상황에 따라서는 동기화를 너무 과도하게 적용하면 성능 저하, 교착 상태(deadlock), 비결정적 동작 등의 문제가 생길 수 있다. 생존 오류나 안전 오류를 피하고 싶으면, 동기화 메서드나 블록 안에서 클라이언트에게 프로그램 제어 흐름을 넘기지 마라. 다시 말해 동기화가 적용된 영역 안에서는 재정의 가능 메서드나 클라이언트가 제공한 함수 객체 메서드를 호출하지 말라는 것이다.\npublic class ObservableSet\u0026lt;E\u0026gt; extends ForwardingSet\u0026lt;E\u0026gt;{ public ObservableSet(Set\u0026lt;E\u0026gt; set) { super(set); } private final List\u0026lt;SetObserver\u0026lt;E\u0026gt;\u0026gt; observers = new ArrayList\u0026lt;\u0026gt;(); public void addObserver(SetObserver\u0026lt;E\u0026gt; observer){ synchronized (observers){ observers.add(observer); } } public boolean removeObserver(SetObserver\u0026lt;E\u0026gt; observer){ synchronized (observers){ //리스트 순회가 이루어지고 있는 도중에 리스트에서 원소를 삭제하려 했기 때문  return observers.remove(observer); } } private void notifyElementAdded(E element){ synchronized (observers){ for(SetObserver\u0026lt;E\u0026gt; observer : observers) observer.added(this,element); } } @Override public boolean add(E element){ boolean added = super.add(element); System.out.println(\u0026#34;added :\u0026#34;+added); if(added) notifyElementAdded(element); return added; } @Override public boolean addAll(Collection\u0026lt;? extends E\u0026gt; c){ boolean result = false; for(E element : c) result |= add(element); return result; } } 위 클래스는 Observer 패턴이다. 집합에 새로운 원소가 추가되었을 때 발생하는 notification을 구독(subscribe) 할 수 있도록 한다.\npublic static void main(String[] args) { ObservableSet\u0026lt;Integer\u0026gt;set = new ObservableSet\u0026lt;\u0026gt;(new HashSet\u0026lt;Integer\u0026gt;()); //옵저버 익명함수 객체  set.addObserver(new SetObserver\u0026lt;Integer\u0026gt;() { @Override public void added(ObservableSet\u0026lt;Integer\u0026gt; set, Integer element) { System.out.println(element); if(element == 23) { set.removeObserver(this); } } }); for(int i=0; i\u0026lt; 25;i++) set.add(i); } 이 프로그램을 돌리면 화면에는 0부터 23이 찍힌 후 구독자는 자기 자신을 구독 해제할 것이다. 그리고 프로그램은 나머지 작업을 계속하게 된다고 예상하지만 실제로는 0부터 23까지 출력되고 ConcurrentModificationException이 발생한다. 그 이유는 리스트 순회가 이루어지고 있는 도중에 리스트에서 원소를 삭제하려 했기 때문이다.\n좀 더 이상한 짓을 해보자. 구독 해제를 시도하는 구독자를 만들되, removeObserver를 직접 호출하는 대신 그 일을 해줄 다른 스레드의 서비스를 이용하는 것이다. 이 구독자는 실행자 서비스(executor service)를 사용한다.\nObservableSet\u0026lt;Integer\u0026gt;set2 = new ObservableSet\u0026lt;\u0026gt;(new HashSet\u0026lt;Integer\u0026gt;()); set2.addObserver(new SetObserver\u0026lt;Integer\u0026gt;() { @Override public void added(ObservableSet\u0026lt;Integer\u0026gt; set, Integer element) { System.out.println(element); if(element == 23){ ExecutorService executor = Executors.newSingleThreadExecutor(); final SetObserver\u0026lt;Integer\u0026gt; observer = this; try{ executor.submit(new Runnable() { @Override public void run() { set.removeObserver(observer); } }).get(); }catch (ExecutionException ex){ throw new AssertionError(ex.getCause()); }catch (InterruptedException ex){ throw new AssertionError(ex); }finally { executor.shutdown(); } } } });  이번에는 예외가 발생하진 않는 반면 교착상태가 생긴다. 후면 스레드는 set.removeObserver를 호출하는데, 이 메서드는 observers에게 락을 걸려한다. 하지만 락을 걸 수 는 없다. 왜냐하면 주 스레드가 이미 락을 걸고 있기 때문이다. 주 스레드는 후면 스레드가 구독 해제를 끝내기를 기다리면서 락을 계속 들고 있는데, 그래서 교착상태가 생기는 것이다.\n다행히도 이런 문제는 불가해 메서드(재정의 메서드나 클라이언트가 제공한 함수 객체 메서드)를 호출하는 부분을 동기화 영역 밖으로 옮기면 쉽게 해결할 수 있다. notifyElementAdded 메서드의 경우, observers리스트의 복사본을 만들어서 락 없이도 안전하게 리스트를 순회할 수 있도록 바꾸는 것이다.이렇게 바꾸면 앞서 보았던 두 예제에서는 더 이상 예외나 교착상태가 일어나지 않는다.\n//불가해 메서드를 호출하는 코드를 동기화 영역 밖으로 옮겼다 private void notifyElementAdded(E element){ List\u0026lt;SetObserver\u0026lt;E\u0026gt;\u0026gt; snapshot = null; synchronized (observers){ snapshot = new ArrayList\u0026lt;SetObserver\u0026lt;E\u0026gt;\u0026gt;(observers); } for(SetObserver\u0026lt;E\u0026gt; observer : snapshot) { System.out.println(\u0026#34;this :\u0026#34;+this+\u0026#34; element:\u0026#34;+element); observer.added(this, element); } } 사실 불가해 메서드 호출 코드를 동기화 영역 밖으로 옮기는 문제라면 더 좋은 해결책이 있다. 릴리스 1.5부터 자바 라이브러리에는 CopyOnWriteArrayList라는 병행성 컬렉션이 추가되었다. 이 리스트는 ArrayList의 변종으로 내부 배열을 통째로 복사하는 방식으로 쓰기 연산을 지원한다. 내부 배열을 절대 수정하지 않으므로 순회 연산만큼은 락을 걸 필요가 없어져서 대단히 빠르다. 이 리스트의 성능은 대체로 끔찍한 수준이지만 구독자(observer) 리스트에는 딱이다. 구독자 리스트는 변경할 일이 거의 없는 데다 순회 연산이 압도적으로 많기 때문이다.\n// 다중 스레드에 안전한 observer 집합 private final List\u0026lt;SetObserver\u0026lt;E\u0026gt;\u0026gt; observers = new CopyOnWriteArrayList\u0026lt;\u0026gt;(); public void addObserver(SetObserver\u0026lt;E\u0026gt; observer){ observers.add(observer); } public boolean removeObserver(SetObserver\u0026lt;E\u0026gt; observer){ return observers.remove(observer); } private void notifyElementAdded(E element){ for(SetObserver\u0026lt;E\u0026gt; observer : observers) observer.added(this,element); } 명심해야 할 것은 동기화 영역 안에서 수행되는 작업의 양을 가능한 한 줄여야 한다는 것이다.\n이제 성능에 관한 내용을 살펴보자. 변경 가능 클래스의 경우, 병렬적으로 이용될 클래스이거나, 내부적인 동기화를 통해 외부에서 전체 객체에 락을 걸 때보다 높은 병행성을 달성할 수 있을 때만 스레드 안전성을 갖도록 구현해야 한다. 그렇지 않다면 내부적인 동기화는 하지 마라. 예를 들어 StringBuffer 객체는 거의 항상 한 스레드만 이용하는 객체인데도 내부적으로 동기화를 하도록 구현되어 있다. 그래서 결국 StringBuilder로 대체된 것이다.\nstatic 필드를 변경하는 메서드가 있을 때는 해당 필드에 대한 접근을 반드시 동기화해야 한다. 보통 한 스레드만 이용하는 메서드라 해도 그렇다. 클라이언트 입장에서는 그런 메서드에 대한 접근을 외부적으로 동기화할 방법이 없다. 다른 클라이언트가 무슨 짓을 할지 알 수 없기 때문이다.\n규칙68 : 스레드보다는 실행자와 태스크를 이용하라 릴리스 1.5부터 자바 플랫폼에는 java.util.concurrent가 추가되었다. 이 패키지에는 실행자 프레임워크(Executor Framework)라는 것이 들어 있는데, 유연성이 높은 인터페이스 기반 태스크 실행 프레임워크다. ExecutorService executor = Executors.newSingleThreadExecutor(); 이 실행자에 Runnable을 넘겨 실행시키려면 다음과 같이 한다. executor.execute(runnable); 실행자가 스스로 자연스럽게 종료되도록 하려면 다음과 같이 하면 된다(이 코드를 빼먹으면 VM은 종료되지 않는다). executor.shutdown();\n실행자 서비스로 할 수 있는 일은 더 많다. 예를 들어, 특정 태스크가 종료되기를 기다릴 수도 있고(규칙 66 SetObserver 예제), 임의의 태스크들이 종료되기를 기다릴 수도 있고(invokeAny나 invokeAll 메서드 사용), 실행자 서비스가 자연스럽게 종료되기를 기다릴 수도 있으며(awaitTermination 메서드 이용), 태스크가 끝날 때마다 그 결과를 차례로 가져올 수도 있다(ExecutorCompletionService 이용).\n큐의 작업을 처리하는 스레드를 여러 개 만들고 싶을 때는 스레드 풀이라 부르는 실행자 서비스를 생성하는 정적 팩터리 메서드를 이용하면 된다. 스레드 풀에 담기는 스레드의 숫자는 고정시켜 놓을 수도 있고, 가변적으로 변하도록 설정할 수도 있다. java.util.concurrent.Executors 클래스에는 필요한 실행자 대부분을 생성할 수 있도록 하는 정적 팩터리 메서드들이 들어 있다. 하지만 일반적이지 않은 무언가가 필요할 때는 ThreadPoolExecutor 클래스를 직접 이용할 수도 있다. 이 클래스를 이용하면 스레드 풀의 동작을 거의 모든 측면에서 세밀하게 제어할 수 있다.\n작은 프로그램이나 부하가 크지 않은 서버를 만들 때는 보통 Executors.newCachedThreadPool이 좋다. 하지만 부하가 심한 곳에는 적합하지 않다. 캐시 기반 스레드 풀의 경우, 작업은 큐에 들어가는 것이 아니라 실행을 담당하는 스레드에 바로 넘겨진다. 가용한 스레드가 없는 경우에는 새 스레드가 만들어진다. 서버 부하가 너무 심해서 모든 CPU가 100% 가깝게 이용되고 있는 상황에서 새 태스크가 들어오면 더 많은 스레드가 만들어질 것이고, 상황은 더 나빠질 것이다. 따라서 부하가 심한 환경에 들어갈 서버를 만들 때는 Executors.newFixedThreadPool을 이용해서 스레드 개수가 고정된 풀을 만들거나, 최대한 많은 부분을 직접 제어하기 위해 ThreadPoolExecutor 클래스를 사용하는 것이 좋다.\n작업 큐를 손수 구현하는 것은 삼가야 할 뿐 아니라, 일반적으로는 스레드를 직접 이용하는 것도 피하는 것이 좋다. Thread는 작업의 단위였을 뿐 아니라 작업을 실행하는 메커니즘이기도 했다. 하지만 이제 Thread는 더 이상 중요하지 않다. 작업과 실행 메커니즘이 분리된 것이다. 중요한 것은 작업의 단위이며, 태스크라 부른다. 태스크에는 두 가지 종류가 있다. Runnable과, 그 가까운 사촌격인 Callable 이다(Runnable과 비슷하지만 값을 반환한다는 차이가 있다). 태스크를 실행하는 일반 메커니즘은 실행자 서비스(executor service)다. 태스크와 실행자 서비스를 분리해서 생각하게 되면 실행 정책을 더욱 유연하게 정할 수 있게 된다. 핵심은, 컬렉션 프레임워크가 데이터를 모으는 일을 처리하는 것과 마찬가지로, 실행자 프레임워크는 태스크를 실행하는 부분을 담당한다는 것이다.\n규칙69 : wait이나 notify 대신 병행성 유틸리티를 이용하라 릴리즈 1.5부터 자바 플랫폼에는 고수준 병행성 유틸리티들이 포함되어, 예전에는 wait과 notify를 사용해 구현해야만 했던 일들을 대신한다. wait과 notify를 정확하게 사용하는 것이 어렵기 때문에, 이 고수준 유틸리티들을 반드시 이용해야 한다. java.util.concurrent에 포함된 이 유틸리티들은 실행자 프레임워크, 병행 컬렉션(concurrent collection), 그리고 동기자(synchronizer)의 세 가지 범주로 나눌 수 있다. 이번 절에서는 병행 컬렉션과 동기자에 대해 간단히 살펴본다.\n병행 컬렉션은 List, Queue, Map 등의 표준 컬렉션 인터페이스에 대한 고성능 병행 컬렉션 구현을 제공한다. 이 컬렉션들은 병행성을 높이기 위해 동기화를 내부적으로 처리한다. 따라서 컬렉션 외부에서 병행성을 처리하는 것은 불가능하다. 락을 걸어봐야 아무 효과가 없을 뿐 아니라 프로그램만 느려진다. 따라서 클라이언트는 병행 컬렉션에 대한 메서드 호출을 원자적으로 작성할 수 없다. 그래서 컬렉션 인터페이스 가운데 일부는 상태 종속 변경 연산으로 확장되었는데, 이는 몇 가지 기본 연산들을 하나의 원자적 연산으로 묶은 것이다. 예를 들어 ConcurrentMap은 Map을 확장해서 몇 가지 메서드를 추가했는데, 그 가운데 putIfAbsent(key,value)도 있다. 이 메서드는 키에 해당하는 값이 없을 때만 주어진 값을 넣고, 해당 키가 있는 경우에는 기존 값을 반환한다. 그리고 대응되는 값이 없었을 때는 null을 반환한다. 이 메서드 덕에 다중 스레드에 안전한 정규화 맵을 쉽게 구현할 수 있다.\n// ConcurrentMap으로 구현한 병행 정규화 맵 public static String intern(String s){ String result = map.get(s); if(result == null){ result = map.putIfAbsent(s,s); if(result == null) result = s; } return result; } 병행성이 높을 뿐 아니라, ConcurrentHashMap은 아주 빠르다. 그러니 확실한 이유가 없다면 Collections.synchronizedMap이나 Hashtable 대신 ConcurrentHashMap을 사용하도록 하자.\n컬렉션 인터페이스 가운데 몇몇은 봉쇄 연산(blocking operation)이 가능하도록 확장되었다. 성공적으로 수행될 수 있을 때까지 대기(wait)할 수 있도록 확장되었다는 것이다. 예를 들어 BlockingQueue는 Queue를 확장해서 take 같은 연산을 추가하였다. take는 큐의 맨 앞(head) 원소를 제거한 다음 반환하는데, 큐가 비어 있는 경우에는 대기한다. ThreadPoolExecutor를 비롯한 대부분의 ExecutorService 구현은 BlockingQueue를 사용한다.\n동기자(synchronizer)는 스레드들이 서로를 기다릴 수 있도록 하여, 상호 협력이 가능하게 한다. 가장 널리 쓰이는 동기자로는 CountDownLatch와 Semaphore가 있다. countdown latch는 일회성 barrier로서 하나 이상의 스레드가 작업을 마칠 때까지 다른 여러 스레드가 대기할 수 있도록 한다. CountDownLatch에 정의된 유일한 생성자는 래치의 countdown 메서드가 호출될 수 있는 횟수를 나타내는 int 값을 인자로 받는다. 대기 중인 스레드가 진행할 수 있으려면 그 횟수만큼 countdown 메서드가 호출되어야 한다.\n예를 들어 어떤 작업을 병렬적으로 처리하는 데 드는 시간을 재는 간단한 프레임워크를 만드는 경우를 생각해 보자. 이 프레임워크는 작업을 실행할 실행자(executor)와 병행성 수준(concurrency level)을 나타내는 int 값, 그리고 수행할 작업을 나타내는 Runnable 객체를 인자로 받는 메서드다. 시간을 재는 타이머 스레드가 실행되기 전에 모든 작업 스레드는 작업 실행 준비를 마쳐야 한다. 그 상태에서 타이머 스레드가 “출발 신호를 울리면” 작업 스레드는 작업을 수행하기 시작한다. 마지막 작업 스레드가 일을 마치면 타이머 스레드는 시계를 멈추고 시간을 잰다.\npublic static long time(Executor executor, int concurrency, final Runnable action) throws InterruptedException{ final CountDownLatch ready = new CountDownLatch(concurrency); final CountDownLatch start = new CountDownLatch(1); final CountDownLatch done = new CountDownLatch(concurrency); for(int i=0; i\u0026lt;concurrency; i++){ executor.execute(new Runnable() { @Override public void run() { ready.countDown(); // 타이머에게 준비됨을 알림  try { start.await(); // 다른 작업 스레드가 준비될 때까지 대기  action.run(); } catch (InterruptedException e) { Thread.currentThread().interrupt(); } finally { done.countDown(); // 타이머에게 끝났음을 알림  } } }); } ready.await(); // 모든 작업 스레드가 준비될 때까지 대기  long startNanos = System.nanoTime(); start.countDown(); // 출발 !  done.await(); // 모든 작업 스레드가 끝날 때까지 대기  return System.nanoTime() - startNanos; } 이 메서드가 세 개의 카운트다운 래치를 사용하고 있음에 유의하자. ready는 작업 스레드가 타이머 스레드에게 실행 준비가 끝났음을 알리려고 사용한다. 그런 다음 작업 스레드는 두 번째 래치 start에서 기다린다. 마지막 작업 스레드가 ready.countDown을 호출하면 타이머 스레드는 작업 시작 시간을 기록하고 start.countDown을 호출하여 모든 작업 스레드가 작업을 시작하도록 한다. 그런 다음 타이머 스레드는 세 번째 래치 done을 이용하여 마지막 작업 스레드가 일을 마친 다음에 done.countDown을 호출할 때까지 기다린다. 모든 작업 스레드가 실행을 마치면 타이머 스레드는 깨어나서 작업에 소요된 시간을 반환한다.\n특정 구간의 실행시간을 잴 때는 System.currentTimeMillis 대신 System.nanoTime을 사용해야 한다. 그래야 더 정밀하게 잴 수 있을 뿐더러, 시스테의 실시간 클락(real-time clock) 변동에도 영향을 받지 않게 된다.\nwait나 notify로 작성한 기존 코드도 유지할 필요가 있을 것이다. wait 메서드는 스레드로 하여금 어떤 조건이 만족되길 기다리도록 하고 싶을 때 사용한다. 동기화 영역 내에서 호출해야 하며, 호출 대상 객체에는 락이 걸린다. wait 메서드는 아래의 표준적 숙어대로 사용한다.\n// wait 메서드를 사용하는 표준적 숙어 synchronized(obj){ while( 이 조건이 만족되지 않을 경우에 순환문 실행 ) obj.wait(); // 락 해제. 깨어나면 다시 락 획득  … // 조건이 만족되면 그에 맞는 작업 실행 } wait 메서드를 호출할 때는 반드시 이 대기 순환문(wait loop) 숙어대로 하자. 순환문 밖에서 호출하면 안된다. 이 순환문은 wait 호출 전후로 조건이 만족되었는지 검사하는 역할을 한다.\nnotify를 쓸 것인가 notifyAll을 쓸 것인가에 대해서는 많은 사람들이 항상 notifyAll을 쓰라고 한다. 깨어날 필요가 있는 모든 스레드를 깨우므로, 항상 정확한 결과가 나올 것이다. 필요 없는 다른 스레드도 깨어날 것이지만 프로그램의 정확성에는 영향을 끼치지 않는다. 대기 조건이 false인 것을 확인하고 나면 다시 대시 상태로 돌아갈 것이기 때문이다.\n규칙70 : 스레드 안전성에 대해 문서로 남겨라 클래스와 사용자 사이의 규약 가운데 중요한 것 하나는, 클래스의 객체나 정적 메서드가 병렬적으로 이용되었을 때 어떻게 동작하느냐 하는 것이다. 병렬적으로 사용해도 안전한 클래스가 되려면, 어떤 수준의 스레드 안전성을 제공하는 클래스인지 문서에 명확하게 남겨야 한다.\n스레드 안전성을 수준별로 요약하였다.\n변경 불가능(immutable) : 이 클래스로 만든 객체들은 상수다. 따라서 외부적인 동기화 메커니즘 없이도 병렬적 이용이 가능하다. String, Long, BigInteger 등이 그 예다.\n무조건적 스레드 안전성 : 이 클래스의 객체들은 변경이 가능하지만 적절한 내부 동기화 메커니즘을 갖추고 있어서 외부적으로 동기화 메커니즘을 적용하지 않아도 병렬적으로 사용할 수 있다. Random, ConcurrentHashMap 같은 클래스가 그 예다.\n조건부 스레드 안전성 : 무조건적 스레드 안전성과 거의 같은 수준이나 몇몇 스레드는 외부적 동기화가 없이는 병렬적으로 사용할 수 없다. Collections.synchronized 계열 메서드가 반환하는 포장 객체(wrapper)가 그 사례다. 이런 객체의 반복자(iterator)는 외부적 동기화 없이는 병렬적으로 이용할 수 없다.\n스레드 안전성 없음 : 이 클래스의 객체들은 변경 가능하다. 해당 객체들을 병렬적으로 사용하려면 클라이언트는 메서드를 호출하는 부분을 클라이언트가 선택한 외부적 동기화 수단으로 감싸야 한다. ArrayList나 HashMap 같은 일반 용도의 컬렉션 구현체들이 그 예다.\n다중 스레드에 적대적 : 이런 클래스의 객체는 설마 메서드를 호출하는 모든 부분을 외부적 동기화 수단으로 감싸더라도 안전하지 않다. 이런 클래스가 되는 것은 보통, 동기화 없이 정적 데이터를 변경하기 때문이다. 누구도 이런 클래스를 고의로 만들지는 않는다. 다행히 자바 라이브러리에는 이런 클래스가 별로 없다. System.runFinalizersOnExit 메서드는 스레드에 적대적인 대표적인 메서드로, 지금은 deprecated 되었다.\n위에 언급한 범주 각각은 스레드 안전성 애노테이션 Immutable, ThreadSafe, NotThreadSafe 각각에 해당한다. 무조건적/조건적 스레드 안전성 범주는 전부 ThreadSafe 애노테이션에 해당한다.\n조건부 스레드 안전성 클래스에 대한 문서를 만들 때는 신중해야 한다. 어떤 순서로 메서드를 호출할 때 외부 동기화 메커니즘을 동원해야 하는지, 그리고 그 순서로 메서드를 실행하려면 어떤 락을 사용해야 하는지 명시해야 한다. 보통은 객체 자체에 락을 걸면 되는데 예외도 있다. 다른 객체에 대한 뷰 역할을 하는 객체의 경우, 클라이언트는 원래 객체에 대해 동기화를 해야 한다. 동기화 없이 직접 변경하는 일을 막기 위해서다.\nMap\u0026lt;K, V\u0026gt; m = Collections.synchronizedMap(new HashMap\u0026lt;K,V\u0026gt;(); … Set\u0026lt;K\u0026gt; s = m.keySet(); // 동기화 블록 안에 있을 필요 없음 … synchronized(m){ // s가 아니라 m에 대해 동기화 ! \tfor(K key : s) key.f(); } enum 자료형의 경우, 변경 불가능성을 문서에 밝힐 필요는 없다. 반환값 자료형을 보고 명확하게 알 수 있는 경우를 빼고, 정적 팩토리 메서드는 자기가 반환하는 객체의 스레드 안전성을 문서에 남겨야 한다.\n내부적인 동기화 private 락 객체 패턴 외부로 공개한 락을 통해 동기화하도록 하는 클래스의 경우, 클라이언트가 여러 메서드를 한 번에 원자적으로 호출 할 수 있다는 유연성이 있긴 하지만, 높아진 유연성만큼 대가도 따른다. ConcurrentHashMap이나 ConcurrentLinkedQueue 같은 병행 컬렉션에서 사용하는 내부적인 고속 병행성 제어 메커니즘과는 잘 어울리지 않는다. 게다가, 클라이언트가 해당 락을 오랫동안 들고 있으면 DoS 공격도 가능하다. 그런 공격을 막는 한 가지 방법은 동기화 메서드를 쓰는 대신(동기화 메서드는 클래스 외부로 공개된 락이나 다름없다) private 락 객체를 이용하는 것이다.\n//DoS 공격을 피하기 위한 private 락 객체 숙어 private final Object lock = new Object(); public void foo(){ synchronized(lock){ ... } } 이 private 락 객체는 클래스 바깥에서는 이용할 수 없으므로, 클라이언트는 객체의 동기화 메커니즘에 개입할 수 없다. lock 필드를 final로 선언한 것에 유의하자. 이렇게 하면 실수로 lock 필드의 내용을 변경하는 일을 막을 수 있다.\nprivate 락 객체 패턴은 무조건적 스레드 안전성을 제공하는 클래스에만 적용할 수 있다. 조건부 스레드 안전성을 제공하는 클래스는 이 숙어를 이용할 수 없다. 특정 순서로 메서드들을 호출할 때 클라이언트가 어떤 락을 획득하게 되는지를 문서로 만들어 남겨야 하기 때문이다.\n요약하자면, 모든 클래스는 자신의 스레드 안전성 수준을 문서로 분명히 밝혀야 한다. synchronized 키워드는 이런 문서에서는 아무런 역할도 하지 못한다. 무조건적 스레드 안전성을 제공하는 클래스를 구현하는 중이라면 메서드를 synchronized로 선언하는 대신 private락 객체를 이용하면 어떨지 따져보자. 이런 락 객체를 이용하면 클라이언트나 하위 클래스가 동기화에 개입하는 것을 막을 수 있고, 다음번 릴리스에는 좀 더 복잡한 병행성 제어 전략도 쉽게 채택할 수 있게 된다.\n규칙71 : 초기화 지연은 신중하게 하라 초기화 지연은 필드 초기화를 그 값이 쓰일 때까지 미루는 것이다. 이 기법은 static 필드와 객체 필드 모두 적용 가능하다. 초기화 지연 기법은 기본적으로 최적화 기법이다. 대부분의 최적화가 다 그렇듯이, 초기화 지연을 적용할 때 따라야 할 최고의 지침은 “정말로 필요하지 않으면 하지 마라”는 것이다. 초기화 지연 기법은 클래스를 초기화하고 객체를 생성하는 비용은 줄이지만, 필드 사용 비용은 증가시킨다. 필드 사용 빈도가 낮고 초기화 비용이 높다면 쓸만할 것이다. 하지만 대부분의 경우 지연된 초기화를 하느니 일반 초기화를 하는 편이 낫다.\n아래 코드는 통상적인 방법으로 초기화하는 전형적 필드 선언문이다. final로 선언하고 있음에 주의하자.\n//객체 필드를 초기화하는 일반적인 방법 private final FieldType field = computerFieldValue(); 초기화 순환성 문제를 해소하기 위해서 초기화를 지연시키는 경우에는 동기화된 접근자를 사용하라.\n//동기화된 접근자를 사용한 객체 필드 초기화 지연 방법 private FieldType field; synchronized FieldType getField(){ if(field == null) field = computerFieldValue(); return field; } 성능 문제 때문에 정적 필드 초기화를 지연시키고 싶을 때는 초기화 지연 담당 클래스 숙어를 적용하라. 클래스는 실제로 사용되는 순간에 초기화된다는 점을 이용한 것이다.\n//정적 필드에 대한 초기화 지연 담당 클래스 숙어 private static class FieldHolder{ static final FieldType field = computerFieldValue(); } static FieldType getField(){ return FieldHolder.field; } FieldHolder 클래스는 FieldHolder.field가 처음으로 이용되는 순간, 그러니까 getField 메서드가 처음으로 호출되는 순간에 초기화된다. 이 숙어가 좋은 점은 getField를 동기화 메서드로 선언하지 않아도 된다는 것이다. 따라서 초기화를 지연시켜도 메서드 이용 비용은 전혀 증가하지 않는다.\n성능 문제 때문에 객체 필드 초기화를 지연시키고 싶다면 이중 검사 숙어를 사용하라. 이 숙어를 사용하면 초기화가 끝난 필드를 이용하기 위해 락을 걸어야 하는 비용을 없앨 수 있다. 이 숙어 뒤에 숨은 아이디어는 필드의 값을 두 번 검사하는 것이다. 한번은 락 없이 검사하고, 초기화가 되지 않은 것 같으면 락을 걸어서 검사한다. 이미 초기화된 필드에는 락을 걸지 않으므로, 필드는 반드시 volatile로 선언해야 한다.\n//이중 검사 패턴을 통해 객체 필드 초기화를 지연시키는 숙어 private volatile FieldType field; FieldType getField() { FieldType result = field; if (result == null) { // 첫 번째 검사(락 없음) \tsynchronized(this){ result = field; if(result == null) // 두 번째 검사(락) \tfield = result = computerFieldValue(); } } return result; } 여기서 지역 변수 result가 하는일은, 이미 초기화된 필드는 딱 한 번만 읽도록 하는 것이다.\n이중 검사 숙어의 변종 가운데는 주의할 것이 두 가지 있다. 때로 여러 번 초기화되어도 상관없는 객체 필드 초기화를 지연시키고 싶을 때가 있다. 이런 상황이라면 이중 검사 숙어의 두 번째 검사는 없애버려도 된다.\n//단일 검사 숙어 - 필드가 여러 번 초기화 될 수도 있다. private volatile FieldType field; FieldType getField() { FieldType result = field; if(result == null) field = result = computerFieldValue(); return result; } 또한 만약 모든 스레드가 필드 값을 재계산하더라도 상관없고 필드 자료형이 long이나 double이 아닌 기본 자료형인 경우에는 단일 검사 숙어에서 volatile 키워드는 빼도 된다.\n규칙72 : 스레드 스케줄러에 의존하지 마라 좋은 프로그램이라면 스케줄링 정책에는 의존하지 말아야 한다. 정확성을 보장하거나 성능을 높이기 위해 스레드 스케줄러에 의존하는 프로그램은 이식성이 떨어진다. 안정적이고, 즉각 반응하며 이식성이 좋은 프로그램을 만드는 가장 좋은 방법은, 실행 가능 스레드의 평균적 수가 프로세서 수보다 너무 많아지지 않도록 하는 것이다.\n마찬가지로 Thread.yield나 스레드 우선순위에 의존하지도 마라. 이런 것들은 스케줄러 입장에서는 단순한 힌트일 뿐이다.\n규칙73 : 스레드 그룹은 피하라 스레드 그룹은 원래 애플릿을 격리시켜 보안 문제를 피하고자 고안된 것이었으나, 그 목적을 달성하진 못했다. 그 중요성도 점차 희미해져, 자바 보안 모델을 표준화한 결과물에는 아예 언급도 되지 못했다.\n역설적이게도 ThreadGroup API의 스레드 안전성은 취약하다. 스레드 그룹은 이제 폐기된 추상화 단위다. 스레드를 논리적인 그룹으로 나누는 클래스를 만들어야 한다면, 스레드 풀 실행자(thread pool executor)를 이용하는 것이 바람직할 것이다.\n"
},
{
	"uri": "/effective_java/%E1%84%8C%E1%85%B5%E1%86%A8%E1%84%85%E1%85%A7%E1%86%AF%E1%84%92%E1%85%AA/",
	"title": "직렬화",
	"tags": [],
	"description": "",
	"content": " 규칙74 : Serializable 인터페이스를 구현할 때는 신중하라 클래스 선언부에 \u0026ldquo;implements Serializable\u0026rdquo;만 붙이면 직렬화 가능한 객체를 만드는 클래스를 구현할 수 있을 때도 있다. 너무 간단하기 때문에, 직렬화를 지원하기 위해 프로그래머 입장에서 해야 하는 일이 별로 없다는 잘못된 믿음이 만연해 있지만 사실은 훨씬 더 복잡하다.\nSerializable 구현과 관련된 가장 큰 문제는 일단 클래스를 릴리스하고 나면 클래스 구현을 유연하게 바꾸기 어려워진다. Serializable을 구현하면, 그 클래스의 바이트 스트림 인코딩도 공개 API의 일부가 되어 버린다. 따라서 아무리 잘 설계한 직렬화 형식도 클래스 진화라는 관점에서 보면 족쇄가 될 수 있다.\n두 번째 문제는 버그나 보안 취약점이 발생할 가능성이 높아진다. 보통 객체는 생성자를 통해 생성한다. 직렬화는 언어 외적인 객체 생성 메커니즘이다. 기본 동작을 받아들이건 재정의 하건 간에, 역직렬화는 생성자와 동일한 이슈를 갖고 있는 \u0026ldquo;숨은 생성자\u0026rdquo;다. 역직렬화 과정에 관계된 생성자가 명시적으로 존재하지 않기 때문에 불변식 훼손이나 불법 접근 문제에 쉽게 노출된다.\n세 번째 문제는 새 버전 클래스를 내놓기 위한 테스트 부담이 늘어난다는 것이다. 직렬화 가능 클래스를 수정할 때는, 새 릴리스에서 만들고 직렬화한 객체를 예전 릴리스에서 역직렬화할 수 있는지, 그리고 그 역도 가능한지 검사하는 것이 중요하다.\n상속을 염두에 두고 설계하는 클래스는 Serializable을 구현하지 않는 것이 바람직하다. 또한 인터페이스는 가급적 Serializable을 상속하지 말아야 한다. 하지만 예를 들어 Serializable을 구현하는 객체만 참여가 가능한 프레임워크가 있을 때, 이런 프레임워크를 이용하려면 클래스나 인터페이스가 Serializable을 구현하거나 계승하도록 해야 할 것이다.\n객체 필드를 갖는 클래스를 직렬화 가능하고 계승 가능한 클래스로 구현할 때는 반드시 조심해야 할 것이 하나 있다. 객체 필드가 기본값으로 초기화되면 위배되는 불변식이 있는 경우에는 아래의 readObjectNoData 메서드를 클래스에 반드시 추가해야 한다.\n// 상태유지 계승 가능 직렬화 가능 // 클래스에 대한 readObjectNoData 메서드 private void readObjectNoData() throws InvalidObjectException { throw new InvalidObjectException(\u0026#34;Stream data requied\u0026#34;); } 내부 클래스는 Serializable을 구현하면 안된다. 내부 클래스에는 바깥 객체에 대한 참조를 보관하고 바깥 유효범위의 지역 변수 값을 보관하기 위해 컴파일러가 자동으로 생성하는 인위생성 필드(synthetic field)가 있다. 익명 클래스나 지역 클래스 이름과 마찬가지로, 언어 명세서에는 이런 필드가 클래스 정의에 어떻게 들어맞는지 나와 있지 않다. 따라서 내부 클래스의 직렬화 형식은 정의될 수 없다. 하지만 정적 멤버 클래스는 Serializable을 구현해도 된다.\n클래스를 설계할 때 완전히 Serializable을 구현하고 싶지는 않지만 그렇다고 하위 클래스의 Serializable 구현을 금하고 싶지도 않다면 무인자 생성자를 제공하는 것이 방법이다.\n// 직렬화가 불가능한 상태유지(stateful) 클래스. // 하지만 직렬화가 가능한 하위 클래스를 만들 수 있다. public abstract class AbstractFoo{ private int x, y; // 상태  // 아래 enum과 필드는 초기화 과정을 추적하기 위한 것이다.  private enum State { NEW, INITIALIZING, INITIALIZED }; private final AtomicReference\u0026lt;State\u0026gt; init = new AtomicReference\u0026lt;State\u0026gt;(State.NEW); public AbstractFoo(int x, int y) { initialize(x, y); } // 이 생성자와 그 아래 메서드는 하위 클래스의 readObject 메서드가  // 상태를 초기화할 수 있도록 하기 위한 것이다.  protected AbstractFoo() { } protected final void initialize(int x, int y){ if (!init.compareAndSet(State.NEW, State.INITIALIZING)) throw new IllegalStateException(\u0026#34;Already initialized\u0026#34;); this.x = x; this.y = y; ...//원래 생성자가 하던 나머지 작업  init.set(State.INITIALIZED); } // 이 메서드들은 하위 클래스의 writeObject 메서드에 의해 객체가  // 수동적으로 직렬화될 수 있도록 내부 상태 정보를 제공하는 역할을 한다.  protected final int getX() { checkInit(); return x; } protected final int getY() { checkInit(); return y; } // 모든 public 및 protected 객체 메서드에서 반드시 호출해야 하는 메서드  private void checkInit(){ if(init.get() != State.INITIALIZED) throw new IllegalStateException(\u0026#34;Uninitialized\u0026#34;); } ... // 이하 생략 } AbstractFoo의 모든 public 및 protected 객체 메서드는 다른 작업을 하기 전에 반드시 checkInit 메서드를 호출해야 한다. 잘못 작성된 하위 클래스가 객체 초기화를 제대로 하지 못한 상태에서 다른 메서드를 호출하면 재빨리, 그리고 깔끔하게 실패하도록 하기 위한 것이다. init 필드가 원자적 참조 필드라는 것에 주의하자. 어떤 악의적 사용자가 오더라도 객체 무결성을 보존할 수 있도록 하기 위한 것이다.\n이런 조치가 없었다면? 가령 어떤 스레드가 객체에 initialize를 호출하는 순간에 두 번째 스레드가 그 객체를 사용하려 한다고 해 보자. 그 두 번째 스레드는 상태가 깨진 객체를 이용하게 될 수 있다. compareAndSet을 사용해 enum에 대한 참조를 원자적으로 조작하는 이 패턴은, 다 목적 스레드 안전 상태 기계를 구현하ㅣ 좋다. 이 메커니즘을 갖추고 나면, 직렬화 가능 하위 클래스를 구현하는 것은 쉽다.\n// 직렬화 불가능 상태유지(stateful) 클래스의 직렬화 가능 하위 클래스 public class Foo extends AbstractFoo implements Serializable{ private void readObject(ObjectInputStream s) throw IOException, ClassNotFountException{ s.defaultReadObject(); // 상위 클래스 상태를 수동으로 역직렬화 한 다음 초기화  int x = s.readInt(); int y = s.readInt(); initialize(x, y); } private void writeObject(ObjectOutputStream s) throws IOException { s.defaultWriteObject(); // 상위 클래스 상태를 수동으로 직렬화  s.writeInt(getX()); s.writeInt(getY()); } // 생성자는 이 메커니즘과 상관없음  public Foo(int x, int y) { super(x, y); } private static final long serialVersionUID = 2213124123213123L; } 규칙75 : 사용자 지정 직렬화 형식을 사용하면 좋을지 따져 보라 Serializable을 구현한 클래스를 만들면서 기본 직렬화 형식을 그대로 이용하면, 다음번 릴리스때 기존 구현을 빼버리는것이 불가능해진다. 그 직렬화 형식에 영원히 갇혀버리게 되는 것이다. 따라서 어떤 직렬화 형식이 적절할지 따져보지도 않고 기본 직렬화 형식을 그대로 받아들이지 마라.\n어떤 객체의 기본 직렬화 형식은 해당 객체가 루트인 객체 그래프의 물리적 표현을 나름 효과적으로 인코딩한 것이다. 다시 말해 객체 안에 담긴 데이터와, 해당 객체를 통해 접근할 수 있는 모든 객체에 담긴 데이터를 기술한다. 또한 이 객체들이 서로 연결된 토폴로지(topology)도 기술한다. 그런데 어떤 객체의 가장 효과적인 직렬화 형식은 해당 객체가 나타내는 논리적 데이터만 담아야 하며, 물리적 표현과는 무관해야 한다. 기본 직렬화 형식은 그 객체의 물리적 표현이 논리적 내용과 동일할 때만 적절하다.\n// 기본 직렬화 형식을 그대로 써도 좋은 클래스 후보 public class Name implements Serializable { //성(last name) null이 될 수 없다. \t//@Serial \tprivate final String lastName; //이름(first name) null이 될 수 없다. \t//@Serial \tprivate final String fisrtName; //중간 이름(middle name) 없을 때는 null이다. \t//@Serial \tprivate final String middleName; … // 이하 생략 } 논리적으로 말해서 어떤 사람의 이름은 성, 이름, 그리고 중간 이름을 나타내는 문자열 세 개로 구성된다. Name에 선언된 객체 필드들은 그 논리적 내용을 충실히 반영한다. 설사 기본 직렬화 형식이 만족스럽다 하더라도, 불변식이나 보안 조건을 만족시키기 위해서는 readObject 메서드를 구현해야 마땅한 경우도 많다. lastName, fisrtName, middleName은 private 필드임에도 문서화 주석이 달려있다는 것에 주의하자. 이 private 필드들이 pulbic API, 즉 클래스의 직렬화 형식을 규정하기 때문이며, 그래서 반드시 문서화해야 한다. @Serial 태그는 Javadoc 유틸리티에게 직렬화 형식을 다루는 특별한 페이지로 해당 문서를 분리하라는 지시를 내린다.\nName과는 정반대 격인 클래스도 하나 살펴보자. 이 클래스는 문자열의 리스트를 나타낸다.\n// 기본 직렬화 형식이 쓸만하지 않은 클래스 사례 public final class StringList implements Serializable { private int size = 0; private Entry head = null; private static class Entry implements Serializable { String data; Entry next; Entry previous; } …// 이하 생략 } 논리적으로 말해서 이 클래스는 문자열 리스트를 표현한다. 물리적으로 보자면 이 리스트는 이중 연결 리스트다. 기본 직렬화 형태를 그대로 받아들일 경우, 모든 연결 리스트 항목과 항목 간 양방향 연결 구조가 직렬화 형식에 그대로 반영될 것이다. 객체의 물리적 표현 형태가 논리적 내용과 많이 다를 경우 기본 직렬화 형식을 그대로 받아들이면 네 가지 문제가 생기게 된다. 1. 공개 API가 현재 내부 표현 형태에 영원히 종속된다. 2. 너무 많은 공간을 차지하는 문제가 생길 수 있다. 3. 너무 많은 시간을 소비하는 문제가 생길 수 있다. 4. 스팩 오버플로 문제가 생길 수 있다.\nStringList의 적절한 직렬화 형식은 그저 리스트에 담기는 문자열의 수 다음에 실제 문자열들이 오는 형태일 것이다. StringList의 논리적 데이터 형태만을 나타내는 형식으로서, 물리적 표현 형태에 대한 세부사항은 제거된 것이다. 아래의 StringList 코드에는 이 직렬화 형식을 구현하는 writeObject와 readObject 메서드가 포함되어 있다.\n// 사용자 정의 직렬화 형식을 이용하는 StringList public final class StringList implements Serializable { private transient int size = 0; private transient Entry head = null; // 더 이상 Serializable일 필요가 없음 ! \tprivate static class Entry { String data; Entry next; Entry previous; } // 주어진 문자열을 리스트에 추가 \tpulbic final void add(String s) { … } /** * this가 가리키는 {@code StringList} 객체를 직렬화 * *@serialData 리스트의 크기(리스트 내 문자열 개수)가 먼저 기록되고 *({@code int}), 그 다음에는 모든 문자열({@code String} 각각)이 순서대로 기록된다. * */ private void writeObject(ObjectOutputStream s) throws IOException { s.defaultWriteObject(); s.writeInt(size); // 순서대로 모든 원소 기록 \tfor(Entry e = head; e != null; e = e.next) s.writeObject(e.data); } private void readObject(ObjectInputStream s) throws IOException, ClassNotFoundException { s.defaultReadObject(); int numElements = s.readInt(); // 모든 원소를 읽어 리스트에 저장 \tfor(int i = 0; i\u0026lt;numElements; i++) add((String) s.readObject()); } … // 이하 생략 } writeObject가 맨 처음으로 defaultWriteObject를 호출하고 있음에 유의하자. readObject가 처음으로 하는 것도 defaultReadObject를 호출하는 것이다. StringList의 모든 필드가 transient임에도 말이다. 객체의 모든 필드가 transient일 때는 defaultWriteObject나 defaultReadObject를 호출하지 않는 것도 기술적으로 가능하긴 하지만 권장하는 사항은 아니다.\n어떤 직렬화 형식을 이용하건, 직렬화 가능 클래스를 구현할 때는 직렬 버전 UID를 명시적으로 선언해야 한다. 그렇게 하면 직렬 버전 UID 때문에 생길 수 있는 잠재적 호환성 문제가 사라진다. 성능이 조금 개선되는 효과도 있다. 직렬 버전 UID를 지정하지 않으면 실행시간에 UID를 만드느라 시간이 많이 걸리는 계산을 하게 된다. 직렬 버전 UID를 선언하는 것은 간단하다. 클래스에 아래의 한줄을 추가하기만 하면 된다.\nprivate static final long serialVersionUID = \u0026lt;무작위로 고른 Long 값\u0026gt;; 새 클래스를 만드는 경우에는 위의 \u0026lt;\u0026gt; 자리에 무슨 값을 넣건 상관없다.\n규칙76 : readObject 메서드는 방어적으로 구현하라 readObject 메서드가 실질적으로는 public 생성자나 마찬가지고 생성자를 구현할 때와 같은 점에 주의해야 한다. 생성자와 마찬가지로 인자의 유효성을 검사해야 하고 필요하다면 인자를 방어적으로 복사해야 한다. readObject 메서드를 구현할 때 이런 사항들을 망각하면 공격자는 쉽게 클래스의 불변식을 망가뜨릴 수 있게 된다. 간단히 이야기해서, readObject는 바이트 스트림을 인자로 받는 생성자다. 일반적으로 이 바이트 스트림은 정상적인 과정을 통해 만들어진 객체를 직렬화한 결과다. 문제는 인공적으로 만들어진 바이트 스트림을 readObject에 인자로 넘길 때 생긴다. 클래스 불변식을 위반하는 객체를 만들어 낼 수 있게 되는 것이다.\n객체를 역으로 직렬화할 때는 클라리언트가 가질 수 없어야 하는 객체 참조를 담은 모든 필드를 방어적으로 복사하도록 해야 한다.\n// 방어적 복사와 유효성 검사를 모두 시행하는 readObject 메서드 private void readObject(ObjectInputStream s) throws IOException, ClassNotFoundException { s.defaultReadObject(); // 모든 변경 가능 필드를 방어적으로 복사  start = new Date(start.getTime()); end = new Date(end.getTime()); // 불변식이 만족되는지 검사  if (start.compareTo(end) \u0026gt; 0) throw new InvalidObjectException(start + \u0026#34; after \u0026#34; + end); } 유효성 검사 이전에 방어적 복사를 시행한다는 점과 final로 선언된 필드에는 방어적 복사를 할 수 없기 때문에 start와 end가 비-final인 것도 주의하자. 릴리즈 1.4부터 방어적 복사 없이도 악의적 객체 참조 공격을 막을 수 있도록 하기 위해 고안된 writeUnshared와 readUnshared 메서드는 사용하지 마라. 필요한 안전성을 제공하지 못한다.\nreadObject 메서드와 생성자에는 한 가지 유사성이 더 있다. readObject 메서드는 재정의 가능 메서드를 직접적이건 간접적이건 호출해서는 안 된다. 이 규칙을 위반할 경우, 하위 클래스 객체의 상태가 완전히 역직렬화 되기 전에 재정의한 메서드가 실행될 것이며 그 결과로 오류가 발생할 것이다.\n요약하자면, readObject 메서드를 구현할 때는 public 생성자를 구현할 때와 같은 마음가짐을 가지라는 것이다.\n규칙77 : 개체 통제가 필요하다면 readResolve 대신 enum 자료형을 이용하라 싱글턴 클래스를 만들어도 implements Serializable을 붙이는 순간 이 클래스는 더 이상 싱글턴 클래스가 아니다. 역직렬화되면서 생성된 객체는 초기화될 당시에 만들어진 객체와 다르다. 이때 readResolve를 이용하면 readObject가 만들어낸 객체를 다른 것으로 대체할 수 있다.\n// instance control을 위해 readResolve를 활용한 사례 private Object readResolve() { //유일한 객체를 반환하도록 하고 여기로 오는 바이트 스트림은 GC 대상이 되도록 한다. \treturn INSTANCE; } 이 메서드는 역으로 직렬화된 객체는 무시하고 클래스가 초기화될 당시에 만들어진 유일한 객체를 반환한다. 사실 instance control을 위해 readResolve를 활용 할 때는 객체 참조 자료형으로 선언된 모든 객체 필드를 반드시 transient로 선언해야 한다.\nEnum으로 싱글턴을 구현하면 선언된 상수 이외의 다른 객체는 존재할 수 없다는 확실한 보장이 생긴다.\n규칙78 : 직렬화된 객체 대신 직렬화 프락시를 고려해 보라 Serializable 인터페이스를 구현하겠다고 결정을 내리게 되면 버그나 보안 결함이 생길 가능성이 높아진다. 일반 생성자 대신 언어 외적인 메커니즘을 통해 객체를 생성할 수 있게 되기 때문이다. 이런 위험을 줄이기 위한 방법으로 직렬화 프락시 패턴이 있다.\n// Period 클래스의 직렬화 프락시 private static class SerializationProxy implements Serializable { private final Date start; private final Date end; SerializationProxy(Period p) { this.start = p.start; this.end = p.end; } private static final long serialVersionUID = 2344939929329329L; // 아무 수가 가능 } 우선 바깥 클래스 객체의 논리적 상태를 간결하게 표현하는 직렬화 가능 클래스를 private static 중첩 클래스로 설계한다. 이 중첩 클래스를 직렬화 프락시라고 부르는데, 바깥 클래스를 인자 자료형으로 사용하는 생성자를 하나만 가진다. 이 생성자는 인자에서 데이터를 복사하기만 한다. 일관성 검사를 할 필요도 없고, 방어적 복사를 할 필요도 없다. 설계상 직렬화 프락시의 기본 직렬화 형식은 바깥 클래스의 완벽한 직렬화 형태다.\n// 직렬화 프락시 패턴을 구현하기 위한 writeReplace 메서드 private Object writeReplace() { return new SerializationProxy(this); } 프락시를 추가한 다음 바깥 클래스 아래에 writeReplace 메서드를 구현한다. 이 메서드는 직렬화 프락시가 있는 클래스라면 아무 수정 없이 그대로 사용할 수 있다. 이 메서드가 있으면 직렬화 시스템은 바깥 클래스 객체 대신 SerializationProxy 객체를 직렬화한다. 다시 말해 writeReplace 메서드는 직렬화가 이루어지기 전에 바깥 클래스 객체를 직렬화 프락시 객체로 변환한다.\n바깥 클래스로 직렬화된 객체를 악의적으로 만들 수 있기 때문에 readObject 메서드를 추가한다.\n// 직렬화 프락시 패턴 구현을 위한 readObject 메서드 private void readObject(ObjectInputStream stream) throws InvalidObjectException{ throw new InvalidObjectException(\u0026#34;Proxy required\u0026#34;); } 마지막으로 SerializationProxy 클래스에 자기와 논리적으로 동일한 바깥 클래스 객체를 반환하는 readResolve 메서드를 추가해야 한다. 이 메서드가 있으면 직렬화 시스템은 역직렬화를 끝내자마자 직렬화 프락시 객체를 다시 바깥 클래스 객체로 변환하게 된다.\n// Period.SerializationProxy의 readResolve 메서드 private Object readResolve() { return new Period(start, end); // public 생성자 이용 } 마지막으로 직렬화 프락시 패턴은 클라이언트가 확장 할 수 있는 클래스에는 적용할 수 없다.\n"
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/effective_java/",
	"title": "Effective Java(3rd edition 작업중)",
	"tags": [],
	"description": "",
	"content": " Effective java "
},
{
	"uri": "/finalizer-attack/",
	"title": "Finalizer attack",
	"tags": [],
	"description": "",
	"content": " 참고 : https://www.ibm.com/developerworks/library/j-fv/j-fv-pdf.pdf\nHow to attack Finalizers는 객체 생성할 때 취약점이 존재한다. finalizer의 개념은 java 메소드가 os로 리턴해야하는 자원을 해제 할 수있게 하는 것인데 finalizer에서 자바 코드가 실행될 수 있으므로 아래와 같은 코드가 허용된다.\npublic class Zombie { static Zombie zombie; public void finalize() { zombie = this; } } Zombie finalizer가 호출됐을 때 zombie static 변수에 this가 저장된다. 객체는 다시 접근할 수 있게 됐고 gc되지 않는다.\n더 교활한 버전은 부분적으로 구성된 오브젝트조차도 부활시킬 수 있다.\npublic class Zombie2 { static Zombie2 zombie; int value; public Zombie2(int value) { if(value \u0026lt; 0) { throw new IllegalArgumentException(\u0026#34;Negative Zombie2 value\u0026#34;); } this.value = value; } public void finalize() { zombie = this; } } 객체가 value 조건을 충족시키지 못하는 경우에도 finalizer로 작성할 수 있다. finalize () 메소드의 존재로 인해 value 인수에 대한 검사의 결과는 무효화된다.\n물론 아무도 위와 같은 코드를 작성하지는 않는다. 그러나 클래스가 subclassed된 경우 취약점이 발생할 수 있다.\nclass Vulnerable { Integer value = 0; Vulnerable(int value) { if (value \u0026lt;= 0) { throw new IllegalArgumentException(\u0026#34;Vulnerable value must be positive\u0026#34;); } this.value = value; } @Override public String toString() { return (value.toString()); } }public class AttackVulnerable extends Vulnerable { static Vulnerable vulnerable; public AttackVulnerable(int value) { super(value); } public void finalize() { vulnerable = this; } public static void main(String[] args) { try { new AttackVulnerable(-1); } catch (Exception e) { System.out.println(e); } System.gc(); System.runFinalization(); if (vulnerable != null) { System.out.println(\u0026#34;Vulnerable object \u0026#34; + vulnerable + \u0026#34; created!\u0026#34;); } } } AttackVulnerable 클래스의 메인 메서드에서 새로운 AttackVulnerable 객체 생성을 시도한다. value가 -1이기 때문에 Exception이 발생하고 catch 블록으로 온다. System.gc()와 System.runFinalization() 호출은 vm이 gc를 실행하고 모든 finalizer를 실행하도록 권장한다.\n이러한 호출은 공격이 성공하는 데 반드시 필요한 것은 아니지만 공격의 최종 결과를 보여준다. 즉, 값이 잘못된 Vulnerable 개체가 만들어진다.\njava.lang.IllegalArgumentException: Vulnerable value must be positive Vulnerable object 0 created! Process finished with exit code 0  실행하면 위와 같은 결과가 나온다. 왜 Vulnerable value가 -1가 아니라 0일까? Vulnerable 생성자에서 인자 검사전까지는 value 할당을 하지 않은것을 주목해라. 그래서 value는 초기값 0이다.\n이러한 종류의 공격은 명시적인 보안 검사를 우회하는 데 사용될 수도 있다. 아래의 예제는 현재 디렉토리에 write 권한이 없을 때 SecurityException이 발생하도록 설계됐다.\npublic class Insecure { Integer value = 0; public Insecure(int value) { SecurityManager sm = System.getSecurityManager(); if (sm != null) { FilePermission fp = new FilePermission(\u0026#34;index\u0026#34;, \u0026#34;write\u0026#34;); sm.checkPermission(fp); } this.value = value; } @Override public String toString() { return (value.toString()); } }public class AttackInsecure extends Insecure { static Insecure insecure; public AttackInsecure(int value) { super(value); } public void finalize() { insecure = this; } public static void main(String[] args) { try { new AttackInsecure(-1); } catch (Exception e) { System.out.println(e); } System.gc(); System.runFinalization(); if (insecure != null) { System.out.println(\u0026#34;Insecure object \u0026#34; + insecure + \u0026#34; created!\u0026#34;); } } } java -Djava.security.manager AttackInsecure java.security.AccessControlException: Access denied (java.io.FilePermission index write) Insecure object 0 created!  How to avoid the attack Java Language Specification (JLS) 세번째 edition 까지는 initialized flag, subclassing 금지, final finalizer 생성 세가지였고 불충분한 해결책이었다.\ninitialized flag\n객체가 정상적으로 생성될 때 flag값을 셋팅하고 메서드 호출 때마다 제일 먼저 저 flag 값을 검사하는 방법이다. 이 코딩 기법은 작성하기 번거롭고 실수로 생략하기 쉽다. 그리고 subclassing을 통한 공격을 막을 수는 없다.\npreventing subclssing\n클래스를 final로 선언함으로써 subclass 자체를 막아버린다. 하지만 이 기법은 확장성 자체를 없애버린다.\ncreate a final finalizer\nfinal finalizer 메서드를 생성함으로써 subclass에서 finalizer 메서드 재사용을 금지시킨다. 이 접근의 단점은 finalizer 존재가 그것이 없는 것보다 더 오래 살아 있다는것을 의미한다는 점이다.\nA newer, better way 추가 코드나 제한없이 이러한 종류의 공격을 막기위해 자바 설계자는 JLS를 수정하여 java.lang.Object가 생성되기 전에 exception이 생성자에서 발생하면 finalize 메서드가 실행되지 않는다.\n그런데 java.lang.Object가 생성되기 전에 어떻게 exception이 발생할 수 있냐? 결국 모든 생성자의 첫행은 this() 또는 super()에 대한 호출이어야 한다. 생성자에 명시적으로 호출이 포함되어 있지 않으면 super() 호출이 암시적으로 추가된다. 따라서 객체가 생성되기 전에 동일한 클래스 또는 슈퍼 클래스의 다른 객체가 만들어져야 한다. 결국 생성되고 있는 메서드의 코드가 실행되기 전에 java.lang.Object 자체의 생성과 모든 subclass의 생성이 이뤄진다.\njava.lang.Object가 생성되기 전에 예외를 throw하는 방법을 이해하려면, Object 생성 순서를 정확하게 이해해야한다. JLS는 순서를 명시적으로 작성했다.\nObject가 생성될 때 JVM은 다음과 같이 동작한다. 1. 객체를 위한 공간을 할당한다. 2. 객체의 모든 인스턴스 변수를 기본값으로 설정. 여기에는 객체의 수퍼 클래스에 있는 인스턴스 변수가 포함된다. 3. 객체에 대한 파라미터 변수를 지정한다. 4. 명시적 또는 암시적 생성자 호출 (생성자에서 this () 또는 super () 호출)을 처리한다. 5. 클래스의 변수를 초기화한다. 6. 생성자의 나머지 부분을 실행한다.\n요점은 생성자 내의 모든 코드가 처리되기 전에 생성자의 파라미터가 처리된다는 것이다. 즉, 파라미터를 처리하는 동안 유효성 검사를 수행하면 예외를 throw하여 클래스가 finalize 되지 않도록 할 수 있다.\npublic class Invulnerable { int value = 0; Invulnerable(int value) { this(checkValues(value)); this.value = value; } private Invulnerable(Void checkValues) { } static Void checkValues(int value) { if (value \u0026lt;= 0) { throw new IllegalArgumentException(\u0026#34;Invulnerable value must be positive\u0026#34;); } return null; } @Override public String toString() { return (Integer.toString(value)); } } 위 코드를 보면 public 생성자 Invulnerable에서 checkValues 메서드를 수행하고 그 결과로 private 생성자를 호출한다. 이 메서드는 생성자가 super class의 생성자를 호출하기 전에 호출된다. 따라서 checkValues에 예외가 발생하면 Invulnerable 객체는 finalize 되지 않는다.\npublic class AttackInvulnerable extends Invulnerable { static Invulnerable vulnerable; public AttackInvulnerable(int value) { super(value); } public void finalize() { vulnerable = this; } public static void main(String[] args) { try { new AttackInvulnerable(-1); } catch (Exception e) { System.out.println(e); } System.gc(); System.runFinalization(); if (vulnerable != null) { System.out.println(\u0026#34;Invulnerable object \u0026#34; + vulnerable + \u0026#34;created !\u0026#34;); } else { System.out.println(\u0026#34;Attack failed\u0026#34;); } } } java.lang.IllegalArgumentException: Invulnerable value must be positive Attack failed  "
},
{
	"uri": "/gitflow/",
	"title": "Git Flow",
	"tags": [],
	"description": "",
	"content": " 참고 : http://nvie.com/posts/a-successful-git-branching-model/ 이 작업 흐름 모델은 branch 그룹에 역할을 부여하고 branch들간의 상호작용을 엄격하게 제한한다. 이 모델은 branch를 5 가지 역할로 나눈다.\n1. develop branch 2. feature branch 3. release branch 4. master branch 5. hotfix branch\ndevelop branch\ndevelop branch는 하나만 존재한다. 여기에서 모든 개발이 시작된다. 하지만 절대로 develop branch에 곧바로 commit하지 않는다. 이 브랜치에 merge되는 것은 feature branch와 release나 hotfix의 버그 수정이다. 이 branch는 오직 merge commit만 할 수 있다.\nfeature branch\nfeature branch는 여러 개 존재할 수 있다. 여기에 속하는 branch는 develop branch를 기반에 두고 새롭게 branch되어 새로운 기능 개발이나 버그 수정을 담당한다. 그리고 각각의 branch는 하나의 기능(의도)만을 맡는다. 따라서 branch의 이름을 제대로 짓는 것이 중요하다. feature branch들은 오직 develop branch에 merge될 때만 관계성이 생긴다. 갈라져 나오는 것도 다시 merge하는 것도 오직 develop branch와 한다.\nrelease branch\nrelease branch는 develop branch에서 갈라져 나와서 배포 준비를 하는 branch이다. 이 branch는 새로운 기능 추가는 더 하지 않고 오로지 버그 수정만 한다. 즉 배포본의 완성도를 높이는 branch이다. 당연히 수정된 버그는 develop branch로 merge되야 한다.\nmaster branch\nmaster branch는 실제 배포되는 버전이 있는 branch이다. 이 branch는 오직 release와 hotfix branch하고만 관계를 맺는다. hotfix branch\nhotfix branch는 master branch, 즉 현재 배포 중인 코드에 버그가 있어 급히 수정할 때만 사용하는 branch이다. hotfix branch로 수정한 내용은 master와 develop branch에만 반영한다. 정리\ndevelop branch를 중심으로 feature branch들을 통해 기능을 추가하고, release branch를 통해 배포 준비와 코드의 버그를 수정하며, master로 배포하고, hotfix로 배포된 버전의 버그를 수정해 master와 develop branch에 반영하는 것을 반복하는 것이 git-flow 작업 흐름이다.\nGit-Rebase 아래 커밋 그래프는 일반적으로 merge했을 때의 모습이다. 하지만 두 개를 넘어서 세 개 이상의 branch가 하나의 master branch에 merge된다고 해보자. 구체적으로 설명해보면 hotfix1 branch를 만든 이후에 master branch에 어떠한 커밋 내역이 있는 상태로 hotfix2, hotfix3 branch를 만들어서 각각 커밋을 했고, hotfix1 branch에도 다른 커밋 내역이 있는 상황이다. 이를 차례대로 master branch에 merge한다고 해보자.\n먼저 hotfix1 branch를 merge해봤다. 이번에는 hotfix2 branch를 merge했다. 벌써 커밋 그래프가 상당히 꼬여가는 것이 보인다. 이제 hotfix3 branch를 merge한 다음이다. 이제 그냥 보기만 해도 꽤 복잡해 보인다. 고작 세 개째인데 말이다. 프로젝트 멤버가 세 명 이상이면 혹은 동시에 개발 중인 기능이 여러 개라면 브랜치가 세 개 이상으로 생성되는 일은 매우 흔한 상황이다. 그럴 때마다 각자의 코드를 master branch에 반영하면 커밋 내역 그래프가 매우 알아보기 어려울 것이다. 하지만 git rebase 명령을 사용하면 이를 깔끔하게 정리할 수 있다(rebase는 단어 그대로 다시 base를 정하는 것이다).\ngit-rebase 구체적인 과정\n최초 커밋 그래프는 다음과 같다. hotfix1 branch부터 정리해보겠다. master branch 앞으로 hotfix1 branch를 이동시키는 것이다. 따라서 git checkout hotfix1 명령을 실행해 master branch에서 hotfix1 branch로 체크아웃한다. 그리고 git rebase master 명령을 실행한다. 충돌이 나면 해결하기 위해 git rebase는 세 가지 옵션을 제공한다.\ngit rebase --continue : 충돌 생태를 해결한 후 계속 작업을 진행할 수 있게 한다. git rebase --skip : merge 대상 branch의 내용으로 강제 merge를 실행한다. 즉 여기서 명령을 실행하면 master branch를 강제로 merge한 상태가 된다. 또한 해당 branch에서는 다시 git rebase 명령을 실행할 수 없다. git rebase --abort : git rebase 명령을 실행을 취소한다.  명령을 실행하면 master branch의 공통 부모까지의 hotfix1 branch의 커밋을 master branch의 뒤에 차례대로 적용한다. 명령어를 자세히 살펴보면 더 쉽게 이해할 수 있다. (hotfix) rebase (onto) master라는 거다. 즉, 현재 작업중인 branch의 base를 master로 다시 설정하라는 말이다. 여기까지만이라면 단순하게 hotfix1과 master branch가 따로따로 있는 것에 불과하다. 말 그대로 hotfix1의 base를 다시 설정한 것과 같은 효과다. merge 해야만 비로소 master branch에 hotfix1 branch가 반영이 된다. 그런데 git rebase 명령을 실행하면 무조건 fast-forward가 가능하지만, 이런 경우 merge 커밋을 남기는 것도 좋다. git merge hotfix1 --no-ff라는 명령을 실행해 fast-forward를 하지 말라는 옵션을 주어서 merge를 실행하면 아래와 같은 그래프가 된다. 따라서 git checkout master 명령을 실행해 master branch로 이동한 후 git merge hotfix1 --no-ff명령을 실행해 최종 merge를 해준다.\n"
},
{
	"uri": "/junit+mockito_vs_groovy+spock/",
	"title": "JUnit+Mockito vs Groovy+Spock",
	"tags": [],
	"description": "",
	"content": " 발표 순서 1. Spock 기본적인 문법 2. 블로그에서 groovy를 이용한 통합테스트 방식 소개 3. 간단한 Spock 적용 후기\ncf) 마지막 부분에 Spring Boot 1.4 Test방식 소개\nSpock 참고 : http://thejavatar.com/testing-with-spock/ 참고 : http://farenda.com/spock-framework-tutorial/\n먼저 의존성 추가\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.spockframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spock-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0-groovy-2.4\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 스프링 프로젝트\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.spockframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spock-spring\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0-groovy-2.4\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 첫 예제 3개의 섹션으로 나눠진다(BDD에 기반해서 given when then).\ncf) expect는 간단한 테스트할 때\nclass SpockNameInverterTest extends Specification{ def \u0026#34;NameInverter 테스트\u0026#34;(){ expect: invert(null) == \u0026#34;\u0026#34; } private String invert(String name){ return null; } } Stub def \u0026#34;creating example stubs\u0026#34;() { given: List list = Stub(List) List list2 = Stub() // preffered way  def list3 = Stub(List) }def \u0026#34;Stub 사용법\u0026#34;() { given: List list = Stub() list.size() \u0026gt;\u0026gt; 3 expect: list.size() == 3 } 조금 더 난이도 있는 UserService 예제\npublic class User { String name; } public interface UserService { void save(User user); }def \u0026#34;유저 이름이 Norman이면 exception, 유저이름이 R이면 정상처리\u0026#34;() { given: UserService service = Stub() service.save({ User user -\u0026gt; \u0026#39;Norman\u0026#39; == user.name }) \u0026gt;\u0026gt; { throw new IllegalArgumentException(\u0026#34;We don\u0026#39;t want you here, Norman!\u0026#34;) } when: User user = new User(name: \u0026#39;Norman\u0026#39;) service.save(user) then: thrown(IllegalArgumentException) when: User user2 = new User(name: \u0026#39;R\u0026#39;) service.save(user2) then: notThrown(IllegalArgumentException) } wildcard\ngiven: // 모든 인자 허용  list.contains(_) \u0026gt;\u0026gt; true // 모든 Integer 인자 허용  list.add(_ as Integer) \u0026gt;\u0026gt; true // null이 아니면 허용  list.add(!null) \u0026gt;\u0026gt; true // someObject가 아니면 허용  list.add(!someObject) \u0026gt;\u0026gt; truedef \u0026#34;만약 리스트에 Integer 추가하면 예외처리\u0026#34;() { given: List list = Stub() list.add(_ as Integer) \u0026gt;\u0026gt; { throw new IllegalArgumentException() } when: list.add(2) then: thrown(IllegalArgumentException) when: list.add(\u0026#34;String\u0026#34;) then: notThrown(IllegalArgumentException) } cf) JDK7에서 새롭게 소개된 Invokedynamic. 자바는 static type 언어라고 불리며, 이는 컴파일 타임에서 이미 멤버 변수들이나 함수 변수들의 타입이 반드시 명시적으로 지정돼야 함을 의미한다. 그에 반해 루비나 자바스크립트는 이른바 ‘duck-typing’이라고 하는 타입 시스템을 사용함으로써 컴파일 타임에서의 타입을 강제하지 않는다. Invokedynamic은 이러한 duck-typing을 JVM레벨에서 기본적으로 지원하면서 자바 외에 다른 언어들이 JVM이라는 플랫폼 위에서 최적화된 방식으로 실행될 수 있는 토대를 제공한다.\nMock def \u0026#34;creating example mocks\u0026#34;() { given: List list = Mock(List) List list2 = Mock() // preffered way  def list3 = Mock(List) } Dummy 객체 자체를 테스트하기보다 여러 인터페이스들이 연결되어 있는 특정 메서드를 체크하는게 더 관심있을 때 Mock이나 Spy를 쓴다.\ncf) Stub vs Mock Stub 은 테스트 과정에서 일어나는 호출에 대해 지정된 답변을 제공하고, 그 밖의 테스트를 위해 별도로 프로그래밍 되지 않은 질의에 대해서는 대게 아무런 대응을 하지 않는다.\nMock Object 는 검사하고자 하는 코드와 맞물려 동작하는 객체들을 대신하여 동작하기 위해 만들어진 객체이다. 검사하고자 하는 코드는 Mock Object 의 메서드를 부를 수 있고, 이 때 Mock Object는 미리 정의된 결과 값을 전달한다.\ncf) 토비의 스프링에서 Stub과 Mock 비교 Stub은 테스트 대상 Object의 의존객체로 존재하면서 테스트 동안에 코드가 정상적으로 수행할 수 있도록 돕는다. 때론 테스트 대상 Object가 의존 Object에게 출력한 값에 관심이 있거나, 의존 Object를 얼마나 사용했는가 하는 커뮤니케이션 행위 자체에 관심이 있을 수 있다. 문제는 이 정보를 테스트에서는 직접 알 수가 없기 때문에 목 객체를 만들어서 사용해야 한다.\nSpy Stub이나 Mock과는 다르게 Spy는 Dummy 객체가 아니다. Spy는 실제 일반 객체를 감싼것이다. Spy를 만들 때는 interface로 만들지 않고 class로 만들어야 한다.\ndef \u0026#34;interface로 Spy 만들면 안된다.\u0026#34;() { given: UserService service = Spy(UserService) expect: service.save(new User(name: \u0026#39;Norman\u0026#39;)) } 결과 : Cannot invoke real method on interface based mock object 아래의 예제는 Transaction 객체를 생성자 인수로 받는 UserServiceImpl 클래스를 Spy한다.\npublic interface Transaction { } public interface UserService { boolean isServiceUp(); void save(User user); } public class UserServiceImpl implements UserService{ public UserServiceImpl(Transaction transaction) { } @Override public boolean isServiceUp() { return false; } @Override public void save(User user) { System.out.println(\u0026#34;UserServiceImpl\u0026#34;); } }def \u0026#34;class로 Spy를 만들어야 된다.\u0026#34;() { given: Transaction transaction = Stub(Transaction) UserService service = Spy(UserServiceImpl, constructorArgs: [transaction]) expect: service.save(new User(name: \u0026#39;Norman\u0026#39;)) } cf) 참고자료에서는 이렇게 하면 Spy객체가 만들어진다고 했는데 나는 에러가 발생함. cglib 의존성 추가해주니 Spy 객체 생성됌.\norg.spockframework.mock.CannotCreateMockException: Cannot create mock for class spock.basic.UserServiceImpl. Mocking of non-interface types requires the CGLIB library. Please put cglib-nodep-2.2 or higher on the class path. \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;cglib\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;cglib\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; where: def \u0026#34;다양한 제곱 테스트\u0026#34;() { expect: Math.pow(base, 2) == expectedResult where: base || expectedResult 2 || 4 3 || 9 10 || 100 } 블로그에서 groovy를 이용한 통합테스트 방식 소개 참고 : http://groovy-coder.com/?p=111\n올랑(Hollandaise) 소스를 만들기 위해서는 cooking temperature를 매우 정밀하게 조절해야 한다.\n그래서 올랑(Hollandaise) 소스를 위해 애플리케이션에서 temperature monitoring 하는 system을 만든다고 해보자. HollandaiseTemperatureMonitor 클래스(production code)는 다음과 같다.\n@Service public class HollandaiseTemperatureMonitor { /** Maximum hollandaise cooking temperature in degree celsius */ private static final int HOLLANDAISE_MAX_TEMPERATURE_THRESHOLD = 80; /** Minimum hollandaise cooking temperature in degree celsius */ private static final int HOLLANDAISE_MIN_TEMPERATURE_THRESHOLD = 45; private final Thermometer thermometer; @Autowired public HollandaiseTemperatureMonitor(Thermometer thermometer) { this.thermometer = thermometer; } public boolean isTemperatureOk() { int temperature = thermometer.currentTemperature(); boolean belowMinimumThreshold = temperature \u0026lt; HOLLANDAISE_MIN_TEMPERATURE_THRESHOLD; boolean aboveMaximumThreshold = temperature \u0026gt; HOLLANDAISE_MAX_TEMPERATURE_THRESHOLD; boolean outOfLimits = belowMinimumThreshold || aboveMaximumThreshold; return !outOfLimits; } } Spock을 이용한 단위 테스트\nclass HollandaiseTemperatureMonitorSpec extends Specification { @Unroll def \u0026#34;returns #temperatureOk for temperature #givenTemperature\u0026#34;() { given: \u0026#34;a stub thermometer returning given givenTemperature\u0026#34; Thermometer thermometer = Stub(Thermometer) thermometer.currentTemperature() \u0026gt;\u0026gt; givenTemperature and: \u0026#34;a monitor with the stubbed thermometer\u0026#34; HollandaiseTemperatureMonitor watchman = new HollandaiseTemperatureMonitor(thermometer) expect: watchman.isTemperatureOk() == temperatureOk where: givenTemperature || temperatureOk 0 || false 100 || false 80 || true 45 || true 60 || true -10 || false } } cf) @Unroll : Indicates that iterations of a data-driven feature should be made visible as separate features to the outside world(IDEs, reports, etc.) 테스트 구현에 영향을 미치지 않음.\n통합 테스트\n@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT) class ApplicationSpecWithoutAnnotation extends Specification { @Autowired WebApplicationContext context def \u0026#34;should boot up without errors\u0026#34;() {expect: \u0026#34;web application context exists\u0026#34; context != null } } @SpringApplicationConfiguration 대신에 @SpringBootTest를 사용한다. 그러나 아직 Spring Boot 1.4는 Spock과 호환되지 않는다. spock-spring 플러그인이 @SpringBootTest를 인식하지 못한다. 그래서 @SpringBootTest 이전에 @ContextConfiguration이나 @ContextHierarchy를 추가해줘야 한다. cf) @DataJpaTest,@WebMvcTest도 아직 지원안한다.\n@ContextConfiguration // not mentioned by docs, but had to include this for Spock to startup the Spring context @SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT) class SpringBootSpockTestingApplicationSpecIT extends Specification { @Autowired WebApplicationContext context def \u0026#34;should boot up without errors\u0026#34;() { expect: \u0026#34;web application context exists\u0026#34; context != null } } 간단한 Spock 적용 후기 Name Inverter 참고 : https://www.youtube.com/watch?v=czjWpmy3rkM\nspock으로 진행해봤는데 에러가 났을 때 좀 더 친절한 메세지 외에는 장점을 못느꼈습니다(중요한건 리팩토링이지 명세가 아닌거 같습니다). 미담 프로젝트 단위 테스트 java+mockito\n@Mock MessageRepository messageRepository; @Mock EmployeeRepository employeeRepository; @Mock EpisodeCountRepository episodeCountRepository; @Before public void setUp() throws Exception { MockitoAnnotations.initMocks(this); messageService = new MessageService(messageRepository, employeeRepository, episodeCountRepository); messageFixture(); }@Test(expected = NotStartException.class) public void 시작안했는데_랜덤메세지를_호출하면_예외가_잘_발생하나_확인(){ // Given  messages = Arrays.asList(message1,message2,message3); // When  when(episodeCountRepository.findEpisodeCount()).thenReturn(3L); when(messageRepository.findByEpisode(3L)).thenReturn(messages); when(episodeCountRepository.findEventStatus()).thenReturn(true); MessageService messageServiceSpy = Mockito.spy(messageService); when(messageServiceSpy.createRandom(3)).thenReturn(1); when(messageServiceSpy.getMessageByRandom()).thenReturn(message1); // Then  messageServiceSpy.getMessageByRandom(); } groovy+spock\ndef \u0026#34;시작안했는데 랜덤메세지를 호출하면 예외가 잘 발생하나 확인\u0026#34;(){ given: List\u0026lt;Message\u0026gt; messages = messageFixture() def mockMessageRepository = Mock(MessageRepository.class) def mockEmployeeRepository = Mock(EmployeeRepository.class) def mockEpisodeCountRepository = Mock(EpisodeCountRepository.class) def messageService = new MessageService(mockMessageRepository, mockEmployeeRepository, mockEpisodeCountRepository) when: mockMessageRepository.findByEpisode(3L) \u0026gt;\u0026gt; messages mockEpisodeCountRepository.findEpisodeCount() \u0026gt;\u0026gt; 3L; mockEpisodeCountRepository.findEventStatus() \u0026gt;\u0026gt; true messageService.getMessageByRandom() then: thrown(NotStartException.class) } Spring Boot 1.4 Test방식 변경부분 소개 참고 : https://spring.io/blog/2016/04/15/testing-improvements-in-spring-boot-1-4\nSpring Framework 4.3부터 생성자를 통한 주입에서 더이상 @Autowired가 필요 없어졌다. 생성자가 하나만 있다는 전제하에 Spring이 autowire target으로 본다.\n@Component public class MyComponent { private final SomeService service; public MyComponent(SomeService service) { this.service = service; } } 그래서 MyComponent 테스트가 쉬워진다.\n@Test public void testSomeMethod() { SomeService service = mock(SomeService.class); MyComponent component = new MyComponent(service); // setup mock and class component methods } Spring Boot 1.3에서\n@RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(classes=MyApp.class, loader=SpringApplicationContextLoader.class) public class MyTest { // ...  } @ContextConfiguration과 SpringApplicationContextLoader를 조합해서 썼다.\n@RunWith(SpringJUnit4ClassRunner.class) @SpringApplicationConfiguration(MyApp.class) public class MyTest { // ...  } @SpringApplicationConfiguration을 쓸 수도 있었다.(이게 더 직관적으로 보여서 이걸 썼다.)\n@RunWith(SpringJUnit4ClassRunner.class) @SpringApplicationConfiguration(MyApp.class) @IntegrationTest public class MyTest { // ...  } @IntegrationTest을 쓰는 방법도 있었다. 또는 @WebIntegrationTest(@IntegrationTest + @WebAppConfiguration)\n@RunWith(SpringJUnit4ClassRunner.class) @SpringApplicationConfiguration(MyApp.class) @WebIntegrationTest public class MyTest { // ...  } 마지막으로 random port로 돌릴 수도 있고 @WebIntegrationTest(randomPort=true) 추가적인 프로퍼티 설정도 있다. @IntegrationTest(\u0026quot;myprop=myvalue\u0026quot;) or @TestPropertySource(properties=\u0026quot;myprop=myvalue\u0026quot;)\n선택지가 너무 많아서 고통스럽다.\nSpring Boot 1.4에서는\n@RunWith(SpringRunner.class) @SpringBootTest(webEnvironment=WebEnvironment.RANDOM_PORT) public class MyTest { // ...  } SpringRunner는 기존의 SpringJUnit4ClassRunner의 새로운 이름이다. 그리고 @SpringBootTest로 심플해졌다. webEnvironment속성은 테스트에서 Mock 서블릿 환경 또는 진짜 HTTP server(RANDOM_PORT or DEFINED_PORT)를 설정할 수 있다.\n만약 specific configuration을 load하고 싶으면 @SpringBootTest의 classes속성을 사용하면 된다. classes속성을 생략하면 inner-classes에서 @Configuration을 제일 먼저 load하려 시도하고, 없다면 @SpringBootApplication class를 찾는다.\n@RunWith(SpringRunner.class) @SpringBootTest(webEnvironment=WebEnvironment.RANDOM_PORT) public class MyTest { @Autowired private TestRestTemplate restTemplate; @Test public void test() { this.restTemplate.getForEntity( \u0026#34;/{username}/vehicle\u0026#34;, String.class, \u0026#34;Phil\u0026#34;); } } @SpringBootTest가 사용되는곳에서는 TestRestTemplate이 빈으로 사용가능하다.\nMocking and spying\n@RunWith(SpringRunner.class) @SpringBootTest(webEnvironment = WebEnvironment.RANDOM_PORT) public class SampleTestApplicationWebIntegrationTests { @Autowired private TestRestTemplate restTemplate; @MockBean private VehicleDetailsService vehicleDetailsService; @Before public void setup() { given(this.vehicleDetailsService. getVehicleDetails(\u0026#34;123\u0026#34;) ).willReturn( new VehicleDetails(\u0026#34;Honda\u0026#34;, \u0026#34;Civic\u0026#34;)); } @Test public void test() { this.restTemplate.getForEntity(\u0026#34;/{username}/vehicle\u0026#34;, String.class, \u0026#34;sframework\u0026#34;); } } 위의 예에서 VehicleDetailsService Mockito mock을 만들고 ApplicationContext에 빈으로 주입시켰다. 그리고 setup 메서드에서 Stubbing behavior를 했다. 최종적으로 mock을 호출할 테스트를 만들었다. Mock들은 테스트마다 자동적으로 리셋되기 때문에 @DirtiesContext가 필요없다. (@DirtiesContext 사용은 applicationContext의 제어를 받지 않고 직접 통제하겠다는 것)\nspy도 유사하다. @SpyBean을 통해 ApplicationContext에 존재하는 빈을 spy로 감싼다.\nTesting the JPA slice\n@RunWith(SpringRunner.class) @DataJpaTest public class UserRepositoryTests { @Autowired private TestEntityManager entityManager; @Autowired private UserRepository repository; @Test public void findByUsernameShouldReturnUser() { this.entityManager.persist(new User(\u0026#34;sboot\u0026#34;, \u0026#34;123\u0026#34;)); User user = this.repository.findByUsername(\u0026#34;sboot\u0026#34;); assertThat(user.getUsername()).isEqualTo(\u0026#34;sboot\u0026#34;); assertThat(user.getVin()).isEqualTo(\u0026#34;123\u0026#34;); } } @DataJpaTest는 1. Configure an in-memory database. 2. Auto-configure Hibernate, Spring Data and the DataSource. 3. Perform an @EntityScan 4. Turn on SQL logging\nTestEntityManager는 Spring Boot에서 제공한다. standard JPA EntityManager를 대신한다.\n[용어정리] Mock Object Mock Object 는 검사하고자 하는 코드와 맞물려 동작하는 객체들을 대신하여 동작하기 위해 만들어진 객체이다. 검사하고자 하는 코드는 Mock Object 의 메서드를 부를 수 있고, 이 때 Mock Object는 미리 정의된 결과 값을 전달한다. MockObject는 자신에게 전달된 인자를 검사할 수 있으며, 이를 테스트 코드로 전달할 수도 있다.\nstub Stub 은 테스트 과정에서 일어나는 호출에 대해 지정된 답변을 제공하고, 그 밖의 테스트를 위해 별도로 프로그래밍 되지 않은 질의에 대해서는 대게 아무런 대응을 하지 않는다. 또한 Stub은 email gateway stub 이 \u0026lsquo;보낸\u0026rsquo; 메시지를 기억하거나, \u0026lsquo;보낸\u0026rsquo; 메일 개수를 저장하는 것과 같이, 호출된 내용에 대한 정보를 기록할 수 있다. Mock은 Mock 객체가 수신할 것으로 예상되는 호출들을 예측하여 미리 프로그래밍한 객체이다.\nexample\n1. Behavior verify //Let\u0026#39;s import Mockito statically so that the code looks clearer import static org.mockito.Mockito.*; //mock creation List mockedList = mock(List.class); //using mock object mockedList.add(\u0026#34;one\u0026#34;); mockedList.clear(); //verification verify(mockedList).add(\u0026#34;one\u0026#34;); verify(mockedList).clear(); 2. Stubbing //You can mock concrete classes, not only interfaces LinkedList mockedList = mock(LinkedList.class); //stubbing when(mockedList.get(0)).thenReturn(\u0026#34;first\u0026#34;); when(mockedList.get(1)).thenThrow(new RuntimeException()); //following prints \u0026#34;first\u0026#34; System.out.println(mockedList.get(0)); //following throws runtime exception System.out.println(mockedList.get(1)); //following prints \u0026#34;null\u0026#34; because get(999) was not stubbed System.out.println(mockedList.get(999)); //Although it is possible to verify a stubbed invocation, usually it\u0026#39;s just redundant //If your code cares what get(0) returns then something else breaks (often before even verify() gets executed). //If your code doesn\u0026#39;t care what get(0) returns then it should not be stubbed. Not convinced? See here. verify(mockedList).get(0);"
},
{
	"uri": "/java8_in_action/part1/",
	"title": "Part1 기초",
	"tags": [],
	"description": "",
	"content": " 1장 - 자바8을 눈여겨봐야 하는 이유 Stream processing : stream이란 한번에 한 개씩 만들어지는 연속적인 데이터 항목들의 모임을 말한다.\n동작 파라미터화 : 메서드를 다른 메서드의 인수로 넘겨주는 기능을 제공한다.\n병렬성과 공유 가변 데이터 : 다른 코드와 동시에 실행하더라도 안전하게 실행할 수 있는 코드를 만드려면 공유된 가변 데이터에 접근하지 말아야 한다. 이런 함수를 pure 함수, stateless 함수라 부른다.\n자바 함수 프로그래밍 언어에서 함수라는 용어는 메서드 특히 정적 메서드와 같은 의미로 사용된다. 자바의 함수는 이에 더해 수학적인 함수처럼 사용되며 부작용을 일으키지 않는 함수를 의미한다.\n자바8에서는 함수를 새로운 값의 형식으로 추가했다.(즉, 함수 자체가 값)\n메서드 레퍼런스\nex) 디렉토리에서 모든 숨겨진 파일을 필터링하는 문제에서 우선 주어진 파일이 숨겨져 있는지 체크하는 기능\nFile[] hiddenFiles = new File(“.”).listFiles(new FileFilter(){ public boolean accept(File file){ return file.isHidden(); //숨겨진 파일 필터링. \t} } 위의 코드를 보면 자바8 전까지는 File 클래스에 이미 isHidden이라는 메서드가 있는데 FileFilter로 감싼 다음에 FileFilter를 인스턴스화해야 했다.\nFile[] hiddenFiles = new File(“.”).listFiles(File::isHidden); 자바8의 메서드 레퍼런스 :: (이 메서드를 값으로 사용하라는 의미)를 이용해서 listFiles에 직접 전달할 수 있다. 기존에 객체 레퍼런스(new로 객체 레퍼런스를 생성함)를 이용해서 객체를 이리저리 주고받았던 것처럼 자바 8에서는 File::isHidden을 이용해서 메서드 레퍼런스를 만들어 전달할 수 있게 되었다.\n람다: 익명 함수\n함수도 값으로 취급할 수 있다. ex) (int x) -\u0026gt; x+1 : x라는 인수를 호출하면 x+1을 반환하라.\n코드 넘겨주기: 예제\nApple이라는 클래스와 getColor라는 메서드가 있고, Apples 리스트를 포함하는 inventory라는 변수가 있다고 가정하자. 이때 모든 녹색 사과를 선택해서 리스트를 반환하는 프로그램을 구현하려 한다. 이처럼 특정 항목을 선택해서 반환하는 동작을 ‘필터\u0026rsquo;라고 한다. 자바8 이전에는 다음처럼 filterGreenApples라는 메서드를 구현했을 것이다.\npublic static List\u0026lt;Apple\u0026gt; filterGreenApples(List\u0026lt;Apple\u0026gt; inventory){ List\u0026lt;Apple\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); for (Apple apple : inventory){ if(“green”.equals(apple.getColor()){ result.add(apple); } } return result; } 하지만 누군가는 애플을 무게로 필터링 하고 싶을 수 있다. 그러면 전체 코드를 복붙해서 다음처럼 구현할 수 있을 것이다.\npublic static List\u0026lt;Apple\u0026gt; filterGreenApples(List\u0026lt;Apple\u0026gt; inventory){ List\u0026lt;Apple\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); for (Apple apple : inventory){ if(apple.getWeight() \u0026gt; 150){ result.add(apple); } } return result; } 중복의 단점이 드러나는 안좋은 방법이다. 자바8 에서는 코드를 인수로 넘겨줄 수 있어서 filter 메서드를 중복으로 구현할 필요가 없다.\npublic static boolean isGreenApple(Apple apple){ return \u0026#34;green\u0026#34;.equals(apple.getColor()); } public static boolean isHeavyApple(Apple apple){ return apple.getWeight() \u0026gt; 150; } static List\u0026lt;Apple\u0026gt; filterApples(List\u0026lt;Apple\u0026gt; inventory, Predicate\u0026lt;Apple\u0026gt; p){ List\u0026lt;Apple\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); for(Apple apple : inventory){ if(p.test(apple)){ result.add(apple); } } return result; } 다음 처럼 메서드를 호출 할 수 있다.\nfilterApples(inventory, Apple::isGreenApple);\nfilterApples(inventory, Apple::isHeavyApple);\ncf) Predicate : 수학에서는 인수로 값을 받아 true / false를 반환하는 함수를 Predicate라고 한다.\n메서드 전달에서 람다로\nisHeavyApple, isGreenApple처럼 한두 번만 사용할 메서드를 매번 정의하는 것은 귀찮은 일이다. 자바8 에서는 다음처럼 새로운 개념을 이용해서 코드를 구현할 수 있다. filterApples(inventory, (Apple a) -\u0026gt; “green”.equals(a.getColor());\nfilterApples(inventory, (Apple a) -\u0026gt; a.getWeight() \u0026gt; 150);\nfilterApples(inventory, (Apple a) -\u0026gt; a.getWeight() \u0026lt; 80 || “brown”.equals(a.getColor());\n즉, 한 번만 사용할 메서드는 따로 정의를 구현할 필요가 없다. 하지만 람다가 몇 줄 이상으로 길어진다면(복잡한 동작을 수행하는 상황) 익명 람다보다는 코드가 수행하는 일을 잘 설명하는 이름을 가진 메서드를 정의하고 메서드 레퍼런스를 활용하는 것이 바람직하다. 코드의 명확성이 우선시 되어야 한다.\n스트림 다음은 리스트에서 고가의 거래(Transcation)만 필터링한 다음에 통화로 결과를 그룹화하는 코드다.\nMap\u0026lt;Currency, List\u0026lt;Transaction\u0026gt;\u0026gt; transactionsByCurrencies = new HashMap\u0026lt;\u0026gt;(); // 그룹화된 트랜잭션을 더할 Map 생성  for (Transaction transaction : transactions){ // 트랜잭션의 리스트를 반복 \tif (transaction.getPrice() \u0026gt; 1000){ // 고가의 트랜잭션을 필터링 \tCurrency currency = transaction.getCurrency(); // 트랜잭션의 통화 추출 \tList\u0026lt;Transcation\u0026gt; transactionsForCurrency = transactionsByCurrencies.get(currency); if (transactionsForCurrency == null){ // 현재 통화의 그룹화된 맵에 항목이 없으면 새로 만든다. \ttransactionsForCurrency = new ArrayList\u0026lt;\u0026gt;(); transactionsByCurrencies.put(currency, transactionsForCurrency); } transactionsForCurrency.add(transaction); // 현재 탐색된 트랜잭션을 같은 통화의 트랜잭션 리스트에 추가한다. \t} } 위 예제 코드에는 중첩된 제어 흐름 문장이 많아서 코드를 한 번에 이해하기 어렵다. 스트림 API를 이요하면 다음처럼 문제를 해결할 수 있다.\nimport static java.util.stream.Collections.toList; Map\u0026lt;Currency, List\u0026lt;Transaction\u0026gt;\u0026gt; transactionByCurrencies = transactions.stream() .filter((Transaction t) -\u0026gt; t.getPrice() \u0026gt; 1000) //고가의 트랜잭션 필터링 \t.collect(groupingBy(Transaction::getCurrency);\t 컬렉션에서는 반복 과정을 직접 처리해야 했다. 이런 방식의 반복을 외부 반복이라고 한다. 반면 스트림 API를 이용하면 루프를 신경쓸 필요가 없다. 라이브러리 내부에서 모든 데이터가 처리된다. 이와 같은 반복을 내부 반복이라고 한다.\n컬렉션은 어떻게 데이터를 저장하고 접근할지에 중점을 두는 반면 스트림은 데이터에 어떤 계산을 할 것인지 묘사하는 것에 중점을 둔다는 점을 기억하자. 스트림은 스트림 내의 요소를 쉽게 병렬로 처리할 수 있는 환경을 제공한다는 것이 핵심이다.\n컬렉션을 필터링할 수 있는 가장 빠른 방법은 컬렉션을 스트림으로 바꾸고, 병렬로 처리한 다음에, 리스트로 다시 복원하는 것이다.\n디폴트 메서드 디폴트 메서드는 특정 프로그램을 구현하는 데 도움을 주는 기능이 아니라 미래에 프로그램이 쉽게 변화할 수 있는 환경을 제공하는 기능이다.\n2장 - 동작 파라미터화 코드 전달하기 동작 파라미터화를 이용하면 자주 바뀌는 요구사항에 효과적으로 대응할 수 있다. 동작 파라미터화란 아직은 어떻게 실행할 것인지 결정하지 않은 코드 블록을 의미한다. 이 코드 블록은 나중에 프로그램에서 호출한다. 즉, 코드 블록의 실행은 나중으로 미뤄진다. 결과적으로 코드 블록에 따라 메서드의 동작이 파라미터화된다.\n동작 파라미터화\npublic interface ApplePredicate{ boolean test (Apple apple); } 선택 조건을 결정하는 인터페이스이다. 이와 같은 동작을 프레디케이트(불린을 반환하는 함수)라고 한다.\n다음 예제처럼 다양한 선택 조건을 대표하는 여러 버전의 ApplePredicate를 정의할 수 있다.\n//무거운 사과만 선택 public class AppleHeavyWeightPredicate implements ApplePredicate{ public boolean test(Apple apple){ return apple.getWeight() \u0026gt; 150; } } //녹색 사과만 선택 public class AppleGreenColorPredicate implements ApplePredicate{ public boolean test(Apple apple){ return “green”.equals(apple.getColor()); } } // 템플릿 부분 public static List\u0026lt;Apple\u0026gt; filterApples(List\u0026lt;Apple\u0026gt; inventory, ApplePredicate p){ List\u0026lt;Apple\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); for (Apple apple : inventory){ if (p.test(apple)){ result.add(apple); } } return result; } 하지만 익명 클래스를 사용해도 반복되어 지저분한 코드는 여전히 많고 많은 프로그래머가 익명 클래스의 사용에 익숙하지 않다.\n람다 표현식 사용\n자바8의 람다 표현식을 이용해서 간단히 재구현할 수 있다.\nList\u0026lt;Apple\u0026gt; result = filterApples(inventory, (Apple apple) -\u0026gt; “red”.equals(apple.getColor()));\n리스트 형식으로 추상화\nApple 이외의 다양한 물건에서 필터링이 작동하도록 리스트 형식을 추상화할 수 있다.\npublic interface Predicate\u0026lt;T\u0026gt;{ boolean test(T t); } public static \u0026lt;T\u0026gt; List\u0026lt;T\u0026gt; filter(List\u0026lt;T\u0026gt; list, Predicate\u0026lt;T\u0026gt; p){ List\u0026lt;T\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); for (T e : list){ if (p.test(e)){ result.add(e); } } return result; } 이제 바나나, 오렌지, 정수, 문자열 등의 리스트에 필터 메서드를 사용할 수 있다. List\u0026lt;Apple\u0026gt; redApples = filter(inventory, (Apple apple) -\u0026gt; “red”.equals(apple.getColor());\nList\u0026lt;String\u0026gt; evenNumbers = filter(numbers, (Integer i) -\u0026gt; i % 2 == 0);\n실전 예제 - Comparator로 정렬하기\n자바8의 List에는 sort 메서드가 포함되어 있다.(물론 Collections.sort도 존재) 다음과 같은 인터페이스를 갖는 java.util.Comparator 객체를 이용해서 sort의 동작을 파라미터화 할 수 있다.\n//java.uitl.Comparator public interface Comparator\u0026lt;T\u0026gt;{ public int compare(T o1, T o2); } Comparator를 구현해서 sort 메서드의 동작을 다양화할 수 있다. 예를 들어 익명 클래스를 이용해서 무게가 적은 순으로 목록에서 사과를 정렬할 수 있다.\ninventory.sort(new Comparator\u0026lt;Apple\u0026gt;{ public int compare(Apple a1, Apple a2){ return a1.getWeight().compareTo(a2.getWeight()); } }); 람다 표현식을 이용하면 다음처럼 간단하게 코드를 구현할 수 있다.\ninventory.sort( (Apple a1, Apple a2) -\u0026gt; a1.getWeight().compareTo(a2.getWeight()); 3장 - 람다 표현식 람다란 무엇인가 람다 표현식은 메서드로 전달할 수 있는 익명 함수를 단순화한것이라고 할 수 있다.\nComparator\u0026lt;Apple\u0026gt; byWeight = new Comparator\u0026lt;Apple\u0026gt;() { public int compare(Apple a1, Apple a2) { return a1.getWeight().compareTo(a2.getWeight()); } };Comparator\u0026lt;Apple\u0026gt; byWeight = (Apple a1, Apple a2) -\u0026gt; a1.getWeight().compareTo(a2.getWeight()); 람다는 세 부분으로 이루어진다.\n파라미터 리스트 : Comparator의 compare 메서드의 파라미터(두개의 사과).\n화살표 : 화살표(-\u0026gt;)는 람다의 파라미터 리스트와 바디를 구분한다.\n람다의 바디 : 두 사과의 무게를 비교한다. 람다의 반환값에 해당하는 표현식이다.\n자바8의 유효한 5가지 람다 표현식\n(String s) -\u0026gt; s.length()\n첫 번째 람다 표현식은 String 형식의 파라미터 하나를 가지며 int를 반환한다. 람다 표현식에는 return이 함축되어 있으므로 return 문을 명시적으로 사용하지 않아도 된다.\n(Apple a) -\u0026gt; a.getWeight() \u0026gt; 150\n두번째 람다 표현식은 Apple 형식의 파라미터를 가지며 boolean을 반환한다.\n(int x, int y) -\u0026gt; { System.out.println(“Result:”); System.out.println(x+y); 세 번째 람다 표현식은 int 형식의 파라미터 두 개를 가지며 리턴값이 없다(void 리턴). 이 예제에서 볼 수 있듯이 람다 표현식은 여러 행의 문장을 포함할 수 있다.\n() -\u0026gt; 42\n네 번째 람다 표현식은 파라미터가 없으며 int를 반환한다.\n(Apple a1, Apple a2) -\u0026gt; a1.getWeight().compareTo(a2.getWeight());\n다섯 번째 람다 표현식은 Apple 형식의 파라미터 두 개를 가지며 int를 반환한다.\n//cf) 유효하지 않은 람다 표현식 (Integer i ) -\u0026gt; return “Alan” + i; (String s) -\u0026gt; {“Iron Man”;} //return은 흐름 제어문이다. { } 안에 있어야 한다. (Integer i ) -\u0026gt; { return “Alan” + i }; //“Iron Man”은 구문(statement)이 아니라 표현식(expression)이다. (String s) -\u0026gt; “Iron Man” 또는 (String s) -\u0026gt; { return “Iron Man” } 어디에, 어떻게 람다를 사용할까? 함수형 인터페이스라는 문맥에서 람다 표현식을 사용할 수 있다. 함수형 인터페이스는 정확히 하나의 추상 메서드를 지정하는 인터페이스다. 지금까지 살펴본 자바 API의 함수형 인터페이스로 Comparator, Runnable 등이 있다.\n//java.util.Comparator public interface Comparator\u0026lt;T\u0026gt;{ int compare(T o1, T o2); } //java.lang.Runnable public interface Runnable{ void run(); } cf) 인터페이스는 디폴트 메서드(인터페이스의 메서드를 구현하지 않은 클래스를 고려해서 기본 구현을 제공하는 바디를 포함하는 메서드)를 포함할 수 있다. 많은 디폴트 메서드가 있더라도 추상 메서드가 오직 하나면 함수형 인터페이스다.\n람다 표현식으로 함수형 인터페이스의 추상 메서드 구현을 직접 전달할 수 있으므로 전체 표현식을 함수형 인터페이스의 인스턴스로 취급(기술적으로 따지면 함수형 인터페이스를 concrete 구현한 클래스의 인스턴스)할 수 있다.\n함수 디스크립터\n함수형 인터페이스의 추상메서드 시그너처를 함수 디스크립터라고 부른다. 예를 들어 () -\u0026gt; void 라는 표기는 파라미터 리스트가 없으며 void를 반환하는 함수를 의미한다. 람다 표현식은 함수형 인터페이스의 추상 메서드와 같은 시그니처를 갖는다는 사실을 기억하자.\n함수형 인터페이스를 인수를 받는 메서드에만 람다 표현식을 사용할 수 있다.\nexecute(() -\u0026gt; {}); public void execute(Runnable r){ r.run(); } cf) @FunctionalInterface은 함수형 인터페이스임을 가리키는 애노테이션이다. 만약 실제로 함수형 인터페이스가 아니면 컴파일러가 에러를 발생시킨다.\n람다 활용: 실행 어라운드 패턴 자원 처리(예를 들면 DB의 파일 처리)에 사용하는 순환 패턴은 자원을 열고, 처리한 다음에, 자원을 닫는 순서로 이루어진다. 설정과 정리 과정은 대부분 비슷하다. 즉, 실제 자원을 처리하는 코드를 설정과 정리 두 과정이 둘러싸는 형태를 갖는데 이 같은 형식의 코드를 실행 어라운드 패턴이라고 부른다.\npublic String processFile() throws IOException{ try(BufferedReader br = new BufferedReader(new FileReader(\u0026#34;data.txt\u0026#34;))){ return br.readLine(); } } cf) 자바7에 새로 추가된 try-with-resources 구문을 사용했다. 이를 사용하면 자원을 명시적으로 닫을 필요가 없다.\n현재 코드는 파일에서 한 번에 한 줄만 읽을 수 있다. 기존의 설정, 정리 과정은 재사용하고 processFile 메서드만 다른 동작을 다른 동작을 수행하도록 해보자. processFile의 동작을 파라미터화하는 것이다. 즉, processFile 메서드가 BufferedReader를 이용해서 다른 동작을 수행할 수 있도록 processFile 메서드로 동작을 전달해야 한다.\nString result = processFile((BufferedReader br) -\u0026gt; br.readLine() + br.readLine());\n함수형 인터페이스 자리에 람다를 사용할 수 있다. 따라서 BufferedReader -\u0026gt; String과 IOException을 던질 수 있는 시그니처와 일치하는 함수형 인터페이스를 만들어야 한다.\n@FuntionalInterface public interface BufferedReaderProcessor{ String process(BufferedReader b) throws IOException; } public String processFile(BufferedReaderProcessor p) throws IOException{ try(BufferedReader br = new BufferedReader(new FileReader(\u0026#34;data.txt\u0026#34;))){ return p.process(br); } } 이제 BufferedReaderProcessor에 정의된 process 메서드의 시그니처와 일치하는 다양한 람다를 전달할 수 있다.\nString oneLine = processFile((BufferedReader br) -\u0026gt; br.readLine()); String twoLines = processFile((BufferedReader br) -\u0026gt; br.readLine() + br.readLine()); 람다와 함수형 인터페이스 예제\n| 사용 사례 | 람다 예제 | 대응하는 함수형 인터페이스 | | \u0026ndash; | \u0026ndash; | \u0026ndash; | | 불린 표현 | (List\u0026lt;String\u0026gt; list) -\u0026gt; list.isEmpty() | Predicate\u0026lt;List\u0026lt;String\u0026gt;\u0026gt; | | 객체 생성 | () -\u0026gt; new Apple(10) | Supplier\u0026lt;Apple\u0026gt; | | 객체에서 소비 | (Apple a) -\u0026gt; System.out.println(a.getWeight()) | Consumer\u0026lt;Apple\u0026gt; | | 객체에서 선택/추출 | (String s) -\u0026gt; s.length() | Function\u0026lt;String, Integer\u0026gt;또는 ToInteFunction\u0026lt;String\u0026gt; | | 두 값 조합 | (int a, int b) -\u0026gt; a * b | IntBinaryOperator | | 두 객체 비교 | (Apple a1, Apple a2) -\u0026gt; a1.getWeight().compareTo(a2.getWeight()) | BiFunction\u0026lt;Apple,Apple,Integer\u0026gt; 또는 ToIntBiFunction\u0026lt;Apple,Apple\u0026gt; |\n예외, 람다, 함수형 인터페이스의 관계\n함수형 인터페이스는 확인된 예외를 던지는 동작을 허용하지 않는다. 그래서 예외를 던지를 람다 표현식을 만들려면 확인된 예외를 선언하는 함수형 인터페이스를 직접 정의하거나 람다를 try/catch 블록으로 감싸야 한다.\n@FunctionalInterface public interface BufferedReaderProcessor{ String process(BufferedReader b) throws IOException; } BufferedReaderProcessor p = (BufferedReader br) -\u0026gt; br.readLine(); 위의 예제는 IOException을 명시적으로 선언하는 함수형 인터페이스 BufferedReaderProcessor 이다. 그러나 우리는 Function\u0026lt;T, R\u0026gt; 형식의 함수형 인터페이스를 기대하는 API를 사용하고 있으며 직접 함수형 인터페이스를 만들기 어려운 상황이다. 이런 상황에서는 아래 예제처럼 명시적으로 확인된 예외를 잡을 수 있다.\nFunction\u0026lt;BufferedReader, String\u0026gt; f = (BufferedReader b) -\u0026gt; { try{ return b.readLine(); } catch(IOException e){ throw new RuntimeException(e); } }; 형식 검사, 형식 추론, 제약 람다 표현식 자체에는 람다가 어떤 함수형 인터페이스를 구현하는지의 정보가 포함되어 있지 않다. 람다가 사용되는 context를 이용해서 람다의 형식(type)을 추론할 수 있다. 특별한 void 호환 규칙\n람다의 바디에 일반 표현식이 있으면 void를 반환하는 함수 디스크립터와 호환된다(물론 파라미터 리스트도 호환되어야 함). 예를 들어 List의 add 메서드는 boolean을 반환하지만 Consumer 컨텍스트(T -\u0026gt; void)에도 유효한 코드다.\n// Predicate는 불린 반환값을 갖는다. Predicate\u0026lt;String\u0026gt; p = s -\u0026gt; list.add(s); // Consumer는 void 반환값을 갖는다. Consumer\u0026lt;String\u0026gt; b = s -\u0026gt; list.add(s); 형식 추론\n//형식을 추론하지 않음 Comparator\u0026lt;Apple\u0026gt; c = (Apple a1, Apple a2) -\u0026gt; a1.getWeight().compareTo(a2.getWeight()); //형식을 추론함 Comparator\u0026lt;Apple\u0026gt; c = (a1, a2) -\u0026gt; a1.getWeight().compareTo(a2.getWeight()); //형식 추론한 다른 예제 List\u0026lt;Apple\u0026gt; greenApples = filter(inventory, a -\u0026gt; “green”.equals(a.getColor())); 지역 변수 사용\n람다 표현식에서는 자유 변수(파라미터로 넘겨진 변수가 아니라 외부에서 정의된 변수)를 활용할 수 있다. 이와 같은 동작을 람다 캡쳐링이라고 부른다.\nint portNumber = 123; Runnable r = () -\u0026gt; System.out.println(portNumber); 하지만 자유 변수에도 약간의 제약이 있다. 람다는 인스턴스 변수와 정적 변수를 자유롭게 캡쳐(자신의 바디에서 참조할 수 있도록) 할 수 있다. 하지만 그러려면 지역 변수는 final로 선언되거나 실질적으로 final 처럼 취급되어야 한다.\n//컴파일 에러 int portNumber = 123; Runnable r = () -\u0026gt; System.out.println(portNumber); portNumber = 321; 지역변수에 왜 이러한 제약이 필요한지 알아보자.\n우선 내부적으로 지역 변수는 스택에 위치한다. 람다에서 지역 변수에 바로 접근할 수 있다는 가정 하에 람다가 스레드에서 실행된다면 변수를 할당한 스레드가 사라져서 변수 할당이 해제되었는데도 람다를 실행하는 스레드에서는 해당 변수에 접근하려 할 수 있다. 따라서 자바 구현에서는 원래 변수에 접근을 허용하는 것이 아니라 자유 지역 변수의 복사본을 제공한다. 따라서 복사본의 값이 바뀌지 않아야 하므로 지역 변수에는 한 번만 값을 할당해야 한다는 제약이 생긴것이다.\n람다와 익명 클래스 모두 메서드의 인수로 전달될 수 있으며 자신의 외부 영역의 변수에 접근할 수 있다. 다만 람다와 익명 클래스는 람다가 정의된 메서드의 지역 변수의 값은 바꿀 수 없다. 람다가 정의된 메서드의 지역 변숫값은 final 변수여야 한다. 람다는 변수가 아닌 값에 국한되어 어떤 동작을 수행한다는 사실이 명확해진다. 지역 변숫값은 스택에 존재하므로 자신을 정의한 스레드와 생존을 같이 해야 하며 따라서 지역 변수는 final 이어야 한다. 가변 지역 변수를 새로운 스레드에서 캡쳐할 수 있다면 안전하지 않은 동작을 수행할 가능성이 생긴다(인스턴스 변수는 스레드가 공유하는 힙에 존재하므로 특별한 제약이 없다).\n메서드 레퍼런스 메서드 레퍼런스를 이용하면 기존의 메서드 정의를 재활용해서 람다처럼 전달할 수 있다. 때로는 메서드 레퍼런스를 사용하는 것이 더 가독성이 좋으며 자연스러울 수 있다.\n// 기존 코드 inventory.sort((Apple a1, Apple a2) -\u0026gt; a1.getWeight().compareTo(a2.getWeight())); // 메서드 레퍼런스와 java.util.Comparator.comparing을 활용한 코드 inventory.sort((comparing(Apple::getWeight());  메서드 레퍼런스는 특정 메서드만을 호출하는 람다의 축약형이라고 생각할 수 있다. 예를 들어 Apple::getWeight는 Apple 클래스에 정의된 getWeight의 메서드 레퍼런스다. 실제로 메서드를 호출하는 것은 아니므로 괄호는 필요없다. 결과적으로 메서드 레퍼런스는 람다 표현식 (Apple a) -\u0026gt; a.getWeight()를 축약한 것이다.\n람다와 메서드 레퍼런스 단축 표현 예제\n| 람다 | 메서드 레퍼런스 단축 표현 | | \u0026ndash; | \u0026ndash; | | (Apple a) -\u0026gt; a.getWeight() | Apple :: getWeight | | () -\u0026gt; Thread.currentThread().dumpStack() | Thread.currentThread() :: dumpStack | | (str, i) -\u0026gt; str.substring(i) | String :: substring | | (String s) -\u0026gt; System.out.println(s) | System.out :: println |\n메서드 레퍼런스를 만드는 방법\n메서드 레퍼런스는 세 가지 유형으로 구분할 수 있다. ‘정적 메서드 레페런스’, ‘다양한 형식의 인스턴스 메서드 레퍼런스’, ‘기존 객체의 인스턴스 메서드 레퍼런스\u0026rsquo;\n생성자 레퍼런스\nClassName :: new 처럼 클래스명과 new 키워드를 이용해서 기존 생성자의 레퍼런스를 만들 수 있다.\nSupplier\u0026lt;Apple\u0026gt; c1 = Apple :: new; // 디폴트 생성자 Apple()의 생성자 레퍼런스 Apple a1 = c1.get(); // Supplier의 get 메서드를 호출해서 새로운 Apple 객체를 만들 수 있다.  // 위 예제는 다음 코드와 같다. Supplier\u0026lt;Apple\u0026gt; c1 = () -\u0026gt; new Apple(); // 람다 표현식은 디폴트 생성자를 가진 Apple을 만든다. Apple a1 = c1.get(); // Supplier의 get 메서드를 호출해서 새로운 Apple 객체를 만들 수 있다. Apple(Integer weight) 라는 시그니처를 갖는 생성자는 Function 인터페이스의 시그니처와 같다.\nFunction\u0026lt;Integer, Apple\u0026gt; c2 = Apple :: new; // Apple (Integer weight)의 생성자 레퍼런스 Apple a2 = c2.apply(110); // Function의 apply 메서드를 무게를 인수로 호출해서 새로운 Apple 객체를 만들 수 있다.  //위 예제는 다음 코드와 같다. Function\u0026lt;Integer, Apple\u0026gt; c2 = (weight) -\u0026gt; new Apple(weight); // 특정 무게의 사과를 만드는 람다 표현식 Apple a2 = c2.apply(110); // Function의 apply 메서드를 무게를 인수로 호출해서 새로운 Apple 객체를 만들 수 있다. 람다, 메서드 레퍼런스 활용하기 // 1단계 public class AppleComparator implements Comparator\u0026lt;Apple\u0026gt;{ public int compare(Apple a1, Apple a2){ return a1.getWeight().compareTo(a2.getWeight()); } } inventory.sort(new AppleComparator()); // 2단계: 익명 클래스 사용 inventory.sort(new Comparator\u0026lt;Apple\u0026gt;(){ public int compare(Apple a1, Apple a2){ return a1.getWeight().compareTo(a2.getWeight()); } }); // 3단계 : 람다 표현식 사용 inventory.sort((Apple a1, Apple a2) -\u0026gt; a1.getWeight().compareTo(a2.getWeight())); //형식 추론을 통해 더 간소화 inventory.sort((a1, a2) -\u0026gt; a1.getWeight().compareTo(a2.getWeight())); inventory.sort(comparing((a) -\u0026gt; a.getWeight())); // 4단계 : 메서드 레퍼런스 사용 inventory.sort(comparing(Apple::getWeight)); 람다 표현식을 조합할 수 있는 유용한 메서드 여러 개의 람다 표현식을 조합해서 복잡한 람다 표현식을 만들 수 있다(디폴트 메서드 덕분).\nComparator 조합\n// 역정렬 inventory.sort(comparing(Apple::getWeight)).reversed(); // Comparator 연결 inventory.sort(comparing(Apple::getWeight).reversed().thenComparing(Apple::getCountry)); Predicate 조합\n// 반전시킴 Predicate\u0026lt;Apple\u0026gt; notRedApple = redApple.negate(); // and 조합 Predicate\u0026lt;Apple\u0026gt; redAndHeavyApple = redApple.and(a -\u0026gt; a.getWeight() \u0026gt; 150); cf) a.or(b).and\u0026copy;는 (a || b) \u0026amp;\u0026amp; c 와 같다.\nFunction 조합\n// andThen - 주어진 함수를 먼저 적용한 결과를 다른 함수의 입력으로 전달하는 함수를 반환 Function\u0026lt;Integer, Integer\u0026gt; f = x -\u0026gt; x+1; Function\u0026lt;Integer, Integer\u0026gt; g = x -\u0026gt; x*2; Function\u0026lt;Integer, Integer\u0026gt; h = f.andThen(g);; int result = h.apply(1); // 4를 반환  //compose - 인자로 주어진 함수를 먼저 실행한 다음에 그 결과를 외부 함수의 인수로 제공 Function\u0026lt;Integer, Integer\u0026gt; f = x -\u0026gt; x+1; Function\u0026lt;Integer, Integer\u0026gt; g = x -\u0026gt; x*2; Function\u0026lt;Integer, Integer\u0026gt; h = f.compose(g);; int result = h.apply(1); // 3를 반환 "
},
{
	"uri": "/java8_in_action/part2-1_%E1%84%92%E1%85%A1%E1%86%B7%E1%84%89%E1%85%AE%E1%84%92%E1%85%A7%E1%86%BC_%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5_%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5/",
	"title": "Part2-1 함수형 데이터 처리",
	"tags": [],
	"description": "",
	"content": " 4장 - 스트림 소개 DB에서는 select name from dishes where calorie \u0026lt; 400문장 처럼 선언형으로 연산을 표현할 수 있다(직접 구현할 필요가 없다). SQL 질의 언어에서는 우리가 기대하는 것이 무엇인지 직접 표현할 수 있다.\n스트림이란 무엇인가? 스트림이란 자바 API에 새로 추가된 기능으로, 스트림을 이용하면 선언형(즉, 데이터를 처리하는 임의 구현 코드 대신 질의로 표현할 수 있다)으로 컬렉션 데이터를 처리할 수 있다. 또한 스트림을 이용하면 멀티 스레드 코드를 구현하지 않아도 데이터를 투명하게 병렬로 처리할 수 있다. 다음 예제는 저칼로리의 요리명을 반환하고, 칼로리를 기준으로 요리를 정렬하는 자바7 코드다.\nList\u0026lt;Dish\u0026gt; lowCaloricDishes = new ArrayList\u0026lt;\u0026gt;(); for(Dish d : menu){ if(d.getCalories() \u0026lt; 400){ lowCaloricDishes.add(d); } } Collections.sort(lowCaloricDishes, new Comparator\u0026lt;Dish\u0026gt;() { public int compare(Dish d1, Dish d2){ return Integer.compare(d1.getCalories(), d2.getCalories()); } }); List\u0026lt;String\u0026gt; lowCaloricDishesName = new ArrayList\u0026lt;\u0026gt;(); for(Dish d : lowCaloricDishes){ lowCaloricDishesName.add(d.getName()); } 위 코드에서는 lowCaloricDishes라는 ‘가비지 변수’가 사용되었다. 즉 lowCaloricDishes는 컨테이너 역할만 하는 중간 변수다. 자바8에서 이러한 세부 구현은 라이브러리 내에서 모두 처리한다.\n//자바8 코드 import static java.util.Comparator.comparing; import static java.uitl.stream.Collectors.toList; List\u0026lt;String\u0026gt; lowCaloricDishesName = menu.stream() .filter(d -\u0026gt; d.getCalories() \u0026lt; 400) // 400칼로리 이하의 요리 선택  .sorted(comparing(Dish::getCalories)) // 칼로리로 요리 정렬  .map(Dish::getName) // 요리면 추출  .collect(toList()); // 모든 요리명을 리스트에 저장  stream()을 parallelStream()으로 바꾸면 이 코드를 멀티코어 아키텍처에서 병렬로 실행할 수 있다.\nList\u0026lt;String\u0026gt; lowCaloricDishesName = menu.parallelStream() .filter(d -\u0026gt; d.getCalories() \u0026lt; 400) // 400칼로리 이하의 요리 선택  .sorted(comparing(Dish::getCalories)) // 칼로리로 요리 정렬  .map(Dish::getName) // 요리면 추출  .collect(toList()); // 모든 요리명을 리스트에 저장  자세한 내용은 7장에서 설명하겠다.\n스트림 시작하기 스트림이란 정확히 뭘까? 스트림이란 데이터 처리 연산을 지원하도록 소스에서 추출된 연속된 요소로 정의할 수 있다. 이 정의를 하나씩 살펴보자.\n연속된 요소 : 컬렉션과 마찬가지로 스트림은 특정 요소 형식으로 이루어진 연속된 값 집합의 인터페이스를 제공한다. 컬렉션은 자료구조이므로 컬렉션에서는 (예를 들어 ArrayList를 사용할 것인지 아니면 LinkedList를 사용할 것이지에 대한) 시간과 공간의 복잡성과 관련된 요소 저장 및 접근 연산이 주를 이룬다. 반면 스트림은 filter, sorted, map처럼 표현 계산식이 주를 이룬다. 즉, 컬렉션의 주제는 데이터고 스트림의 주제는 계산이다.\n소스 : 스트림은 컬렉션, 배열, I/O 자원 등의 데이터 제공 소스로부터 데이터를 소비한다. 정렬된 컬렉션으로 스트림을 생성하면 정렬이 그대로 유지된다. 즉, 리스트로 스트림을 만들면 스트림의 요소는 리스트의 요소와 같은 순서를 유지한다.\n데이터 처리 연산 : 스트림은 함수형 프로그래밍 언어에서 일반적으로 지원하는 연산과 DB와 비슷한 연산을 지원한다. 예를 들어 filter, map, reduce, find, match, sort 등으로 데이터를 조작할 수 있다.\n또한 스트림은 다음과 같은 두 가지 중요한 특징을 갖는다.\n파이프라이닝 : 스트림 연산은 스트림 연산끼리 연결해서 커다란 파이프라인을 구성할 수 있도록 스트림을 자신을 반환한다.\n내부 반복 : 반복자를 이용해서 명시적으로 반복하는 컬렉션과 달리 스트림은 내부 반복을 지원한다.\nimport static java.util.stream.Collectors.toList; List\u0026lt;String\u0026gt; threeHighCaloricDishNames = menu.stream() // 메뉴(요리 리스트)에서 스트림을 얻는다.  .filter(d -\u0026gt; d.getCalories() \u0026gt; 300) // 파이프라인 연산 만들기. 첫 번째로 고칼로리 요리를 필터링한다.  .map(Dish::getName) // 요리명 추출  .limit(3) //선착순 세 개만 선택  .collect(toList()); // 결과를 다른 리스트로 저장  System.out.println(threeHighCaloricDishNames); // 결과는 [pork, beef, chicken] 이다.  우선 menu에 stream 메서드를 호출해서 요리 리스트(menu)로부터 스트림을 얻었다. 여기서 데이터 소스는 요리 리스트(menu)다. 데이터 소스는 연속된 요소를 스트림에 제공한다. 다음으로 스트림에 filter, map, limit, collect로 이어지는 일련의 데이터 처리 연산을 적용한다. collect를 제외한 모든 연산은 서로 파이프라인을 형성할 수 있도록 스트림을 반환한다. 마지막으로 collect 연산으로 파이프라인을 처리해서 결과를 반환한다(collect는 스트림이 아니라 List를 반환한다). 마지막에 collect를 호출하기 전까지는 menu에서 아무것도 선택되지 않으며 출력 결과도 없다. 즉, collect가 호출되기 전까지 메서드 호출이 저장되는 효과가 있다.\n스트림과 컬렉션 자바의 기존 컬렉션과 새로운 스트림 모두 연속된 요소 형식의 값을 저장하는 자료구조의 인터페이스를 제공한다. 여기서 ‘연속된’이라는 표현은 순서와 상관없이 아무 값에나 접속 하는 것이 아니라 순차적으로 값에 접근한다는 것을 의미한다. 이제 컬렉션과 스트림의 차이를 살펴보자.\n데이터를 언제 계산하느냐가 컬렉션과 스트림의 가장 큰 차이라고 할 수 있다. 컬렉션은 현재 자료구조가 포함하는 모든 값을 메모리에 저장하는 자료구조다. 즉, 컬렉션의 모든 요소는 컬렉션에 추가하기 전에 계산되어야 한다(컬렉션에 요소를 추가하거나 컬렉션의 요소를 삭제할 수 있다. 이런 연산을 수행할 때마다 컬렉션의 모든 요소를 메모리에 저장해야 하며 컬렉션에 추가하려는 요소는 미리 계산되어야 한다).\n반면 스트림은 이론적으로 요청할 때만 요소를 계산하는 고정된 자료구조다(스트림에 요소를 추가하거나 스트림에서 요소를 제거할 수 없다). 사용자가 요청하는 값만 스트림에서 추출한다는 것이 핵심이다. 결과적으로 스트림은 생산자와 소비자 관계를 형성한다. 또한 스트림은 게으르게 만들어지는 컬렉션과 같다. 즉, 사용자가 데이터를 요청할 때만 값을 계산한다.\n반면 컬렉션은 적극적으로 생성된다(생산자 중심: 팔기도 전에 창고를 가득 채움). 소수 예제를 적용해보면 컬렉션은 끝이 없는 모든 소수를 포함하려 할 것이므로 무한 루프를 돌면서 새로운 소수를 계산하고 추가하기를 반복할 것이다. 결국 소비자는 영원히 결과를 볼 수 없게 된다.\n스트림은 단 한번만 소비 할 수 있다.\nList\u0026lt;String\u0026gt; title = Arrays.asList(“java8”, “in”, “action”); Stream\u0026lt;String\u0026gt; s = title.stream(); s.forEach(System.out::println); // title의 각 단어를 출력  s.forEach(System.out::println); // java.lang.IllegalStateException : 스트립이 이미 소비되었거나 닫힘 cf) 스트림과 컬렉션의 철학적 접근\n스트림을 시간적으로 흩어진 값의 집합으로 간주할 수 있다. 반면 컬렉션은 특정 시간에 모든 것이 존재하는 공간(컴퓨터 메모리)에 흩어진 값으로 비유할 수 있다. for-each 루프 내에서 반복자를 이용해서 공간에 흩어진 요소에 접근할 수 있다.\n컬렉션과 스트림의 또 다른 차이점은 데이터 반복 처리 방법이다. 컬렉션 인터페이스를 사용하려면 사용자가 직접 요소를 반복해야 한다. 이를 외부 반복이라고 한다. 반면 스트림 라이브러리는 반복을 알아서 처리하고 결과 스트림값을 어딘가에 저장해주는 내부 반복을 사용한다. 스트림 라이브러리의 내부 반복은 데이터 표현과 하드웨어를 활용한 병렬성 구현을 자동으로 선택한다. 반면 for-each를 이용하는 외부 반복에서는 병렬성을 스스로 관리해야 한다.\n스트림 연산 스트림 인터페이스의 연산을 크게 두 가지로 구분할 수 있다.\nList\u0026lt;String\u0026gt; threeHighCaloricDishNames = menu.stream() // 메뉴(요리 리스트)에서 스트림을 얻는다.  .filter(d -\u0026gt; d.getCalories() \u0026gt; 300) // 중간 연산  .map(Dish::getName) // 중간 연산  .limit(3) // 중간 연산  .collect(toList()); // 스트림을 리스트로 변환. 최종 연산 filter, map, limit는 서로 연결되어 파이프라인을 형성한다.\ncollect로 파이프라인을 실행한 다음에 닫는다.\n연결할 수 있는 스트림 연산을 중간 연산이라고 하며, 스트림을 닫는 연산을 최종 연산이라고 한다. 왜 스트림의 연산을 두 가지로 구분하는 것일까?\n중간 연산\nfilter나 sorted 같은 중간 연산은 다른 스트림을 반환한다. 따라서 여러 중간 연산을 연결해서 질의를 만들 수 있다. 중간 연산의 중요한 특징은 단말 연산을 스트림 파이프라인에 실행하기 전까지는 아무 연산도 수행하지 않는다는 것, 즉 게이르다는 것이다. 중간 연산을 합친 다음에 합쳐진 중간 연산을 최종 연산으로 한 번에 처리하기 때문이다.\n// 제품 코드에는 이와 같은 출력 코드를 추가하지 않는게 좋다. 그러나 학습용으로는 매우 좋은 기법이다.  List\u0026lt;String\u0026gt; names = menu.stream() .filter(d -\u0026gt;{ System.out.println(\u0026#34;filtering\u0026#34; + d.getName()); return d.getCalories() \u0026gt; 300; }) .map(d -\u0026gt; { System.out.println(\u0026#34;mapping\u0026#34; + d.getName()); return d.getName(); }) .limit(3) .collect(toList()); System.out.println(names); filteringpork mappingpork filteringbeef mappingbeef filteringchicken mappingchicken [pork, beef, chicken] 스트림의 게으른 특성 덕분에 몇 가지 최적화 효과를 얻을 수 있었다. 첫째, 300칼로리가 넘는 요리는 여러 개지만 오직 처음 3개만 선택되었다. 이는 limit 연산 그리고 쇼트서킷이라 불리는 기법 덕분이다. 둘째, filter와 map은 서로 다른 연산이지만 한 과정으로 병합되었다(이 기법을 루프 퓨전이라고 한다).\n최종 연산\n최종 연산은 스트림 파이프라인에서 결과를 도출한다. 보통 최종 연산에 의해 List, Integer, void 등 스트림 이외의 결과가 반환된다. 예를 들어 파이프라인에서 forEach는 소스의 각 요리에 람다를 적용한 다음에 void를 반환하는 최종 연산이다. System.out.println을 forEach에 넘겨주면 menu에서 만든 스트림의 모든 요리를 출력한다. menu.stream().forEach(System.out::println);\ncf) 스트림 파이프라인의 개념은 빌더 패턴과 비슷하다.\n중간 연산\n| 연산 | 형식 | 반환형식 | 연산의 인수 | 함수 디스크립터 | | \u0026ndash; | \u0026ndash; | \u0026ndash; | \u0026ndash; | \u0026ndash; | | filter | 중간연산 | Stream\u0026lt;T\u0026gt; | Predicate\u0026lt;T\u0026gt; | T -\u0026gt; boolean | | map | 중간연산 | Stream\u0026lt;T\u0026gt; | Function\u0026lt;T,R\u0026gt; | T -\u0026gt; R | | limit | 중간연산 | Stream\u0026lt;T\u0026gt; | | | | sorted | 중간연산 | Stream\u0026lt;T\u0026gt; | Comparator\u0026lt;T\u0026gt; | (T,T) -\u0026gt; int | | distinct | 중간연산 | Stream\u0026lt;T\u0026gt; | | | | 최종 연산\n| 연산 | 형식 | 목적 | | \u0026ndash; | \u0026ndash; | \u0026ndash; | | forEach | 최종연산 | 스트림의 각 요소를 소비하면서 람다를 적용한다. void를 반환한다. | | count | 최종연산 | 스트림의 요소 개수를 반환한다. long을 반환한다. | | collect | 최종연산 | 스트림을 리듀스해서 리스트, 맵, 정수 형식의 컬렉션을 만든다. |\n5장 - 스트림 활용 필터링 슬라이싱 filter 메서드는 프레디케이트(불린을 반환하는 함수)를 인수로 받아서 프레디케이트와 일치하는 모든 요소를 포함하는 스트림을 반환한다.\n// 채식 요리인지 확인하는 메서드 레퍼런스 List\u0026lt;Dish\u0026gt; vegetarianMenu = menu.stream() .filter(Dish::isVegetarian) .collect(toList()); 고유 요소 필터링\nList\u0026lt;Integer\u0026gt; numbers = Arrays.asList(1,2,1,1,3,4,5); numbers.stream().filter(i -\u0026gt; i%2 == 0).distinct().forEach(System.out::println); 스트림 축소\nList\u0026lt;Dish\u0026gt; vegetarianMenu = menu.stream() .filter(d -\u0026gt; d.getCalories() \u0026gt; 300) .limit(3) .collect(toList()); 요소 건너뛰기\n// 300칼로리 이상의 처음 두 요리를 건너 뛴 다음에 300칼로리가 넘는 나머지 요리를 반환한다. List\u0026lt;Dish\u0026gt; vegetarianMenu = menu.stream() .filter(d -\u0026gt; d.getCalories() \u0026gt; 300) .skip(2) .collect(toList()); 매핑 특정 객체에서 특정 데이터를 선택하는 작업은 데이터 처리 과정에서 자주 수행되는 연산이다. 예를 들어 SQL의 테이블에서 특정 열만 선택할 수 있다. 스트림 API의 map과 flatMap 메서드는 특정 데이터를 선택하는 기능을 제공한다.\n스트림의 각 요소에 함수 적용하기\nList\u0026lt;String\u0026gt; dishNames = menu.stream() .map(Dish::getName) // map 메서드의 출력 스트림은 Stream\u0026lt;String\u0026gt; 형식을 갖는다. \t.collect(toList()); List\u0026lt;String\u0026gt; words = Arrays.asList(“java8”, “in”, “action”); List\u0026lt;Integer\u0026gt; list = words.stream().map(String::length).collect(toList()); 스트림 평면화\n메서드 map을 이용해서 리스트의 각 단어의 길이를 반환하는 방법을 확인했다. 이를 응용해서 리스트에서 고유 문자로 이루어진 리스트를 반환해보자. 예를 들어 [“Hello”, “World”] 리스트가 있다면 결과로 [“H”,”e”,”l”,”o”,”W”,”r”,”d”]를 포함하는 리스트가 반환되어야 한다. 다음처럼 문제를 해결할 수 있다.\nwords.stream() .map(word -\u0026gt; word.split(“”)) .distinct() .collect(toList()); 하지만 위 코드에서 map으로 전달한 람다는 각 단어의 String[](문자열 배열)을 반환한다는 문제가 있다. 따라서 map 메서드가 반환한 스트림의 형식은 Stream\u0026lt;String[]\u0026gt;이다. 우리가 원하는 것은 문자열의 스트림을 표현할 Stream\u0026lt;String\u0026gt;이다. 다행히 flatMap이라는 메서드를 이용해서 이 문제를 해결할 수 있다.\n먼저 각 단어를 개별 문자열로 이루어진 배열로 만든 다음에 각 배열을 별로의 스트림으로 만들어야 한다.\nList\u0026lt;String\u0026gt; words = Arrays.asList(\u0026#34;Hello\u0026#34;, \u0026#34;World\u0026#34;); List\u0026lt;String\u0026gt; str = words.stream() .map(w -\u0026gt; w.split(\u0026#34;\u0026#34;)) .flatMap(Arrays::stream) .distinct() .collect(toList()); System.out.println(str); flatMap은 각 배열을 스트림이 아니라 스트림의 콘텐츠로 매핑한다. 즉, 생성된 스트림을 하나의 스트림으로 평면화한다.\n검색과 매칭 특정 속성이 데이터 집합에 있는지 여부를 검색하는 데이터 처리도 자주 사용된다. 스트림 API는 AllMatch, anyMatch, noneMatch, findFirst, findAny 등 다양한 유틸리티 메서드를 제공한다.\n// 프레디케이트가 주어진 스트림에서 적어도 한 요소와 일치하는지 확인할 때 anyMatch 메서드를 이용한다. if(menu.stream().anyMatch(Dish::isVegetarian) { // anyMatch는 불린을 반환하므로 최종 연산이다. \t... } // 프레디케이트가 모든 요소와 일치하는지 검사 boolean isHealthy = menu.stream().allMatch(d -\u0026gt; d.getCalories() \u0026lt; 1000); //noneMatch boolean isHealthy = menu.stream().noneMatch(d -\u0026gt; d.getCalories() \u0026lt; 1000);  anyMatch, allMatch, noneMatch 세 가지 메서드는 스트림 쇼트서킷 기법, 즉 자바의 \u0026amp;\u0026amp;, ||와 같은 연산을 활용한다.\n쇼트서킷 평가\n때로는 전체 스트리믈 처리하지 않았더라도 결과를 반환할 수 있다. 예를 들어 여러 and 연산으로 연결된 커다란 불린 표현식을 평가한다고 가정하자. 표현식에서 하나라도 거짓이라는 결과가 나오면 나머지 표현식의 결과와 상관없이 전체 결과도 거짓이 된다. 이러한 상황을 쇼트서킷이라고 부른다.\nallMatch, noneMatch, findFirst, findAny 등의 연산은 모든 스트립의 요소를 처리하지 않고도 결과를 반환할 수 있다. 원하는 요소를 찾았으면 즉시 결과를 반환할 수 있다. 마찬가지로 스트림의 모든 요소를 처리할 필요 없이 주어진 크기의 스트림을 생성하는 limit도 쇼트서킷 연산이다. 특히 무한한 요소를 가진 스트림을 유한한 크기로 줄일 수 있는 유용한 연산이다.\n요소 검색\nfindAny 메서드는 현재 스트림에서 임의의 요소를 반환한다.\nOptional\u0026lt;Dish\u0026gt; dish = menu.stream().filter(Dish::isVegetarian).findAny(); 그런데 위 코드에 사용된 Optional은 무엇일까? Optional\u0026lt;T\u0026gt; 클래스는 값의 존재나 부재 여부를 표현하는 컨테이너 클래스다. 이전 예제에서 findAny는 아무 요소도 반환하지 않을 수 있다. null은 쉽게 에러를 일으킬 수 있으므로 자바8 라이브러리 설계자는 Optional\u0026lt;T\u0026gt;라는 기능을 만들었다.\nisPresent() 는 Optional이 값을 포함하면 참(true)을 반환한고, 값을 포함하지 않으면 거짓(false)를 반환한다. ifPresent(Consumer\u0026lt;T\u0026gt; block)은 값이 있으면 주어진 블록을 실행한다. menu.stream() .filter(Dish::isVegetarian) .findAny() // Optional\u0026lt;Dish\u0026gt; 반환 \t.ifPresent(d -\u0026gt; System.out.println(d.getName()); // 값이 있으면 출력하고, 없으면 아무 일도 일어나지 않는다.  T get()은 값이 존재하면 값을 반환하고 값이 없으면 NoSuchElementException을 일으킨다. T orElse(T other)는 값이 있으면 값을 반환하고, 값이 없으면 기본값을 반환한다. 그런데 왜 findFirst와 findAny 두 가지 메서드 모두 필요할까? 바로 병렬성 때문이다. 병렬 실행에서는 첫 번째 요소를 찾기 어렵다. 따라서 요소의 반환 순서가 상관없다면 병렬 스트림에서는 제약이 적은 findAny를 사용한다.\n리듀싱 모든 스트림 요소를 처리해서 값으로 도출하는 것을 리듀싱 연산이라고 한다.\n요소의 합\nint sum = numbers.stream().reduce(0, (a,b) -\u0026gt; a+b); reduce를 이용하면 애플리케이션의 반복된 패턴을 추상화할 수 있다. reduce는 두 개의 인수를 갖는다. 초기값 0과 두 요소를 조합해서 새로운 값을 만드는 BinaryOperator\u0026lt;T\u0026gt;. 메서드 레퍼런스를 이용해서 이 코드를 좀 더 간결하게 만들 수 있다. 자바 8에서는 Integer 클래스에 두 숫자를 더하는 정적 sum 메서드를 제공한다. int sum = numbers.stream().reduce(0,Integer::sum);\n초기값을 받지 않도록 오버로드된 reduce도 있다. 그러나 이 reduce는 Optional 객체를 반환한다. Optional\u0026lt;Integer\u0026gt; sum = numbers.stream().reduce((a,b)-\u0026gt;(a+b)); 스트림에 아무 요소도 없는 상황이라면 초기값이 없으므로 reduce는 합계를 반환할 수 없다. 따라서 합계가 없음을 가리킬 수 있도록 Optional 객체로 감싼 결과를 반환한다.\n최대/최소값\nOptional\u0026lt;Integer\u0026gt; max = numbers.stream().reduce(Integer::max);\nreduce 메서드의 장점과 병렬화\nreduce를 이용하면 내부 반복이 추상화되면서 내부 구현에서 병렬로 reduce를 실행할 수 있게 된다. 반복적인 합계에서는 sum 변수를 공유해야 하므로 쉽게 병렬화 하기 어렵다.\n스트림 연산: 상태 없음과 상태 있음\nmap, filter 등은 입력 스트림에서 각 요소를 받아 0 또는 결과를 출력 스트림으로 보낸다. 따라서 (사용자가 제공한 람다나 메서드 레퍼런스가 내부적인 가변 상태를 갖지 않는다는 가정 하에) 이들은 보통 상태가 없는, 즉 내부 상태를 갖지 않는 연산이다(stateless operation). 하지만 reduce, sum, max 같은 연산은 결과를 누적할 내부 상태가 필요하다. 스트림에서 처리하는 요소 수와 관계없이 내부 상태의 크기는 한정되어 있다.\nsorted나 distinct 같은 연산은 filter나 map처럼 스트림을 입력으로 받아 다른 스트림을 출력하는 것처럼 보일 수 있다. 하지만 스트림의 요소를 정렬하거나 중복을 제거하려면 과거의 이력을 알고 있어야 한다. 따라서 이러한 연산은 내부 상태를 갖는 연산으로 간주할 수 있다.\n실전 연습 Trader raoul = new Trader(\u0026#34;Raoul\u0026#34;,\u0026#34;Cambridge\u0026#34;); Trader mario = new Trader(\u0026#34;Mario\u0026#34;,\u0026#34;Milan\u0026#34;); Trader alan = new Trader(\u0026#34;Alan\u0026#34;,\u0026#34;Cambridge\u0026#34;); Trader brian = new Trader(\u0026#34;Brian\u0026#34;,\u0026#34;Cambridge\u0026#34;); List\u0026lt;Transaction\u0026gt; transactions = Arrays.asList( new Transaction(brian,2011,300), new Transaction(raoul,2012,1000), new Transaction(raoul,2011,400), new Transaction(mario,2012,710), new Transaction(mario,2012,700), new Transaction(alan,2012,950) ); //1번 2011년에 일어난 모든 트랜잭션을 찾아 값을 오름차순으로 정리하라 List\u0026lt;String\u0026gt; list = transactions.stream() .filter(t -\u0026gt; t.getYear() ==2011) .map(Transaction::toString) .sorted() .collect(toList()); System.out.println(\u0026#34;1번\u0026#34;+list); //2번 거래자가 근무하는 모든 도시를 중복 없이 나열하시오 List\u0026lt;String\u0026gt; cities = transactions.stream() .map(t -\u0026gt; t.getTrader().getCity()) .distinct() .collect(toList()); System.out.println(\u0026#34;2번\u0026#34;+cities); //3번 Cambridge에서 근무하는 모든 거래자를 찾아서 이름순으로 정렬하시오 List\u0026lt;String\u0026gt; tradersInCombridege = transactions.stream() .filter(t -\u0026gt; t.getTrader().getCity().equals(\u0026#34;Cambridge\u0026#34;)) .map(t -\u0026gt; t.getTrader().getName()) .sorted() .distinct() .collect(toList()); System.out.println(\u0026#34;3번\u0026#34;+tradersInCombridege); List\u0026lt;Trader\u0026gt; tradersInCambridege2 = transactions.stream() .map(Transaction::getTrader) .filter(t -\u0026gt; t.getCity().equals(\u0026#34;Cambridge\u0026#34;)) .sorted(comparing(Trader::getName)) .distinct() .collect(toList()); System.out.println(\u0026#34;3번-2 \u0026#34;+tradersInCambridege2); //4번 모든 거래자의 이름을 알파벳순으로 정렬해서 반환하시오. String traders = transactions.stream() .map(t -\u0026gt;t.getTrader().getName()) .sorted() .distinct() .reduce(\u0026#34;\u0026#34;,(a,b)-\u0026gt;a+b); System.out.println(\u0026#34;4번 \u0026#34;+traders); String traders2 = transactions.stream() .map(t -\u0026gt;t.getTrader().getName()) .sorted() .distinct() .collect(joining()); System.out.println(\u0026#34;4번-2 \u0026#34;+traders2); //5번 밀라노에 거래자가 있는가? boolean milanoTrader = transactions.stream() .anyMatch(t -\u0026gt; t.getTrader().getCity().equals(\u0026#34;Milan\u0026#34;)); System.out.println(\u0026#34;5번\u0026#34;+milanoTrader); //6번 Cambridge에 거주하는 거래자의 모든 트랜잭션 값을 출력하시오 List\u0026lt;String\u0026gt; transactionValue = transactions.stream() .map(t -\u0026gt; t.getTrader().getCity()) .distinct() .collect(toList()); System.out.println(\u0026#34;6번\u0026#34; +transactionValue); //7번 전체 트랜잭션 중 최대값은 얼마인가 int max = transactions.stream().map(i -\u0026gt; i.getValue()).reduce(0,Integer::max); System.out.println(\u0026#34;7번 최대값 :\u0026#34;+max); //8번 전체 트랜잭션 중 최소값 Optional\u0026lt;Integer\u0026gt; min = transactions.stream().map(i-\u0026gt;i.getValue()).reduce(Integer::min); System.out.println(\u0026#34;8번 최소값 :\u0026#34;+min.get()); 숫자형 스트림 스트림 API 숫자 스트림을 효율적으로 처리할 수 있도록 세 가지 기본형 특화 스트림을 제공한다. 박싱 비용을 피할 수 있도록 ‘int 요소에 특화된 IntStream’, ‘double 요소에 특화된 DoubleStream’, ‘long 요소에 특화된 LongStream’을 제공한다. 특화 스트림은 오직 박싱 과정에서 일어나는 효율성과 관련 있으며 스트림에 추가 기능을 제공하진 않는다는 사실을 기억하자.\n숫자 스트림으로 매핑\n스트림을 특화 스트림으로 변환할 때는 mapToInt, mapToDouble, mapToLong 세 가지 메서드를 가장 많이 사용한다. 이들 메서드는 map과 정확히 같은 기능을 수행하지만, Stream\u0026lt;T\u0026gt; 대신 특화된 스트림을 반환한다.\nint calories = menu.stream().mapToInt(Dish::getCalories).sum(); mapToInt 메서드는 각 요리에서 모든 칼로리를 추출한 다음에 IntStream(Stream\u0026lt;Integer\u0026gt;가 아님)을 반환한다. 따라서 IntStream 인터페이스에서 제공하는 sum 메서드를 이용해서 칼로리 합계를 계산할 수 있다. 스트림이 비어 있으면 sum은 기본값 0을 반환한다. IntStream은 max, min, average 등 다양한 유틸리티 메서드도 지원한다.\n객체 스트림으로 복원하기\nboxed 메서드를 이용해서 특화 스트림을 일반 스트림으로 변환할 수 있다.\nIntStream intStream = menu.stream().mapToInt(Dish::getCalories); // 스트림을 숫자 스트림으로 변환 Stream\u0026lt;Integer\u0026gt; stream = intStream.boxed(); // 숫자 스트림을 스트림으로 변환  기본값 : OptionalInt\n합계 에제에서는 0이라는 기본값이 있었으므로 별 문제가 없었다. 하지만 IntStream에서 최대값을 찾을 때는 0이라는 기본값 때문에 잘못된 결과가 도출될 수 있다. 스트림에 요소가 없는 상황과 실제 최대값이 0인 상황을 어떻게 구별할 수 있을까. OptionalInt, OptionalDouble, OptionalLong 세 가지 기본형 특화 스트림 버전이 있다.\nOptionalInt maxCalories = menu.stream().maxToInt(Dish::getCalories).max(); int max = maxCalories.orElse(1); // 값이 없을 때 기본 최대값을 명시적으로 설정  숫자 범위\n프로그램에서는 특정 범위의 숫자를 이용해야 하는 상황이 자주 발생한다. 자바8의 IntStream과 LongStream에서는 range와 rangeClosed라는 두 가지 정적 메서드를 제공한다. 두 메서드 모두 첫 번째 인수로 시작값을, 두 번째 인수로 종료값을 갖는다. range 메서드는 시작값과 종료값이 결과에 포함되지 않는 반면 rangeClosed는 시작값과 종료값이 결과에 포함된다는 점이 다르다.\nIntStream evenNumbers = IntStream.rangeClosed(1,100).filter(n-\u0026gt;n%2==0); System.out.println(evenNumbers.count());  스트림 만들기 값으로 스트림 만들기\n임의의 수를 인수를 받는 정적 메서드 Stream.of를 이용해서 스트림을 만들 수 있다. 예를 들어 다음 코드는 Stream.of로 문자열 스트림을 만드는 예제다. 스트림의 모든 문자열을 대문자로 변환한 후 문자열을 하나씩 출력한다.\nStream\u0026lt;String\u0026gt; stream = Stream.of(“java8”,”lambda”,”in”,”action”); stream.map(String::toUpperCase).forEach(System.out::println); 다음 처럼 empty 메서드를 이용해서 스트림을 비울 수 있다. Stream\u0026lt;String\u0026gt; emptyStream = Stream.empty();\n배열로 스트림 만들기\n배열을 인수로 받는 정적 메서드 Arrays.stream을 이용해서 스트림을 만들 수 있다.\nint[] numbers = {2, 3, 5, 7, 11, 13}; int sum = Arrays.stream(numbers).sum(); 파일로 스트림 만들기\n파일을 처리하는 I/O 연산에 사용하는 자바의 NIO API도 스트림 API를 활용할 수 있도록 엡테이트되었다. java.nio.file.Files의 많은 정적 메서드가 스트림을 반환한다. 예를 들어 Files.lines는 주어진 파일의 행 스트림을 문자열로 반환한다.\nlong uniqueWords =0; try(Stream\u0026lt;String\u0026gt; lines = Files.lines(Paths.get(“data.txt”), Charset.defaultCharset())) { // 스트림은 자원을 자동으로 해제할 수 있는 AutoClosable이다. \tuniqueWords = lines.flatMap(line -\u0026gt; Arrays.stream(line.split(“ “))) // 단어 스트림 생성 \t.distinct() // 중복 제거 \t.count(); // 고유 단어 수 계산 } catch(IOException e){ } // 파일을 열다가 예외가 발생하면 처리 함수로 무한 스트림 만들기\n스트림 API는 함수에서 스트림을 만들 수 있는 두 개의 정적 메서드 Stream.iterate와 Stream.generate를 제공한다. 두 연산을 이용해서 무한 스트림, 즉 고정된 컬렉션에서 고정된 크기의 스트림을 만들었던 것과는 달리 크기가 고정되지 않은 스트림을 만들 수 있다. iterate와 generate에서 만든 스트림은 요청할 때마다 주어진 함수를 이용해서 값을 만든다. 따라서 무제한으로 값을 계산할 수 있다. 하지만 보통 무한한 값을 출력하지 않도록 limit(n) 함수를 함께 연결해서 사용한다.\n// iterate를 사용하는 방법 Stream.iterate(0, n -\u0026gt; n+2) .limit(10) .forEach(System.out::println); iterate 메서드는 초기값(예제에서는 0)과 람다(예제에서는 UnaryOperator\u0026lt;T\u0026gt; 사용)를 인수로 받아서 새로운 값을 끊임없이 생산할 수 있다. 예제에서는 람다 n -\u0026gt; n+2 즉 이전 결과에 2를 더한 값을 반환한다. 결과적으로 짝수 스트림을 생성한다. 기본적으로 기존 결과에 의존해서 순차적으로 연산을 수행한다. iterate는 요청할 때마다 값을 생산할 수 있으며 끝이 없으므로 무한 스트림을 만든다. 이러한 스트림을 언바운드 스트림이라고 표현한다.\n// 피보나치 수열 Stream.iterate(new int[]{0,1}, t -\u0026gt; new int[]{t[1], t[0] + t[1]}) .limit(10) .map(t -\u0026gt; t[0]) .forEach(System.out::println);// generate 사용하는 방법 Stream.generate(Math::random) .limit(5) .forEach(System.out::println); iterate와 비슷하게 generate도 요구할 때 값을 계산하는 무한 스트림을 만들 수 있다. 하지만 iterate와 달리 generate는 생산된 각 값을 연속적으로 계산하지 않는다. generate는 Supplier\u0026lt;T\u0026gt;를 인수로 받아서 새로운 값을 생산한다.\n"
},
{
	"uri": "/java8_in_action/part2-2_%E1%84%92%E1%85%A1%E1%86%B7%E1%84%89%E1%85%AE%E1%84%92%E1%85%A7%E1%86%BC_%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5_%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5/",
	"title": "Part2-2 함수형 데이터 처리",
	"tags": [],
	"description": "",
	"content": " 6장 - 스트림으로 데이터 수집 4장과 5장에서는 스트림에서 최종 연산 collect를 사용하는 방법을 확인했다. 하지만 toList로 스트림 요소를 항상 리스트로만 변환했다. 이 장에서는 reduce가 그랬던 것처럼 collect 역시 다양한 요소 누적 방식을 인수로 받아서 스트림을 최종 결과로 도출하는 리듀싱 연산을 수행할 수 있음을 설명한다.\n// 통화별로 트랜잭션을 그룹화한 코드 - 명령형 버전 Map\u0026lt;Currency, List\u0026lt;Transaction\u0026gt;\u0026gt; transactionByCurrencies = new HashMap\u0026lt;\u0026gt;(); for(Transaction transaction : transactions){ Currency currency = transaction.getCurrency(); List\u0026lt;Transaction\u0026gt; transactionForCurrency = transactionByCurrencies.get(currency); if(transactionForCurrency == null){ transactionForCurrency = new ArrayList\u0026lt;\u0026gt;(); transactionByCurrencies.put(currency, transactionForCurrency); } transactionForCurrency.add(transaction); } 통화별로 트랜잭션 리스트를 그룹화하기 위해 위와 같은 방법도 있지만 자바8에서는 더 간결한 구현이 가능하다.\nMap\u0026lt;Currency, List\u0026lt;Transaction\u0026gt;\u0026gt; transactionByCurrencies = transactions.stream().collect(groupingBy(Transaction::getCurrency)); 컬렉터란 무엇인가? Collector 인터페이스 구현은 스트림의 요소를 어떤 식으로 도출할지 지정한다. 5장에서는 \u0026lsquo;각 요소를 리스트로 만들어라\u0026rsquo;를 의미하는 toList를 Collector 인터페이스의 구현으로 사용했다. 여기서는 groupingBy를 이용해서 \u0026lsquo;각 키(통화) 버킷 그리고 각 키 버킷에 대응하는 요소 리스트를 값으로 포함하는 맵을 만들라\u0026rsquo;는 동작을 수행한다.\ncollect 메서드로 Collector 인터페이스 구현을 전달한다. 스트림에 collect를 호출하면 스트림의 요소에 내부적으로 리듀싱 연산이 수행된다. 통화 예제에서 보여주는 것처럼 Collector 인터페이스의 메서드를 어떻게 구현하느냐에 따라 스트림에 어떤 리듀싱 연산을 수행할지 결정된다. Collectors 유틸리티 클래스는 자주 사용하는 컬렉터 인스턴스를 손쉽게 생성할 수 있는 정적 팩토리 메서드를 제공한다. ex) toList(), counting()\n리듀싱과 요약\n첫 번째 예제로 counting()이라는 팩토리 메서드가 반환하는 컬렉터로 메뉴에서 요리 수를 계산한다.\nlong howMayDishes = menu.stream().collect(counting());\n두 번째는 메뉴에서 칼로리가 가장 높은 요리를 찾는다고 해보자. Collectors.maxBy, Collectors.minBy 두 개의 메서드를 이용해서 스트림의 최댓값과 최솟값을 계산할 수 있다. 두 컬렉터는 스트림의 요소를 비교하는데 사용할 Comparator를 인수로 받는다.\nComparator\u0026lt;Dish\u0026gt; dishCaloriesComparator = Comparator.comparingInt(Dish::getCalories); Optional\u0026lt;Dish\u0026gt; mostCalorieDish = menu.stream().collect(maxBy(dishCaloriesComparator)); 또한 스트림에 있는 객체의 숫자 필드의 합계나 평균 등을 반환하는 연산에도 리듀싱 기능이 자주 사용된다. 이러한 연산을 요약 연산이라 부른다.\n다음은 메뉴 리스트의 총 칼로리를 계산하는 코드다.\nint totalCalories = menu.stream.collect(summingInt(Dish::getCalories)); summingInt 뿐만 아니라 summingLong, summingDouble, averagingInt, averagingLong, averagingDouble 등 다양한 형식이 존재한다.\ndouble avgCalories = menu.stream.collect(averagingInt(Dish::getCalories)); 두 개 이상의 연산을 한 번에 수행해야 할 때도 있다. 이런 상황에서는 팩토리 메서드 summarizingInt가 반환하는 컬렉터를 사용할 수 있다. 예를 들어 다음은 하나의 요약 연산으로 메뉴에 있는 요소수, 합계, 평균, min, max 등을 계산하는 코드다.\nIntSummaryStatistics menuStatistics = menu.stream().collect(summarizingInt(Dish::getCalories)); 위 코드를 실행하면 IntSummaryStatistics 클래스로 모든 정보가 수집된다.\nIntSummaryStatistics { count=9, sum=4300, min=120, average=477.777778, max=800 } 마찬가지로 int뿐 아니라 long이나 double에 대응하는 summarizingLong, summarizingDouble 메서드와 관련된 LongSummaryStatistics, DoubleSummaryStatistics 클래스도 있다.\n문자열 연결\n문자열 연결을 위해 joining메서드는 내부적으로 StringBuilder를 이용해서 문자열을 하나로 만든다. 추가적으로 연결된 문자열들 사이에 구분 문자열을 넣을 수 있도록 오버로드된 joining 팩토리 메서드도 있다.\nString shortMenu = menu.stream().map(Dish::getName).collect(joining(\u0026#34;,\u0026#34;)); //코드 실행 결과 pork, beef, chicken, french fries, rice, season fruit, pizza, prawns, salmon 범용 리듀싱 요약 연산\n지금까지 살펴본 모든 컬렉터는 reducing 팩토리 메서드로도 정의할 수 있다. 즉 범용 Collectors.reducing으로도 구현할 수 있다.\nint totalCalories = menu.stream().collect(reducing(0, Dish::getCalories, (i,j) -\u0026gt; i+j)); reducing은 세 개의 인수를 받는다. 첫 번째 인수는 리듀싱 연산의 시작값이거나 스트림에 인수가 없을 때는 반환값이다. 두 번째 인수는 변환 함수다. 세 번째 인수는 같은 종류의 두 항목을 하나의 값으로 더하는 BinaryOperator다.\n다음처럼 한 개의 인수를 가진 reducing 버전을 이용해서 가장 칼로리가 높은 요리를 찾는 방법도 있다.\nOptional\u0026lt;Dish\u0026gt; mostCalorieDish = menu.stream().collect(reducing( (d1, d2) -\u0026gt; d1.getCaloriees() \u0026gt; d2.getCalories() ? d1 : d2)); 한 개의 인수를 갖는 reducing 컬렉터는 시작값이 없으므로 빈 스트림이 넘겨졌을 때 시작값이 설정되지 않는 상황이 벌어진다. 그래서 Optional로 받고, 반환함수가 자기 자신이기 때문에(항등 함수) 최종적으로 Optional\u0026lt;Dish\u0026gt; 객체를 반환한다.\n컬렉션 프레임워크 유연성: 같은 연산도 다양한 방식으로 수행할 수 있다.\n이전 예제의 람다표현식 대신 Integer 클래스의 sum 메서드 레퍼런스를 이용하면 코드를 좀 더 단순화할 수 있다.\nint totalCalories = menu.stream().collect(reducing( 0, // 초기값  Dish::getCalories, //변환 함수  Integer::sum)); // 합계 함수 또 컬렉터를 이용하지 않는 방법도 있다.\nint totalCalories = menu.stream().map(Dish::getCalories).reduce(Integer::sum).get(); reduce(Integer::sum)도 빈 스트림과 관련한 널 문제를 피할 수 있도록 int가 아닌 Optional\u0026lt;Integer\u0026gt;를 반환한다. 그리고 get으로 Optional 객체 내부의 값을 추출했다. 요리 스트림은 비어있지 않다는 사실을 알고 있으므로 get을 자유롭게 사용할 수 있다. 마지막으로 스트림을 IntStream으로 매핑한 다음에 sum 메서드를 호출하는 방법으로도 결과를 얻을 수 있다.\nint totalCalories = menu.stream().mapToInt(Dish::getCalories).sum(); 마지막 방식이 가독성이 가장 좋고 간결하다. 또한 IntStream 덕분에 자동 언박싱 연산을 수행하거나 Integer를 int로 변환하는 과정을 피할 수 있으므로 성능까지 좋다.\n그룹화 메뉴를 그룹화한다고 가정하자. 예를 들어 고기를 포함하는 그룹, 생선을 포함하는 그룹, 나머지 그룹으로 메뉴를 그룹화할 수 있다. 다음처럼 팩토리 메서드 Collectors.groupingBy를 이용해서 쉽게 메뉴를 그룹화할 수 있다.\nMap\u0026lt;Dish.Type, List\u0026lt;Dish\u0026gt;\u0026gt; dishesByType = menu.stream().collect(groupingBy(Dish::getType)); 다음은 Map에 포함된 결과다.\n{Fish=[prawns, salmon], OTHER=[french fries, rice], MEAT=[pork, beef, chicken]}  스트림의 각 요리에서 Dish.Type과 일치하는 모든 요리를 추출하는 함수를 groupingBy 메서드로 전달했다. 이 함수를 기준으로 스트림이 그룹화되므로 이를 분류 함수라고 부른다.\n그런데 위와 같이 단순한 분류 기준이 아닌 복잡한 분류 기준이 필요한 상황에서는 메서드 레퍼런스를 분류 함수로 사용할 수 없다. 예를 들어 400칼로리 이하를 \u0026lsquo;diet\u0026rsquo;로, 400~700칼로리를 \u0026lsquo;normal\u0026rsquo;로, 700칼로리 초과를 \u0026lsquo;fat\u0026rsquo; 요리로 분류한다고 가정하자. Dish 클래스에는 이러한 연산에 필요한 메서드가 없으므로 메서드 레퍼런스를 분류 함수로 사용할 수 없다. 따라서 다음 예제처럼 람다 표현식으로 필요한 로직을 구현해야 한다.\npublic enum CaloricLevel { DIET, NORMAL, FAT } Map\u0026lt;CaloricLevel, List\u0026lt;Dish\u0026gt;\u0026gt; dishesByCaloricLevel = menu.stream().collect( groupingBy(dish -\u0026gt; { if (dish.getCalories() \u0026lt;= 400) return CaloricLevel.DIET; else if (dish.getCalories() \u0026lt;= 700) return CaloricLevel.NORMAL; else return CaloricLevel.FAT; }) ); 다수준 그룹화\n지금까지 메뉴의 요리를 종류 또는 칼로리로 그룹화하는 방법을 살펴봤다. 그러면 요리 종류와 칼로리 두 가지 기준으로 동시에 그룹화할 수 있을까?\n두 인수를 받는 팩토리 메서드 Collections.groupingBy를 이용해서 항목을 다수준으로 그룹화할 수 있다.\nMap\u0026lt;Dish.Type, Map\u0026lt;CaloricLevel, List\u0026lt;Dish\u0026gt;\u0026gt;\u0026gt; dishesByTypeCaloricLevel = menu.stream().collect( groupingBy(Dish::getType, groupingBy(dish -\u0026gt; { if (dish.getCalories() \u0026lt;= 400) return CaloricLevel.DIET; else if (dish.getCalories() \u0026lt;= 700) return CaloricLevel.NORMAL; else return CaloricLevel.FAT; }))); {MEAT={DIET=[chicken], NORMAL=[beef], FAT=[pork]}, FISH={DIET=[prawns], NORMAL=[salmon]}, OTHER={DIET=[rice, seasonal fruit], NORMAL=[french fries, pizza]}}  분할 분할은 분할 함수라 불리는 프레디케이트를 분류 함수로 사용하는 특수한 그룹화 기능이다. 분할 함수는 불린을 반환하므로 맵의 키 형식은 Boolean이다. 결과적으로 그룹화 맵은 최대 두 개(T/F)의 그룹으로 분류된다. 예를 들어 채식주의자 친구를 저녁에 초대했다고 가정하자. 그러면 이제 모든 요리를 채식 요리와 채식이 아닌 요리로 분류 해야 한다.\nMap\u0026lt;Boolean, List\u0026lt;Dish\u0026gt;\u0026gt; partitionedMenu = menu.stream().collect(partitioningBy(Dish::isVegetarian)); 위 코드를 실행하면 다음과 같은 맵이 반환된다.\n{false=[pork, beef, chicken, prawns, salmon], true=[french fries, rice, season fruit, pizza]}  이제 참값의 키로 맵에서 모든 채식 요리를 얻을 수 있다.\nList\u0026lt;Dish\u0026gt; vegetarianDishes = partitionedMenu.get(true); 물론 이전 예제에서 사용한 프레디케이트로 필터링한 다음에 별도의 리스트에 결과를 수집해도 같은 결과를 얻을 수 있다.\nList\u0026lt;Dish\u0026gt; vegetarianDishes = menu.stream().filter(Dish::isVegetarian).collect(toList());"
},
{
	"uri": "/java8_in_action/part3-1_%E1%84%92%E1%85%AD%E1%84%80%E1%85%AA%E1%84%8C%E1%85%A5%E1%86%A8%E1%84%8B%E1%85%B5%E1%86%AB_%E1%84%8C%E1%85%A1%E1%84%87%E1%85%A18_%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%80%E1%85%B3%E1%84%85%E1%85%A2%E1%84%86%E1%85%B5%E1%86%BC/",
	"title": "Part3-1 효과적인 자바8 프로그래밍",
	"tags": [],
	"description": "",
	"content": " 9장 디폴트 메서드 스터디에서 나온 내용 : 인터페이스를 구현한 클래스에서 바로 사용하기 위해 default 메서드를 사용하면 안된다. 인터페이스를 직접 사용하는 클라이언트가 쉽게 쓰기 위해 사용돼야 한다. ex list.sort(Compator\u0026lt;? super E\u0026gt; c)\n그리고 만약 한 인터페이스를 구현한 클래스가 10개 있는데 그 중 2개는 인터페이스의 추상 메서드를 잘 안쓰고 빈 구현만 해놨다면 2개의 구현체가 그 인터페이스를 바라보고 있는게 올바른지 의심해볼 필요가 있다.(디폴트 메서드로 만들어서 빈 구현체를 없애는 게 아니라)\n자바 8 이전에는 만약 인터페이스에 새로운 메서드를 정의하면\n구현 클래스를 수정해줘야 했다.\n그부분이 라이브러리 설계자 입장에서는 큰 제약이었다. 특히 모두에게 공개된 API 경우, 사용자가 직접 구현한 클래스까지 설계자가 커버할 수 없다.\n그래서 새롭게 나온게 자바8 디폴트 메서드이다.\ndefault Stream\u0026lt;E\u0026gt; stream() { return StreamSupport.stream(spliterator(), false); } default Stream\u0026lt;E\u0026gt; parallelStream() { return StreamSupport.stream(spliterator(), true); } @Override default Spliterator\u0026lt;E\u0026gt; spliterator() { return Spliterators.spliterator(this, 0); } @SuppressWarnings({\u0026#34;unchecked\u0026#34;, \u0026#34;rawtypes\u0026#34;}) default void sort(Comparator\u0026lt;? super E\u0026gt; c) { Object[] a = this.toArray(); Arrays.sort(a, (Comparator) c); ListIterator\u0026lt;E\u0026gt; i = this.listIterator(); for (Object e : a) { i.next(); i.set((E) e); } } cf) Effective Java 규칙 24\n제거할 수 없는 경고 메세지는 형 안전성이 확실할 때만 @SuppressWarings(“unchecked”)를 사용해 억제해라.\nRawtypes는 제너릭을 사용하는 클래스 매개 변수가 불특정일 때의 경고다.\n3장에서 소개한 Predicate, Function 등 많은 함수형 인터페이스도 다양한 디폴트 메서드를 포함한다. 함수형 인터페이스는 오직 하나의 추상 메서드를 포함한다. 디폴트 메서드는 추상 메서드에 해당하지 않는다는 점을 기억하자.\n디폴트 메서드가 생기면서 들었던 의문\n 이렇게 되면 추상 클래스와 다른게 뭐지? 자바는 다중 상속을 허용안하는데 여러 디폴트 메서드를 상속받을 수 있게 되면서 다중 상속이 가능해진건가?  책에서 말하는 추상 클래스와 인터페이스의 차이점(문법적 차이만 설명함)\n 클래스는 하나의 추상 클래스만 상속받을 수 있지만 인터페이스는 여러 개 구현할 수 있다. 추상 클래스는 인스턴스 변수로 공통 상태를 가질 수 있지만 인터페이스는 인스턴스 변수를 가질 수 없다.  1. 추상클래스 vs 인터페이스\n클린코더스 : 추상 클래스 대신 인터페이스를 써라. Extends는 비싸니까(한번밖에 사용불가능)\nEffective Java 규칙 18 : 추상 클래스 대신 인터페이스를 사용하라.\n2. 다중 상속\n책에서는 다중 상속으로 프로그램에 유연성을 제공한다고 말한다.\n디폴트 메서드에 대해서 좀 더 자세히 알아보자. API버전 1(p291 ~ 292)에서 Resizable 인터페이스에 새로운 메서드가 추가되었다고 해보자.\npublic interface Resizable extends Drawable{ int getWidth(); int getHeight(); void setWidth(int width); void setHeight(int height); void setAbsoluteSize(int width, int height); //새롭게 추가  void setRelativeSize(int wFactor, int hFactor); } 재컴파일 하면 에러가 발생한다.\n공개된 API를 고치면 기존 버전과의 호환성 문제가 발생한다.\ncf) 공개된 API란 거창한것이 아니라 public으로 만든 것들을 의미한다.\n인터페이스에 메서드를 추가했을 때는 바이너리 호환성을 유지하지만 인터페이스를 구현하는 클래스를 재컴파일 하면 에러가 발생한다. 즉, 다양한 호환성이 있다는 사실을 이해해야 한다.\n바이너리 호환성 : 뭔가를 바꾼 이후에도 에러 없이 기존 바이너리가 실행될 수 있는 상황.\nex) 인터페이스에 메서드를 추가했을 때 추가된 메서드를 호출하지 않는 한 문제가 일어나지 않는데 이를 바이너리 호환성이라고 한다.\n소스 호환성 : 코드를 고쳐도 기존 프로그램을 성공적으로 재컴파일 할 수 있음.\nex) 인터페이스에 메서드를 추가하면 소스 호환성이 아니다. 추가한 메서드를 구현하도록 클래스를 고쳐야 하기 때문이다. 디폴트 메서드로 만들면 소스 호환성이 유지된다.\n동작 호환성 : 코드를 바꾼 다음에도 같은 입력값이 주어지면 프로그램이 같은 동작을 실행한다는 의미.\nex) 인터페이스에 메서드를 추가하더라도 프로그램에서 추가된 메서드를 호출할 일은 없으므로 동작 호환성은 유지된다.\n디폴트 메서드 활용 패턴 선택형 메서드(optional method) : Iterator는 hasNext와 next뿐 아니라 remove 메서드도 정의하지만 사용자들이 remove는 잘 사용하지 않으므로 자바8 이전에는 Iterator를 구현하는 많은 클래스에서 remove에 빈 구현을 제공했다. 하지만 이제 디폴트 메서드를 이용하면 구현 클래스에서 빈 구현을 제공할 필요가 없어진다.\npublic interface Iterator\u0026lt;E\u0026gt; { boolean hasNext(); E next(); default void remove() { throw new UnsupportedOperationException(\u0026#34;remove\u0026#34;); } } 동작 다중 상속(multiple inheritance of behavior) 자바8에서는 인터페이스가 구현을 포함할 수 있으므로 클래스는 여러 인터페이스에서 동작을 상속받을 수 있다.\n옳지 못한 상속 상속으로 코드 재사용 문제를 모두 해결할 수 있는 것은 아니다.\n예를 들어 한 개의 메서드를 재사용하려고 100개의 메서드와 필드가 정의되어 있는 클래스를 상속받는 것은 좋은 생각이 아니다. 이럴 때는 delegation(위임), 즉 멤버 변수를 이용해서 클래스에서 필요한 메서드를 직접 호출하는 메서드를 작성하는 것이 좋다.\n종종 final로 선언된 클래스를 볼 수 있는데 (ex String) 다른 클래스가 상속다지 못하게 함으로써 원래 동작이 바뀌지않길 원할 때 쓴다. 이렇게 하면 다른 누군가가 그 클래스의 핵심 기능을 바꾸지 못하도록 제한할 수 있다.\n해석 규칙(같은 디폴트 메서드 시그너처가 있을 때) p302 [해석규칙]\n 클래스가 항상 이긴다. 클래스나 슈퍼클래스에서 정의한 메서드가 디폴트 메서드보다 우선권을 갖는다. 1번 규칙 이외의 상황에서는 서브 인터페이스가 이긴다. 상속관계를 갖는 인터페이스에서 같은 시그너처를 갖는 메서드를 정의할때는 서브인터페이스가 이긴다. 여전히 디폴트 메서드의 우선순위가 결정되지 않았다면 여러 인터페이스를 상속받는 클래스가 명시적으로 디폴트 메서드를 오버라이드하고 호출해야 한다.  Q) 컴파일러는 누구의 hello 메서드 정의를 사용할까? 정답은 B(2번 규칙에 의해서)\nQ) 컴파일러는 누구의 hello 메서드 정의를 사용할까? 이것도 정답은 B(2번 규칙에 의해서)\nQ) 컴파일러는 누구의 hello 메서드 정의를 사용할까? 정답은 D (1번 규칙, 클래스가 항상 이긴다)\n이번에는 인터페이스 간에 상속관계가 없으므로 2번 규칙을 적용할 수 없다. 충돌을 해결하기 위해선 개발자가 직접 클래스 C에서 hello 메서드를 오버라이드한 다음에 호출하려는 메서드를 명시적으로 선택해야 한다.\npublic class C implements A,B{ public void hello(){ B.super.hello(); } } 다이아몬드 문제 public class D implements B,C { public static void main(String... args) { new D().hello(); } } A만 디폴트 메서드를 정의하고 있다. 따라서 결국 프로그램 출력 결과는 “Hello from A”가 된다.\npublic class D implements B,C { public static void main(String... args) { new D().hello(); } } B에도 같은 시그너처의 디폴트 메서드가 있다면?\nB는 A를 상속받으므로 2번 규칙에 따라 B가 선택된다.\nB와 C가 모두 디폴트 메서드 hello 메서드를 정의한다면 충돌이 발생하므로 이전에 설명한 것 처럼 둘 중 하나의 메서드를 명시적으로 호출해야 한다.\n10장 null 대신 Optional 값이 없는 상황에서 어떻게 처리할까?\nPerson/Car/Insurance 데이터 모델 public class Person { private Car car; public Car getCar() { return car; } } public class Car { private Insurance insurance; public Insurance getInsurance() { return insurance; } } public class Insurance { private String name; public String getName() { return name; } } 첫 번째 방법으로는 deep doubt(깊은 의심)이 있다.\npublic String getCarInsuranceName(Person person) { if (persion != null) { Car car = persion.getCar(); if (car != null) { Insurance insurance = car.getInsurance(); if (insurance != null) { return insurance.getName(); } } } return \u0026#34;Unknown\u0026#34;; } 두 번째 방법으로는 다양한 출구를 만드는 것이다.\npublic String getCarInsuranceName(Person person) { if (person == null) { return \u0026#34;Unknown\u0026#34;; } Car car = person.getCar(); if (car == null) { return \u0026#34;Unknown\u0026#34;; } Insurance insurance = car.getInsurance(); if (insurance == null) { return \u0026#34;Unknown\u0026#34;; } return insurance.getName(); } 위 코드는 중첩 if 블록을 없앴지만 네 개의 출구가 생겼기 때문에 유지보수하기 힘들어진다.\n그래서 자바8은 java.util.Optional\u0026lt;T\u0026gt;를 제공한다. Optional은 선택형값을 캡슐화하는 클래스다. 값이 있으면 Optional 클래스는 값을 감싼다. 반면 값이 없으면 Optional.empty 메서드로 Optional을 반환한다. 즉, Optional 타입은 값이 없을 수 있음을 명시적으로 보여준다.\n빈 Optional\nOptional\u0026lt;Car\u0026gt; optCar = Optional.empty(); null이 아닌 값으로 Optional 만들기\ncar가 null이라면 즉시 NPE가 발생한다(Optional을 사용하지 않았다면 car의 프로퍼티에 접근하려 할 때 에러가 발생했을 것이다).\nOptional\u0026lt;Car\u0026gt; optCar = Optional.of(car); null값으로 Optional만들기\nnull값을 저장할 수 있는 Optional을 만들 수 있다. 만약 car가 null이면 빈 Optional 객체가 반환된다.\nOptional\u0026lt;Car\u0026gt; optCar = Optional.ofNullable(car); flatMap으로 Optional 객체 연결 Optional\u0026lt;Person\u0026gt; optPerson = Optional.of(person); Optional\u0026lt;String\u0026gt; name = optPerson.map(Person::getCar) .map(Car::getInsurance) .map(Insurance::getName); 위 코드는 컴파일 되지 않는다. 그 이유는 optPerson.map(Person::getCar)코드가 Optional\u0026lt;Optional\u0026lt;Car\u0026gt;\u0026gt;를 리턴하기 때문이다. 그래서 이 문제를 해결하기 위해서는 flatMap을 써야한다.\n스트림의 flatMap은 함수를 인수로 받아서 다른 스트림을 반환하는 메서드다. 보통 인수로 받은 함수를 스트림의 각 요소에 적용하면 스트림의 스트림이 만들어진다. 하지만 flatMap은 인수로 받은 함수를 적용해서 생성된 각각의 스트림에서 콘텐츠만 남긴다.\nOptional\u0026lt;Person\u0026gt; optPerson = Optional.of(person); String s = optPerson .flatMap(Person::getCar) .flatMap(Car::getInsurance) .map(Insurance::getName) .orElse(\u0026#34;Unknown\u0026#34;); 만약 flatMap을 빈 Optional에 호출하면 아무 일도 일어나지 않고 그대로 반환된다. 반면 Optional이 Person을 감싸고 있다면 flatMap에 전달된 Function이 Person에 적용된다. Function을 적용한 결과가 이미 Optional이므로 flatMap 메서드는 결과를 그대로 반환할 수 있다.\ncf) 도메인 모델에 Optional을 사용했을 때 데이터를 직렬화 할 수 없는 이유\nOptional 클래스는 필드 형식으로 사용할 것을 가정하지 않았으므로 Serializable 인터페이스를 구현하지 않는다. 따라서 직렬화 모델이 필요하다면 Optional로 값을 반환받을 수 있는 메서드를 추가하는 방식을 권장한다.\npublic class Person { private Car car; public Optional\u0026lt;Car\u0026gt; getCarAsOptional() { return Optioanl.ofNullable(car); } } Optional 인스턴스에서 값을 읽을 수 있는 다양한 인스턴스 메서드\nget()은 값을 읽는 가장 간단한 메서드면서 동시에 가장 안전하지 않은 메서드다. 값이 있으면 해당 값을 반환하고 없으면 NoSuchElementException을 발생시킨다.\norElse(T other)는 Optional이 값을 포함하지 않을 때 디폴트값을 제공할 수 있다.\norElseGet(Supplier\u0026lt;? extends T\u0026gt; other)은 Optional에 값이 없을 때만 Supplier가 실행된다. 디폴트 메서드를 만드는데 시간이 오래걸리거나 Optional이 비어있을 때만 디폴트값을 생성하고 싶을 때 사용한다.\norElseThrow(Supplier\u0026lt;? extends X\u0026gt; exceptionSupplier)는 Optional이 비어있을 때 예외를 발생시키는 점에서 get 메서드와 비슷하지만 이 메서드는 발생시킬 예외의 종류를 선택할 수 있다.\nifPresent(Consumer\u0026lt;? super T\u0026gt; consumer)는 값이 존재할 때 인수로 넘겨준 동작을 실행할 수 있다. 값이 없으면 아무 일도 일어나지 않는다. 추가적으로 값이 존재하면 true를 반환하고 값이 없으면 false를 반환하는 isPresent()메서드도 있다.\npublic boolean isPresent() { return value != null; } public void ifPresent(Consumer\u0026lt;? super T\u0026gt; consumer) { if (value != null) consumer.accept(value); } filter로 특정값 거르기\nOptional 객체가 값을 가지며 프레디케이트와 일치하면 filter 메서드는 그 값을 반환하고 그렇지 않으면 빈 Optional 객체를 반환한다. Optional이 비어있다면 filter 연산은 아무 동작도 하지 않는다.\n"
},
{
	"uri": "/singleton/",
	"title": "Singleton",
	"tags": [],
	"description": "",
	"content": " 직접 코딩 public class Singleton { private static Singleton instance; private Singleton() {} public static Singleton getInstange() { if (instance == null) instance = new Singleton(); return instance; } } 멀티스레드 환경에서도 하나만 생성되게 하려면? public enum EnumSingleton { INSTANCE; public static EnumSingleton getInstance() { return INSTANCE; } } 이펙티브자바 규칙3 enum방식을 적용한다. 이전 방식에 비해 더 간결하고, 직렬화가 자동으로 처리된다. 리플렉션을 통한 공격에도 안전하다. 원소가 하나뿐인 enum 자료형이야말로 싱글턴을 구현하는 가장 좋은 방법이다.\n처음 코드 방식으로 멀티스레드 환경에서 돌리게 되면 경쟁 조건 때문에 제대로 동작하지 않을 가능성이 있다. 스레드 A와 스레드 B가 동시에 getInstance를 수행한다고 치자. singleton 변수가 null이라는 사실을 본 다음 스레드 A는 인스턴스를 새로 생성한다. 스레드 B도 singleton 변수가 null인지 살펴본다. 이때 singleton 변수의 null 여부는 스케줄이 어떻게 변경될지 또는 스레드 A가 인스턴스를 생성하고 singleton 변수에 저장하기까지 얼마나 걸리는지 등의 예측하기 어려운 타이밍에 따라 달라진다. 원래 getInstance는 항상 같은 인스턴스를 리턴하도록 설계돼 있는데, 스레드 B가 살펴보는 그 시점에 singleton 변수가 null이면 getInstance를 호출한 두 스레드가 각자 서로 다른 인스턴스를 가져갈 수도 있다. 그래서 그에 대한 해결책으로 getInstance 메서드에 synchronized를 해줄 수 있다(성능은 안좋음).\npublic class Singleton { private static Singleton instance; private Singleton() {} public static synchronized Singleton getInstange() { if (instance == null) instance = new Singleton(); return instance; } } 다른 방법(성질 급한 초기화)으로는 static 구문에서 초기화함으로써 생성될 때나 참조될 때 따로 동기화를 맞출 필요없게 한다.\npublic class Singleton { private static Singleton instance = new Singleton(); public static Singleton getInstance() { return instance; } } 또 다른 방법(늦은 초기화 홀더 클래스)은 다음과 같다.\npublic class ResourceFactory { private static class ResourceHolder { public static Resource resource = new Resource(); } public static Resource getResource() { return ResourceHolder.resource; } } 오로지 Resource 클래스를 초기화할 목적으로 늦은 초기화 홀더 클래스 구문을 적용해 작성한 클래스다. JVM은 ResourceHolder 클래스를 실제로 사용하기 전까지는 해당 클래스를 초기화하지 않으며, Resource 클래스 역시 static 초기화 구문에서 초기화하기 때문에 추가적인 동기화 기법을 적용할 필요가 없다. 어느 스레드건 간에 처음 getResource 메서드를 호출하면 JVM에서 ResourceHolder 클래스를 읽어들여 초기화하고, ResourceHolder 클래스를 초기화하는 도중에 Resource 클래스 역시 초기화하게 돼 있다.\n초기화 지연은 신중하게 하라(규칙71) 에서도 위의 방식을 추천한다. \u0026lsquo;성능 문제 때문에 정적 필드 초기화를 지연시키고 싶을 때는 초기화 지연 담당 클래스(lazy initialization holder class) 숙어를 적용하라\u0026rsquo;\n이 숙어가 좋은 점은 getResource를 동기화 메서드로 선언하지 않아도 된다는 것이다. 따라서 초기화를 지연시켜도 메서드 이용 비용은 전혀 증가하지 않는다. 최신 VM은 클래스를 초기화하기 위한 필드 접근은 동기화한다. 하지만 클래스가 일단 초기화되고 나면 코드를 바꿔서 앞으로의 필드 접근에는 어떤 동기화나 검사도 필요치 않도록 만든다.\nSingleton 단점 1.클래스를 싱글턴으로 만들면 클라이언트를 테스트하기가 어려워질 수가 있다. 싱글턴이 어떤 인터페이스를 구현하는 것이 아니면 가짜 구현으로 대체할 수 없기 때문이다.\n2.리플렉션 기능을 통해 private 생성자를 호출하는 공격을 받을 수 있다. AccessibleObject.setAccessible 메서드의 도움을 받아 권한 획득이 가능하다.\nConstructor\u0026lt;?\u0026gt; con = Private.class.getDeclaredConstructors()[0]; con.setAccessible(true); Private p = (Private) con.newInstance(); 3.싱글턴 클래스를 직렬화 가능(Serializable) 클래스로 만드려면 클래스 선언에 implements Serializable을 추가하는 것으로는 부족하다. (규칙 77) 싱글턴 특성을 유지하려면 모든 필드를 transient로 선언하고 readResolve 메서드를 추가해야 한다. 그렇지 않으면 직렬화된 객체가 역직렬화될 때마다 새로운 객체가 생기게된다.\n// 싱글턴 상태를 유지하기 위한 readResolve 구현 private Object readResolve() { // 동일한 Elvis 객체가 반환되도록 하는 동시에, 가짜 Elvis 객체는 GC가 처리하도록 만든다.  return INSTANCE; } 역직렬화할 객체의 클래스에 제대로 선언된 readResolve 메서드가 정의되어 있는 경우, 역직렬화가 끝나서 만들어진 객체에 대해 이 메서드가 호출된다.\n4.private 생성자를 갖고 있기 때문에 상속할 수 없다. (토비 스프링) 기술적인 서비스만 제공하는 경우라면 상관없겠지만, 애플리케이션의 로직을 담고 있는 일반 오브젝트의 경우 싱글톤으로 만들었을 때 객체지향적인 설계의 장점을 적용하기가 어렵다는 점은 심각한 문제다.\n5.서버환경에서는 싱글톤이 하나만 만들어지는 것을 보장하지 못한다. (토비 스프링) 서버에서 클래스 로더를 어떻게 구성하고 있느냐에 따라서 싱글톤 클래스임에도 하나 이상의 오브젝트가 만들어질 수 있다. 여러 개의 JVM에 분산돼서 설치가 되는 경우에도 각각 독립적으로 오브젝트가 생기기 때문에 싱글톤으로서의 가치가 떨어진다.\n6.싱글톤의 사용은 전역 상태를 만들 수 있기 때문에 바람직하지 못하다. (토비 스프링) 싱글톤은 사용하는 클라이언트가 정해져 있지 않다. 싱글톤의 스태틱 메서드를 이용해 언제든지 싱글톤에 쉽게 접근할 수 있기 때문에 애플리케이션 어디서든지 사용될 수 있고, 그러다 보면 자연스럽게 전역 상태로 사용되기 쉽다. 아무 객체나 자유롭게 접근하고 수정하고 공유할 수 있는 전역 상태를 갖는 것은 객체지향 프로그래밍에서는 권장되지 않는 프로그래밍 모델이다.\nDouble checked locking 악명 높은 피해야 할 패턴이다(하지만 이펙티브 자바 규칙 71에서는 사용에 문제삼지 않는다). 굉장히 초기에 사용하던 JVM은 경쟁이 별로 없는 상태라고 해도 동기화를 맞추려면 성능에 엄청난 영향을 주었다. 그 결과 동기화 기법이 주는 영향을 최소화하고자 하는 여러 가지 기발한 방법이 나타나기 시작했다. 일부 괜찮은 방법도 있었고, 안좋은 방법도 있었고, 정말 문제 많은 방법도 있었다. DCL은 정말 문제 많은 방법에 속하는 놈이다.\n@NotThreadSafe public class DoubleCheckedLocking { private static Resource resource; public static Resource getInstance() { if (resource == null) { synchronized(this) { if (resource == null) resource = new Resource(); } } return resource; } } DCL은 먼저 동기화 구문이 없는 상태로 초기화 작업이 필요한지를 확인하고, resource 변수의 값이 null이 아니라면(다시 말해 초기화가 돼 있다면) resource 변수에 참조된 객체를 사용한다. 만약 초기화 작업이 필요하다면 동기화 구문을 사용해 락을 걸고 Resource 객체가 초기화됐는지 다시 한 번 확인하는데, 이렇게 하면 Resource 객체를 초기화하는 작업은 한 번에 하나의 스레드만 가능하긴 하다.\n여기서 가장 자주 사용하는 부분, 즉 이미 만들어진 Resource 인스턴스에 대한 참조를 가져오는 부분은 동기화돼 있지 않았다. 바로 이 부분이 문제인데 ‘부분 구성’된 Resource 인스턴스를 사용하게 될 가능성이 있다. 그래서 이미 초기화된 필드에는 락을 걸지 않으므로, 필드는 반드시 volatile로 선언해야 한다.\nDCL이 갖고 있는 더 큰 문제는 동기화돼 있지 않은 상태에서 발생할 수 있는 가장 심각한 문제가 스테일 값(여기서는 null)을 사용할 가능성이 있는 정도에 불과하다고 추정하고 있다는 점이다. 만약 stale 값을 사용하는 경우가 발생하면 락을 확보한 채로 재시도해도 문제를 해결한다. 하지만 실제 최악의 상황은 추정했던 최악의 상황보다 더 심각하다. 즉, 현재 객체에 대한 참조를 제대로 본다 하더라도 객체의 상태를 볼 때 스테일 값을 보게되는 경우, 즉 참조된 객체 내부의 상태가 올바르지 않은 상태일 경우가 생길 수 있다.\n자바 1.5 이후 수정된 자바 메모리 모델의 내용을 보면 resource 변수를 volatile로 선언했을 때는 DCL마저 정상적으로 동작한다. 또한 volatile 변수에 대한 읽기 연산은 volatile이 아닌 변수의 읽기 연산보다 자원을 아주 조금 더 사용할 뿐이기 때문에 성능에 미치는 영향도 미미하다.\nVolatile과 Syncronized 1.자바 병렬프로그래밍 3장 객체공유 p67\n소스코드의 특정 블록을 동기화시키고자 할 때는 항상 메모리 가시성(memory visibility)문제가 발생하는데, 큰 문제일 경우도 있고 별로 문제가 되지 않을 수도 있다. 다시 말하자면 특정 변수의 값을 사용하고 있을 때 다른 스레드가 해당 변수의 값을 사용하지 못하도록 막아야 할 뿐만 아니라, 값을 사용한 다음 동기화 블록을 빠져나가고 나면 다른 스레드가 변경된 값을 즉시 사용할 수 있게 해야 한다는 뜻이다.\n가시성은 그다지 직관적으로 이해할 수 있는 문제가 아니기 때문에 흔히 무시하고 넘어가는 경우가 많다. 만약 단일 스레드만 사용하는 환경이라면 특정 변수에 값을 지정하고 다음번에 해당 변수의 값을 다시 읽어보면, 이전에 저장해뒀던 바로 그 값을 가져올 수 있다. 대부분 이런 경우가 정상적이라고 생각하게 된다. 한마디로 그렇다고 이해하기는 어려울 수 있지만, 특정 변수에 값을 저장하거나 읽어내는 코드가 여러 스레드에서 앞서거니 뒤서거니 실행된다면 반드시 그렇지 않을 수도 있다. 일반적으로 말하자면 특정 변수의 값을 가져갈 때 다른 스레드가 작성한 값을 가져갈 수 있다는 보장도 없고, 심지어는 값을 읽지 못할 수도 있다. 메모리상의 공유된 변수를 여러 스레드에서 서로 사용할 수 있게 하려면 반드시 동기화 기능을 구현해야 한다.\npublic class NoVisibility { private static boolean ready; private static int number; private static class ReaderThread extends Thread { public void run() { while(!ready) Thread.yield(); System.out.println(number); } } public static void main(String[] args) { new ReaderThread().start(); number = 42; ready = true; } } 위의 예제를 보면 동기화 작업이 되어 있지 않은 상태에서 여러 스레드가 동일한 변수를 사용할 때 어떤 문제가 생길 수 있는지를 알 수 있다. 메인 스레드와 읽기 스레드가 ready와 number라는 변수를 공유해 사용한다. 메인 스레드는 읽기 스레드를 실행시킨 다음 number라는 변수에 42라는 값을 넣고, ready 변수의 값을 true로 지정한다. 읽기 스레드는 ready 변수의 값이 true가 될 때까지 반복문에서 기다리다가 ready 값이 true로 변경되면 number 변수의 값을 출력한다. 일반적으로는 읽기 스레드가 42라는 값을 출력하리라고 생각할 수 있겠지만, 0이라는 값을 출력할 수도 있고, 심지어는 영원히 값을 출력하지 못하고 ready 변수의 값이 true로 바뀌기를 계속해서 기다릴 수도 있다. 말하자면 메인 스레드에서 number 변수와 ready 변수에 지정한 값을 읽기 스레드에서 사용할 수 없는 상황인데, 두 개 스레드에서 변수를 공유해 사용함에도 불구하고 적절한 동기화 기법을 사용하지 않았기 때문에 이런 일이 발생한다.\nNoVisibility 클래스의 소스코드를 보면, ready 변수의 값을 읽기 스레드에서 영영 읽지 못할 수도 있기 때문에 무한 반복에 빠질 수 있다. 더 이상하게는 읽기 스레드가 메인 스레드에서 number 변수에 지정한 값보다 ready 변수의 값을 먼저 읽어가는 상황도 가능하다. 흔히 재배치(reordering)라고 하는 현상이다. 재배치 현상은 특정 메서드의 소스코드가 100% 코딩된 순서로 동작한다는 점을 보장할 수 없다는 점에 기인하는 문제이며, 단일 스레드로 동작할 때는 차이점을 전혀 알아챌 수 없지만 여러 스레드가 동시에 동작하는 경우에는 확연하게 나타날 수 있다(자바 메모리 모델에서는 별다른 동기화 구조가 잡혀 있지 않은 경우에 컴파일러가 직접 코드 실행 순서를 조절하면서 하드웨어 레지스터에 데이터를 캐시하거나 CPU가 명령 실행 순서를 재배치하고 프로세서 내부의 캐시에 데이터를 보관하는 등의 작업을 할 수 있도록 되어 있다).\nNoVisibility 예제에서는 제대로 동기화되지 않은 프로그램을 실행했을 때 나타날 수 있는 여러 종류의 어이없는 상황 가운데 stale 데이터라는 결과를 체험했다. 읽기 스레드가 ready 변수의 값을 읽으려 할 때, 이미 최신 값이 아니었기 때문이다. 변수를 사용하는 모든 경우에 동기화를 시켜두지 않으면 해당 변수에 대한 최신 값이 아닌 다른 값을 사용하게 되는 경우가 발생할 수 있다. 게다가 더 큰 문제는 항상 stale 데이터를 사용하게 될 때도 있고, 정상적으로 동작하는 경우도 있다는 점이다. 다시 말하자면 특정 스레드가 어떤 변수를 사용할 대 정상적인 최신 값을 사용할 ‘수’도 있고, 올바르지 않은 값을 사용할 ‘수’도 있다는 말이다.\n동기화되지 않은 상태에서 특정 스레드가 변수의 값을 읽으려 한다면 stale 상태의 값을 읽어갈 가능성이 있긴 하지만, 그래도 전혀 엉뚱한 값을 가져가는 것이 아니라 바로 이전에 다른 스레드에서 설정한 값을 가져가게 된다. 하지만 64비트를 사용하는 숫자형(long, double 등)에 volatile 키워드를 사용하지 않은 경우에는 난데없는 값마저 생길 가능성이 있다. 자바 메모리 모델은 메모리에서 값을 가져오고 저장하는 연산이 단일해야 한다고 정의하고 있지만, volatile로 지정되지 않은 long이나 double 형의 64비트 값에 대해서는 메모리에 쓰거나 읽을 때 두 번의 32비트 연산을 사용할 수 있도록 허용하고 있다. 따라서 volatile을 지정하지 않은 long 변수의 값을 쓰는 기능과 읽는 기능이 서로 다른 스레드에서 동작한다면, 이전 값과 최신 값에서 각각 32비트를 읽어올 가능성이 생긴다.\ncf) 락은 상호 배제뿐만 아니라 정상적인 메모리 가시성을 확보하기 위해서도 사용한다. 변경 가능하면서 여러 스레드가 공유해 사용하는 변수를 각 스레드에서 각자 최신의 정상적인 값으로 활용하려면 동일한 락을 사용해 모두 동기화시켜야 한다\n자바 언어에서는 volatile 변수로 약간 다른 형태의 좀더 약한 동기화 기능을 제공하는데, 다시 말해 volatile로 선언된 변수의 값을 바꿨을 때 다른 스레드에서 항상 최신 값을 읽어 갈 수 있도록 해준다. 특정 변수를 선언 할 때 volatile 키워드를 지정하면 컴파일러와 런타임 모두 ‘이 변수는 공유해 사용하고, 따라서 실행 순서를 재배치 해서는 안 된다’고 이해한다. volatile로 지정된 변수는 프로세서의 레지스터에 캐시되지도 않고, 프로세서 외부의 캐시에도 들어가지 않기 때문에 volatile 변수의 값을 읽으면 항상 다른 스레드가 보관해둔 최신의 값을 읽어갈 수 있다.\n실제로 volatile 변수가 갖는 가시성 효과는 volatile로 지정된 변수 자체의 값에 대한 범위보다 약간 확장되어 있다. 스레드 A가 volatile 변수에 값을 써넣고 스레드 B가 해당 변수의 값을 읽어 사용한다고 할 때, 스레드 B가 volatile 변수의 값을 읽고 나면 스레드 A가 변수에 값을 쓰기 전에 볼 수 있었던 모든 변수의 값을 스레드 B도 모두 볼 수 있다는 점이다. 따라서 메모리 가시성의 입장에서 본다면 volatile 변수를 사용하는 것과 synchronized 키워드로 특정 코드를 묶는 게 비슷한 효과를 가져오고, volatile 변수의 값을 읽고 나면 synchronized 블록에 진입하는 것과 비슷한 상태에 해당한다.\n2.변경 가능 공유 데이터에 대한 접근은 동기화하라.(규칙66)\nsynchronized 키워드는 특정 메서드나 코드 블록을 한 번에 한 스레드만 사용하도록 보장한다. 많은 프로그래머는 동기화(synchronization)를 상호 배제적(mutually exclusive)인 관점, 그러니까 다른 스레드가 변경 중인 객체의 상태를 곽측할 수 없어야 한다는 관점으로만 바라본다. 맞는 말이나, 딱 절반만 이야기 했을 뿐이다. 동기화 없이는 한 스레드가 만든 변화를 다른 스레드가 확인 할 수 없다. 동기화는 스레드가 일관성이 깨진 객체를 관측할 수 없도록 할 뿐 아니라, 동기화 메서드나 동기화 블록에 진입한 스레드가 동일한 락의 보호 아래 이루어진 모든 변경의 영향을 관측할 수 있도록 보장한다.\n성능을 높이기 위해서는 원자적 데이터를 읽거나 쓸 때 동기화를 피해야 한다는 이야기를 아마 들어보았을 것이다. 아주 위험한 이야기다. 언어 명세상으로는 필드에서 읽어낸 값은 임의의 값이 될 수 없다고 되어 있으나, 그렇다고 어떤 스레드가 기록한 값을 반드시 다른 스레드가 보게 되리라는 보장은 없다. 상호 배제성뿐 아니라 스레드 간의 안정적 통신을 위해서라도 동기화는 반드시 필요하다. 자바 언어 명세의 일부인 메모리 모델 때문이다. 메모리 모델은 한 스레드가 만든 변화를 다른 스레드가 볼 수 있게 되는 시점과 그 절차를 규정한다.\n//잘못된 코드 public class StopThread { private static boolean stopRequested; public static void main(String[] args) throws InterruptedExcetpion{ Thread backgroundThread = new Thread(new Runnable() { public void run() { int i = 0; while (!stopRequested) i++; } }); backgroundThread.start(); TimeUnit.SECONDS.sleep(1); stopRequested = true; } } 실행한지 1초가 지나면 main 스레드가 stopRequested의 값을 true로 바꾸므로 backgroundThread가 실행하는 순환문도 그때 중지될 것 같다. 하지만 이 프로그램의 문제는 동기화 메커니즘을 적용하지 않은 탓에 main 스레드가 변경한 stopRequested의 새로운 값을 backgroundThread가 언제쯤 보게 될지 알수가 없다는 것이다. 이 문제를 수정하는 한 가지 방법은 stopRequested 필드를 동기화하는 것이다.\npublic class StopThread { private static boolean stopRequested; private static synchronized void requestStop() { stopRequested = true; } private static synchronized boolean stopRequested() { return stopRequested; } public static void main(String[] args) throws InterruptedExcetpion{ Thread backgroundThread = new Thread(new Runnable() { public void run() { int i = 0; while (!stopRequested()) i++; } }); backgroundThread.start(); TimeUnit.SECONDS.sleep(1); requestStop(); } } 쓰기 메서드와 읽기 메서드에 동기화 메커니즘이 적용되었음에 유의하자. 쓰기 메서드만 동기화하는 것으로는 충분치 않다. 사실, 읽기 연산과 쓰기 연산에 전부 적용하지 않으면 동기화는 아무런 효과도 없다. StopThread의 동기화 메서드가 하는 일은 동기화가 없이도 원자적이다. 다시 말해서, 이들 메서드에 동기화를 적용한 것은 상호 배제성을 달성하기 위해서가 아니라, 순전히 스레드 간 통신 문제를 해결하기 위해서였다. 비록 순환문의 각 단계마다 동기화를 실행하는 비용이 크진 않지만, 그 비용을 줄여서 좋은 성능을 내면서도 간결하기까지 한 대안이 있다. 위 코드에 사용된 boolean 필드 stopRequested를 volatile로 선언하는 것이다. 그러면 락은 없어도 된다. 비록 volatile이 상호 배제성을 실현하진 않지만, 어떤 스레드건 가장 최근에 기록된 값을 읽도록 보장한다.\npublic class StopThread { private static volatile boolean stopRequested; public static void main(String[] args) throws InterruptedExcetpion{ Thread backgroundThread = new Thread(new Runnable() { public void run() { int i = 0; while (!stopRequested) i++; } }); backgroundThread.start(); TimeUnit.SECONDS.sleep(1); stopRequested = true; } } 그런데 volatile을 사용할 때는 주의해야 한다. 아래의 메서드를 보자. 일련번호를 만들어 내는 메서드다.\n//잘못된 예제 - 동기화가 필요하다 private static volatile int nextSerialNumber = 0; public static int generateSerialNumber() { return nextSerialNumber++; } 이 메서드의 원래 의도는, 호출 될 때마다 다른 값을 반환하는 것이었다. 그런데 동기화 없이는 제대로 동작하지 않는다. 문제는 증가 연산자 ++가 원자적이지 않다는 데 있다. 이 연산자는 nextSerialNumber 필드에 두 가지 연산을 순서대로 시행한다. 먼저 값을 읽고, 그 다음에 새로운 값, 즉 읽은 값 더하기 1을 필드에 쓴다. 첫 번째 스레드가 필드의 값을 읽은 후 새 값을 미처 기록하기 전에 두 번째 스레드가 필드에서 같은 값을 읽으면, 두 스레드는 같은 일련번호를 얻게 된다. 이것은 안전 오류다.\n이 문제를 해결하는 한 가지 방법은 메서드를 synchronized로 선언하는 것이다. 그러면 여러 스레드가 동시에 호출하더라도 서로 겹쳐 실행되지 않는 메서드가 되고, 각각의 메서드 호출은 그전에 행해진 모든 호출의 영향을 관측할 수 있게 된다. synchronized 키워드를 붙였다면, nextSerialNumber에 붙였던 volatile 키워드는 삭제해야 한다. 더 좋은 방법은 AtomicLong 클래스를 쓰는 것이다. 이 클래스는 java.util.concurrent.atomic의 일부다. 원하는 일을 해주면서도, synchronized 키워드를 사용한 해법보다 성능도 좋다.\nprivate static final AtomicLong nextSerialNum = new AtomicLong(); public static long generateSerialNumber() { return nextSerialNum.getAndIncrement(); } Thread-safe 하다는 것은? 자바 병렬 프로그래밍 p47\n스레드에 안전한 코드를 작성하는 것은 근본적으로는 상태, 특히 공유되고 변경할 수 있는 상태에 대한 접근을 관리하는 것이다. 공유 됐다는 것은 여러 스레드가 특정 변수에 접근할 수 있다는 뜻이고, 변경할 수 있다(mutable)는 것은 해당 변수 값이 변경될 수 있다는 뜻이다. 스레드 안전성이 마치 코드를 보호하는 것처럼 이해하는 경우가 많지만, 실제로는 데이터에 제어 없이 동시 접근하는 걸 막으려는 의미 임을 알아두자.\n스레드 안전성은 코드에 적용되는 용어일 수도 있지만 주로 상태에 대한 것이고, 상태를 캡슐화하는 코드 전체에 적용될 수 있으며, 적용되는 코드는 객체이거나 또는 프로그램 전체일 수도 있다.\n스레드에 대한 납득할 만한 정의의 핵심은 모두 정확성(correctness) 개념과 관계 있다. 스레드 안전성에 대한 정의가 모호한 것은 정확성에 대한 명확한 정의가 없기 때문이다. 일단 “특정 코드가 동작한다”고 확신하기만 하면, 이런 코드 신뢰도는 많은 사람이 생각하는 정확성과 대략 일치한다. 이런 맥락에서 단일 스레드에서의 정확성은 ‘척 보면 아는’ 어떤 것이라고 가정하자. 낙관적으로 ‘정확성’을 인지할 수 있는 어떤 것으로 정의하면 스레드 안전성도 다소 덜 순환적으로 정의할 수 있다. 즉 여러 스레드가 클래스에 접근할 때 계속 정확하게 동작하면 해당 클래스는 스레드 안전하다. 모든 단일 스레드 프로그램은 멀티스레드 프로그램의 한 종류라고 볼 수 있기 때문에, 애당초 단일 스레드 환경에서도 제대로 동작하지 않으면 스레드 안전할 수 없다.\n스레드 안전한 클래스는 클라이언트 쪽에서 별도로 동기화할 필요가 없도록 동기화 기능도 캡슐화한다. 상태 없는 객체는 항상 스레드 안전하다. 상태를 일관성 있게 유지하려면 관련 있는 변수들을 하나의 단일 연산으로 갱신해야 한다. (락을 사용해서)\n과도한 동기화가 안좋은점은? (규칙67) 상황에 따라서는 동기화를 너무 과도하게 적용하면 성능저하, 교착상태(deadlock), 비결정적 동작 등의 문제가 생길 수 있다. 생존 오류나 안전 오류를 피하고 싶으면, 동기화 메서드나 블록 안에서 클라이언트에게 프로그램 제어 흐름을 넘기지 마라. 다시 말해서, 동기화가 적용된 영역 안에서는 재정의(override) 가능 메서드나 클라이언트가 제공한 함수 객체 메서드를 호출하지 말라는 것이다. 동기화 영역이 존재하는 클래스 관점에서 보면, 그런 메서드는 불가해(alien) 메서드다. 무슨 일을 하는지 알 수도 없고, 제어할 수도 없다. 불가해 메서드가 어떤 일을 하느냐에 따라, 동기화 영역 안에서 호출하게 되면 예외나 교착상태, 데이터 훼손이 발생할 수 있다.\n다음은 옵저버 패턴 코드다. 각각의 add, remove, notify 메서드에 모두 동기화가 적용되어 있다.\nprivate final List\u0026lt;SetObserver\u0026lt;E\u0026gt;\u0026gt; observers = new ArrayList\u0026lt;\u0026gt;(); public void addObserver(SetObserver\u0026lt;E\u0026gt; observer){ synchronized (observers){ observers.add(observer); } } public boolean removeObserver(SetObserver\u0026lt;E\u0026gt; observer){ synchronized (observers){ return observers.remove(observer); } } private void notifyElementAdded(E element){ synchronized (observers){ for(SetObserver\u0026lt;E\u0026gt; observer : observers) observer.added(this,element); } } 이 코드를 돌리면 0에서 23까지 찍히고, 23에 도달하면 구독자는 자기 자신을 구독 해제한 후 프로그램은 나머지 작업을 조용히 계속할 거라 생각한다.\nObservableSet\u0026lt;Integer\u0026gt;set = new ObservableSet\u0026lt;\u0026gt;(new HashSet\u0026lt;Integer\u0026gt;()); //옵저버 익명함수 객체  set.addObserver(new SetObserver\u0026lt;Integer\u0026gt;() { @Override public void added(ObservableSet\u0026lt;Integer\u0026gt; set, Integer element) { System.out.println(element); if(element == 23) { set.removeObserver(this); } } }); for(int i=0; i\u0026lt; 25;i++) set.add(i); 하지만 실제로는 ConcurrentModificationException이 발생한다. 문제는 add 메서드를 통해 리스트 순회가 이루어지고 있는 도중에 리스트에서 원소를 삭제하려 한 것이다. 불법이다. notifyElementAdded 메서드의 순환문은 동기화 블록 안에 있다. observers 리스트가 병렬적으로 수정되는 일을 막기 위해서였다. 하지만 이렇게 했어도 순환문을 실행하는 스레드 자신이 구독자 집합에 저장된 메서드를 역호출(callback)해서 observers 리스트를 변경하는 경우까지 차단할 순 없었다.\n좀 더 이상한 짓을 해보자. 구독 해제를 시도하는 구독자를 만들되, removeObserver를 직접 호출하는 대신 그 일을 해줄 다른 스레드의 서비스를 이용하는 것이다. 이 구독자는 실행자 서비스(executor service)를 사용한다.\n// 괜히 후면 스레드를 이용하는 구독자 ObservableSet\u0026lt;Integer\u0026gt;set2 = new ObservableSet\u0026lt;\u0026gt;(new HashSet\u0026lt;Integer\u0026gt;()); set2.addObserver(new SetObserver\u0026lt;Integer\u0026gt;() { @Override public void added(ObservableSet\u0026lt;Integer\u0026gt; set, Integer element) { System.out.println(element); if(element == 23){ ExecutorService executor = Executors.newSingleThreadExecutor(); final SetObserver\u0026lt;Integer\u0026gt; observer = this; try{ executor.submit(new Runnable() { @Override public void run() { set.removeObserver(observer); } }).get(); }catch (ExecutionException ex){ throw new AssertionError(ex.getCause()); }catch (InterruptedException ex){ throw new AssertionError(ex); }finally { executor.shutdown(); } } } }); 이번에는 예외가 발생하진 않는 반면 교착상태가 생긴다. 후면 스레드는 set.removeObserver를 호출하는데, 이 메서드는 observers에 락을 걸려 한다. 하지만 락을 걸 수는 없다. 왜냐하면 주 스레드가 이미 락을 걸고 있기 때문이다. 주 스레드는 후면 스레드가 구독 해제를 끝내기를 기다리면서 락을 계속 들고 있는데, 그래서 교착상태가 생기는 것이다.\n동기화 영역 안에서 불가해 메서드를 호출하는것은 많은 실제 시스템에서 교착상태가 생기는 원인이다. 그래도 앞서 살펴본 두 예제(예외와 데드락)는 운이 좋은 편이다. 불가해 메서드 added가 호출될 시점에, 동기화 영역이 보호하는 자원 observers의 상태는 일관되게 유지되고 있었으니까.\n다행히 이런 문제는 불가해 메서드를 호출하는 부분을 동기화 영역 밖으로 옮기면 쉽게 해결 할 수 있다. //불가해 메서드를 호출하는 코드를 동기화 영역 밖으로 옮겼다 private void notifyElementAdded(E element){ List\u0026lt;SetObserver\u0026lt;E\u0026gt;\u0026gt; snapshot = null; synchronized (observers){ snapshot = new ArrayList\u0026lt;SetObserver\u0026lt;E\u0026gt;\u0026gt;(observers); } for(SetObserver\u0026lt;E\u0026gt; observer : snapshot) { System.out.println(\u0026#34;this :\u0026#34;+this+\u0026#34; element:\u0026#34;+element); observer.added(this, element); } } notifyElementAdded 메서드의 경우, observers 리스트의 복사본을 만들어서 락 없이도 안전하게 리스트를 순회할 수 있도록 바꾸는 것이다.\n사실 불가해 메서드 호출 코드를 동기화 영역 밖으로 옮기는 문제라면 더 좋은 해결책이 있다. 릴리스 1.5부터 자바 라이브러리에는 CopyOnWriteArrayList라는 병행성 컬렉션이 추가되었다. 이 리스트는 ArrayList의 변종으로 내부 배열을 통째로 복사하는 방식으로 쓰기 연산을 지원한다. 내부 배열을 절대 수정하지 않으므로 순회 연산만큼은 락을 걸 필요가 없어져서 대단히 빠르다. 이 리스트의 성능은 대체로 끔찍한 수준이지만 구독자(observer) 리스트에는 딱이다. 구독자 리스트는 변경할 일이 거의 없는 데다 순회 연산이 압도적으로 많기 때문이다.\n// 다중 스레드에 안전한 observer 집합 private final List\u0026lt;SetObserver\u0026lt;E\u0026gt;\u0026gt; observers = new CopyOnWriteArrayList\u0026lt;\u0026gt;(); public void addObserver(SetObserver\u0026lt;E\u0026gt; observer){ observers.add(observer); } public boolean removeObserver(SetObserver\u0026lt;E\u0026gt; observer){ return observers.remove(observer); } private void notifyElementAdded(E element){ for(SetObserver\u0026lt;E\u0026gt; observer : observers) observer.added(this,element); } 명심해야 할 것은 동기화 영역 안에서 수행되는 작업의 양을 가능한 한 줄여야 한다는 것이다.\n이제 성능에 관한 내용을 살펴보자. 변경 가능(mutable) 클래스의 경우, 병렬적으로 이용될 클래스이거나, 내부적인 동기화를 통해 외부에서 전체 객체에 락을 걸 때보다 높은 병행성을 달성할 수 있을 때만 스레드 안전성을 갖도록 구현해야 한다. 그렇지 않다면 내부적인 동기화는 하지 마라. 예를 들어 StringBuffer 객체는 거의 항상 한 스레드만 이용하는 객체인데도 내부적으로 동기화를 하도록 구현되어 있다. 그래서 결국 StringBuilder로 대체된 것이다.\nstatic 필드를 변경하는 메서드가 있을 때는 해당 필드에 대한 접근을 반드시 동기화해야 한다. 보통 한 스레드만 이용하는 메서드라 해도 그렇다. 클라이언트 입장에서는 그런 메서드에 대한 접근을 외부적으로 동기화할 방법이 없다. 다른 클라이언트가 무슨 짓을 할지 알 수 없기 때문이다.\nLock 자바 병렬 프로그래밍 p59 재진입성 : 스레드가, 다른 스레드가 가진 락을 요청하면 해당 스레드는 대기 상태에 들어간다. 하지만 암묵적인 락은 재진입 가능하기 때문에 특정 스레드가 자기가 이미 획득한 락을 다시 확보할 수 있다. 재진입성은 확보 요청 단위가 아닌 스레드 단위로 락을 얻는다는 것을 의미한다(이는 pthreads의 기본 락 동작과 다르다 pthreads에선 확보 요청 기준으로 락을 허용한다).\n재진입성 때문에 락의 동작을 쉽게 캡슐화할 수 있고, 객체 지향 병렬 프로그램을 개발하기가 단순해졌다. 재진입 가능한 락이 없으면 하위 클래스에서 synchronized 메서드를 재정의하고 상위 클래스의 메서드를 호출하는 예제와 같은 지극히 자연스러워 보이는 코드도 데드락에 빠질 것이다.\npublic class Widget { public synchronized void doSomething() { ... } } public class LoggingWidget extends Widget { public synchronized void doSomething() { super.doSomething(); } } Widget과 LoggingWidget의 doSomething 메서드는 둘 다 synchronized로 선언돼 있고, 각각 진행 전에 Widget에 대한 락을 얻으려고 시도한다. 하지만 암묵적인 락이 재진입 가능하지 않았다면, 이미 락을 누군가 확보했기 때문에 super.doSomething 호출에서 락을 얻을 수 없게 되고, 결과적으로 확보할 수 없는 락을 기다리면서 영원히 멈춰 있었을 것이다. 재진입성은 이런 경우에 데드락에 빠지지 않게 해준다.\n"
},
{
	"uri": "/spring_%E1%84%80%E1%85%A2%E1%84%87%E1%85%A1%E1%86%AF_%E1%84%8B%E1%85%B5%E1%84%89%E1%85%B2%E1%84%86%E1%85%A9%E1%84%8B%E1%85%B3%E1%86%B7/spring_%E1%84%80%E1%85%A2%E1%84%87%E1%85%A1%E1%86%AF_%E1%84%8B%E1%85%B5%E1%84%89%E1%85%B21/",
	"title": "Spring Issue1",
	"tags": [],
	"description": "",
	"content": " 1. 통합테스트 애노테이션 정리 Spring @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(classes = Application.class) @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(\u0026#34;/app-config.xml\u0026#34;) @ContextConfiguration은 통합 테스트에서 클래스 레벨 메타데이터(xml 파일 or javaConfig 파일)를 정의한다. 다시 말해, context를 로드하는데 사용되는 annotated class(@Configuration 클래스)나 application context resource locations(classpath에 위치한 XML 설정 파일)들을 선언한다.\n또한 @ContextConfiguration은 ContextLoader 전략을 사용할 수 있다. 하지만 일반적으로 로더를 직접 명시할 필요는 없다. default loader가 initializers 뿐만 아니라 resource locations 또는 annotated classes를 지원하기 때문이다.\n문제 발생\nSpring Boot에서 @ContextConfiguration(classes = Application.class)만 설정했더니\n[main] DEBUG org.springframework.core.type.classreading.AnnotationAttributesReadingVisitor - Failed to class-load type while reading annotation metadata. This is a non-fatal error, but certain annotation metadata may be unavailable. java.lang.ClassNotFoundException: org.springframework.data.web.config.EnableSpringDataWebSupport ... java.lang.ClassNotFoundException: org.springframework.security.config.annotation.web.configuration.EnableWebSecurity ...  위와 같은 에러뿐만 아니라 기본적인 Autowired 설정도 안되고, BeanCreationException도 발생했다.\n원인은 애노테이션이 classpath에 없기 때문에 클래스가 로드될 때 JVM이 drop 시켜서 발생한 문제였다.\n해결 방법1\nSpring Boot에서는 기존의 @ContextConfiguration 대신 @SpringApplicationConfiguration을 제공한다. ApplicationContext 설정을 @SpringApplicationConfiguration으로 사용하면 SpringApplication 으로 생성되고 추가적인 Spring Boot feature들을 얻을 수 있다.\n해결 방법2\n@ContextConfiguration(classes = Application.class, loader = SpringApplicationContextLoader.class) 그런데 1.4부터 SpringApplicationContextLoader가 Deprecated 되었다.\n해결 방법3\n@ContextConfiguration(classes = Application.class, initializers = ConfigFileApplicationContextInitializer.class) ConfigFileApplicationContextInitializer는 Spring Boot application.properties파일을 로드해 테스트 코드에 적용한다. @SpringApplicationConfiguration가 제공하는 full feature들이 필요 없을 때 사용된다.\ncf) spring boot 1.4\n직접적인 Configuration 설정 없이도 @*Test 애노테이션이 자동으로 primary configuration을 찾는다(테스트가 포함된 패키지로부터 @SpringBootApplication또는 @SpringBootConfiguration 애노테이션 클래스를 찾는다).\nSpring Boot // 방법1 @RunWith(SpringJUnit4ClassRunner.class) @SpringApplicationConfiguration(classes = Application.class) // 방법2 (1.4부터 SpringApplicationContextLoader Deprecated 됌) @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(classes = Application.class, loader = SpringApplicationContextLoader.class) // 방법3 @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(classes = Application.class, initializers = ConfigFileApplicationContextInitializer.class) // 방법4 (spring boot 1.4부터 가능) @RunWith(SpringRunner.class) @SpringBootTest(webEnvironment=WebEnvironment.RANDOM_PORT) cf) 방법4에서 @SpringBootTest에서 classes 속성을 생략하면 inner-classes에서 @Configuration을 제일 먼저 로드하려 시도하고, 없으면 @SpringBootApplication class를 찾는다.\n@WebApplicationContext\nWebApplicationContext을 생성할 수 있게 해준다.\n@RunWith(SpringJUnit4ClassRunner.class) @SpringApplicationConfiguration(classes = Application.class) @WebAppConfiguration public class AccountControllerTest { @Autowired WebApplicationContext wac; MockMvc mockMvc; @Before public void setUp() { mockMvc = MockMvcBuilders.webAppContextSetup(wac).build(); } ... } 2. dataSource 메이븐 pom.xml에서 에서 spring-boot-starter-data-jpa 를 추가하면 그안에 spring-boot-starter-jdbc가 있고 그 안에 tomcat-jdbc가 있다.\nSpring Boot에서는 DataSource 관리를 위한 구현체로써 tomcat-jdbc(The Tomcat JDBC Pool) 을 default로 제공한다.\n근데 실서버에 배포 했을 때 에러가 반복해서 발생했고 그 주기도 일정치 않아서 재연이 쉽지 않았다. validationQuery: select 1을 설정했음에도 connection이 자꾸 닫히는 문제가 발생했다.\n[2016-05-19 17:37:40.187] boot - 11886 ERROR [http-nio-8080-exec-3] --- SqlExceptionHelper: No operations allowed after connection closed. [2016-05-19 17:37:40.188] boot - 11886 ERROR [http-nio-8080-exec-3] --- TransactionInterceptor: Application exception overridden by rollback exception javax.persistence.PersistenceException: org.hibernate.exception.JDBCConnectionException: could not prepare statement at org.hibernate.jpa.spi.AbstractEntityManagerImpl.convert(AbstractEntityManagerImpl.java:1763) at org.hibernate.jpa.spi.AbstractEntityManagerImpl.convert(AbstractEntityManagerImpl.java:1677) at org.hibernate.jpa.internal.QueryImpl.getResultList(QueryImpl.java:458) at org.hibernate.jpa.criteria.compile.CriteriaQueryTypeQueryAdapter.getResultList(CriteriaQueryTypeQueryAdapter.java:67) at org.springframework.data.jpa.repository.support.SimpleJpaRepository.findAll(SimpleJpaRepository.java:323) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.springframework.data.repository.core.support.RepositoryFactorySupport$QueryExecutorMethodInterceptor.executeMethodOn(RepositoryFactorySupport.java:483) at org.springframework.data.repository.core.support.RepositoryFactorySupport$QueryExecutorMethodInterceptor.doInvoke(RepositoryFactorySupport.java:468) at org.springframework.data.repository.core.support.RepositoryFactorySupport$QueryExecutorMethodInterceptor.invoke(RepositoryFactorySupport.java:440) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:61) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:99) at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:281) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:136) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.data.jpa.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:131) 그래서 해결책으로 hikari cp를 사용했다.\n//관련 의존성 추가 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.zaxxer\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;HikariCP\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.4.6\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-configuration-processor\u0026lt;/artifactId\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt;//설정 추가 @Configuration @ConfigurationProperties(prefix = \u0026#34;hikari.datasource\u0026#34;) public class JpaConfig extends HikariConfig { @Bean public DataSource dataSource() throws SQLException{ return new HikariDataSource(this); } } // yml 추가 hikari: datasource: jdbcUrl: jdbc:mysql://blabla driverClassName: com.mysql.jdbc.Driver username: blabla password: blabla maximum-pool-size: 5 connection-test-query: select 1  그러나 설정파일에 hikari 의존이 생기는 건 좋지 않다.\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-jpa\u0026lt;/artifactId\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.apache.tomcat\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;tomcat-jdbc\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; 위와 같이 tomcat에서 제공하는 기본 dataSource를 지우면 boot에서 자동으로 hikari cp로 설정된다. 따라서 JpaConfig 파일도 필요 없게 되고 yml에서 hikari를 지워도 된다.\n2016.08.12 추가\nSpring Boot 1.4부터는 db 프로파일에 spring.datasource.hikari를 명시적으로 작성할 수 있게 됐다.\n3. request url에 문자열 \u0026ldquo;.t\u0026rdquo;을 확장자로 인식 @RequestMapping(value = \u0026#34;/messages/receiverUsername/{receiverUsername:.+}\u0026#34;, method = RequestMethod.GET) 위와 같이 정규식으로 모든 문자열을 (. 포함) 받겠다고 명시했음에도 .t는 인식이 안되는 문제가 발생했다.\n이유는 .t라는 확장자가 있기 때문에 아래와 같이 설정에서 mediaType을 json으로 직접 명시해주면 해결이 가능하다.\n@Override public void configureContentNegotiation(ContentNegotiationConfigurer configurer) { configurer.favorPathExtension(true); configurer.useJaf(false); configurer.ignoreAcceptHeader(true); configurer.mediaType(\u0026#34;json\u0026#34;, MediaType.APPLICATION_JSON); } 4. Spring MVC Test Spring Framework 4.2.6에서 Spring MVC Test를 처음 생성하다 다음과 같은 에러가 발생했다.\njava.lang.NoClassDefFoundError: javax/servlet/SessionCookieConfig 문제는 org.springframework.mock.web에 있는 mock set들은 Servlet 3.0 API를 기반으로 동작하는데 현재 프로젝트 Servlet 버전은 2.5였다.\n변경 전 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.servlet\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;javax.servlet-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.5\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 변경 후 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.servlet\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;javax.servlet-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1.0\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; The Spring 4.0.1 reference documentation is now more clear about the Mocks: Servlet 3.0+ is strongly recommended and a prerequisite in Spring\u0026rsquo;s test and mock packages for test setups in development environments.\n5. 날짜 // 기존 날짜 데이터 처리 방식 long plusDay = xxxSchedule.getExecutionDate().getTime() + TimeUnit.DAYS.toMillis(extendDays); xxxSchedule.setRegisterDate(Date.from(Instant.now())); xxxSchedule.setExecutionDate(new Date(plugDay)); // 자바8 현재 날짜 구하기 LocalDateTime.now() LocalDate.now().format(DateTimeFormatter.ofPattern(\u0026#34;yyyyMMdd\u0026#34;)); // 타임스탬프에서 날짜 가져오기 Long time = 1470651527000L; DateFormat dateFormat = new SimpleDateFormat(\u0026#34;yyyy-MM-dd\u0026#34;); String format = dateFormat.format(time); 6. Mockito verify\nverify(xxxRepository, never()).save(any(xxx.class)); never() : 어떤 조건에 따라 호출되면 안되는 경우, 진짜 호출이 안되는지 확인.\n\u0026lt;T\u0026gt; T any(Class\u0026lt;T\u0026gt; clazz): anyObject와는 다르게 클래스를 지정할 수 있다.\nspy\n해당 서비스안에 있는 일반 메서드를 when().thenReturn()을 통해 제어하고 싶을 때 서비스를 spy로 만들어서 할 수 있다.\nxxxService xxxServiceSpy = Mockito.spy(xxxService); ArgumentCaptor\n참고 : http://stackoverflow.com/questions/12295891/how-to-use-argumentcaptor-for-stubbing\nstub을 만들지 않고, 메서드가 호출됐는지 확인하는 것과 인자가 정확한지 확인하고 싶을 때 ArgumentCaptor방식을 사용할 수 있다.\nArgumentCaptor\u0026lt;SomeClass\u0026gt; argumentCaptor = ArgumentCaptor.forClass(SomeClass.class); verify(someObject).doSomething(argumentCaptor.capture()); assertNull(argumentCaptor.getValue().getXXX()); 7. YAML 기존 spring 프로젝트에서 yml 설정을 하기 위해서 먼저 의존성을 추가해준다.\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.yaml\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;snakeyaml\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.17\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 그리고 서블릿 컨텍스트에 yaml 설정을 추가해준다.\n\u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:mvc=\u0026#34;http://www.springframework.org/schema/mvc\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:context=\u0026#34;http://www.springframework.org/schema/context\u0026#34; xsi:schemaLocation=\u0026#34; http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\u0026#34;\u0026gt; \u0026lt;bean id=\u0026#34;yamlProperties\u0026#34; class=\u0026#34;org.springframework.beans.factory.config.YamlPropertiesFactoryBean\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;resources\u0026#34; value=\u0026#34;classpath:application.yml\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;context:property-placeholder properties-ref=\u0026#34;yamlProperties\u0026#34; /\u0026gt; cf) spring boot에서는 classpath 에 application.yml 을 추가 하면 자동으로 boot가 스캔하기 때문에 따로 설정이 필요없다.\n \u0026lt;build\u0026gt; \u0026lt;!-- Turn on filtering by default for application properties --\u0026gt; \u0026lt;resources\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;directory\u0026gt;${basedir}/src/main/resources\u0026lt;/directory\u0026gt; \u0026lt;filtering\u0026gt;true\u0026lt;/filtering\u0026gt; \u0026lt;includes\u0026gt; \u0026lt;include\u0026gt;**/application.yml\u0026lt;/include\u0026gt; \u0026lt;include\u0026gt;**/application.properties\u0026lt;/include\u0026gt; \u0026lt;/includes\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;directory\u0026gt;${basedir}/src/main/resources\u0026lt;/directory\u0026gt; \u0026lt;excludes\u0026gt; \u0026lt;exclude\u0026gt;**/application.yml\u0026lt;/exclude\u0026gt; \u0026lt;exclude\u0026gt;**/application.properties\u0026lt;/exclude\u0026gt; \u0026lt;/excludes\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;/resources\u0026gt; \u0026lt;/build\u0026gt;  application.yml 작성 예\nspring: profiles.active: local --- spring: velocity: properties.input.encodig: UTF-8 properties.output.encodig: UTF-8 cache: false jpa: show-sql: true database-platform: org.hibernate.dialect.MySQL5Dialect hibernate: ddl-auto: validate naming-strategy: org.hibernate.cfg.ImprovedNamingStrategy properties: hibernate: temp: use_jdbc_metadata_defaults: false --- spring: profiles: h2-db datasource: jdbcUrl: jdbc:h2:mem:AZ;DB_CLOSE_DELAY=-1;DB_CLOSE_ON_EXIT=FALSE driverClassName: org.h2.Driver username: xxx password: xxx maxWait: 1000 h2: console: enabled: true path: /h2-console jpa: show-sql: false database-platform: org.hibernate.dialect.H2Dialect hibernate: ddl-auto: create naming-strategy: org.hibernate.cfg.ImprovedNamingStrategy properties: hibernate: temp: use_jdbc_metadata_defaults: false logging: level: info --- spring: profiles: real-db datasource: jdbcUrl: xxx driverClassName: com.mysql.jdbc.Driver username: xxx password: xxx maximum-pool-size: 5 connection-test-query: select 1 --- spring: profiles: aws-db-test datasource: jdbcUrl: xxx driverClassName: com.mysql.jdbc.Driver username: xxx password: xxx maximum-pool-size: 5 connection-test-query: select 1 --- spring: profiles: local datasource: url: xxx driverClassName: com.mysql.jdbc.Driver username: xxx password: xxx maxWait: 1000 validationQuery: select 1  8. 기존 xml 설정을 JavaConfig로 변경하기 먼저 web.xml에서 contextConfigLocation을 xml 파일 위치 대신 AppConfig 위치로 변경해준다.\n\u0026lt;!-- Processes application requests --\u0026gt; \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;appServlet\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;org.springframework.web.servlet.DispatcherServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;contextConfigLocation\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt; classpath:spring/servlet-context.xml \u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;load-on-startup\u0026gt;1\u0026lt;/load-on-startup\u0026gt; \u0026lt;/servlet\u0026gt;\u0026lt;!-- Processes application requests --\u0026gt; \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;appServlet\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;org.springframework.web.servlet.DispatcherServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;contextClass\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt; org.springframework.web.context.support.AnnotationConfigWebApplicationContext \u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;contextConfigLocation\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt; (패키지명)xxx.xxx.xxx.xxx.config.AppConfig \u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;load-on-startup\u0026gt;1\u0026lt;/load-on-startup\u0026gt; \u0026lt;/servlet\u0026gt; 그리고 ContextLoaderListener가 자동으로 생성하는 컨텍스트의 클래스는 기본적으로 XmlWebApplicationContext다. 이를 다른 애플리케이션 컨텍스트 구현 클래스로 변경하고 싶으면 contextClass 파라미터를 이용해 지정해주면 된다.\n두번째로 AppConfig 파일에 기존 xml에 있던 설정들을 옮긴다.\nimport lombok.extern.slf4j.Slf4j; import org.apache.commons.lang.StringUtils; import org.springframework.beans.BeansException; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.beans.factory.config.YamlProcessor; import org.springframework.beans.factory.config.YamlPropertiesFactoryBean; import org.springframework.boot.yaml.SpringProfileDocumentMatcher; import org.springframework.context.ApplicationContext; import org.springframework.context.ApplicationContextAware; import org.springframework.context.EnvironmentAware; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.ComponentScan; import org.springframework.context.annotation.Configuration; import org.springframework.context.annotation.ImportResource; import org.springframework.context.support.PropertySourcesPlaceholderConfigurer; import org.springframework.core.env.Environment; import org.springframework.data.jpa.repository.config.EnableJpaRepositories; import org.springframework.scheduling.annotation.EnableAsync; import org.springframework.scheduling.annotation.EnableScheduling; import org.springframework.transaction.annotation.EnableTransactionManagement; import org.springframework.web.client.RestTemplate; import java.io.IOException; import java.util.Properties; @Configuration @Slf4j @EnableJpaRepositories(basePackages = \u0026#34;xxx.xxx.xxx.xxx\u0026#34;, transactionManagerRef = \u0026#34;xxxTransactionManager\u0026#34;) @EnableScheduling @EnableAsync @EnableTransactionManagement @ComponentScan(\u0026#34;xxx.xxx.xxx\u0026#34;) @ImportResource({\u0026#34;classpath:spring/applicationContext-db.xml\u0026#34;, \u0026#34;classpath:spring/applicationContext-jpa.xml\u0026#34;}) public class AppConfig implements EnvironmentAware, ApplicationContextAware { private ApplicationContext ctx; private Environment env; @Bean RestTemplate getRestTemplate() { return new RestTemplate(); } @Bean public YamlProcessor.DocumentMatcher documentMatcher() { String[] profile = getProfile(); log.info(\u0026#34;ActiveProfile: {}\u0026#34;, (Object[]) profile); return new SpringProfileDocumentMatcher(profile); } @Bean(name = \u0026#34;yamlProperties\u0026#34;) public YamlPropertiesFactoryBean yamlPropertiesFactoryBean(YamlProcessor.DocumentMatcher documentMatcher) throws IOException { YamlPropertiesFactoryBean yamlPropertiesFactoryBean = new YamlPropertiesFactoryBean(); yamlPropertiesFactoryBean.setResources(ctx.getResources(\u0026#34;classpath:application.yml\u0026#34;)); yamlPropertiesFactoryBean.setDocumentMatchers(documentMatcher); return yamlPropertiesFactoryBean; } @Bean public PropertySourcesPlaceholderConfigurer propertySourcesPlaceholderConfigurer(@Qualifier(\u0026#34;yamlProperties\u0026#34;) Properties yamlProperties) { PropertySourcesPlaceholderConfigurer p = new PropertySourcesPlaceholderConfigurer(); p.setProperties(yamlProperties); return p; } @Override public void setEnvironment(Environment environment) { this.env = environment; } @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { this.ctx = applicationContext; } private String[] getProfile() { String[] activeProfiles = env.getActiveProfiles(); if (activeProfiles != null) { return activeProfiles; } Properties properties = System.getProperties(); String profileActive = properties.getProperty(\u0026#34;spring.profiles.active\u0026#34;); return new String[] { StringUtils.defaultString(profileActive, \u0026#34;dev\u0026#34;) }; } } 9. Mybatis db 언더바 사용된 컬럼과 자바 카멜케이스 변수 자동 매핑 방법1 : application.yml\nmybatis: mapper-locations: classpath:mybatis/mapper/*.xml configuration: map-underscore-to-camel-case: true  방법2 : mybatis-config.xml\n\u0026lt;settings\u0026gt; \u0026lt;setting name=\u0026#34;mapUnderscoreToCamelCase\u0026#34; value=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;/settings\u0026gt; cf) 다른 설정정보 참고 : http://www.mybatis.org/mybatis-3/ko/configuration.html\n10. @RequestParam값이 Optional일때 DefaultValue 적용 @RequestParam(value = \u0026#34;bongsoo\u0026#34;, required = false) int bongsoo int형이기 때문에 값이 없을때 null일 수 없다. 그래서 defaultValue를 미리 지정해주는게 좋다.\n@RequestParam(value = \u0026#34;bongsoo\u0026#34;, required = false, defaultValue=\u0026#34;0\u0026#34;) int bongsoo 11. 세션 스코프 빈 사용 컨트롤러에서 세션 스코프 빈을 사용할 일이 있었고, 컨트롤러는 싱글톤 빈이기 때문에 일반적으로 DI방식을 이용해 주입해서는 방법이 없다. DL 방식을 이용하는 방법도 있지만 애플리케이션 로직에 스프링 코드가 들어간다는 단점이 있다.\n그래서 프록시 DI 방식을 택했다.\n@Scope(value = \u0026#34;session\u0026#34;, proxyMode = ScopedProxyMode.TARGET_CLASS) @Component public class Work { ... } @Scope 애노테이션으로 스코프를 지정했다면 proxyMode 엘리먼트를 이용해서 프록시를 이용한 DI가 되도록 지정할 수 있다. 클라이언트(여기선 컨트롤러 클래스)는 스코프 프록시 오브젝트를 실제 스코프 빈처럼 사용하면 프록시에서 현재 스코프에 맞는 실제 빈 오브젝트로 작업을 위임해준다.\n스코프 프록시는 각 요청에 연결된 HTTP 세션정보를 참고해서 사용자마다 다른 Work 오브젝트를 사용하게 해준다. 클라이언트인 컨트롤러 입장에서는 모두 같은 오브젝트를 사용하는 것처럼 보이지만, 실제로는 그 뒤에 사용자별로 만들어진 여러 개의 Work가 존재하고, 스코프 프록시는 실제 Work 오브젝트로 클라이언트의 호출을 위임해주는 역할을 해줄 뿐이다.\n프록시 빈이 인터페이스를 구현하고 있고, 클라이언트에서 인터페이스로 DI 받는다면 proxyMode를 ScopedProxyMode.INTERFACES로 지정해주고, 프록시 빈 클래스를 직접 DI 한다면 ScopedProxyMode.TARGET_CLASS로 지정하면 된다(여기서는 Work 클래스로 직접 DI 할 것이므로 ScopedProxyMode.TARGET_CLASS).\n스코프 프록시의 DI 사용 @Controller public void MainController { @Autowired Work work; } cf) XML 설정방식\n\u0026lt;bean id=\u0026#34;work\u0026#34; class=\u0026#34;...Work\u0026#34; scope=\u0026#34;session\u0026#34;\u0026gt; \u0026lt;aop:scoped-proxy proxy-target-class=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; DI 받을 때 클래스를 이용한다면 proxy-target-class를 true로 설정하고, 인터페이스를 이용한다면 false로 하거나 아예 생략하면 된다.\n12. Spring Boot war 배포로 변경하기  pom.xml xml 변경 전 : \u0026lt;packaging\u0026gt;jar\u0026lt;/packaging\u0026gt; 변경 후 : \u0026lt;packaging\u0026gt;war\u0026lt;/packaging\u0026gt;  configuration  @SpringBootApplication public class Application extends WebMvcConfigurerAdapter { public static void main(String[] args) { SpringApplication.run(Application.class, args); } ... }@Configuration public class AppConfig extends SpringBootServletInitializer { @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder application) { return application.sources(Application.class); } } 13. Spring Boot CORS 처리 대부분의 웹 브라우저는 보안상의 이유로 다른 도메인의 URL을 호출해서 데이터를 가져오는 것을 금지하고 있다. 우리 웹 서비스에서만 사용하기 위해 다른 서브 도메인을 가진 API 서버를 구축했는데, 다른 웹 서비스에서 마음대로 접근해서 사용하면 문제가 되기 때문이다.\n그런데 하나의 도메인을 가진 웹 서버에서 모든 처리를 하기에는 효율성이나 성능 등 여러 문제로 각 기능별로 여러 서버를 두는 경우가 많다(API 서버, WAS 서버, 파일 서버 등등). 물리적으로 분리된 서버이고, 다른 용도로 구축된 서버이니 당연히 각각 다른 도메인을 가진 서버들일 텐데, 서로간에 Ajax 통신을 할 수 없는 것일까? 즉 서로 다른 도메인 간의 호출을 의미하는 크로스 도메인 문제를 해결할 수는 없는 것일까?\nCORS(Cross Origin Resource Sharing)은 외부 도메인에서의 요청(접근)을 허용해주는 메커니즘이다.\n원문 : http://ooz.co.kr/232\npublic class CORSFilter extends OncePerRequestFilter { @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException { // 모든 도메인에 대해 허용하겠다는 의미  response.addHeader(\u0026#34;Access-Control-Allow-Origin\u0026#34;, \u0026#34;*\u0026#34;); response.addHeader(\u0026#34;Access-Control-Allow-Methods\u0026#34;, \u0026#34;GET, POST, PUT, DELETE\u0026#34;); response.addHeader(\u0026#34;Access-Control-Allow-Headers\u0026#34;, \u0026#34;content-type, accept, api_id, api_key\u0026#34;); response.addHeader(\u0026#34;Access-Control-Max-Age\u0026#34;, \u0026#34;1800\u0026#34;); filterChain.doFilter(request, response); } } 위와 같이 필터 클래스를 만들고\n@Bean public FilterRegistrationBean registration(){ FilterRegistrationBean register = new FilterRegistrationBean(); CORSFilter corsFilter = new CORSFilter(); register.setFilter(corsFilter); register.setEnabled(true); register.setUrlPatterns(Collections.singletonList(\u0026#34;/*\u0026#34;)); return register; } 빈으로 등록만 해주면 url 패턴에 따라 필터가 작동된다.\nCORS support in Spring Framework http://spring.io/blog/2015/06/08/cors-support-in-spring-framework\n@CrossOrigin 애노테이션을 추가해줌으로써 CORS를 가능하게 해준다.\n@RestController @RequestMapping(\u0026#34;/account\u0026#34;) public class AccountController { @CrossOrigin @RequestMapping(\u0026#34;/{id}\u0026#34;) public Account retrieve(@PathVariable Long id) { // ...  } @RequestMapping(method = RequestMethod.DELETE, value = \u0026#34;/{id}\u0026#34;) public void remove(@PathVariable Long id) { // ...  } } 컨트롤러 전체에 적용도 가능하다.\n@CrossOrigin(origins = \u0026#34;http://domain2.com\u0026#34;, maxAge = 3600) @RestController @RequestMapping(\u0026#34;/account\u0026#34;) public class AccountController { @RequestMapping(\u0026#34;/{id}\u0026#34;) public Account retrieve(@PathVariable Long id) { // ...  } @RequestMapping(method = RequestMethod.DELETE, value = \u0026#34;/{id}\u0026#34;) public void remove(@PathVariable Long id) { // ...  } } Java Config\n@Configuration @EnableWebMvc public class WebConfig extends WebMvcConfigurerAdapter { @Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping(\u0026#34;/api/**\u0026#34;) .allowedOrigins(\u0026#34;http://domain2.com\u0026#34;) .allowedMethods(\u0026#34;PUT\u0026#34;, \u0026#34;DELETE\u0026#34;) .allowedHeaders(\u0026#34;header1\u0026#34;, \u0026#34;header2\u0026#34;, \u0026#34;header3\u0026#34;) .exposedHeaders(\u0026#34;header1\u0026#34;, \u0026#34;header2\u0026#34;) .allowCredentials(false).maxAge(3600); } } XML namespace\n\u0026lt;mvc:cors\u0026gt; \u0026lt;mvc:mapping path=\u0026#34;/api/**\u0026#34; allowed-origins=\u0026#34;http://domain1.com, http://domain2.com\u0026#34; allowed-methods=\u0026#34;GET, PUT\u0026#34; allowed-headers=\u0026#34;header1, header2, header3\u0026#34; exposed-headers=\u0026#34;header1, header2\u0026#34; allow-credentials=\u0026#34;false\u0026#34; max-age=\u0026#34;123\u0026#34; /\u0026gt; \u0026lt;mvc:mapping path=\u0026#34;/resources/**\u0026#34; allowed-origins=\u0026#34;http://domain1.com\u0026#34; /\u0026gt; \u0026lt;/mvc:cors\u0026gt; 14. @JsonInclude @Pattern @Data @JsonInclude(JsonInclude.Include.NON_NULL) public class User { private Long id; @NotEmpty @Pattern(regexp = \u0026#34;[a-zA-Z\\\\d._-]{6,100}\u0026#34;) private String name; @NotEmpty @Length(min = 6, max = 100) @Pattern(regexp = \u0026#34;^[a-zA-Z\\\\d.-_]+@[a-zA-Z\\\\d-]+(.[a-z]+)+$\u0026#34;) private String email; @NotEmpty @Length(min = 6) private String password; private Date regDt; } @JsonInclude(JsonInclude.Include.NON_NULL) 객체를 Json으로 변환할 때, null값 필드는 아예 Json으로 매핑 안되게 해주는 설정이다.\n15. Swagger를 조회하는 URL 바꾸고 싶을 때 @Controller public class ApiDocController { @GetMapping(\u0026#34;/swagger-ui\u0026#34;) public void apiDocs (OutputStream response) throws IOException { InputStream source = new ClassPathResource(\u0026#34;/META-INF/resources/swagger-ui.html\u0026#34;).getInputStream(); StreamUtils.copy(source, response); } } 16. WebApplicationInitializer를 이용한 컨텍스트 등록 서블릿 3.0 이상부터 사용 가능하다. web.xml 파일만을 단독으로 사용하던 것에서 탈피해, 설정 방식을 모듈화해서 관리하는 방법을 도입했다.\n@Order(value = 1) public class WebAppIntializer implements WebApplicationInitializer { @Override public void onStartup(ServletContext servletContext) throws ServletException { //parent  AnnotationConfigWebApplicationContext rootContext = new AnnotationConfigWebApplicationContext(); rootContext.register(AppConfig.class); servletContext.addListener(new ContextLoaderListener(rootContext)); // new ContextLoader(rootContext).initWebApplicationContext(servletContext);  //child  AnnotationConfigWebApplicationContext dispatcherServletContext = new AnnotationConfigWebApplicationContext(); dispatcherServletContext.register(WebConfig.class); ServletRegistration.Dynamic dispatcher = servletContext.addServlet(\u0026#34;dispatcher\u0026#34;, new DispatcherServlet(dispatcherServletContext)); dispatcher.setLoadOnStartup(1); dispatcher.addMapping(\u0026#34;/\u0026#34;); //Encoding Filter 등록  FilterRegistration.Dynamic encodingFilter = servletContext.addFilter(\u0026#34;CharacterEncodingFilter\u0026#34;, new CharacterEncodingFilter()); encodingFilter.setInitParameter(\u0026#34;encoding\u0026#34;, \u0026#34;UTF-8\u0026#34;); encodingFilter.setInitParameter(\u0026#34;forceEncoding\u0026#34;, \u0026#34;true\u0026#34;); encodingFilter.addMappingForUrlPatterns(null, true, \u0026#34;/*\u0026#34;);\u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-war-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;webappDirectory\u0026gt;deploy\u0026lt;/webappDirectory\u0026gt; \u0026lt;failOnMissingWebXml\u0026gt;false\u0026lt;/failOnMissingWebXml\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 17. maven-clean-plugin mvn clean을 수행하면 기본적으로 target 디렉토리 밑에 있는 내용을 삭제한다. 그런데 target 디렉토리 외에 다른 디렉토리도 지우고 싶다면, pom.xml에 직접 설정할 수도 있다.\n\u0026lt;plugin\u0026gt; \u0026lt;artifactId\u0026gt;maven-clean-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.5\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;filesets\u0026gt; \u0026lt;fileset\u0026gt; \u0026lt;directory\u0026gt;deploy/WEB-INF/lib\u0026lt;/directory\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;fileset\u0026gt; \u0026lt;directory\u0026gt;deploy/WEB-INF/classes\u0026lt;/directory\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;/filesets\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 18. maven profiles \u0026lt;properties\u0026gt; \u0026lt;java-version\u0026gt;1.8\u0026lt;/java-version\u0026gt; \u0026lt;env\u0026gt;local\u0026lt;/env\u0026gt; \u0026lt;/properties\u0026gt; ... \u0026lt;profiles\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;local\u0026lt;/id\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;env\u0026gt;local\u0026lt;/env\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;dev\u0026lt;/id\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;env\u0026gt;dev\u0026lt;/env\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;/profiles\u0026gt; \u0026lt;build\u0026gt; \u0026lt;resources\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;directory\u0026gt;src/main/resources\u0026lt;/directory\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;resource\u0026gt; \u0026lt;directory\u0026gt;src/main/resources-${env}\u0026lt;/directory\u0026gt; \u0026lt;/resource\u0026gt; \u0026lt;/resources\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-compiler-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.6.0\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;source\u0026gt;${java-version}\u0026lt;/source\u0026gt; \u0026lt;target\u0026gt;${java-version}\u0026lt;/target\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-war-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;webappDirectory\u0026gt;target/deploy\u0026lt;/webappDirectory\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; 19. HandlerMethodArgumentResolver를 이용한 사용자 검증 HandlerMethodArgumentResolver 인터페이스를 구현하여 컨트롤러의 메서드 파라미터를 검증, 수정 할 수 있다.\n/** * Strategy interface for resolving method parameters into argument values in * the context of a given request. * * @author Arjen Poutsma * @since 3.1 * @see HandlerMethodReturnValueHandler */ public interface HandlerMethodArgumentResolver { /** * Whether the given {@linkplain MethodParameter method parameter} is * supported by this resolver. * @param parameter the method parameter to check * @return {@code true} if this resolver supports the supplied parameter; * {@code false} otherwise */ boolean supportsParameter(MethodParameter parameter); /** * Resolves a method parameter into an argument value from a given request. * A {@link ModelAndViewContainer} provides access to the model for the * request. A {@link WebDataBinderFactory} provides a way to create * a {@link WebDataBinder} instance when needed for data binding and * type conversion purposes. * @param parameter the method parameter to resolve. This parameter must * have previously been passed to {@link #supportsParameter} which must * have returned {@code true}. * @param mavContainer the ModelAndViewContainer for the current request * @param webRequest the current request * @param binderFactory a factory for creating {@link WebDataBinder} instances * @return the resolved argument value, or {@code null} * @throws Exception in case of errors with the preparation of argument values */ Object resolveArgument(MethodParameter parameter, ModelAndViewContainer mavContainer, NativeWebRequest webRequest, WebDataBinderFactory binderFactory) throws Exception; } 쿠키로 인증 구현 예\npublic class CookieHandlerMethodArgumentResolver implements HandlerMethodArgumentResolver { private XxxService xxxService; public CookieHandlerMethodArgumentResolver(XxxService xxxService) { this.xxxService = xxxService; } @Override public boolean supportsParameter(MethodParameter methodParameter) { return methodParameter.hasParameterAnnotation(Authentication.class) \u0026amp;\u0026amp; methodParameter.getParameterType().equals(User.class); } @Override public Object resolveArgument(MethodParameter methodParameter, ModelAndViewContainer modelAndViewContainer, NativeWebRequest nativeWebRequest, WebDataBinderFactory webDataBinderFactory) throws Exception { HttpServletRequest servletRequest = nativeWebRequest.getNativeRequest(HttpServletRequest.class); javax.servlet.http.Cookie cookie = WebUtils.getCookie(servletRequest, \u0026#34;loginCookie\u0026#34;); if (StringUtils.isNotEmpty(cookie)) { String EncryptVal = cookie.getValue(); String userId = JavaEnCrypto.Decrypt(EncryptVal); if (isVaild(userId)) { User user = new User(); user.setUserName(userId); return user; } } return null; } private boolean isVaild(String userId) { if (xxxService.checkEmail(userId).isDuplicated()){ return true; } else { return false; } } } 설정은 다음과 같이 한다.\n//boot config @SpringBootApplication public class Application extends WebMvcConfigurerAdapter { @Override public void addArgumentResolvers(List\u0026lt;HandlerMethodArgumentResolver\u0026gt; argumentResolvers) { argumentResolvers.add(authenticationResolver(xxxService)); } @Bean public CookieHandlerMethodArgumentResolver authenticationResolver(xxxService xxxService) { CookieHandlerMethodArgumentResolver cookieHandlerMethodArgumentResolver = new CookieHandlerMethodArgumentResolver(xxxService); return cookieHandlerMethodArgumentResolver; } }//xml config \u0026lt;mvc:annotation-driven\u0026gt; \u0026lt;mvc:argument-resolvers\u0026gt; \u0026lt;bean class=\u0026#34;xxx.xxx.CookieHandlerMethodArgumentResolver\u0026#34;\u0026gt; \u0026lt;constructor-arg\u0026gt; \u0026lt;bean class=\u0026#34;xxx.xxx.xxxService\u0026#34;/\u0026gt; \u0026lt;/constructor-arg\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/mvc:argument-resolvers\u0026gt; \u0026lt;/mvc:annotation-driven\u0026gt;//Controller class  public ResponseEntity\u0026lt;ResultResponse\u0026gt; logout(@Authentication User user, HttpServletResponse response) { if (user != null) {} else {} } 20. @JsonView 출처 url : http://www.concretepage.com/spring-4/spring-mvc-4-rest-jackson-jsonview-annotation-integration-example\npublic class Profile { public interface PublicView {} public interface FriendsView extends PublicView {} public interface FamilyView extends FriendsView {} }@RestController @RequestMapping(\u0026#34;/app\u0026#34;) public class UserController { @Autowired private UserService userService; @JsonView(Profile.PublicView.class) @RequestMapping(value = \u0026#34;/publicprofile\u0026#34;, produces = MediaType.APPLICATION_JSON_VALUE) public List\u0026lt;User\u0026gt; getAllPublicProfile() { return userService.getAllUsers(); } @JsonView(Profile.FriendsView.class) @RequestMapping(value = \u0026#34;/friendprofile\u0026#34;, produces = MediaType.APPLICATION_JSON_VALUE) public List\u0026lt;User\u0026gt; getAllFriendsProfile() { return userService.getAllUsers(); } @JsonView(Profile.FamilyView.class) @RequestMapping(value = \u0026#34;/familyprofile\u0026#34;, produces = MediaType.APPLICATION_JSON_VALUE) public List\u0026lt;User\u0026gt; getAllFamilyProfile() { return userService.getAllUsers(); } }public class User { @JsonView(Profile.PublicView.class) private String userId; private String password; private int age; @JsonView(Profile.FamilyView.class) private long mobnum; @JsonView(Profile.FriendsView.class) private String mailId; @JsonView(Profile.PublicView.class) private String name; @JsonView(Profile.PublicView.class) private College college; @JsonView(Profile.PublicView.class) private Address address; ... }public class College { @JsonView(Profile.PublicView.class) private String colName; @JsonView(Profile.FriendsView.class) private String colLocation; ... }public class Address { @JsonView(Profile.FamilyView.class) private String houseNo; @JsonView(Profile.FriendsView.class) private String city; @JsonView(Profile.PublicView.class) private String country; ... } 결과 /app/publicprofile\n결과 app/friendprofile\n결과 app/familyprofile\n21. Spring Boot Embedded Tomcat AJP 연동 Spring Boot의 Embeded WAS로 Tomcat을 쓸 경우 아래와 같은 설정으로 AJP 연동을 할 수 있다.\n@Bean public EmbeddedServletContainerFactory servletContainer() { TomcatEmbeddedServletContainerFactory tomcat = new TomcatEmbeddedServletContainerFactory(); tomcat.addContextCustomizers((context) -\u0026gt; { StandardRoot standardRoot = new StandardRoot(context); standardRoot.setCacheMaxSize(100 * 1024); standardRoot.setCacheObjectMaxSize(4 * 1024); }); if (tomcatAjpEnabled) { Connector ajpConnector = new Connector(\u0026#34;AJP/1.3\u0026#34;); ajpConnector.setProtocol(\u0026#34;AJP/1.3\u0026#34;); ajpConnector.setPort(ajpPort); ajpConnector.setSecure(false); ajpConnector.setAllowTrace(false); ajpConnector.setScheme(\u0026#34;http\u0026#34;); tomcat.addAdditionalTomcatConnectors(ajpConnector); } return tomcat; } 참고로 AJP를 쓸 경우 HTTP 메서드 등 PATCH를 쓸 수 없다는 제약이 있다.\n"
},
{
	"uri": "/spring_%E1%84%80%E1%85%A2%E1%84%87%E1%85%A1%E1%86%AF_%E1%84%8B%E1%85%B5%E1%84%89%E1%85%B2%E1%84%86%E1%85%A9%E1%84%8B%E1%85%B3%E1%86%B7/spring_%E1%84%80%E1%85%A2%E1%84%87%E1%85%A1%E1%86%AF_%E1%84%8B%E1%85%B5%E1%84%89%E1%85%B22/",
	"title": "Spring Issue2",
	"tags": [],
	"description": "",
	"content": " 22. Spring Security X-Frame-Options 이슈 Default Security Headers\nCache-Control: no-cache, no-store, max-age=0, must-revalidate Pragma: no-cache Expires: 0 X-Content-Type-Options: nosniff Strict-Transport-Security: max-age=31536000 ; includeSubDomains X-Frame-Options: DENY X-XSS-Protection: 1; mode=block  cf) Strict-Transport-Security는 HTTPS 요청일때만 추가된다.\nX-Frame-Options: DENY  response header에 X-Frame-Options를 갖고 있는 모든 사이트는 iframe 안에서 렌더링 되지 못하도록 브라우저가 막는다.\ncustomize\nX-Frame-Options: SAMEORIGIN X-Frame-Options: ALLOW-FROM https://example.com/  SAMEORIGIN : 같은 도메인일때만 ifrmae을 허용한다.\n\u0026lt;http\u0026gt; \u0026lt;!-- ... --\u0026gt; \u0026lt;headers\u0026gt; \u0026lt;frame-options policy=\u0026#34;SAMEORIGIN\u0026#34; /\u0026gt; \u0026lt;/headers\u0026gt; \u0026lt;/http\u0026gt;http // ... \t.headers() .frameOptions() .sameOrigin(); ALLOW-FROM : 구체적인 도메인 지정\nSolution\n\u0026lt;http\u0026gt; \u0026lt;!-- ... --\u0026gt; \u0026lt;headers disabled=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;/http\u0026gt;http.headers().frameOptions().disable() 23. HTTP Strict Transport Security (HSTS) https://docs.spring.io/spring-security/site/docs/4.0.x/reference/html/headers.html#headers-hsts\n웹 브라우저가 HTTPS 프로토콜만을 사용해서 서버와 통신하도록 하는 기능을 한다. 만약 HTTPS로 접속에 실패하면 사이트 접근에 실패하게 된다. 서버가 HTTP 응답 헤더에 Strict-Transport-Security를 내려주면 브라우저는 그 사이트에 접속할 때 무조건 HTTPS로만 연결한다.\nHSTS가 적용되기 위해서는 서버도 헤더를 내려줘야하고 브라우저도 그 헤더에 따른 동작을 해야하는 것이다. HSTS를 사용하는 대신 서버에서 HTTP 접속을 HTTPS로 redirect 시키는 방법이 있지만 일단 한번 HTTP 연결을 거쳐가는 것이기 때문에 쿠키 정보 탈취 등 보안에 취약하다.\nStrict-Transport-Security: max-age=31536000 ; includeSubDomains; preload  max-age : 지정 시간(단위 초)만큼 HTTPS를 사용\nincludeSubdomains : HSTS를 서브 도메인에도 적용\npreload : 브라우저가 해당 사이트를 HSTS 적용 preload list에 추가하도록 함\npreload list\nHTTPS로 웹 사이트에 접속하기 위해 적어도 한번 웹 서버와 통신을 해야하는데, 통신 해보기 전에 미리 HTTPS로 접속하도록 목록을 미리 만들어둔 것이다.\n이는 브라우저가 지원해주는 기능이고 브라우저 안에 기본적으로 내장되어 있는 사이트 목록들이 있다. 그리고 서버가 헤더에 preload값을 내려주면 이 목록에 해당 사이트도 추가하게 되는 것이다(브라우저에 캐시됌). preload에 추가된 사이트는 서버가 HSTS헤더를 삭제해도 브라우저에는 설정이 유지된다.\n만약 내장되는 preload list에 추가되면 삭제되기까지(목록 삭제 및 사용자 브라우저 업데이트) 시간이 오래 걸리므로 추가는 신중하게 해야한다. preload list는 크롬이 관리하고 있고 대부분의 브라우저들(파이어폭스, 오페라, 사파리, IE11, Edge)이 이 목록을 같이 사용한다.\n만약 수동으로 해제하고자 한다면 크롬은 chrome://net-internals/#hsts에 들어가서 Delete Domain에서 삭제할 도메인을 입력하고 삭제하면 된다.\nHSTS 설정 코드\n\u0026lt;http\u0026gt; \u0026lt;!-- ... --\u0026gt; \u0026lt;headers\u0026gt; \u0026lt;hsts include-subdomains=\u0026#34;true\u0026#34; max-age-seconds=\u0026#34;31536000\u0026#34; /\u0026gt; \u0026lt;/headers\u0026gt; \u0026lt;/http\u0026gt;@EnableWebSecurity public class WebSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http // ... \t.headers() .httpStrictTransportSecurity() .includeSubdomains(true) .maxAgeSeconds(31536000); } } HSTS disable 코드\n\u0026lt;http\u0026gt; \u0026lt;!-- ... --\u0026gt; \u0026lt;headers\u0026gt; \u0026lt;hsts disable=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;/headers\u0026gt; \u0026lt;/http\u0026gt;@EnableWebSecurity public class WebSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http // ... \t.headers() .httpStrictTransportSecurity().disable(); } } 24. List에 있는 value를 Mybatis foreach로 insert 하기 public class TestDto { private List\u0026lt;String\u0026gt; list; // getter \u0026amp; setter }\u0026lt;insert id=\u0026#34;insertTest\u0026#34; parameterType=\u0026#34;com.test.dto.TestDto\u0026#34;\u0026gt; INSERT INTO test_table (id, order) VALUES \u0026lt;foreach collection=\u0026#34;list\u0026#34; item=\u0026#34;value\u0026#34; index=\u0026#34;order\u0026#34; open=\u0026#34;\u0026#34; separator=\u0026#34;,\u0026#34; close=\u0026#34;\u0026#34;\u0026gt; (#{value}, #{order}) \u0026lt;/foreach\u0026gt; \u0026lt;/insert\u0026gt; 25. 컨트롤러에서 List 객체 받는 방법 정리 방법1\n$.ajax({ url: \u0026#34;/test1\u0026#34;, type: \u0026#34;post\u0026#34;, contentType: \u0026#39;application/json;charset=UTF-8\u0026#39;, data: JSON.stringify(list) }).done(function (data, status, xhr) { ... @RequestMapping(value = \u0026#34;/test1\u0026#34;, produces = {\u0026#34;application/json;charset=UTF-8\u0026#34;}, method = RequestMethod.POST) public void test1(@RequestBody List\u0026lt;String\u0026gt; list) { ... } 방법2\n$.ajax({ url: \u0026#34;/test2\u0026#34;, type: \u0026#34;post\u0026#34;, contentType: \u0026#39;application/json;charset=UTF-8\u0026#39;, data: JSON.stringify({ name: yangbongsoo, age: 29, list: list }) }).done(function (data, status, xhr) { ... @RequestMapping(value = \u0026#34;/test2\u0026#34;, produces = {\u0026#34;application/json;charset=UTF-8\u0026#34;}, method = RequestMethod.POST) public void test2(@RequestBody TestDto testDto) { ... }public class TestDto { private String name; private int age; private List\u0026lt;String\u0026gt; list; //getter and setter } 26. Mac에서 Spring Boot의 시작이 느릴 때 Mac에서 Spring Boot의 시작이 느리다면 아래와 같이 hostname을 지정해 본다.\nsudo scutil --set HostName MyMacBook  Spring Boot의 StartupInfoLogger 에서는 InetAddress.getLocalHost().getHostName();를 호출한다. Mac에서는 Hostname이 지정되어 있지 않을 경우 해당 메서드 호출에 몇초가 걸리는 것으로 파악된다.\n27. Tomcat8 UMASK 이슈 스프링 이슈는 아니지만 따로 적을 곳이 없어서 여기에 적음\n파일 업로드를 할 때 업로드된 파일 권한이 위에서 아래로 바뀌는 현상 발견\n-rw-r--r-- -rw-r-----  원인을 찾아보니 tomcat 7.0.68 catalina.sh에서는 UMASK가 주석처리 되어있었는데\n#JAVA_OPTS=\u0026quot;$JAVA_OPTS -Dorg.apache.catalina.security.SecurityListener.UMASK=`umask`\u0026quot;  tomcat 8.5.32 catalina.sh에서 UMASK에 대한 부분이 바꼈다.\n# Set UMASK unless it has been overridden if [ -z \u0026quot;$UMASK\u0026quot; ]; then UMASK=\u0026quot;0027\u0026quot; fi umask $UMASK ... # Make the umask available when using the org.apache.catalina.security.SecurityListener JAVA_OPTS=\u0026quot;$JAVA_OPTS -Dorg.apache.catalina.security.SecurityListener.UMASK=`umask`\u0026quot;  문제가 되는 이유는, 아파치 httpd.conf에서 User nobody를 할 경우에 640이면 파일 read를 못하게 된다. 기존 tomcat7에서는 read에 문제가 되지 않았던 부분이다.\nfile 666 - 022 = 644(-rw-r--r--) file 666 - 027 = 640(-rw-r-----)  cf) 027은 000 010 111이고 보수로 전환하면 111 101 000이 된다. UMASK 보수 값과 파일 기본 허가권을 AND 연산하면\n110 110 110 111 101 000 ----------- 110 100 000  640이 된다.\n28. Maven에서 dependency 의 scope 설정 compile(default) : 컴파일 시 라이브러리를 사용한다. runtime : 실행 시 라이브러리를 사용한다. provided : 외부에서 라이브러리가 제공된다. 컴파일 시 사용하지만 빌드에 포함하지 않는다. 보통 JSP, Servlet 라이브러리들에 사용한다. test : 테스트 코드에만 사용한다. \u0026lt;mvc:annotation-driven/\u0026gt; \u0026lt;context:component-scan base-package=\u0026#34;\u0026#34;/\u0026gt; base-package포함, 하위의 클래스들 중 @Controller, @Repository, @Service, @Component가 붙어 있는 클래스들을 자동으로 스프링 빈으로 등록한다.\n\u0026lt;tx:annotation-driven/\u0026gt; \u0026lt;context:component-scan base-package=\u0026#34;\u0026#34;/\u0026gt; bace-package포함, 하위의 클래스들 중 @Transcational이 붙은 곳에 트랜잭션을 적용한다.\n\u0026lt;context:component-scan\u0026gt; / \u0026lt;mvc:annotation-driven\u0026gt; / \u0026lt;context:annotation-config\u0026gt; 차이점\n context:component-scan  특정 패키지안의 클래스들을 스캔하고, 빈 인스턴스를 생성한다. @Component @Controller @Service @Repository 애노테이션이 존재해야 빈을 생성할 수 있다. 이것의 장점 중 하나는 @Autowired 와 @Qualifier 애노테이션을 이해한다는 것인데 component-scan을 선언했다면 context:annotation-config를 선언할 필요가 없다.  mvc:annotation-driven  스프링 MVC 컴포넌트들을 그것의 디폴트 설정을 가지고 활성화 하기위해 사용된다. 만약 context:component-scan을 XML 파일에서 빈을 생성하기 위해 사용하면서 mvc:annotation-driven을 포함시키지 않아도 MVC 애플리케이션은 작동할 것이다. 그러나 mvc:annotation-driven은 특별한 일들을 하는데 이 태그는 당신의 @Controllers에게 요청을 전파하기위해 요구되는 HandlerMapping과 HandlerAdapter를 등록한다. 게다가, 클래스패스상에 존재하는 디폴트 작업을 수행한다.  context:annotation-config  context:annotation-config은 애플리케이션 컨텍스트안에 이미 등록된 빈들의 애노테이션을 활성화하기 위해 사용된다.(그것들이 XML로 설정됐는지 혹은 패키지스캐닝을 통한건지는 중요하지 않다.) 그 의미는 이미 스프링 컨텍스트에 의해 생성되어 저장된 빈들에 대해서 @Autowired와 @Qualifier 애노테이션을 해석할거란 얘기다. component-scan 또한 같은일을 할 수 있는데, 추가적으로 애플리케이션 컨텍스트에 빈을 등록하기위한 패키지들을 스캔한다. context:annotation-config는 빈을 등록하기 위해 검색할 수 없다. context:annotation-config 태그를 설정하면 @Required @Autowired @Resource @PostConstruct @PreDestroy @Configuration 기능을 각각 설정하는 수고를 덜게 해준다.   mvc:resources\n\u0026lt;mvc:default-servlet-handler default-servlet-name=\u0026#34;default\u0026#34;/\u0026gt; DispatcherServlet이 처리하지 못한 요청을 서블릿 컨테이너의 DefaultServlet에게 넘겨주는 역할을 하는 핸들러이다.\n/js/jquery.js 처럼 컨트롤러에 매핑안되는 URL같은 경우는 DefaultServletHttpRequestHandler가 담당한다. 이 핸들러는 매핑 우선순위가 가장 낮아서 애노테이션 매핑 등등을 거쳐서 다 실패한 URL만 넘어온다. 그리고 요청을 자신이 직접 읽어서 처리하는 것이 아니라, 원래 서버가 제공하는 디폴트 서블릿으로 넘겨버린다. 그러면 서버의 기본 디폴트 서블릿이 동작해서 스태틱리소스를 처리하는 것이다. 다시말해 일단 스프링이 다 받고 스프링이 처리 못하는 건 다시 서버의 디폴트 서블릿으로 넘긴다는 아이디어이다.\n*.ico파일 처리 못하는 현상은 web.xml에 ico의 MIME타입을 지정해주면 된다.\n\u0026lt;mime-mapping\u0026gt; \u0026lt;extension\u0026gt;ico\u0026lt;/extension\u0026gt; \u0026lt;mime-type\u0026gt;image/vnd.microsoft.icon\u0026lt;/mime-type\u0026gt; \u0026lt;/mime-mapping\u0026gt; 정적자원 설정하기 CSS,JS,이미지 등의 자원은 거의 변하지 않기 때문에, 웹 브러우저에 캐시를 하면 네트워크 사용량, 서버 사용량, 웹 브라우저의 반응 속도 등을 개선할 수 있다. 스프링 MVC를 이용하는 웹 애플리케이션에 정적 자원 파일이 함께 포함되어 있다면 웹 서버 설정을 사용하지 않고 캐시를 사용하도록 지정할 수 있다.\n\u0026lt;mvc:resources mapping=\u0026#34;/resources/**\u0026#34; location=\u0026#34;/resources/\u0026#34; cache-period=\u0026#34;60\u0026#34;/\u0026gt; mapping : 요청 경로 패턴을 설정한다. (컨텍스트 경로를 제외한 나머지 부분의 경로) location : 웹 애플리케이션 내에서 요청 경로 패턴에 해당하는 자원의 위치를 지정한다. 위치가 여러곳일 경우 각 위치를 콤마로 구분한다. cache-period: 웹 브라우저에 캐시 시간 관련 응답 헤더를 전송한다. 초 단위로 캐시 시간을 지정하며 이 값이 0이면 웹 브라우저가 캐시하지 않도록 한다.\n위 설정의 경우 요청 경로가 /resources/로 시작하면, 그에 해당하는 자원을 /resources/나 /WEB-INF/resources/ 디렉토리에서 검색한다.\n빈 설정방식의 변화 1.x : 모든걸 \u0026lt;bean\u0026gt; \u0026lt;/bean\u0026gt;으로 2.0.x : \u0026lt;tx:annotation-driven 2.5x : @Service, @Repository 같이 설정 \u0026lt;context:component-scan base-package=\u0026quot;~\u0026quot; 3.0.x : @Configuration, @Bean 3.1.x : @Enable~ ex) @EnableTransactionManagement @EnableWebMvc는 \u0026lt;mvc:annotation-driven\u0026gt;과 똑같다. 따라서 애노테이션 드리븐을 설정하면 위의 주석에 해당하는 것들이 자동으로 등록이 된다. 기본적으로 Http메세지 컨버터도 등록이 되지만, JSON을 위한 MappingJackson2HttpMessageConverter는 직접 등록해줘야 사용할 수 있다.\n웹 환경에서 스프링 애플리케이션이 기동하는 방식 서블릿 컨테이너는 브라우저와 같은 클라이언트로부터 들어오는 요청을 받아서 서블릿을 동작시켜주는 일을 맡는다. 서블릿은 웹 애플리케이션이 시작될 때 미리 만들어둔 웹 애플리케이션 컨텍스트에게 빈 오브젝트로 구성된 애플리케이션의 기동 역할을 해줄 빈을 요청해서 받아둔다. 그리고 미리 지정된 메서드를 호출함으로써 스프링 컨테이너가 DI 방식으로 구성해둔 애플리케이션의 기능이 시작되는 것이다.\n스프링은 이런 웹 환경에서 애플리케이션 컨텍스트를 생성하고 설정 메타정보로 초기화해주고, 클라이언트로부터 들어오는 요청마다 적절한 빈을 찾아서 이를 실행해주는 기능을 가진 DispatcherServlet이라는 이름의 서블릿을 제공한다. DispatcherServlet은 서블릿이 초기화 될때 자신만의 컨텍스트를 생성하고 초기화한다.\n"
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/understanding_the_tomcat_classpath/",
	"title": "Understanding The Tomcat Classpath",
	"tags": [],
	"description": "",
	"content": " 원문 : https://www.mulesoft.com/tcat/tomcat-classpath\n아파치 톰캣 유저 포럼에 공통된 질문들이 있다. 바로 웹 애플리케이션에 필요한 Jar 파일들을 포함시키기 위해 톰캣 classpath를 어떻게 설정해야 되는가이다. 먼저 톰캣이 어떻게 생성되고 classpath를 이용하는지 알아보자. 그리고 classpath와 관련된 이슈들을 하나씩 살펴보자.\nWhy Classpaths Cause Trouble For Tomcat Users classpath는 JVM에게 프로그램을 돌리기 위해 필요한 클래스들과 패키지들이 어디에 있는지 말해주는 argument다. classpath는 항상 프로그램 외부 소스에서 셋팅된다. 이렇게 프로그램으로부터 classpath에 대한 책임을 분리시키는 것은 자바 코드가 추상적인 방식으로 클래스들과 패키지들을 참조할 수 있게 한다.\n그런데 왜 많은 자바 개발자들이 classpath가 뭐고 어떻게 동작하는지 이해했음에도 불구하고 톰캣을 돌릴 때 문제가 생기는 걸까?\n이 질문에 대한 3가지 답이 있고 우리는 각각에 대해서 자세히 알아볼 것이다.\n 톰캣은 다른 자바 프로그램들과 같은 방법으로 classpath를 resolve하지 않는다. 톰캣이 classpath를 reslove하는 방법은 모든 주요 릴리즈마다 조용히 바뀌어왔다. 톰캣 문서와 디폴트 설정은 어떤 일을 달성하는 best way을 강제한다. 만약 best way를 따르지 않으면 톰캣이 기술적으로 custom 설정을 지원해도 you\u0026rsquo;re left in the dark. 그리고 outside dependencies, shared dependencies, 동일한 dependency의 여러 버전 같은 덜 공통적인 classpath 상황들에 대한 제어 방법을 제공하지 않는다.  How Tomcat Classpath UsageDiffers From Standard Usage 그럼 톰캣 classpath 사용이 표준 사용과는 어떻게 다른지 알아보자.\n아파치 톰캣은 설정을 표준화하는 노력과 웹 애플리케이션 배포의 효율적인 관리를 위해 가능한 self-contained하고 직관적이고 자동적인것을 목표로 한다. 반면에 보안과 namespace 이유로 다른 라이브러리 접근에 제한을 건다.\n톰캣 start 스크립트는 \u0026ldquo;system\u0026rdquo; classloader를 만들 때 자바 classpath 환경변수를 무시하고 자신만의 classpath를 실행시킨다. 자바 classpath 환경변수(의존성 레파지토리들을 선언하는 전통적인 장소)를 사용하지 않는다. 다시 말해, 아무리 시스템 환경변수에 추가적인 레파지토리를 선언해도 톰캣이 boot 될때마다 자신만의 환경변수로 그것을 덮어쓰게 된다.\n그렇다면 톰캣이 어떻게 classpath를 reslove하는지 이해하기 위해 startup process를 살펴보자.\n JVM bootstrap loader가 코어 자바 라이브러리들을 로드한다(JVM은 JAVA_HOME 변수를 사용하여 코어 라이브러리들을 찾는다).\n Startup.sh는 \u0026ldquo;start\u0026rdquo; 파라미터와 함께 Catalina.sh를 호출해서 system classpath를 overwrites하고 bootstrap.jar와 tomcat-juli.jar를 로드한다. 이러한 리소스들은 톰캣에서만 볼 수 있다.\n Class loader들은 각각 deployed Context로 만들어진다. deployed Context는 각 web 애플리케이션의 WEB-INF/classes 와 WEB-INF/lib에 있는 모든 클래스들과 JAR 파일들을 순서대로 로드한다. 이러한 리소스들은 그것들을 로드한 웹 애플리케이션에서만 볼 수 있다.\n The Common class loader는 $CATALINA_HOME/lib에 있는 모든 클래스들과 JAR 파일들을 로드한다. 이러한 리소스들은 톰캣과 모든 애플리케이션에서 볼 수 있다.\n  자바 애플리케이션의 standard location에서 하나의 속성이 설정된 한 classpath를 reslove 하는 것보다, 톰캣은 4개 이상의 속성들이 설정된 다수의 classpath들을 resolve한다(그중 단 하나만이 standard location에서 설정된 것이다).\n다음은 classpath resolution을 한 버전에서 다른 버전으로 바꿀 때 생기는 혼란에 대해서 살펴보자.\nHow Tomcat Class Loading Has Changed From Version To Version 이전 톰캣 버전에서 classloader hierachy는 약간씩 다르게 동작했다.\nTomcat 4.x와 그 이전에서 \u0026ldquo;server\u0026rdquo; loader는 Catalina 클래스들을 로딩하는 책임이 있었다. 지금은 commons loader가 제어한다.\nTomcat 5.x에서 \u0026ldquo;shared\u0026rdquo; loader는 $CATALINA_HOME/shared/lib 디렉토리에 위치해서, 애플리케이션들 간의 공유되는 클래스들을 로딩하는 책임이 있었다. 하지만 공유되는 의존성들을 dependent Contexts에서 간단하게 복제하는 쪽으로 유저들을 이끌면서 Tomcat 6에서 버려졌다. 결국 이 loader 또한 Common loader로 대체됐다. 추가적으로 Tomcat 5.x는 모든 Catalina 컴포넌트들을 로드하는 Catalina loader를 포함했었고 지금은 다시 Common loader가 제어한다.\nWhen You Can\u0026rsquo;t Do Things The \u0026ldquo;Best\u0026rdquo; Way Tomcat을 documentation이 추천하는 대로만 사용하면 classpath와 관련된 문제는 발생하지 않는다.\nWAR들은 모든 라이브러리, 패키지들의 중복된 버전을 갖게 되고 standard Tomcat distribution에 포함되지 않은 여러 애플리케이션들 간에 JAR를 공유할 필요가 없다. 또한 외부 리소스를 호출할 필요도 없고, 웹 애플리케이션을 돌리기 위해 필요한 single JAR파일의 multiple 버전 같은 복잡한 상황도 발생하지 않는다.\n하지만 그렇게만 사용되지 않는게 현실이다. 이런 상황에 놓인 유저들에게는 catalina.properties 파일이 모든 문제의 답이다.\nConfiguring Tomcat Classpath Handling Via catalina.properties 다행히 default class loading methods 사용을 원치 않는 유저라면 톰캣 classpath option들을 하드코딩하지 않아도 된다. Catalina central properties 파일인 $CATALINA_HOME/conf/catalina.properties에서 읽어온다.\n이 파일은 JVM이 제어하는 bootstrap loader 이외의 모든 loader들에 대한 설정을 포함하고 있고, 또 JVM이 제어하는 system loader는 톰캣 startup 스크립트에 의해 re-written된다.\n이 파일을 살펴보면 다음과 같은 사실을 알 수 있다. 1. 서버와 Shared loader들은 그것 자체로 제거되지 않는다. 만약 속성들이 정의되지 않았다면 Commons loader가 제어한다. 2. 다양한 loader들에 의해 로드된 클래스들과 JAR파일들은 자동적으로 로드되지 않고, simple wildcard syntax를 그룹으로 간단히 지정된다. 3. 이 파일에 외부 레파지토리를 명세할 수 없다.\nserver loader는 혼자 남지만 shared loader는 여전히 많은 유용한 애플리케이션들을 갖고 있다. (Note : shared loader는 Commons loader가 클래스 로딩을 끝낸 후에 start-up process에서 클래스들을 마지막으로 로드할 것이다.)\n이제 톰캣 classpath에 대한 공통적인 문제를 어떻게 고쳐야 되는지 살펴보자.\nProblems, Solutions, and Best Practices 문제 : 애플리케이션이 외부 레파지토리를 의존하고 있는데 그걸 import 할 수가 없다.\n톰캣이 외부 레파지토리를 인식하려면 shared loader 아래의 catalina.properties에 syntax 맞게 선언해라.\n 클래스 레파지토리로서 폴더를 추가하려면 path/to/foldername 클래스 레파지토리로서 폴더안에 JAR 파일들을 추가하려면 path/to/foldername/*.jar 클래스 레파지토리로서 단일 JAR 파일을 추가하려면 file:/path/to/foldername/jarname.jar 환경변수를 호출하려면 ${}를 사용해라 ex) ${VARIABLE_NAME} 여러 리소스들을 선언하려면 각각의 entry를 콤마로 구분지어라. 모든 경로들은 상대 경로로 CATALINA_BASE or CATALINA_HOME를 이용할 수 있고 아예 절대 경로를 사용할 수도 있다.  문제 : 다수의 애플리케이션이 하나의 JAR 파일을 공유하길 원한다. 그리고 그 JAR 파일은 톰캣 안에 있길 원한다.\n$CATALINA_HOME/lib안의 JDBC 드라이버들과 같은, 공통적인 서드파티 라이브러리들 말고는 추가적인 라이브러리들을 포함하지 않는게 best다. 대신에 Tomcat 5.x에서 사용되는 /shared/lib과 /shared/classes 디렉토리를 만들고 catalina.properties에서 shared.loader 속성을 설정해라. \u0026quot;shared/classes,shared/lib/*.jar\u0026quot;\n문제 : 애플리케이션에 또다른 프레임워크와 함께 내장 톰캣 서버를 사용하고 있는데 애플리케이션에서 프레임워크 컴포넌트들을 접근하려고 할 때마다 classpath 에러가 발생한다.\n이 문제는 이번 주제 범위에서 다소 벗어나있지만 공통적인 classpath와 관련된 질문이다. 다음은 에러 원인에 대한 간략한 개요다.\nSpring이나 Wicket 같은 프레임워크를 추가하는 애플리케이션에 내장된 톰캣은 프레임워크를 시작할 때, 애플리케이션의 WEB-INF/lib 디렉토리 안에 것을 로드하지 않고 System classloader를 사용해 코어 클래스를 로드한다.\n이것은 톰캣이 독립형 애플리케이션 컨테이너로써 돌아가는 기본 동작이다. 그러나 내장형일 때는 리소스를 웹 애플리케이션에서 이용할 수 없게 되는 결과를 낳는다.\nJava class loading is lazy. 즉, 어떤 클래스를 요청하는 첫 classloader는 그 라이프사이클의 나머지 클래스를 소유하고 있다. 만약 System classloader(System classloader의 클래스들은 웹 애플리케이션을 볼 수 없다)가 프레임워크 클래스를 처음으로 로드했다면 JVM은 classpath 에러를 발생시키는 원인이 되는 추가적인 클래스 인스턴스들을 막는다.\n이 문제는 애플리케이션에 custom bootstrap classloader를 추가함으로써 해결할 수 있다. 웹 애플리케이션을 대신해서 적절한 라이브러리들을 로드하기 위해 custom bootstrap classloader를 설정해라. 그리고 나머지는 정상적으로 start-up 시키면 애플리케이션의 모든 classloader 충돌을 해결할 수 있다.\n문제 : WAR의 일부분으로 모든 의존성 패키지를 포함하는 standard 애플리케이션을 사용하고 있지만 여전히 클래스 definition error가 발생한다.\n이 문제는 잘못 구현된 빌드나 배포 프로세스를 포함해 여러가지에 의해 발생할 수 있지만 대부분 웹 애플리케이션의 디렉토리 구조 때문에 발생한다.\nJava naming convention은 클래스 이름들이, 자신들이 저장되는 디렉터리 구조를 반영하도록 한다. 예를 들어 com.mycompany.mygreat.class 클래스는 WEB-INF/classes/com/mycompany/ 디렉토리에 저장될 필요가 있다.\n종종 코드에서 누락된 기간(missing period)은 classpath와 관련된거 같은 에러를 유발한다. 톰캣을 비난하기 전에 항상 가장 간단한 해결책부터 체크해라!\n문제 : 웹 애플리케이션의 다른 섹션들은 같은 JAR 라이브러리의 서로 다른 두개 버전을 사용해야 한다.\n이러한 상황은 단일 애플리케이션에서, 다른 버전의 라이브러리를 의존하는 다수의 웹 프레임워크를 사용할때 자주 발생한다.\n이 문제는 serious pain이고 3가지 해결책이 있지만 그 중 어느것도 classpath 자체적으로 해결될순 없다.\n우리가 이 문제를 여기에 포함시킨 이유는 몇몇 유저들이 프레임워크 JAR안에 포함된 Manifest 파일에서, 필요한 의존성에 대한 다른 버전의 classpath들을 대안으로 명세하는 것을 시도했기 때문이다.\n이 feature가 Weblogic(일부 유저가 톰캣을 사용하는 이유가 될 수 있는) 같은 웹 애플리케이션 서버에 의해 지원되는 동안에, Manifest 파일을 이용해 classpath를 명세하는 것은 톰캣에서 지원되지 않으며 서블릿 스펙도 아니다.\n이 문제를 해결하기 위해 4가지 접근방법이 있다. 하지만 그 중 어떤것도 단순히 classpath를 고치는 것으로 해결될 수 없고 그 중 어떤것도 고통에서 자유로울 순 없다.\n첫째, 프레임워크 버전을 업데이트 해라.\n둘째, 두개 이상의 custom classloader를 만들어라(각 JAR당 하나씩). 그리고 필요로하는 버전으로 클래스의 두개의 인스턴스를 만들기 위해 애플리케이션의 WEB-INF/context.xml 파일에 설정해라.\n셋째, 프레임워크와 단일 JAR 파일에서 의존성을 패키징하기 위해 jarjar 유틸리티를 사용해라. 그러면 같이 함께 로드될 것이다. 이 방법은 이상적이진 않지만 동작은 할 것이다.\n마지막으로, 이런 문제를 하루걸러 계속 다루게 된다면 OSGi 프레임워크를 구현하는것을 고려해라. 이 프레임워크는 특별할 상황을 위해 설계되었고 하나의 클래스의 여러 버전이 하나의 JVM에서 실행되어야만 한다.\n"
},
{
	"uri": "/apache-and-tomcat/",
	"title": "apache and tomcat",
	"tags": [],
	"description": "",
	"content": " cf) Apache Syntax error check\n$ apachectl -t  start / stop / restart\n$ apachectl start $ apachectl stop $ apachectl restart  httpd.conf ServerRoot \u0026#34;/usr\u0026#34; (mac에 기본적으로 깔려있는 apache 기준) ... #Listen 12.34.56.78:80 Listen 80 ... LoadModule jk_module /private/etc/apache2/other/mod_jk.so #\u0026#39;Main\u0026#39; server configuration #이 섹션의 지시문은 \u0026lt;main\u0026gt; 서버가 사용하는 값을 설정하며, #\u0026lt;VirtualHost\u0026gt; 정의에 의해 처리되지 않는 요청에 응답한다. #또한 이 값은 나중에 파일에 정의 할 수있는 \u0026lt;VirtualHost\u0026gt; 컨테이너의 기본값을 제공한다. #이러한 지시어는 모두 \u0026lt;VirtualHost\u0026gt; 컨테이너 안에 나타날 수 있는데, 가상 호스트가 정의 될 때 기본 설정은 무시된다. ServerAdmin you@example.com ServerName www.example.com:80 #문서를 제공할 디렉토리다. 기본적으로 모든 요청은 디렉토리에서 처리되지만 #심볼릭 링크와 별칭을 사용하여 다른 위치를 가리킬 수도 있다. DocumentRoot \u0026#34;/abc/def/ght\u0026#34; #default는 매우 제한적인 기능으로 구성한다. #서버의 파일 시스템 전체에 대한 액세스를 거부한다. #아래의 다른 \u0026lt;Directory\u0026gt; 블록에서 웹 콘텐츠 디렉토리에 대한 액세스를 명시적으로 허용해야 한다. \u0026lt;Directory /\u0026gt; Options FollowSymLinks AllowOverride none Order deny,allow Deny from all \u0026lt;/Directory\u0026gt; ... #StartServers : 아파치 구동 시 띄울 프로세스 갯수 #MinSpareServers, MaxSpareServers : #부하가 적어서 MinSpareServers 개수 보다 적었을 경우 최소한 이 개수 만큼 유지하려고 아파치가 노력하고 #부하가 증가하여 프로세스 개수가 많아질 경우에 MaxSpareServers 개수 이하로 줄이려고 아파치는 노력한다. #ServerLimit :아파치 동시 접속자 수 설정 (apache 2.2.x 버전의 \u0026#34;ServerLimit\u0026#34; 는 DEFAULT = 256 , MAX = 20000 으로 지정) #MaxClients : 실행 가능한 최대 프로세스 갯수 #MaxRequestsPerChild : 프로세스가 요청 받을 수 있는 맥시멈 수 (0일 경우엔 무한) \u0026lt;IfModule mpm_prefork_module\u0026gt; StartServers 5 MinSpareServers 5 MaxSpareServers 10 #ServerLimit 2048 MaxClients 105 MaxRequestsPerChild 0 \u0026lt;/IfModule\u0026gt; ... ############################ # JKConnector Configuation # ############################ \u0026lt;IfModule mod_jk.c\u0026gt; JkMount /*.ybs tomcat JkMount /*.jsp tomcat JkMount /jkmanager/* jkstatus JkMountCopy All JkLogFile \u0026#34;/var/log/apache2/mod_jk.log\u0026#34; JkShmFile \u0026#34;/var/log/apache2/mod_jk.shm\u0026#34; JkWorkersFile /private/etc/apache2/workers.properties \u0026lt;Location /jkmanager/\u0026gt; JkMount jkstatus Order deny,allow Deny from all Allow from 127.0.0.1 \u0026lt;/Location\u0026gt; \u0026lt;/IfModule\u0026gt; ############################### # Virtual Hosts Configuration # ############################### \u0026lt;VirtualHost *:80\u0026gt; ServerAdmin goodbs1000@gmail.com DocumentRoot /Users/yangbongsoo/Documents/myProject/target/deploy ServerName xxx.xxx.com \u0026lt;Directory \u0026#34;/Users/yangbongsoo/Documents/myProject/target/deploy\u0026#34;\u0026gt; Options FollowSymLinks AllowOverride None Order allow,deny Allow from all \u0026lt;/Directory\u0026gt; \u0026lt;Directory ~ \u0026#34;/\\.svn/*\u0026#34;\u0026gt; Order deny,allow Deny from all \u0026lt;/Directory\u0026gt; \u0026lt;Directory ~ \u0026#34;/META-INF\u0026#34;\u0026gt; Order deny,allow Deny from all \u0026lt;/Directory\u0026gt; \u0026lt;Directory ~ \u0026#34;/WEB-INF\u0026#34;\u0026gt; Order deny,allow Deny from all \u0026lt;/Directory\u0026gt; RewriteEngine on RewriteRule ^/(projectName)*(/)*$ /projectName/Main.jsp [R] JkMountCopy On JkMount /*.ybs tomcat JkMount /*.jsp tomcat \u0026lt;/VirtualHost\u0026gt; ServerRoot : 서버의 설정, 에러, 로그파일들이있는 디렉토리 트리의 맨 위\nListen : 아파치를 디폴트가 아닌 특정 IP 주소 나 포트에 바인드 할 수도 있다(prevent Apache from glomming onto all bound IP addresses).\nLoadModule jk_module : 본인 pc에 디폴트로 mod_jk가 없어서 so 파일을 구해다 other 디렉토리에 넣었다.\nVirtualHost : 위와 같이 http.conf에서 직접 작업 하지 않고 Include /private/etc/apache2/extra/httpd-vhosts.conf 한 후 그곳에서 작업해도 된다.\nworkers.properties worker.list=tomcat worker.tomcat.type=ajp13 worker.tomcat.port=8009 worker.tomcat.host=localhost worker.tomcat.socket_timeout=100 worker.tomcat.connection_pool_timeout=100 #worker.tomcat.lbfactor=1 worker.list=jkstatus worker.jkstatus.type=status Tomcat 참고문헌 : 자바 고양이 톰캣 이야기 (최진식 저)\nserver.xml \u0026lt;?xml version=\u0026#39;1.0\u0026#39; encoding=\u0026#39;utf-8\u0026#39;?\u0026gt; \u0026lt;Server port=\u0026#34;8005\u0026#34; shutdown=\u0026#34;SHUTDOWN\u0026#34;\u0026gt; \u0026lt;Listener className=\u0026#34;org.apache.catalina.core.JasperListener\u0026#34; /\u0026gt; \u0026lt;Listener className=\u0026#34;org.apache.catalina.core.JreMemoryLeakPreventionListener\u0026#34; gcDaemonProtection=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;Listener className=\u0026#34;org.apache.catalina.mbeans.GlobalResourcesLifecycleListener\u0026#34; /\u0026gt; \u0026lt;Service name=\u0026#34;Catalina\u0026#34;\u0026gt; \u0026lt;Connector port=\u0026#34;8080\u0026#34; protocol=\u0026#34;HTTP/1.1\u0026#34; connectionTimeout=\u0026#34;20000\u0026#34; URIEncoding=\u0026#34;UTF-8\u0026#34; redirectPort=\u0026#34;8443\u0026#34; /\u0026gt; \u0026lt;!-- \u0026lt;Connector port=\u0026#34;8443\u0026#34; protocol=\u0026#34;org.apache.coyote.http11.Http11Protocol\u0026#34; maxThreads=\u0026#34;150\u0026#34; SSLEnabled=\u0026#34;true\u0026#34; scheme=\u0026#34;https\u0026#34; secure=\u0026#34;true\u0026#34; clientAuth=\u0026#34;false\u0026#34; sslProtocol=\u0026#34;TLS\u0026#34; /\u0026gt; --\u0026gt; \u0026lt;!-- Define an AJP 1.3 Connector on port 8009 --\u0026gt; \u0026lt;Connector port=\u0026#34;8009\u0026#34; protocol=\u0026#34;AJP/1.3\u0026#34; enableLookups=\u0026#34;false\u0026#34; acceptCount=\u0026#34;1000\u0026#34; debug=\u0026#34;0\u0026#34; connectionTimeout=\u0026#34;180000\u0026#34; useBodyEncodingForURI=\u0026#34;true\u0026#34; maxPostSize=\u0026#34;4194304\u0026#34; maxParameterCount=\u0026#34;4000\u0026#34; disableUploadTimeout=\u0026#34;true\u0026#34; redirectPort=\u0026#34;8443\u0026#34; /\u0026gt; \u0026lt;Engine name=\u0026#34;Catalina\u0026#34; defaultHost=\u0026#34;localhost\u0026#34;\u0026gt; \u0026lt;!-- my Server Setting start --\u0026gt; \u0026lt;Host name=\u0026#34;localhost\u0026#34; appBase=\u0026#34;webapps\u0026#34; unpackWARs=\u0026#34;true\u0026#34; autoDeploy=\u0026#34;true\u0026#34; xmlValidation=\u0026#34;false\u0026#34; xmlNamespaceAware=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;Context docBase=\u0026#34;/xxx/xxx/xxx/xxx/xxxx\u0026#34; path=\u0026#34;/myProject\u0026#34; /\u0026gt; \u0026lt;Context docBase=\u0026#34;/xxx/xxx/xxx/xxx/xxx\u0026#34; path=\u0026#34;/monitor\u0026#34; reloadable=\u0026#34;false\u0026#34; /\u0026gt; \u0026lt;Context path=\u0026#34;/managerAgent\u0026#34; debug=\u0026#34;0\u0026#34; privileged=\u0026#34;true\u0026#34; docBase=\u0026#34;managerAgent.war\u0026#34; /\u0026gt; \u0026lt;/Host\u0026gt; \u0026lt;!-- my Server Setting end --\u0026gt; \u0026lt;/Engine\u0026gt; \u0026lt;/Service\u0026gt; \u0026lt;/Server\u0026gt; Server\n최상위 Element인 \u0026lt;Server\u0026gt;는 \u0026lt;Service\u0026gt; 모음으로, Shutdown 요청 처리를 위한 address와 port 속성을 가지고 있다. 각각 Shutdown 요청을 받기 위해 listen하는 IP address와 포트를 설정하며 기본값을 localhost와 8005이다. 만약 port 속성을 -1로 설정하면 Shutdown 포트 기능을 사용하지 않는다. 한 shuStdown 속성은 Shutdown 명령어(패스워드)를 설정한다. 기본 설정 값 \u0026lsquo;SHUTDOWN\u0026rsquo;인데 보안상 변경하는 것이 좋다.\nService\nServer 하위에 있으며 Connector 모음이다. Service 속성은 className과 name 단 2개다.\nEngine\ndefaultHost 속성은 Engine 하위에 속한 Host 가운데 하나이며 어떤 Host도 처리하지 않는 요청을 처리한다.\nHost\nHost Container는 가상 호스트 기능을 제공한다. Host 이름은 name 속성을 통해 설정한다. 만약 할당된 URL이 있다면 URL로 설정한다. 상위 Engine 내에 2개 이상의 Host가 구성되어 있다면 그중 1개가 defaultHost값이 되어야한다. appBase는 Host의 애플리케이션 디렉토리다. 기본은 webapps다. autoDeploy 속성을 통해 appBase 내 변경 사항을 주기적으로 확인할 수 있다(기본 true). 하지만 운영 환경이라면 가급적 false로 설정하는 것이 좋다. unpackWARs는 WAR 파일을 풀어서 사용할지 여부를 설정하는 속성으로 기본 true이다.\nContext\nHost 내에 배포된 애플리케이션이다. reloadable 속성은 WEB-INF/classes 및 WEB-INF/lib 디렉토리에 변경이 발생할 때 자동 반영 여부를 결정하는 속성으로 기본 false다. true로 설정하면 빈번한 Tomcat 재기동을 피할 수 있어 개발 시에는 유용하지만 운영 시에는 적지 않은 오버 헤드를 동반하므로 적용에 신중해야 한다.\nApache MaxClients와 Tomcat MaxThreads 설정값 참고문헌 : http://d2.naver.com/helloworld/132178\n apache, tomcat이 구동되지 않은 상태에서 서버의 메모리 정보를 확인한다. (total : 1998MB, used : 142MB, free : 1855MB) tomcat 설정에 따른 메모리 점유(Perm Gen + Native Heap Area) : 1152MB\nCATALINA_OPTS=\u0026quot;-server -Xms1024m -Xmx1024m -XX:MaxPermSize=128m  swap으로 인한 성능 저하를 막으려면 어떠한 상황에서도 전체 메모리의 최대 80%인 1598.4MB 이상 사용되지 않도록 해야함 cf) 80%는 swappiness가 기본값인 60일 경우에 해당하는 수치이며 본인 서버에서는 swappiness값이 0이었다. 하지만 동일하게 80% 적용.\n apache 없이 사용되는 메모리는 1152+ 142 = 1294MB이기 때문에 apache가 사용 가능한 최대 메모리는 304.4MB (1598.4 - 1294)\n top으로 확인 시 apache 프로세스 1개당 약 2.9MB 사용\n apache process 최대 갯수(MaxClients)는 약 105개 (304.4 / 2.9)\n tomcat Max Threads는 통상적으로 MaxClients의 * 1.1이므로 약 116개\n  \u0026lt;IfModule mpm_prefork_module\u0026gt; StartServers 5 MinSpareServers 5 MaxSpareServers 10 #ServerLimit 2048 MaxClients 105 MaxRequestsPerChild 0 \u0026lt;/IfModule\u0026gt;\u0026lt;Connector port=\u0026#34;8009\u0026#34; protocol=\u0026#34;AJP/1.3\u0026#34; enableLookups=\u0026#34;false\u0026#34; acceptCount=\u0026#34;1000\u0026#34; debug=\u0026#34;0\u0026#34; connectionTimeout=\u0026#34;180000\u0026#34; useBodyEncodingForURI=\u0026#34;true\u0026#34; maxPostSize=\u0026#34;4194304\u0026#34; maxThreads=\u0026#34;106\u0026#34; maxParameterCount=\u0026#34;4000\u0026#34; disableUploadTimeout=\u0026#34;true\u0026#34; redirectPort=\u0026#34;8443\u0026#34; /\u0026gt;"
},
{
	"uri": "/identity/",
	"title": "identity",
	"tags": [],
	"description": "",
	"content": " SAML 기반의 web sso 원리 정리 통합인증(SSO, Single Sign On)은 한 번의 인증 과정으로 여러 컴퓨터 상의 자원을 이용 가능하게 하는 인증 기능이다. 싱글 사인온, 단일 계정 로그인, 단일 인증이라고 한다.\n보안이 필요한 환경에서 통합인증을 도입하는 경우, 여러 응용 프로그램의 로그인 처리가 간소화되어 편리성을 도모할 수 있는 반면, 통합인증의 시작점이 되는, 즉 최초의 로그인 대상이 되는 응용 프로그램 혹은, 운영체제에 대한 접근 보안이 중요하게 된다. 보안위험이 적은 환경에서는 편리성만을 추구하면 되지만, 보안이 요구되는 환경에서는 1회용 비밀번호를 이용하는 등, 이중 인증 등으로 보안을 강화할 필요가 있다.\nSingle Sign On을 지원하기 위한 프로토콜이나 방법은 여러가지가 있다. 그중 대표적인 방법으로 CAS,SAML,OAuth등이 있는데, CAS는 쿠기를 기반으로 하기 때문에 같은 도메인명 (xxx.domain.com yyy.domain.com) 사이에서만 SSO가 가능하다. (그만큼 구현도 쉽다.) OAuth는 현재 B2C쪽에 많이 사용되는 프로토콜이고, 그리고 마지막으로 SAML 있다. cross domain간 SSO 구현이 가능하며, OAuth 만큼이나 많이 사용되고 있다.\nSAML은 어떤 구현체가 아니라 SSO등(꼭 SSO만은 아님)을 구현하기 위한 XML 스펙이다.\nHTTP GET, POST 또는 SOAP 웹서비스 등 여러가지 방법으로 구현될 수 있으며, 여기서는 HTTP Post를 이용한 SSO 원리와 솔루션 설계시 유의 사항을 설명한다.\nsite Sp A로 초기 로그인  Browser에서 사이트 Sp A로 접속한다. 사이트 Sp A에는 로그인이 되어 있지 않기 때문에 (세션이 없어서). Sp A에서는 SAML request를 만들어서, Browser에게로 redirect URL을 보낸다. Browser는 redirect URL에 따라 IdP에 접속하고, Idp에서 login form을 넣고 log in을 한다. 이때, IdP와 Brower 사이에 HttpSession 또는 Cookie로 Login에 대한 정보를 기록한다. 그리고 다시 사이트 Sp A로의 SAML response를 포함한 redirect URL을 browser로 전송한다. Browser는 SAML reponse를 가지고 Sp A로 접속하면, Sp A에는 인증된 정보를 가지고 로그인 처리를 한다. ※ 이 과정에서는 바로 사이트 Sp A의 사용자 페이지(예를 들어 /home)등으로 가는 것이 아니라, SAML에 의해서 미리 정의한 Sp A의 SAML response 처리 URL로 갔다가 SAML response를 처리가 끝나면 인증 처리를 한후, 사용자 페이지(/home)으로 다시 redirect한다.  site Sp A로 로그인된 상태에서 site Sp B로 로그인  사이트 Sp A에서 로그인된 상태에서 Sp B에 접속한다. 사이트 Sp B는 로그인이 되어 있지 않기 때문에, SAML 메시지를 만들어서 IdP의 login from으로 redirect URL을 보낸다. 브라우져는 redirect URL을 따라서 IdP에 접속을 한다. IdP에 접속을 하면 앞의 과정에서 이미 Session 또는 Cookie가 만들어져 있기 때문에 별도의 로그인 폼을 띄위지 않고, SAML response message와 함께, Sp B로의 redirect URL을 전송한다. Browser는 Sp B에 인증된 정보를 가지고 로그인한다.  SAML 기반의 SSO 솔루션\nsimplePHPSAML : 가장 널리 쓰이고, 사용이 쉽다.\nShibboleth : java stack으로 구현이 되어 있으며, terracotta를 이용하여 session을 저장하기 때문에 상대적으로 확장성이 높다.\nWSO2 identity server : 자체 OSGi 컨테이너인 carbon 엔진 위에서 동작한다. SAML 뿐만 아니라 OAuth,STS 서비스를 추가 지원하며, Provisioning protocol인 SCIM도 함께 지원한다. 오픈 소스이지만, 제품 완성도가 매우 높고, 사용이 매우 쉽다. (모니터링,관리 기능등이 강점)\nOpen AM : Sun IDM을 모태로 하여, 현재 오픈소스화 되었다. 아무래도 enterprise 제품을 기반으로 하다 보니 복잡도가 상대적으로 높다.\n솔루션 설계 시 유의사항\n두 가지 기술적인 이슈가 발생하는데 첫번째는 IdP에 대규모 사용자를 지원할 경우, Session 정보를 어떻게 분산 저장할것인가이다. WSO2 Identity server의 경우에는 각 instance의 memory에 이 session 정보를 저장하고, 자체 clustering feature를 이용하여 이 session을 상호 복제한다. Oracle WebLogic이나 Apache Tomcat cluster의 Http session clustering과 같은 원리이다.\n이 경우에 각 instance의 메모리 size에 따라 저장할 수 있는 session의 수의 한계를 가지게 되고, instance간 session 복제로 인하여, 장애 전파 등의 가능성을 가지게 된다. 그래서 Shibboleth의 경우에는 이 Session 정보를 별도의 terracotta와 같은 data grid에 저장하도록 하여, 확장성을 보장할 수 있다.\n두번째는 로그 아웃에 대한 문제이다. Sp A나 Sp B에 SAML을 이용한 초기 인증이 성공한 경우, 제 로그인(인증)을 막기 위해서 자체적으로 HttpSession등을 사용하여, 별도의 login session을 유지해야 하는데, 이경우 Sp A,Sp B의 Session Time out 시간이 다를 수 있다. 한 사이트에서 logout을 해서 전체 사이트에 걸쳐서 logout이 안될 수 있는 incosistency 문제가 발생한다.\n그래서 WSO2 identity server의 경우에는 별도의 logout URL을 정의하여, IdP에서 logout을 한경우에 전체 사이트에서 logout을 시키는 global logout 기능을 제공한다.\ncf) PingFederate(SSO)\nThe PingFederate® server는 고객, 직원, 협력사들에게 SSO, API security를 제공하는, 모든 기능을 갖춘 federation server다. SAML, WS-Federation, WS-Trust, OAuth and OpenID Connect을 비롯한 모든 최신 identity 표준을 지원한다. 홈페이지 : https://www.pingidentity.com/en/products/pingfederate.html\n[본문]\n위키 : https://ko.wikipedia.org/wiki/%ED%86%B5%ED%95%A9_%EC%9D%B8%EC%A6%9D 조대협 블로그 : http://bcho.tistory.com/755\nFacebook OAuth 추가적인 보안 강화를 위해 사용자 인증(ID, Password)뿐만 아니라, 클라이언트 인증 방식을 추가할 수 있다. 페이스북은 API 토큰을 발급받도록 사용자 ID, 비밀번호 뿐만 아니라 Client ID와 Client Secret이라는 것을 같이 입력받도록 하는데, Client ID는 특정 앱에 대한 등록 ID이고 Client Secret은 특정 앱에 대한 비밀번호로, 페이스북 개발자 포털에서 앱을 등록하면 앱 별로 발급되는 일종의 비밀번호다.\nAPI 토큰을 발급받을 때, Client ID와 Client Secret을 이용하여 클라이언트 앱을 인증하고 사용자 ID와 비밀번호를 추가로 받아서 사용자를 인증해 API 액세스 토큰을 발급한다.\n제 3자 인증 방식(OAuth 2.0 Autorization grant type)\n페이스북이나 트위터와 같은 API 서비스 제공자들이 파트너 애플리케이션에 많이 적용하는 방법으로 자신의 서비스를 페이스북 계정을 이용하여 인증하는 경우다.\n중요한 점은 자신의 서비스에서 사용자 비밀번호를 받지 않고, 페이스북이 사용자를 인증하고 알려주는 방식이다. 즉, 파트너 서비스에는 페이스북 사용자의 비밀번호가 노출되지 않는 방식이다. 전체적인 흐름을 보면 다음과 같다.\n1.먼저 페이스북의 개발자 포털에 접속하여, 페이스북 인증을 사용하고자 하는 애플리케이션 정보를 등록한다(서비스명, 서비스 URL, 그리고 인증이 성공했을 때 인증 성공 정보를 받을 콜백 URL).\n2.페이스북 개발자 포털은 등록된 정보를 기준으로 해당 애플리케이션에 대한 Client ID와 Client Secret을 발급한다. 이 값은 앞에서 설명한 클라이언트 인증에 사용된다.\n3.다음으로 개발하고자 하는 애플리케이션에 이 Client ID와 Client Secret을 넣고, 페이스북 인증 페이지 정보를 넣어서 애플리케이션을 개발한다(Javascript SDK 적용).\n애플리케이션이 개발되서 실행되면 다음과 같은 절차로 사용자 인증을 수행하게 된다.\n 웹 브라우저에서 사용자가 Sokit 서비스에 접근하려고 요청한다. Sokit 서비스는 사용자 인증이 되지 않았기 때문에 페이스북 로그인 페이지 URL을 HTTP 리다이렉션으로 브라우저에 보낸다. 이때 이 URL로 페이스북에 이 로그인 요청이 Sokit에 대한 사용자 인증 요청임을 알려주고자, Client ID 등의 추가 정보와 함께 페이스북 정보 접근 권한(사용자 정보, 그룹 정보 등)을 scope라는 필드를 통해서 요청한다. 브라우저는 페이스북 로그인 페이지로 이동하여 2단계에서 받은 추가적인 정보와 함께 로그인을 요청한다. 페이스북은 사용자에게 로그인 창을 보낸다. 사용자는 로그인 창에 ID/비밀번호를 입력한다. 페이스북은 사용자를 인증하고 인증 관련 정보와 함께 브라우저로 전달하면서 Sokit의 로그인 완료 페이지로 리다이렉션을 요청한다. Sokit은 6에서 온 인증 관련 정보를 받는다. Sokit은 이 정보를 가지고 페이스북에 이 사용자가 제대로 인증을 받은 사용자인지 문의한다. 페이스북은 해당 정보를 보고 제대로 인증된 사용자임을 확인해주고 Access Token을 발급한다. Sokit은 9에서 받은 Access Token으로 페이스북 API 서비스에 접근한다.  HTTP 완벽가이드 11장 - 클라이언트 식별과 쿠키 HTTP는 stateless 하기 때문에 사용자를 식별하기 위해서는 추가적인 기술이 필요하다. HTTP 헤더, IP주소, 로그인 인증, URL에 식별자를 포함하는 방식(Fat URL), 쿠키 이렇게 5가지 방식이 있다.\ncf) 사용자 로그인 인증방식은 웹 사이트 로그인이 더 쉽도록 WWW-Authenticate와 Authorization 헤더를 사용한다. 서버에서, 사용자가 사이트에 접근하기 전에 로그인을 시키고자 한다면 HTTP 401 unauthorized 응답코드와 WWW-Authenticate 헤더를 브라우저에 보낸다. 브라우저는 로그인 대화상자를 보여주고, 다음 요청부터 Authorization 헤더에 그 정보를 기술하여 보낸다.\n그중에서 쿠키는 사용자를 식별하고 세션을 유지하는 방식 중에서 현재까지 장 널리 사용하는 방식이다. 쿠키는 캐시와 충돌할 수 있어서, 대부분의 캐시나 브라우저는 쿠키에 있는 내용물을 캐싱하지 않는다.\n쿠키의 타입\n쿠키는 크게 세션 쿠키(seesion cookie)와 지속 쿠키(persistent cookie) 두 가지 타입으로 나눌 수 있다. 세션 쿠키는 사용자가 부라우저를 닫으면 삭제된다. 지속 쿠키는 디스크에 저장되어, 브라우저를 닫거나 컴퓨를 재시작하더라도 남아있다. 지속쿠키는 사용자가 주기적으로 방문하는 사이트에 대한 설정 정보나 로그인 이름을 유지하려고 사용한다.\n세션 쿠키와 지속 쿠키의 다른 점은 파기되는 시점 뿐이다. 쿠키는 Discard 파라미터가 설정되어 있거나, 파기 되기까지 남은 시간을 가리키는 Expires 혹은 Max-Age 파라미터가 없으면 세션 쿠키가 된다.\n사이트마다 각기 다른 쿠키들\n보통 브라우저는 쿠키를 생성한 서버에게만 쿠키에 담긴 정보를 전달한다. joes-hardware.com에서 생성된 쿠키는 joes-hardware.com에만 보내고 bobs-books.com이나 mary-movie.com에는 보내지 않는다.\n서버는 쿠키를 생성할 때 Set-Cookie 응답 헤더에 Domain 속성을 기술해서 어떤 사이트가 그 쿠키를 읽을 수 있는지 제어할 수 있다.\nSet-cookie: user=\u0026quot;mary17\u0026quot;; domain=\u0026quot;airtravelbargains.com\u0026quot;  예를 들어 위의 HTTP 응답 헤더는 브라우저가 user=\u0026ldquo;mary17\u0026rdquo;이라는 쿠키를 .airtravelbargains.com 도메인을 가지고 있는 모든 사이트에 전달한다는 의미다.\n웹 사이트 일부에만 쿠키를 적용할 수도 있다. URL 경로의 앞부분을 가리키는 Path 속성을 기술해서 해당 경로에 속하는 페이지에만 쿠키를 전달한다.\nSet-cookie: pref=compact; domain=\u0026quot;airtravelbargains.com\u0026quot;; path=/autos/  만약 사용자가 http://www.airtravelbargains.com/specials.html에 접근하면\nCookie: user=\u0026quot;mary17\u0026quot;  위와 같은 쿠키만 얻게 된다. 하지만 http://www.airtravelbargains.com/autos/cheapo/index.html로 접근하면\nCookie: user=\u0026quot;mary17\u0026quot; Cookie: pref=compact  다음과 같은 두 가지 쿠키를 받게 된다.\n"
},
{
	"uri": "/nginx_gzip_option/",
	"title": "nginx gzip 옵션",
	"tags": [],
	"description": "",
	"content": "응답을 압축하면 전송되는 데이터의 크기가 크게 줄어들기도 한다. 그러나 압축은 런타임에 발생하기 때문에 상당한 처리 오버헤드가 추가되어 성능에 부정적인 영향을 미칠 수 있다. NGINX는 클라이언트에 응답을 보내기 전에 압축을 수행하지만 이미 압축 된 응답 (예 : 프록시 서버)을 \u0026ldquo;이중 압축\u0026rdquo;하지 않는다.\n압축을 enable하기 위해서 gzip 지시어를 추가한다. 기본적으로 NGINX는 응답을 text/html MIME type으로만 압축한다.\ngzip on;  다른 MINE type 응답을 압축하기 위해선 gzip_types 지시어를 추가하고 추가적인 type 리스트를 적는다.\ngzip_types text/plain application/x-javascript text/xml text/css application/xml application/javascript;  압축 할 응답의 최소 길이를 지정하기 위해서는 gzip_min_length 지시어을 사용한다. default는 20 byte다. 작은 크기의 파일은 압축되지 않도록 10kb로 설정했다.\ngzip_min_length 10240;  NGINX는 기본적으로 프록시 서버에서 오는 요청에 대한 응답은 압축하지 않는다(요청의 Via 헤더 필드가 있는지 여부에 따라 프록시 서버에서 오는 요청인지 결정된다).\nNginx1 -\u0026gt; Nginx2 -\u0026gt; Upstream Server의 구조일 때, Via 헤더가 자동으로 추가되지 않는다. 따라서 Nginx1에서 아래와 같이 셋팅해주면 Nginx2에서는 gzip설정이 on 되어 있어도 패스한다. Via 헤더의 유무가 중요하다. 헤더 value는 어떤 값이라도 상관없다.\nproxy_set_header Via '10.xx.xx.xx';  주의 : 아래와 같이 add_header를 사용하면 response 헤더에 추가되기 때문에 의도한대로 동작하지 않는다.\nadd_header Via '10.xx.xx.xx';  이러한 응답의 압축을 설정하기 위해서는 gzip_proxied 지시어를 사용한다. gzip_proxied 지시어는 NGINX가 압축해야 하는 프록시된 요청의 종류를 지정하는 여러가지 파라미터가 있다. 예를 들어 프록시 서버에 캐시되지 않는 요청에만 응답을 압축하는 것이 합리적이다.\n이를 위해 gzip_proxied 지시어는 NGINX가 응답의 Cache-Control 헤더 필드를 확인하고 값이 no-cache, no-store 또는 private 인 경우 응답을 압축하도록 지시하는 파라미터를 포함한다. 또한 expired 파라미터를 포함시켜 만료 헤더 필드의 값을 확인해야한다. 이러한 파라미터는 Authorization 헤더 필드가 있는지 확인하는 auth 파라미터와 함께 다음 예제에서 설정된다(인증 된 응답은 최종 사용자에게 고유하며 일반적으로 캐시되지 않는다).\ngzip_proxied no-cache no-store private expired auth;  대부분의 다른 지시어와 마찬가지로 압축을 구성하는 지시어는 http context or server or location configuration block에 포함될 수 있다.\ngzip_http_version 1.1  압축이 필요한 HTTP Request의 최소 버전이다. 디폴트는 1.1이다.\nNginx1 -\u0026gt; Nginx2 -\u0026gt; Upstream Server의 구조일 때, Nginx proxy_http_version 디폴트는 1.0이기 때문에 proxy_http_version 을 1.1로 명시하거나, gzip_http_version 을 1.0으로 명시해야 한다.\ngzip_vary 옵션을 키면 response headers에 Vary: Accept-Encoding이 추가적으로 나온다.\ngzip_vary on;  Vary 헤더를 이해하기 위해서는 먼저 내용 협상(Content-negotiation)에 대한 이해가 필요하다.\n종종 하나의 URL이 여러 리소스에 대응해야 할 경우가 있다. 콘텐츠를 여러 언어로 제공하려고 하는 웹 사이트의 예를 들어보자. 사용자에 맞게 서버가 알아서 영어나 프랑스어로 제공할 수 있도록 HTTP는 내용 협상(Content-negotiation) 방법을 제공한다. 여기서는 서로 다른 버전(영어인지 프랑스어인지)을 배리언트(variant)라고 부른다\n내용 협상 기법은 3가지가 있다(클라이언트 주도 협상, 서버 주도 협상, 투명 협상). 클라이언트 주도 협상은 클라이언트가 요청을 보내면, 서버는 클라이언트에게 선택지를 보내주고, 클라이언트가 선택한다. 서버 입장에서는 구현하기 가장 쉽고 클라이언트도 최선의 선택을 할 수 있지만 최소 두 번의 요청으로 인해 대기시간이 길어질 수 밖에 없다.\n서버 주도협상은 서버가 어떤 페이지를 돌려줄 것인지 결정하게 하는것이다. 그러나 이렇게 하려면 클라이언트는 반드시 자신의 무엇을 선호하는지에 대한 충분한 정보를 서버에게 주어서 서버가 현명한 결정을 할 수 있게 해주어야 한다. 서버는 이 정보를 클라이언트의 요청 헤더에서 얻는다.\nHTTP 서버가 클라이언트에게 보내줄 적절한 응답을 계산하기 위해 사용하는 메커니즘은 다음 두 가지다. - 내용 협상 헤더들을 살펴본다. 서버는 클라이언트의 Accept 관련 헤더들을 들여다보고 그에 알맞은 응답 헤더를 준비한다. - 내용 협상 헤더 외의 다른 헤더들을 살펴본다. 예를 들어, 서버는 클라이언트의 User-Agent 헤더에 기반하여 응답을 보내줄 수도 있다.\n내용 협상 헤더\nAccept : 서버가 어떤 미디어 타입으로 보내도 되는지 알려준다. Accept-Language : 서버가 어떤 언어로 보내도 되는지 알려준다.\nAccept-Charset : 서버가 어떤 charset으로 보내도 되는지 알려준다.\nAccept-Encoding : 서버가 어떤 인코딩으로 보내도 되는지 알려준다.\n이 헤더들이 엔터티 헤더들과 비슷함에 주목하라. 그러나 이 두 종류의 헤더는 서로 분명한 차이가 있다 엔터티 헤더는 선적 화물에 붙이는 라벨과 비슷하다. 그들은 메시지를 서버에서 클라이언트로 전송할 때 필요한 메시지 본문의 속성을 가리킨다.\n엔터티 헤더\nContent-Type\nContent-Language\nContent-Encoding\n한편 내용 협상 헤더들은 클라이언트와 서버가 선호 정보를 서로 교환하고 문서들의 여러 버전 중 하나를 선택하는 것을 도와, 클라이언트의 선호에 가장 잘 맞는 문서를 제공해 주기 위한 목적으로 사용된다.\n내용 협상 헤더의 품질값\nHTTP 프로토콜은 클라이언트가 각 선호의 카테고리마다 여러 선택 가능한 항목을 선호도와 함께 나열할 수 있도록 품질값을 정의하였다. 예를 들어, 클라이언트는 Accept-Language 헤더를 다음과 같은 형식으로 보낼 수 있다.\nAccept-Language: en;q=0.5, fr;q=0.0, nl;q=1.0, tr;q=0.0  q값은 0.0부터 1.0까지의 값을 가질 수 있다(0.0이 가장 낮은 선호도, 1.0이 가장 높은 선호도를 의미한다). 따라서 위의 헤더는 클라이언트가 네덜란드어(nl)로 된 문서를 받기를 원하고 있으나, 영어(en)로 된 문서라도 받아들일 것임을 의미하고 있다. 그러나 어떠한 경우에도 클라이언트는 프랑스어(fr)나 터키어(tr) 버전을 원하지는 않는다.\n그 외의 헤더들에 의해 결정\n서버는 또한 User-Agent와 같은 클라이언트의 다른 요청 헤더들을 이용해 알맞은 요청을 만들어내려고 시도할 수 있다. 예를 들어 서버가 오래된 버전의 웹브라우저는 자바스크립트를 지원하지 않는다는 것을 알고 있다면, 그들에게는 자바스크립트를 포함하지 않은 페이지를 돌려줄 수도 있다.\n이 사례에서 \u0026lsquo;최선\u0026rsquo;에 가장 가까운 대응을 찾아낼 수 있는 q값 메커니즘은 없다. 서버는 정확한 대응을 찾아내거나 아니면 그냥 갖고 있는 것을 제공해주어야 한다.\n캐시는 반드시 캐시된 문서의 올바른 \u0026lsquo;최선의\u0026rsquo; 버전을 제공해주려 해야 하기 때문에, HTTP 프로토콜은 서버가 응답에 넣어 보낼 수 있는 Vary 헤더를 정의한다. Vary 헤더는 캐시에게(그리고 클라이언트나 그 외의 모든 다운스트림 프락시에게) 서버가 내줄 응답의 최선의 버전을 결정하기 위해 어떤 요청 헤더를 참고하고 있는지 말해준다.\nHTTP Vary 응답 헤더는 서버가 문서를 선택하거나 커스텀 콘텐츠를 생성할 때 고려한 클라이언트 요청 헤더 모두(일반적인 내용 협상 헤더 외에 추가로 더해서)를 나열한다. 예를 들어, 제공된 문서가 User-Agent 헤더에 의존한다면, Vary 헤더는 반드시 \u0026ldquo;User-Agent\u0026rdquo;를 포함해야 한다.\n새 요청이 도착했을 때, 캐시는 내용 협상 헤더들을 이용해 가장 잘 맞는 것을 찾는다. 그러나 캐시가 문서를 클라이언트에게 제공해 줄 수 있게 되기 전에, 캐시는 반드시 캐시된 응답 안에 서버가 보낸 Vary 헤더가 들어있는지 확인해야 한다. 만약 Vary 헤더가 존재한다면, 그 Vary 헤더가 명시하고 있는 헤더들은 새 요청과 오래된 캐시된 요청에서 그 값이 서로 맞아야만 한다. 왜냐하면 서버는 클라이언트의 요청 헤더에 따라 그들의 응답이 달라질 수 있기 때문이다.\n만약 서버의 Vary 헤더가 이렇다면, 거대한 수의 다른 User-Aget와 Cookie 값이 많은 배리언트(variant)를 만들어 낼 것이다\nVary: User-Agent, Cookie  캐시는 각 배리언트마다 알맞은 문서 버전을 저장해야 한다. 캐시가 검색을 할 때, 먼저 내용 협상 헤더로 적합한 콘텐츠를 맞춰보고, 다음에 요청의 배리언트를 캐시된 배리언트와 맞춰본다. 만약 맞는 것이 없으면, 캐시는 문서를 서버에서 가져온다.\n참고 : HTTP 완벽가이드 17장 내용 협상과 트랜스코딩\ngzip 압축의 전체 구성은 다음과 같다.\ngzip on; gzip_vary on; gzip_comp_level 5; gzip_min_length 10240; gzip_proxied expired no-cache no-store private auth; gzip_types text/plain application/x-javascript text/xml text/css application/xml application/javascript;  gzip_comp_level 5;  5는 크기와 CPU 사용량간에 완벽한 절충안으로, 대부분의 ASCII 파일 (레벨 9와 거의 동일)에 대해 약 75 %의 감소를 제공한다(기본값 : 1).\nhttps://github.com/h5bp/server-configs-nginx/blob/master/nginx.conf\n추가적으로 ie 6이하는 gzip 옵션이 제공 되지 않으므로 disable 시킬 수도 있다. gzip_disable 옵션에서 정규표현식으로 비활성화 시킬 수 있는데 \u0026ldquo;User-Agent\u0026rdquo;헤더에서 일치하는 것에 국한된다.\ngzip_disable \u0026quot;MSIE [1-6]\\.\u0026quot;;  참고 : https://www.nginx.com/resources/admin-guide/compression-and-decompression/#intro\n"
},
{
	"uri": "/specification_by_example/",
	"title": "specification by example",
	"tags": [],
	"description": "",
	"content": " 전통적으로 올바른 제품을 만들려면 방대한 기능 명세, 문서화, 그리고 오랜 기간에 걸친 테스트 단계가 필요했다. 하지만 요즘처럼 주 단위로 SW를 출시하는 시대에는 이런 방법이 통하지 않는다. 따라서 다음과 같은 해결책이 필요하다.\n 지나친 명세화는 피한다. 실제 개발에 들어가기도 전에 변경될지도 모르는 세부 사항을 정의하느라 시간을 허비하지 않는다. 시스템이 수행하는 내용을 설명하는 신뢰할 만한 문서를 만든다. 그러면 시스템을 쉽게 변경할 수 있다. 명세에 정의된 대로 시스템이 실행되는지 효율적으로 점검한다. 최소한의 유지보수 비용으로 문서를 적절하고 신뢰할 수 있게 유지한다. 앞으로 수행해야 할 작업에 관한 정보를 적기에 공급할 수 있게 모든 것을 짧은 이터레이션과 흐름 기반의 프로세스에 맞춘다.  그리고 프로젝트에서 공통적으로 발견한, SW를 만드는 좋은 방법 중 하나는 바로 예제를 활용한 명세다.\n\u0026lsquo;예제를 활용한 명세\u0026rsquo;의 이점 1. 변경 작업의 효율화 - \u0026lsquo;living documentation’을 활용 2. 재작업 감소 3. 더 나은 업무 배치\n명세 정제하기 협업 과정에서 이뤄지는 열린 토로은 모두가 도메인을 이해하는 데 기여하지만 그 결과로 나온 예제는 종종 필요 이상으로 자세히 작성되곤 한다. 이를테면, 비지니스 사용자는 사용자 인터페이스의 관점에서 생각해서 링크를 클릭하거나 입력 필드에 뭔가를 입력했을 때 시스템이 어떻게 동작할지를 예제로 제공한다. 이 같은 장황한 설명은 시스템을 제한하는데, 필요한 바가 무엇인가가 아닌 뭔가가 어떻게 작동해야 하는가를 상세하게 밝히는 것은 낭비이기 때문이다. 불필요하게 상세하게 작성된 예제는 이해하기도 어렵고 의사소통에 사용하기도 힘들다. cf) \u0026lsquo;기능 회귀’란 이전에 제대로 동작하던 기능에 문제가 생기는 경우를 말한다. 이러한 현상은 변경 과정에서 의도치 않게 발생한다. 이 같은 현상을 막기 위해 회귀 테스트를 수행하는데, 회귀 테스트는 이전에 실행했던 테스트를 재실행하는 방식으로 수행한다.\n리빙 도큐멘테이션 예제를 활용한 명세의 프로세스와 산출물을 살펴볼 수 있는 두 가지 대중적인 모델이 있다. 하나는 \u0026lsquo;인수 테스트 중심 모델\u0026rsquo;이고 다른 하나는 \u0026lsquo;시스템 행위 명세 모델’이다. ‘인수 테스트 중심 모델’은 예제를 활용한 명세 프로세스에서 테스트 자동화 부분에 초점을 맞춘다. 이 모델의 주요 이점은 개발 목표가 분명해지고 기능 회귀가 예방된다는 것이다. ‘시스템 행위 명세 명세 모델’은 시스템의 동작하는 시나리오를 명세화하는 프로세스에 초점을 맞춘다. 이 모델은 협업을 통해 명세를 명확하게 함으로써 이해관계자와 개발팀이 동일하게 이해하는 데 중점을 둔다. 더불어 테스트 자동화를 통해 기능 회귀를 예방하는 것을 중요시한다. 실행된 테스트와 테스트의 목적을 함께 나열하면 회귀 테스트 실패를 조사하는 일이 쉬워진다. (테스트의 목적을 이해할 수 있기 때문에 문제를 더욱 쉽게 해결할 수 있는 것이다) 변화의 시작 품질 향상에 집중하라\n프로세스 변화에 대해 저항할 것이 우려되는 경우, 품질 향상을 위한 공개적인 활동에는 크게 불평하지 않는다. 개발자와 테스터가 긴밀히 협업하지 않는 상태에서 인수품질에 대한 이견이 있을 경우 제품 출시와 관련된 활동을 가시화하는 것이 유용할 수 있다.\n기능 테스트 자동화부터 시작하라\n단지 업무를 떠넘기는 것 아닌가? 개발자가 테스트 자동화에 참여함으로써 테스터의 시간적 여유가 생긴다는 것에 대한 대표적인 반대 의견은 프로그래머가 일을 더하게 되어 기능 개발이 늦어진다는 것이다. 사실 업계의 일반적인 추세는 테스터보다 개발자가 더 많은 팀의 경우 테스터의 업무를 개발자에게 넘기는 것이 그리 나쁘지 않을뿐더러 프로세스의 병목을 제거할 수 있다는 것이다. 시스템에서 가장 위험 요소가 많은 부분부터 자동화를 시작한다.\n레거시 시스템 전체에 자동화 테스트를 적용하려는 것은 헛된 노력에 불과하다. 실행 가능한 명세로 나아가기 위한 한 단계로서 기능적 테스트 자동화를 이용한다면 테스트 자동화의 가치를 보여주고 도구에 익숙할 정도만 자동화해도 충분하다. 그 후 변경을 위해 실행 가능한 명세를 구현하기 시작하면 점점 테스트 커버리지가 올라갈 것이다. 초기 기능 테스트 자동화를 최대한 활용하려면 문제가 일어났을 때 많은 비용이 발생할 수 있는 시스템의 위험 요소를 자동화하는 데 초점을 둔다. 그곳에서 발생하는 문제를 예방하는 것은 즉시 가치를 입증할 것이다. 기능 테스트 커버리지가 높다면 팀은 더 확신을 가질 수 있을 것이다. 위험이 덜한 부분을 자동화해서 얻는 효과는 주목받지 못한다. 도구에 집착하지 마라\n예제를 활용한 명세는 프로그래머 중심이 아니며, 프로그래머만이 도구를 활용한다면 지속되기 어렵다. 이러한 접근법은 기술적이고 개발자 중심의 테스트를 관리하기 위해 프로그래머가 실행 가능한 명세를 위한 비기술적인 도구를 사용하는 것으로 끝나는 경우가 많다. 이것은 시간 낭비다. 도구에서 얻을 수 있는 이점을 분석하고 가장 쉽게 이점을 누릴 수 있는 방법을 모색해라.\n목표에서 범위 도출하기 성공적인 팀은 프로젝트 범위(제품이나 서비스의 기능을 제공하기 위해 수행해야 하는 업무)를 정의하는 책임을 다른 사람에게 떠넘기는 대신 주도적으로 행동하고 적절한 범위를 결정하기 위해 비즈니스 사용자와 협업해서 목표를 달성한다. 이것이 목표에서 범위를 도출하는 핵심이다. 시스템의 기대 결과에서 시작해 범위를 도출하는 방식은 BDD 커뮤니티에서 나온 아이디어다. 그 아이디어는 공통의 문제를 제기할 수 있다는 점에서 최근 많은 주목을 받고 있다. \u0026lsquo;~로서 ~위해 ~가 필요하다. \u0026lsquo;\n기술적인 기능 명세를 그대로 사용하는 대신 그 기능이 어디에 유용한지 상위 수준의 예를 요청해야 한다. 그러면 실제 문제를 알 수 있다. 그 기능이 유용한 예를 물어보는 것이 좀 더 나은 방법이라고 생각한다. 그것이 왜 필요하냐고 묻는 것은 다소 도전적으로 보여서 다른 사람을 방어적으로 만들 수 있고 특히 규모가 큰 조직일수록 더욱 그렇다. 어떤 기능이 어디에 유용한지를 묻는 것은 누군가의 권위에 도전하지 않고도 논의를 시작하는 데 도움이 된다.\n"
},
{
	"uri": "/what__why__how_living_documentation/",
	"title": "what why how living_documentation",
	"tags": [],
	"description": "",
	"content": " What is living documentation 원문 : http://searchsoftwarequality.techtarget.com/definition/living-documentation\n\u0026lsquo;living documentation\u0026rsquo; 은 정보들을 정확하고 이해하기 쉽게 제공하는, 시스템 documentation 의 동적인 방법이다. 자연어로 쓰여진 feature 파일은 코어로써 \u0026lsquo;living documentation’을 돕는다. 각각의 파일은 한 단위의 코드가 어떻게 수행하도록 가정하고, 예제를 줘서 원하는 결과를 설명한다. 그 documentation은 논리적 관점에서 시스템의 원하는 동작을 설명한다. 그래서 비지니스 이해관계자들은 쉽게 확인하고 리뷰할 수 있다. 개발자들은 그들의 프로그램에 뭐가 필요한지 돕는 정보로, 가능한 최소한의 코드를 추가하면서 사용할 수 있다. 테스터들은 documentation을 통해 새로운 테스트를 만들고 테스트 결과가 요구사항들을 만족시키는지 확인할 수 있다. Operation은 진행중인 유지보수 작업을 보조하는 정보로 사용된다.\n\u0026lsquo;living documentation’ 접근은 보통 behavior-driven-development(BDD)와 specification by example(SBE)와 함께한다. 이러한 방법론들과 함께, \u0026lsquo;실행 가능한 명세\u0026rsquo; 예를 들어 ‘automated acceptance tests’ 는 종종 문서의 역할을 하도록 하는 방식으로 작성된다. ‘자동화 테스트’ 는 정기적으로 실행되기 때문에 SW의 변화는 \u0026lsquo;living documentation’ 의 변화를 필요로 한다. 따라서 이러한 방식의 테스팅과정이, 관련된 문서가 항상 최신이라는 것을 보장한다.\ncf) Specification by Example에서 ‘living documentation’ 시스템이 변경될 때 문서에도 그러한 변경사항이 즉시 반영될 수 있는 문서 즉, 실행 가능한 문서를 지칭한다. 오랫동안 업데이트되지 않아서 쓸모 없게 된 문서가 아니라, 항상 최신 상태가 유지되어 신뢰할 수 있을 뿐더러 언제나 사용하고 실행해볼 수 있는 문서를 의미한다.\nWhy You should write living documentation 원문 : http://blog.mojotech.com/why-you-should-write-living-documentation/\n이글을 읽는 당신이 SW 개발자라면 빨리 ‘코드 원숭이’ 라는걸 깨닫길 바란다. 만약 아니라면 당신은 자연어로 쓰여진 프로세스의 상세한 설명과, 컴퓨터가 이해 할 수 있는 프로그래밍 언어 간의 변환이 될것이다. 다음과 같은 상황을 고려해봐라. 종종 우리는 구현해야 되는 feature에 대한 막연한 명세만 갖고 시작할때가 있다. 그럴 때 feature가 정확히 무엇에 관해서인지, 왜 필요한지 그리고 어떻게 사용되는지를 이해하기 위해 몇몇 사람들과 얘기를 나눠야된다.(먼저 누구랑 얘기를 나눌지부터 결정하고) 이런 일이 발생할 때 우리는 무엇이 진짜 문제인지를 이해하기 위해 해결책으로부터 거슬러 올라가서 볼 필요가 있다. 이때 원래 의도된 해결책을 평가할 수 있는 능력을 얻게 된다.\n당신이 요구사항을 갖고 있고 그 feature를 만들어야된다면, 원래의 solution-problem을 포함해서 가능한한 각각의 solution들을 고려해야한다. 다음과 같은 질문을 하라. - input이 무엇인가? 어떤 일이 일어나야 되는가? corner case의 경우가 있는가? - 새로운 feature는 어떻게 기존 애플리케이션과 통합되는가? - 기존 기능에 어떻게 영향을 끼치는가? 얼마나 복잡한가? - 얼마나 사이즈가 큰가? - 성능에 문제가 있는가? - 마지막으로 이러한 질문들이 문제에 중요한가?\n많이 들어본 얘기인가? 여기 또 다른 들어본 얘기가 있다.\n“None of this involves writing code.”\n지금 이 과정은 문제 해결의 필수 요소인 생각과 의사소통에 대한 것이지 코드에 관한 것이 아니다. 우리는 단순 SW 개발자가 아니라 problem solver 이다. 사실 우리는 코드를 전혀 쓰지 않기로 하면서 우리의 문제를 해결한다(저자는 그게 최고의 해결책이라고 주장한다).\nTO DOCUMENT, OR NOT TO DOCUMENT\n당신이 빛을 아직 보지 못한 사람이라고 해보자. 그런데 당신은 빛을 생각해내야 하는 문제에 있다. 어떻게 할 것인가? 아마 해결책에 도달할때까지 빛을 생각해보고, 스케치를 해보고, 써보는걸 반복할 것이다. 그렇게 해서 나온 output은 어떻게 될까? 그냥 무시하는가? 아니면 당신이 사용하는 프로젝트 계획 도구에 묻혀 두고 구현을 시작하는가? 아마 당신은 코드가 디자인이라고 믿을 것이다.\n코드가 디자인인가? 그렇기도 하고 아니기도 하다.\n먼저 이론적으로 코드는 디자인 될 수 있고 동작하는 애플리케이션에 필요한 모든 것이며, 애플리케이션이 어떻게 동작하는지 이해하기 위한 것이다. 하지만 코드는 어떻게 동작하는지만 알려줄 뿐이다. 코드는 ‘왜 그렇게 동작해야되는지 실제로 어떻게 동작하도록 되어 있는지’를 말해주지 않는다. 그래서 코드가 디자인이라고 해도 그것만으로는 부족하다.\n두 번째로, 새로운 애플리케이션을 만드는 사람들에 대해서 생각해보자.(혹은 오랜 시간이 지난 애플리케이션 코드를 볼 때) 단순히 코드를 보는 것만으로는 전체적으로 무슨 일을 하는건지 파악하기 쉽지 않다. 그건 마치 기계가 어떻게 동작하는지 알기 위해 부품 하나하나를 보면서 이해하려고 하는 것과 같다. 이론적으론 가능하나 시간이 오래 걸린다.\n그래서 저자는 documentation이 유용하다라는걸 동의하길 희망한다. 그러나 우리는 모두 documentation이 어떻게 될지 알고 있다. 시간이 지날수록 documentation의 가치는 떨어진다. 계속 최신화해주지 않으면 부식된다. 더 큰 문제는 개발자에게 잘못된 정보를 줄 가능성이 있어서 documentation이 없느니만 못한 결과를 초래하게 된다.\nLIVING DOCUMENTATION\nLiving documentation은 테스트들로 이뤄진 documentation이다. 이러한 이유 때문에 Living documentation은 기존의 documentation처럼 시간이 지날수록 구식이 되긴 힘들다. 아래의 예제는 유명한 Living documentation 도구인 큐컴버에 의해 실행된 것이다.\nFeature: Photo display A photography site is all about photos, and the bigger they are, the better. If we limit the text content, we can use the entire background area to show a single photo. Due to time constraints, we're not building a dedicated photo gallery yet, but we must give people a chance to see more photos, using a very simple navigation system that uses \u0026quot;back\u0026quot; and \u0026quot;forward\u0026quot; links, like a manually activated slideshow. Scenario: photo shown on the homepage When a visitor visits the homepage multiple times Then they should see a different photo each time Scenario: photo navigation When a visitor is looking at a photo Then they can choose to see the photo that follows it And they can choose to see the photo that precedes it Scenario: photo navigation beyond last photo When a visitor tries to see the photo that comes after the last photo Then they should be shown the first photo in the slideshow instead ...  이것들은 living documentation의 일반적인 컴포넌트들이다. - feature 이름 - quick overview : 왜 feature가 있는지, 해결한 문제가 뭔지, 어떤 대안들을 찾아봤는지 등등 - 몇몇 사람들은 잘 알려진 스토리 포맷을 사용한다. “As a \u0026hellip; I want to \u0026hellip; so tht \u0026hellip;” 또 어떤 사람들은 자유로운 포맷을 선호한다. - 시나리오들은 약간의 정해진 포맷으로 작성된다.(각각의 라인은 반드시 Given, When, Then, And, But 중 하나로 시작해야 된다.)\n위 documentation에 그 어떤 코드도 없다는걸 알아챘는가? 완벽하게 자연어로 작성된, 읽을수 있는 문서이기 때문에 이해 관계자(stakeholders)들 또한 볼수 있다. 하지만 무엇보다도 팀 동료들이 읽을 수 있다. 잘 정제된 이러한 documentation은 애플리케이션이 무엇을, 그리고 왜 하는지에 대한 이해를 기본으로 한다. 팀 공통 용어집을 정의하는데, 그리고 이전에 까먹었던 기능을 호출하는데 사용해라. 또 PDF로 출력해서 새로운 팀 동료가 읽게 해라.\nWHY NOT USE A LIGHWEIGHT SPEC FRAMEWORK TO WRITE THE DOCUMENTATION?\nspec framework(예를 들어, RSpec, Capybara’s feature DSL)을 사용할 수 있지만 몇 가지 단점이 있다. 아래의 문서를 보자.\nGherkin 버전\nFeature: Background picture display Scenario: show random background picture When a visitor visits the page multiple times Then they see a different background picture each time  RSpec 버전\ndescribe \u0026quot;Background picture display\u0026quot; do context \u0026quot;When a visitor visits the page multiple times\u0026quot; it \u0026quot;They see a different background picture each time\u0026quot; do end end end  첫 번째와 두 번째의 몇 가지 중요한 차이점들이 있다. 먼저 Gherkin 버전은 RSpec 보다 덜 지저분하다. ‘Feature:’와 ’Scenario:’ 키워드가 있고 들여쓰기가 있다. 반대로 RSpec 버전은 닫는 인용구가 필요하고 3개의 다른 키워드(describe, context, it)를 사용한다.\n둘째, 지금은 코드에 대해서 생각하는 시간이 아니다! 오롯이 비지니스 규칙에만 집중해야한다. 당신은 다시 쓰면서 생각을 명확히 하길 원하기 때문에, 몇 단계를 거쳐서 도메인에 더 잘 맞는 용어로 바꿀것이다. RSpec 예제의 딱딱한 구조는 더 어렵게 만들고 있다. 텍스트는 코드보다 조작하기도 쉽다.\n셋째, 읽기 힘들다. 코드와 비지니스 규칙 설명이 혼재되어 있다. 당신이 비지니스 규칙 부분만 추출하고 싶어도 할 수 없다.\n결론\n이 글에서 저자는 코드에서 한걸음 물러나서 더 상위 레벨 이슈에 대해 생각해보는것을 원했다. 이후의 글에서는 완벽한 예제를 가지고 living documentation에 대해서 더 깊이있게 살펴본 후 더 나은 workflow를 제안할 예정이다. 인간이 쓰는 언어보다 더 강력한 것은 없다. 이걸 사용해라!\n"
},
{
	"uri": "/%E1%84%80%E1%85%A2%E1%86%A8%E1%84%8E%E1%85%A6%E1%84%8C%E1%85%B5%E1%84%92%E1%85%A3%E1%86%BC%E1%84%80%E1%85%AA_%E1%84%83%E1%85%B5%E1%84%8C%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AB%E1%84%91%E1%85%A2%E1%84%90%E1%85%A5%E1%86%AB/",
	"title": "객체지향과 디자인패턴",
	"tags": [],
	"description": "",
	"content": " 서비스 로케이터 로버트 C 마틴은 소프트웨어를 두 개의 영역으로 구분해서 설명하고 있는데, 한 영역은 고수준 정책 및 저수준 구현을 포함한 애플리케이션 영역이고 또 다른 영역은 애플리케이션이 동작하도록 각 객체들을 연결해 주는 메인 영역이다. 본 장에서는 애플리케이션 영역과 메인 영역에 대해 살펴보고, 메인 영역에서 객체를 연결하기 위해 사용되는 방법인 DI와 서비스 로케이터에 대해 알아보자. JobQueue와 Transcoder는 변화되는 부분을 추상화한 인터페이스로서, 다른 코드에 영향을 주지 않으면서 확장할 수 있는 구조를 갖고 있다.(OCP) 따라서 Worker 클래스는 이들 콘크리트 클래스에 의존하지 않는다.\nWorker 클래스는 JobQueue에 저장된 객체로부터 JobData를 가져와 Transcoder를 이용해서 작업을 실행하는 책임이 있다.\npublic class Worker { public void run(){ JobQueue jobQueue = ...;// JobQueue를 구한다.  Transcoder transcoder = ...; // Transcoder를 구한다.  boolean someRunningCondition = true; while(someRunningCondition){ JobData jobData = jobQueue.getJob(); transcoder.transcode(jobData.getSource(), jobData.getTarget()); } } } Worker가 제대로 동작하려면 JobQueue나 Transcoder를 구현한 클래스의 객체가 필요하다. 비슷하게 JobCLI 클래스도 JobQueue에 작업 데이터를 넣어야 하는데, 이를 수행하려면 JobQueue를 구현한 객체를 구해야 한다.\n이를 위해 Locator라는 객체를 사용하기로 했다고 해보자.\npublic class Locator { private static Locator instance; public static Locator getInstance(){ return instance; } public static void init(Locator locator){ instance = locator; } private JobQueue jobQueue; private Transcoder transcoder; public Locator(JobQueue jobQueue, Transcoder transcoder){ this.jobQueue = jobQueue; this.transcoder = transcoder; } public JobQueue getJobQueue(){ return jobQueue; } public Transcoder getTranscoder(){ return transcoder; } }public class Worker { public void run(){ JobQueue jobQueue = Locator.getInstance().getJobQueue(); Transcoder transcoder = Locator.getInstance().getTranscoder(); boolean someRunningCondition = true; while(someRunningCondition){ JobData jobData = jobQueue.getJob(); transcoder.transcode(jobData.getSource(), jobData.getTarget()); } } } public class JobCLI { public void interact(){ JobQueue jobQueue = Locator.getInstance().getJobQueue(); File source = new File(\u0026#34;test.txt\u0026#34;); File target = new File(\u0026#34;test2.txt\u0026#34;); jobQueue.addJob(new JobData(source,target)); } } 여기서 질문이 발생한다. 그렇다면 과연 누가 Locator 객체를 초기화 해줄 것인가? 그리고 JobCLI 객체와 Worker 객체를 생성하고 실행해 주는 건 누구인가?\n드디어 메인 영역이 출현할 차례가 되었다. 메인 영역은 다음 작업을 수행한다. 1. 애플리케이션 영역에서 사용될 객체를 생성한다. 2. 각 객체 간의 의존 관계를 설정한다. 3. 애플리케이션을 실행한다.\npublic class MainTest { public static void main(String[] args) { JobQueue jobQueue = new FileJobQueue(); Transcoder transcoder = new FfmpegTranscoder(); Locator locator = new Locator(jobQueue, transcoder); Locator.init(locator); final Worker worker = new Worker(); Thread t = new Thread(new Runnable() { @Override public void run() { worker.run(); } }); JobCLI cli = new JobCLI(); cli.interact(); } } 사용할 객체를 제공하는 책임을 갖는 객체를 서비스 로케이터라고 부른다.\n프로그램 개발 환경이나 사용하는 프레임워크의 제약으로 인해 DI 패턴을 적용할 수 없는 경우가 있다. 예를 들어 안드로이드 플랫폼의 경우는 화면을 생성할 때 Activity 클래스를 상속받도록 하고 있는데, 이 때 안드로이드 실행환경은 정해진 메서드만을 호출할 뿐, 안드로이드 프레임워크가 DI 처리를 위한 방법을 제공하지는 않는다. 따라서 의존 객체를 찾는 다른 방법인 서비스 로케이터를 살펴보자.\n서비스 로케이터를 구현하는 방법은 다양하게 존재할 수 있는데, 본 장에서는 객체 등록 방식의 구현 방법과 상속을 통한 구현 방법에 대해 알아볼 것이다.\n객체 등록 방식의 구현\n// 생성자를 이용해서 객체를 등록 받는 서비스 로케이터 구현 public class ServiceLocator { private JobQueue jobQueue; private Transcoder transcoder; public ServiceLocator(JobQueue jobQueue, Transcoder transcoder){ this.jobQueue = jobQueue; this.transcoder = transcoder; } public JobQueue getJobQueue(){ return jobQueue; } public Transcoder getTranscoder(){ return transcoder; } //서비스 로케이터 접근 위한 static 메서드  private static ServiceLocator instance; public static void load(ServiceLocator locator){ ServiceLocator.instance = locator; } public static ServiceLocator getInstance(){ return instance; } }// 메인 영역에서 서비스 로케이터에 객체 등록 public static void main(String[] args){ //의존 객체 생성  FileJobQueue jobQueue = new FileJobQueue(); FfmpegTranscoder transcoder = new FfmpegTranscoder(); //서비스 로케이터 초기화  ServiceLocator locator = new ServiceLocator(jobQueue, transcoder); ServiceLocator.load(locator); //애플리케이션 코드 실행  Worker worker = new Worker(); JobCLI jobCli = new JobCLI(); jobCli.interact(); }public class Worker { public void run(){ //서비스 로케이터 이용해서 의존 객체 구함  ServiceLocator locator = ServiceLocator.getInstance(); JobQueue jobQueue = locator.getJobQueue(); Transcoder transcoder = locator.getTranscoder(); boolean someRunningCondition = true; while(someRunningCondition){ JobData jobData = jobQueue.getJob(); transcoder.transcode(jobData.getSource(), jobData.getTarget()); } } } 그런데 서비스 로케이터가 제공할 객체 종류가 많을 경우, 서비스 로케이터 객체를 생성할 때 한번에 모든 객체를 전달하는 것은 코드 가독성을 떨어뜨릴 수 있다. 이런 경우에는 각 객체마다 별도의 등록 메서드를 제공하는 방식을 취해서 서비스 로케이터 초기화 부분의 가독성을 높여줄 수 있다.\n// 객체마다 등록 메서드를 따로 제공하는 방식 public class ServiceLocator { private JobQueue jobQueue; private Transcoder transcoder; public void setTranscoder(Transcoder transcoder) { this.transcoder = transcoder; } public void setJobQueue(JobQueue jobQueue) { this.jobQueue = jobQueue; } public JobQueue getJobQueue(){ return jobQueue; } public Transcoder getTranscoder(){ return transcoder; } //서비스 로케이터 접근 위한 static 메서드  private static ServiceLocator instance; public static void load(ServiceLocator locator){ ServiceLocator.instance = locator; } public static ServiceLocator getInstance(){ return instance; } } 객체를 등록하는 방식의 장점은 서비스 로케이터 구현이 쉽다는 점이다. 하지만 서비스 로케이터에 객체를 등록하는 인터페이스가 노출되어 있기 때문에 애플리케이션 영역에서 얼마든지 의존 객체를 바꿀 수 있다.\npublic class Worker{ public void run(){ //고수준 모듈에서 저수준 모듈에 직접 접근하는 걸 유도할 수 있음  ServiceLocator oldLocator = ServiceLocator.getInstance(); ServiceLocator newLocator = new ServiceLocator( //DIP 위반  new DbJobQueue(), oldLocator.getTranscoder()); } } 상속을 통한 구현 객체를 구하는 추상 메서드를 제공하는 상위 타입 구현 상위 타입을 상속받은 하위 타입에서 사용할 객체 설정\n// 상속 방식 서비스 로케이터 구현의 상위 타입 public abstract class ServiceLocator { public abstract JobQueue getJobQueue(); public abstract Transcoder getTranscoder(); protected ServiceLocator(){ if(instance != null) throw new IllegalStateException(\u0026#34;이미 있어\u0026#34;); ServiceLocator.instance = this; } private static ServiceLocator instance; public static ServiceLocator getInstance(){ return instance; } } ServiceLocator가 추상 클래스라는 것은 이 클래스를 상속받아 추상 메서드의 구현을 제공하는 클래스가 필요하다는 뜻이다.\npublic class MyServiceLocator extends ServiceLocator{ private FileJobQueue jobQueue; private FfmpegTranscoder transcoder; public MyServiceLocator() { super(); this.jobQueue = new FileJobQueue(); this.transcoder = new FfmpegTranscoder(); } @Override public JobQueue getJobQueue() { return jobQueue; } @Override public Transcoder getTranscoder() { return transcoder; } } 서비스 로케이터의 단점은 인터페이스 분리 원칙을 위반한다는 점이다. 예를 들어 JobCLI 클래스가 사용하는 타입은 JobQueue 뿐인데, ServiceLocator를 사용함으로써 Transcoder 타입에 대한 의존이 함께 발생하게 된다.\npublic class JobCLI { public void interact(){ ... //ServiceLocator의 인터페이스 변경 시 영향을 받을 수 있음  JobQueue jobQueue = ServiceLocator.getInstance().getJobQueue(); } } 서비스 로케이터를 사용하는 코드가 많아질수록 이런 문제가 배로 발생하게 된다. 이 문제를 해결하려면 의존 객체마다 서비스 로케이터를 작성해 주어야 한다. 이 방법은 의존 객체 별로 서비스 로케이터 인터페이스가 분리되는 효과는 얻을 수 있지만, 다음 코드 처럼 동일한 구조의 서비스 로케이터 클래스를 중복해서 만드는 문제를 야기할 수 있다.\n// 타입만 다르고 구조가 완전히 같은 Locator 클래스들 public class JobQueueLocator{ private JobQueue jobQueue; public void setJobQueue(JobQueue jobQueue){ this.jobQueue = jobQueue; } public JobQueue getJobQueue(){ return jobQueue; } private static JobQueueLocator instance; public static void load(JobQueueLocator locator){ JobQueueLocator.instance = locator; } public static JobQueueLocator getInstance(){ return instance; } } // TranscoderLocator는 JobQueueLocator와 동일하다 public class TranscoderLocator{ private Transcoder transcoder; public void setTranscoder(Transcoder transcoder){ this.transcoder = transcoder; } public Transcoder getTranscoder(){ return transcoder; } // 동일 패턴 코드 } 이런 중복된 코드를 무조건 피해야 하는데, 제네릭을 사용한 서비스 로케이터는 중복을 피하면서 인터페이스를 분리한 것과 같은 효과를 낼 수 있다.\npublic class ServiceLocator { private static Map\u0026lt;Class\u0026lt;?\u0026gt;, Object\u0026gt; objectMap = new HashMap\u0026lt;\u0026gt;(); public static \u0026lt;T\u0026gt; T get(Class\u0026lt;T\u0026gt; klass){ return (T) objectMap.get(klass); } public static void regist(Class\u0026lt;?\u0026gt; klass, Object obj){ objectMap.put(klass,obj); } } 메인 영역에서는 ServiceLocator.regist() 메서드를 이용해서 객체를 등록해 준다.\nServiceLocator.regist(JobQueue.class, new FileJobQueue()); ServiceLocator.regist(Transcoder.class, new FfmpegTranscoder()); ServiceLocator를 사용하는 코드는 다음과 같이 코드를 작성하게 된다.\n// JobQueue에만 의존 JobQueue jobQueue = ServiceLocator.get(JobQueue.class); 서비스 로케이터의 가장 큰 단점은 동일 타입의 객체가 다수 필요할 경우, 각 객체 별로 제공 메서드를 만들어 주어야 한다는 점이다. 예를 들어, FileJobQueue 객체와 DbJobQueue 객체가 서로 다른 부분에 함께 사용되어야 한다면, 이 경우 ServiceLocator는 다음과 같이 두 개의 메서드를 제공해야 한다.\npublic class ServiceLocator{ public JobQueue getJobQueue1() { ... } public JobQueue getJobQueue2() { ... } } 1,2를 붙이는게 맘에 안들지만 그렇다고 메서드 이름에 File이나 Db라는 단어를 붙이는 것도 안된다. 콘크리트 클래스에 직접 의존하는 것과 동일한 효과를 발생시키기 때문이다. 결론은 부득이한 상황이 아니라면 서비스 로케이터보다는 DI를 사용하자.\n옵저버(Observer) 패턴 StatusChecker는 시스템의 상태가 불안정해지면 이 사실을 SmsSender, MessageSender, EmailSender 객체에게 알려주는데, 여기서 핵심은 상태가 변경될 때 정해지지 않은 임의의 객체에게 변경 사실을 알려준다는 점이다. 이렇게 한 객체의 상태 변화를 정해지지 않은 여러 다른 객체에 통지하고 싶을 때 사용되는 패턴이 옵저버 패턴이다.\n옵저버 패턴에는 크게 주제(subject) 객체와 옵저버 객체가 등장하는데, 주제 객체는 다음의 두 가지 책임을 갖는다. 1. 옵저버 목록을 관리하고, 옵저버를 등록하고 제거할 수 있는 메서드를 제공한다. 2. 상태의 변경이 발생하면 등록된 옵저버에 변경 내역을 알린다. notifyStatus() 메서드가, 등록된 옵저버 객체의 onAbnormalStatus() 메서드를 호출한다.\npublic class StatusSubject { private List\u0026lt;StatusObserver\u0026gt; observers = new ArrayList\u0026lt;\u0026gt;(); public void add(StatusObserver observer){ observers.add(observer); } public void remove(StatusObserver observer){ observers.remove(observer); } public void notifyStatus(Status status){ for(StatusObserver observer : observers){ observer.onAbnormalStatus(status); } } } Status의 상태 변경을 알려야 하는 StatusChecker 클래스는 StatusSubject 클래스를 상속받아 구현한다.\n// 옵저버에게 통지가 필요한 콘크리트 클래스의 구현 public class StatusChecker extends StatusSubject{ public void check(){ Status status = loadStatus(); if(status.isNotNormal()) { super.notifyStatus(status); } } private Status loadStatus(){ Status status = new Status(); return status; } } StatusChecker 클래스는 비정상 상태가 감지되면 상위 클래스의 notifyStatus() 메서드를 호출해서 등록된 옵저버 객체들에 상태 값을 전달한다.\n주제 객체의 상태에 변화가 생길 때 그 내용을 통지받도록 하려면 옵저버 객체를 주제 객체에 등록해 주어야 한다.\npublic class ObserverMain { public static void main(String[] args) { StatusChecker statusChecker = new StatusChecker(); statusChecker.add(new StatusEmailSender()); statusChecker.add(new StatusMessageSender()); statusChecker.add(new StatusSmsSender()); statusChecker.check(); } } 옵저버 패턴을 적용할 때의 장점은 주제 클래스 변경 없이 상태 변경을 통지 받을 옵저버를 추가할 수 있다는 점이다.\n옵저버 패턴이 가장 많이 사용되는 영역을 꼽으라면 GUI 프로그래밍 영역일 것이다. 버튼이 눌릴 때 로그인 기능을 호출한다고 할 때, 버튼이 주제 객체가 되고 로그인 모듈을 호출하는 객체가 옵저버가 된다.\n예를 들어 안드로이드에서는 다음과 같이 OnClickListener 타입의 객체를 Button 객체에 등록하는데, 이때 OnClickListener 인터페이스가 옵저버 인터페이스가 된다.\npublic class MyActivity extends Activity implements View.OnClickListener{ public void onCreate(Bundle savedInstanceState){ super.onCreate(savedInstanceState); setContentView(R.layout.main); … Button loginButton = getViewById(R.id.main_loginbtn); loginButton.setOnClickListener(this); } @Override public void onClick(View v){ login(id, password); } } 한 개의 옵저버 객체를 여러 주체 객체에 등록할 수도 있을 것이다. GUI 프로그래밍을 하면 이런 상황이 흔하게 발생한다.\npublic class MyActivity extends Activity implements View.OnClickListener{ public void onCreate(Bundle savedInstanceState){ super.onCreate(savedInstanceState); setContentView(R.layout.main); … // 두 개의 버튼에 동일한 OnClickListener 객체 등록  Button loginButton = (Button) findViewById(R.id.main_loginbtn); loginButton.setOnClickListener(this); Button logoutButton = (Button) findViewById(R.id.main_logoutbtn); logoutButton.setOnClickListener(this); } @Override public void onClick(View v){ //주제 객체를 구분할 수 있는 방법 필요  if(v.getId() == R.id.main_loginbtn) login(id, password); else if(v.getId() == R.id.main_logoutbtn) logout(); } } 앞서 StatusChecker 예제나 안드로이드 예제는 모두 주제 객체를 위한 추상 타입을 제공하고 있다. 예를 들어, StatusChecker는 상위 타입인 StatusSubject 추상 클래스가 존재하고 안드로이드의 Button 클래스의 상위 타입은 View가 존재한다. 둘 모두 옵저버 객체를 관리하기 위한 기능을 제공한다는 공통점이 있다.\n// StatusChecker 클래스 public void add(StatusObserver observer) { … } // View 클래스 public void setOnClickListener(OnClickListener o) { … } 리스코프 치환 원칙 리스코프 치환 원칙은 OCP을 받쳐 주는 다형성에 관한 원칙을 제공한다. 리스코프 치환 원칙은 다음과 같다. 상위 타입의 객체를 하위 타입의 객체로 치환해도 상위 타입을 사용하는 프로그램은 정상적으로 동작해야 한다.\npublic void someMethod(SuperClass sc){ sc.someMethod(); } someMethod()는 상위 타입인 SuperClass 타입의 객체를 사용하고 있는데, 이 메서드에 다음과 같이 하위 타입의 객체를 전달해도 someMethod()가 정상적으로 동작해야 한다는 것이 리스코프 치환 원칙이다. someMethod(new SubClass());\n리스코프 치환 원칙을 지키지 않을 때의 문제점 리스코프 치환 원칙을 설명할 때 자주 사용되는 대표적인 예가 직사각형 - 정사각형 문제이다.\npublic class Rectangle{ private int width; private int height; public void setWidth(int width){ this.width = width; } public void setHeight(int height){ this.height = hight; } public int getWidth(){ return width; } public int getHeight(){ return height; } } 정사각형을 직사각형의 특수한 경우로 보고 정사각형이 직사각형을 상속받도록 구현했다고 하자. 정사각형은 가로, 세로 길이가 모두 동일해야 하기 때문에 setWidth() 메서드와 setHeight() 메서드를 재정의해서 가로, 세로 값이 일치되도록 구현하였다.\npublic class Square extends Rectangle{ @Override public void setWidth(int width){ super.setWidth(width); super.setHeight(width); } @Override public void setHeight(int height){ super.setWidth(height); super.setHeight(height); } } 이제 Rectangle 클래스를 사용하는 코드를 살펴보자. 이 코드는 높이와 폭을 비교해서 높이를 더 길게 만들어 주는 기능을 제공한다고 해보자.\npublic void increaseHeight(Rectangle rec){ if(rec.getHeight() \u0026lt;= rec.getWidth()){ rec.setHeight(rec.getWidth() + 10); } } increaseHeight() 메서드를 사용하는 코드는 메서드 실행 후에 width 보다 height의 값이 더 크다고 가정할 것이다. 그런데 increaseHeight() 메서드의 rec 파라미터로 Square 객체가 전달되면, 이 가정은 깨진다. Square의 setHeight() 메서드는 높이와 폭을 모두 같은 값으로 만들어 버리기 때문에 increaseHeight() 메서드를 실행하더라도 높이가 폭보다 길어지지 않게 된다.\npublic void increaseHeight(Rectangle rec){ if(rec instanceof Square) throw new CantSupportSquareException(); if(rec.getHeight() \u0026lt;= rec.getWidth()) rec.setHeight(rec.getWidth() + 10); } 이 문제를 해소하기 위해 rec 파라미터의 실제 타입이 Square일 경우를 막는 instanceof 연산자를 사용할 수 있을 것이다. 하지만 instanceof 연산자를 사용한다는 것 자체가 리스코프 치환 원칙 위반이 되고 이는 increaseHeight() 메서드가 Rectangle의 확장에 열려 있지 않다는 것을 뜻한다.\n리스코프 치환 원칙을 어기는 또 다른 흔한 예는 상위 타입에서 지정한 리턴 값의 범위에 해당되지 않는 값을 리턴하는 것이다. 예를 들어, 입력 스트림으로부터 데이터를 읽어와 출력 스트림에 복사해 주는 복사 기능은 다음과 같이 구현될 것이다.\npublic class CopyUtil { public static void copy(InputStream is, OutputStream out){ byte[] data = new byte[512]; int len = -1; //InputStream.read() 메서드는 스트림의 끝에 도달하면 -1을 리턴  while((len = is.read(data)) != -1){ out.write(data,0,len); } } } InputStream의 read() 메서드는 스트림의 끝에 도달해서 더 이상 데이터를 읽어올 수 없을 경우 -1을 리턴한다고 정의되어 있고, CopyUtil.copy() 메서드는 이 규칙에 따라 is.read()의 리턴 값이 -1이 아닐 때까지 반복해서 데이터를읽어와 out에 쓴다. 그런데 만약 InputStream을 상속한 하위 타입에서 read() 메서드를 아래와 같이 구현하면 어떻게 될까?\npublic class SatanInputStream implements InputStream{ public int read(byte[] data){ ... return 0; // 데이터가 없을 때 0을 리턴하도록 구현  } } SatanInputStream의 read() 메서드는 데이터가 없을 때 0을 리턴하도록 구현했다. SatanInputStream 클래스의 사용자는 SatanInputStream 객체로부터 데이터를 읽어 와서 파일에 저장하기 위해 다음과 같이 CopyUtil.copy() 메서드를 사용할 수 있을 것이다.\nInputStream is = new SatanInputStream(someData); OutputStream out = new FileOutputStream(filePath); CopyUtil.copy(is,out); 이렇게 되면 CopyUtil.copy() 메서드는 무한루프에 빠지게 된다. 왜냐하면 SatanInputStream의 read() 메서드는 데이터가 없더라도 -1을 리턴하지 않기 때문이다.\npublic class CopyUtil{ public static void copy(InputStream is, OutputStream out){ ... // is가 SatanInputStream인 경우 read() 메서드는 -1을 리턴하지 않으므로, 아래 코드는 무한루프가 된다.  while((len = is.read(data)) != -1){ out.write(data,0,len); } } } 정리하면 위와 같은 문제가 발생하는 이유는 SatanInputStream 타입의 객체가 상위 타입인 InputStream을 올바르게 대체하지 않기 때문이다. 즉, 리스코프 치환 원칙을 지키지 않았기 때문에 문제가 발생한 것이다.\n리스코프 치환 원칙은 확장에 대한 것이다. 리스코프 치환 원칙을 어기면 OCP를 어길 가능성이 높아진다. 상품에 쿠폰을 적용해서 할인되는 액수 구하는 기능 예를 살펴보자.\npublic class Coupon{ public int calculateDiscountAmount(Item item){ return item.getPrice() * discountRate; } } 이 코드에서 Coupon 클래스의 calculateDiscountAmount() 메서드는 Item 클래스의 getPrice() 메서드를 이용해서 할인될 값을 구하고 있다. 그런데 특수 Item은 무조건 할인을 해주지 않는 정책이 추가되어, 이를 위해 Item 클래스를 상속받는 SpecialItem 클래스를 추가했다고 하자.\npublic class Coupon{ public int calculateDiscountAmount(Item item){ if(item instanceof SpecialItem) return 0; return item.getPrice() * discountRate; } } Item 타입을 사용하는 코드(위 예제에서는 calculateDiscountAmount 메서드)는 SpecialItem 타입이 존재하는지 알 필요 없이 오직 Item 타입만 사용해야 한다. 그런데 instanceof 연산자를 통해 SpecialItem 타입인지의 여부를 확인하고있다. 즉, 하위타입인 SpecialItem이 상위 타입인 Item을 완벽하게 대체하지 못하는 상황이 발생하고 있는 것이다.\n타입을 확인하는 기능을 사용한다는 것은 클라이언트가 상위 타입만을 사용해서 프로그래밍 할 수 없다는 것을 뜻하며, 이는 하위 타입이 상위 타입을 대체할 수 없다는 것을 의미한다. 즉, instanceof 연산자를 사용한다는 것 자체가 리스코프 치환 원칙 위반이 된다.\n위의 예제 같은 경우는 Item에 대한 추상화가 덜 되었기 때문에 리스코프 치환 원칙을 어기게 됐다. 따라서 상품의 가격 할인 가능 여부가 Item 및 그 하위 타입에서 변화되는 부분이며, 변화되는 부분을 Item 클래스에 추가함으로써 리스코프 치환 원칙을 지킬 수 있게 된다.\npublic class Item{ //변화되는 기능을 상위 타입에 추가  public boolean isDiscountAvailable(){ return true; } } public class SpecialItem extends Item{ @Override public boolean isDiscountAvailable(){ return false; } } 이렇게 변화되는 부분을 상위 타입에 추가함으로써, instanceof 연산자를 사용하던 코드를 Item 클래스만 사용하도록 구현할 수 있게 되었다.\npublic class Coupon{ public int calculateDiscountAmount(Item item){ if(!item.isDiscountAvailable()) return 0; return item.getPrice() * discountRate; } } Null 객체 패턴 장기 고객 할인이라든가 신규 고객 할인과 같이 고객의 상태에 따라 특별 할인을 해준다고 가정해 보자. 사용 요금 명세서를 생성하는 기능은 아래 코드와 같이 명세서 상세 내역에 특별 할인 기능을 추가할 수 있을 것이다.\npublic Bill createBill(Customer customer) { Bill bill = new Bill(); //... 사용 내역 추가  bill.addItem(new Item(\u0026#34;기본 사용요금\u0026#34;, price)); bill.addItem(new Item(\u0026#34;할부금\u0026#34;, somePrice)); // 특별 할인 내역 추가  SpecialDiscount specialDiscount = specialDiscountFactory.create(customer); if (specialDiscount != null) { // 특별 할인 대상인 경우만 처리  specialDiscount.addDetailTo(bill); } } 고객에 따라 특별 할인이 없는 경우도 있기 때문에, 위 코드에서는 specialDiscount가 null이 아닌 경우에만 특별 할인 내역을 추가하도록 했다. null 검사 코드를 사용할 때의 단점은 개발자가 null 검사 코드를 빼 먹기 쉽다는 점이다.\nNull 객체 패턴은 null을 리턴하지 않고 null을 대신할 객체를 리턴함으로써 null 검사 코드를 없앨 수 있도록 한다.\npublic class NullSpecialDiscount extends SpecialDiscount { @Override public void addDetailTo(Bill bill) { // 아무 것도 하지 않음  } } Null 객체 패턴은 위와 같이 null 대신 사용될 클래스를 구현한다. 이 클래스는 상위 타입을 상속받으며, 아무 기능도 수행하지 않는다.\npublic class SpecialDiscountFactory { public SpecialDiscount create(Customer customer) { if (checkNewCustomer(customer)) return new NewCustomerSpecialDiscount(); //특별 할인 혜택이 없을 때, null 대신 NullSpecialDiscount 객체 리턴  return new NullSpecialDiscount(); } } 그리고 위와 같이 null을 대체할 클래스의 객체를 리턴한다.\npublic Bill createBill(Customer customer) { Bill bill = new Bill(); //... 사용 내역 추가  bill.addItem(new Item(\u0026#34;기본 사용요금\u0026#34;, price)); bill.addItem(new Item(\u0026#34;할부금\u0026#34;, somePrice)); // 특별 할인 내역 추가  SpecialDiscount specialDiscount = specialDiscountFactory.create(customer); specialDiscount.addDetailTo(bill); // null 검사 불필요 } 이제 SpecialDiscountFactory.create() 메서드를 이용해서 특별 할인 내역을 처리하는 코드는 더 이상 null 검사를 할 필요가 없어진다.\nNull 객체 패턴의 장점은 null 검사 코드를 사용할 필요가 없기 때문에 코드가 간결해진다는 점이다. 코드가 간결해진다는 것은 그 만큼 코드 가독성을 높여 주므로, 향후에 코드 수정을 보다 쉽게 만들어 준다.\n"
},
{
	"uri": "/%E1%84%80%E1%85%A2%E1%86%A8%E1%84%8E%E1%85%A6%E1%84%8C%E1%85%B5%E1%84%92%E1%85%A3%E1%86%BC%E1%84%8B%E1%85%B4_%E1%84%89%E1%85%A1%E1%84%89%E1%85%B5%E1%86%AF%E1%84%80%E1%85%AA_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%A2/",
	"title": "객체지향의 사실과 오해",
	"tags": [],
	"description": "",
	"content": " 동일한 요청에 대해 서로 다른 방식으로 응답할 수 있는 능력을 다형성이라고 한다.\n객체란 인간이 분명하게 인지하고 구별할 수 있는 물리적인 또는 개념적인 경계를 지닌 어떤 것이다.\n상태 행동 식별자 ‘상태’는 특정 시점에 객체가 가지고 있는 정보의 집합으로 객체의 구조적 특징을 표현한다. 객체의 상태는 객체에 존재하는 정적인 프로퍼티와 동적인 프로퍼티 값으로 구성된다. 객체의 프로퍼티는 단순한 값과 다른 객체를 참조하는 링크로 구분할 수 있다.\n상태를 외부에 노출시키지 않고 행동을 경계로 캡슐화하는 것은 결과적으로 객체의 자율성을 높인다.\n‘행동’이란 외부의 요청 또는 수신된 메시지에 응답하기 위해 동작하고 반응하는 활동이다. 행동의 결과로 객체는 자신의 상태를 변경하거나 다른 객체에게 메시지를 전달할 수 있다. 객체는 행동을 통해 다른 객체와의 협력에 참여하므로 행동은 외부에 가시적이어야 한다.\n객체에 접근할 수 있는 유일한 방법은 객체가 제공하는 행동뿐이다. 따라서 행동을 통해서만 상태에 접근할 수 있다는 점은 객체의 캡슐화를 강조한다.\n상태를 먼저 결정하고 행동을 나중에 결정하는 방법은 설계에 나쁜 영향을 끼친다. 훌륭한 객체를 만들기 위해서는 상태가 아니라 행동에 초점을 맞춰야 한다. 즉, 행동이 상태를 결정한다.\n값과 객체의 가장 큰 차이점은 값은 식별자를 가지지 않지만 객체는 식별자를 가진다는 점이다. 값은 오직 상태만을 이용해 동등성을 판단하기 때문에 인스턴스를 구별하기 위한 별도의 식별자를 필요로 하지 않는다. 하지만 객체는 시간에 따라 변경되는 상태를 포함하며, 행동을 통해 상태를 변경한다. 따라서 식별자를 이용한 동일성 검사를 통해 두 인스턴스를 비교할 수 있다.\n객체지향이란 현실 세계의 모방,추상화 라고 하는데 그 안에는 현실 세계를 모방해서 단순화한다는 의미가 숨어 있다. 그러나 객체지향 세계는 현실 세계의 단순한 모방이 아니다. 그렇다면 현실 속의 객체와 소프트웨어 객체 사이의 가장 큰 차이점은 무엇일까? 그것은 현실 속에서는 수동적인 존재가 소프트웨어 객체로 구현될 때는 능동적으로 변한다는 것이다(ex 음료 객체의 수량 상태의 변화는 음료 객체가 책임진다). 객체지향의 세계에서 모든 객체는 자신의 상태를 스스로 관리하는 자율적인 존재다.\n추상화  목적에 맞게 현실을 분해하고 단순화하는 전략 불필요한 부분을 무시함으로써 현실에 존재하는 복잡성을 극복하는것 추상화의 수준, 이익 가치는 목적에 의존적이다. 알아야하는 사실만 정확하게 표현하고 몰라도 되는 정보는 무시함으로써 이해하기쉽고 단순하며 목적에 부합하는 결과를 도출한다.  이 책에서는 추상화를 다음과 같이 정의한다. 어떤 양상, 세부사항, 구조를 좀 더 명확하게 이해하기 위해 특정 절차나 물체를 의도적으로 생략하거나 감춤으로써 복잡도를 극복하는 방법이다. 복잡성을 다루기 위해 추상화하는 두 차원에서 이뤄진다.\n 구체적인 사물들간의 공통점은 취하고 차이점은 버리는 일반화를 통해 단순하게 만드는 것이다. 중요한 부분을 강조하기 위해 불필요한 세부사항을 제거함으로써 단순하게 만드는것이다.  모든 경우에 추상화의 목적은, 복잡성을 이해하기 쉬운 수준으로 단순화하는 것이라는 점을 기억하라\n객체와 타입 우리는 객체를 일종의 데이터처럼 사용한다. 그렇다면 객체는 데이터인가? 그렇지 않다. 객체에서 중요한 것은 객체의 행동이다. 상태는 행동의 결과로 초래된 부수효과를 쉽게 표현하기 위해 도입한 추상적인 개념일 뿐이다. 객체를 창조할 때 가장 중요하게 고려해야 하는 것은 객체가 이웃하는 객체와 협력하기 위해 어떤 행동을 해야 할지를 결정하는 것이다. 즉, 객체가 협력을 위해 어떤 책임을 지녀야 하는지를 결정하는 것이 객체지향 설계의 핵심이다.\n클래스 객체지향 프로그래밍 언어에서 정적인 모델은 클래스를 이용해 구현된다. 따라서 타입을 구현하는 가장 보편적인 방법은 클래스를 이용하는 것이다. 클래스와 타입은 동일한 것이 아니다. 타입은 객체를 분류하기 위해 사용하는 개념이다. 반면 클래스는 단지 타입을 구현할 수 있는 여러 구현 메커니즘 중 하나일 뿐이다.\n객체를 분류하는 기준은 타입이며, 타입을 나누는 기준은 객체가 수행하는 행동이다. 객체를 분류 하기 위해 타입을 결정한 후 프로그래밍 언어를 이용해 타입을 구현할 수 있는 한 가지 방법이 클래스다.\n역할 동일한 역할을 수행할 수 있다는 것은 해당 객체들이 협력 내에서 동일한 책임의 집합을 수행할 수 있다는 것을 의미한다. 동일한 역할을 수행하는 객체들이 동일한 메시지를 수신할 수 있기 때문에 동일한 책임을 수행할 수 있다는 것은 매우 중요한 개념이다.\n객체지향에 대한 선입견 많은 사람들은 시스템에 필요한 데이터를 저장하기 위해 객체가 존재한다고 선입견을 가지고 있다. 그러나 객체가 존재하는 이유는 행위를 수행하며 협력에 참여하기 위해서다. 두 번째 선입견은 객체지향이 클래스와 클래스 간의 관계를 표현하는 시스템의 정적인 측면에 중점을 둔다는 것이다. 클래스는 단지 시스템에 필요한 객체를 표현하고 생성하기 위해 프로그래밍 언어가 제공하는 구현 메커니즘이라는 사실을 기억하라. 객체지향의 핵심은 클래스를 어떻게 구현할 것인가가 아니라 객체가 협력 안에서 어떤 책임과 역할을 수행할 것인지를 결정하는 것이다.\n다형성 서로 다른 객체들이 다형성을 만족시킨다는 것은 객체들이 동일한 책임을 공유한다는 것을 의미한다. 다형성에서 중요한 것은 메시지 송신자의 관점이다. 메시지 수신자들이 동일한 오퍼레이션을 서로 다른 방식으로 처리하더라도 메시지 송신자의 관점에서 이 객체들은 동일한 책임을 수행하는 것이다.\n메시지가 인터페이스를 결정한다. 객체가 다른 객체와 상호작용할 수 있는 유일한 방법은 \u0026lsquo;메시지 전송\u0026rsquo;이다. 따라서 객체의 인터페이스는 객체가 수신할 수 있는 메시지의 목록으로 구성된다.\n도메인 모델링과 유스케이스 도메인 모델이란 사용자가 프로그램을 사용하는 대상 영역에 관한 지식을 선택적으로 단순화하고 의식적으로 구조화한 형태다. 유스케이스는 사용자와 시스템 간의 상호작용을 보여주는 텍스트다. 유스케이스는 다이어그램이 아니다. 다이어그램에 노력을 쏟지 말라. 유스케이스는 하나의 시나리오가 아니라 여러 시나리오들의 집합이다.\n유스케이스는 사용자에게 제공할 기능을 시스템의 책임으로 보게 함으로써 객체 간의 안정적인 구조에 책임을 분배할 수 있는 출발점을 제공한다. 도메인 모델은 기능을 수용하기 위해 은유할 수 있는 안정적인 구조를 제공한다. 책임-주도 설계는 유스케이스로부터 첫 번째 메시지와 사용자가 달성하려는 목표를, 도메인 모델로부터 기능을 수용할 수 있는 안정적인 구조를 제공받아 실제로 동작하는 객체들의 협력 공동체를 창조한다.\n7장 함께 모으기 도메인이란 사용자들이 관심을 가지고 있는 특정분야나 주제를 말하며 SW는 도메인에 존재하는 문제를 해결하기 위해 개발된다.\n객체지향 설계 개념 관점 : 설계는 도메인 안에 존재하는 개념과 개념들 사이에 관계를 표현한다. 명세 관점 : 사용자 영역인 도메인을 벗어나 개발자 영역인 SW로 초점이 옮겨진다. 구현 관점 : 구현 관점의 초점은 객체들이 책임을 수행하는데 필요한 동작하는 코드를 작성하는 것이다.\n이것은 동일한 클래스를 세 가지 다른 방향에서 바라보는 것을 의미한다.\n객체지향 설계의 첫 번째 목표는 훌륭한 객체를 설계하는 것이 아니라 훌륭한 협력을 설계하는 것이다. 협력을 설계할 때는 객체가 메시지를 선택하는 것이 아니라 메시지가 객체를 선택하게 해야 한다.\n상속 프로그래밍 언어를 이용해 일반화와 특수화 관계를 구현하는 가장 일반적인 방법은 클래스 간의 상속을 사용하는 것이다. 일반화의 원칙은 한 타입이 다른 타입의 서브타입이 되기 위해서는 슈퍼 타입에 순응해야 한다는 것인데, 순응에는 구조적인 순응과 행위적인 순응 두 가지 종류가 있다.\n구조적인 순응은 타입의 내연과 관련된 100% 규칙을 의미한다. 즉, 서브타입은 슈퍼타입이 가지고 있는 속성과 연관관계 면에서 100% 일치해야 한다. 예를 들어 Person이 name이라는 속성을 가진다면 Person의 서브타입인 Employee 역시 name이라는 속성을 가질 것이라고 기대할 수 있다.\n행위적인 순응은 타입의 행위에 관한 것이며, 서브타입은 슈퍼타입을 행위적으로 대체 가능해야 한다. 행위적인 순응을 흔히 리스코프 치환 원칙이라고 한다. Person이 getAge()라는 메시지에 대한 응답으로 나이를 반환한다면 서브타입인 Employee 역시 getAge()라는 메시지에 대한 응답으로 나이를 반환해야 한다. 클라이언트 입장에서 Employee는 Person에 대해 행위적으로 순응하기 때문에 대체 가능하다.\n"
},
{
	"uri": "/%E1%84%82%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%87%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF_%E1%84%86%E1%85%A1%E1%86%AB%E1%84%83%E1%85%B3%E1%86%AB_%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF_%E1%84%8C%E1%85%A1%E1%84%87%E1%85%A1%E1%84%91%E1%85%A7%E1%86%AB/",
	"title": "네이버를 만든 기술 자바편",
	"tags": [],
	"description": "",
	"content": " 1. 자바의 날짜와 시간 API 2014년에 최종 배포된 JDK8에는 JSR-310이라는 표준 명세로 날짜와 시간에 대한 새로운 API가 추가됐다. 스프링 프레임워크4.0에서는 JSR-310을 기본으로 지원한다.\npublic class Jsr310Test { @Test public void shouldGetAfterOneDay() { LocalDate theDay = IsoChronology.INSTANCE.date(1582, 10, 4); DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\u0026#34;yyyy.MM.dd\u0026#34;); assertThat(theDay.format(formatter)).isEqualTo(\u0026#34;1582.10.04\u0026#34;); LocalDate nextDay = theDay.plusDays(1); assertThat(nextDay.format(formatter)).isEqualTo(\u0026#34;1582.10.05\u0026#34;); } @Test public void shouldGetAfterOneHour() { ZoneId seoul = ZoneId.of(\u0026#34;Asia/Seoul\u0026#34;); ZonedDateTime theTime = ZonedDateTime.of(1988, 5, 7, 23, 0, 0, 0, seoul); DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\u0026#34;yyyy.MM.dd HH:mm\u0026#34;); assertThat(theTime.format(formatter)).isEqualTo(\u0026#34;1988.05.07 23:00\u0026#34;); ZoneRules seoulRules = seoul.getRules(); assertThat(seoulRules.isDaylightSavings(Instant.from(theTime))).isFalse(); ZonedDateTime after1Hour = theTime.plusHours(1); assertThat(after1Hour.format(formatter)).isEqualTo(\u0026#34;1988.05.08 01:00\u0026#34;); assertThat(seoulRules.isDaylightSavings(Instant.from(after1Hour))).isTrue(); } @Test public void shouldGetAfterOneMinute() { ZoneId seoul = ZoneId.of(\u0026#34;Asia/Seoul\u0026#34;); ZonedDateTime theTime = ZonedDateTime.of(1961, 8, 9, 23, 59, 59, 0, seoul); DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\u0026#34;yyyy.MM.dd HH:mm\u0026#34;); assertThat(theTime.format(formatter)).isEqualTo(\u0026#34;1961.08.09 23:59\u0026#34;); ZonedDateTime after1Minute = theTime.plusMinutes(1); assertThat(after1Minute.format(formatter)).isEqualTo(\u0026#34;1961.08.10 00:30\u0026#34;); } @Test public void shouldGetAfterTwoSecond() { ZoneId utc = ZoneId.of(\u0026#34;UTC\u0026#34;); ZonedDateTime theTime = ZonedDateTime.of(2012, 6, 30, 23, 59, 59, 0, utc); DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\u0026#34;yyyy.MM.dd HH:mm:ss\u0026#34;); assertThat(theTime.format(formatter)).isEqualTo(\u0026#34;2012.06.30 23:59:59\u0026#34;); ZonedDateTime after2Seconds = theTime.plusSeconds(2); assertThat(after2Seconds.format(formatter)).isEqualTo(\u0026#34;2012.07.01 00:00:01\u0026#34;); } @Test(expected=ZoneRulesException.class) public void shouldThrowExceptionWhenWrongTimeZoneId(){ ZoneId.of(\u0026#34;Seoul/Asia\u0026#34;); } @Test public void shouldGetDate() { LocalDate theDay = LocalDate.of(1999, 12, 31); assertThat(theDay.getYear()).isEqualTo(1999); assertThat(theDay.getMonthValue()).isEqualTo(12); assertThat(theDay.getDayOfMonth()).isEqualTo(31); } @Test(expected=DateTimeException.class) public void shouldNotAcceptWrongDate() { LocalDate.of(1999, 13, 31); } @Test public void shouldGetDayOfWeek() { LocalDate theDay = LocalDate.of(2014, 1, 1); DayOfWeek dayOfWeek = theDay.getDayOfWeek(); assertThat(dayOfWeek).isEqualTo(DayOfWeek.WEDNESDAY); } } JDK7에서도 백포트 모듈을 통해 JSR-310을 쓸 수 있다.\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.threeten\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;threetenbp\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.8.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 오늘 날짜 구하기\nLocalDate date = LocalDate.now(); LocalTime time = LocalTime.now(); System.out.println(date.getYear()); System.out.println(date.getMonthValue()); System.out.println(date.getDayOfMonth()); System.out.println(time.getHour()); System.out.println(time.getMinute()); System.out.println(time.getSecond()); 2. 자바의 HashMap은 어떻게 작동하는가? HashMap은 보조 해시 함수를 사용하기 때문에 보조 해시 함수를 사용하지 않는 HashTable에 비해 해시 충돌 발생이 덜하다. 그리고 HashMap은 null을 키로 사용할 수 있다.\n해시 충돌처리\n 개방 주소법(open addressing)  선형탐색법 : 해당 위치가 포화상태면 한자리씩 옮기면서 빈자리 찾아감 2차탐색법 : 해당 위치가 포화상태면 그 자리의 주소 + m^2 값으로 옮기면서 빈자리 찾아감  연쇄방법  합병연쇄 : 빈 버켓에 충돌을 일으키는 레코드를 삽입하고 그 위치를 포인터로서 기억시킴  분리연쇄(seperate chaining) : 각 버켓을 주소로 하는 레코드들을 연결리스트로 연결하고 그 헤드 포인터를 해시 테이블에 저장   자바 HashMap에서 사용하는 방식은 seperate chaining이다. open addressing은 연속된 공간에 데이터를 저장하기 때문에 separate chaining보다 캐시 효율이 높다. 따라서 데이터 개수가 충분히 적다면 open addressing이 separate chaining보다 성능이 더 좋다. 하지만 배열의 크기가 커질수록 캐시 효율이 높다는 open addressing의 장점은 사라진다.\n자바8에서는 데이터 개수가 많아지면 separate chaining에서 연결 리스트 대신 레드블랙 트리를 사용한다. 즉 하나의 해시 버킷에 8개의 키-값 쌍이 모이면 연결리스트를 트리로 변경한다. 만약 해당 버킷에 있는 데이터를 삭제해 개수가 6개에 이르면 다시 연결 리스트로 변경한다.\n보조 해시 함수\nHaspMap은 키-값 쌍 데이터 개수가 일정 개수 이상이면 해시 버킷의 개수를 두배로 늘린다.(버킷의 최대 개수는 2^30개) 그런데 이렇게 해시 버킷 크기를 두 배로 확장하는 것에는 결정적인 문제가 있다. 해시 버킷의 개수 M이 2^a 형태가 되기 때문에 \u0026lsquo;index = X.hashCode() % M\u0026rsquo;을 계산할때 X.hashCode()의 하위 a개의 비트만 사용하게 된다는 것이다. 즉 해시 함수가 32비트 영역을 고르게 사용하도록 만들었다 하더라도 해시 값을 2의 승수로 나누면 해시 충돌이 쉽게 발생할 수 있다. 이 때문에 보조 해시 함수가 필요하다.\n\u0026lsquo;index = X.hashCode() % M\u0026rsquo;을 계산할 때 사용하는 M값은 소수일때 index값의 분포가 가장 균동할 수 있다. 그러나 M값이 소수가 아니기 때문에 별도의 보조 해시 함수를 이용해 index 값 분포가 가급적 균등할 수 있게 해야 한다.\n보조 해시 함수의 목적은 \u0026lsquo;키\u0026rsquo;의 해시 값을 변형해 해시 충돌 가능성을 줄이는 것이다.\nstatic final int hash(Object key){ int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h \u0026gt;\u0026gt;\u0026gt; 16); } 자바 8에서는 자바 5~7과는 다르게 새로운 방식의 보조 해시 함수를 사용하고 있다.\n자바 8의 HashMap 보조 해시 함수는 상위 16비트 값을 XOR로 연산하는 매우 단순한 형태의 보조 해시 함수를 사용한다. 이유는 두가지다. 첫째, 자바 8에서는 해시 충돌이 많이 발생하면 연결 리스트 대신 레드블랙 트리를 사용하므로 해시 충돌 시 발생할 수 있는 성능 문제가 완화됐다. 둘째, 최근 해시 함수는 균등분포가 잘 되게 만들어지는 경향이 있어 자바7까지 사용했던 보조 해시 함수의 효과가 크지 않다. 두번째 이유가 좀 더 결정적인 원인이 되어 자바 8에서 보조 해시 함수 구현을 바꿨다.\nString 객체에 대한 해시 함수\nString 객체의 해시 함수에 31을 사용하는 이유는 31이 소수고 어떤 수에 31을 곱하는 것은 빠르게 계산할 수 있기 때문이다. \u0026lsquo;31N = 32N-N\u0026rsquo;인데, 32는 2^5이니 어떤 수에 대한 32를 곱한 값은 시프트 연산으로 쉽게 구현할 수 있다. 따라서 N에 31을 곱한 값은 (N\u0026lt;\u0026lt;5)-N 과 같다. 31을 곱하는 연산은 이렇게 최적화된 머신 코드로 생성할 수 있기 때문에 String 클래스에서 해시 값을 계산할 때는 31을 승수로 사용한다.\n4. 람다가 이끌어 갈 모던 자바 람다 표현식은 함수를 간결하게 표현한다. 프로그래밍 언어의 개념으로는 단순한 익명 함수 생성 문법이라 이해할만 하다.\n클로저 : 자신을 감싼 영역에 있는 외부 변수에 접근하는 함수다. 클로저에서 접근하는 함수 밖의 변수를 자유 변수라 한다. 이 정의에 따르면 람다 표현식으로 정의한 익명 함수 가운데 일부는 클로저고 일부는 클로저가 아니다.\n자바8 인 액션에서 설명한 클로저 : 원칙적으로 클로저란 함수의 비지역 변수를 자유롭게 참조할 수 있는 함수의 인스턴스를 가리킨다. 예를 들어 클로저를 다른 함수의 인수로 전달할 수 있다. 클로저는 클로저 외부에 정의된 변수의 값에 접근하고, 값을 바꿀수 있다. 자바8의 람다와 익명 클래스는 모두 메서드의 인수로 전달될 수 있으며 자신의 외부 영역의 변수에 접근할 수 있지만 람다가 정의한 메서드의 지역변수 값은 바꿀수 없다.\n람다 표현식의 내부 구현\n자바의 람다는 앞에서 본 다른 JVM 언어가 그랬듯(groovy, scala, kotlin 일부 함수) 익명 클래스의 생성을 축약한 것처럼 보인다. 그러나 람다는 익명 클래스를 생성하지 않는다. 컴파일된 소스 폴더나 역컴파일을 해도 익명 클래스의 흔적은 없다.\n우선 람다 표현식이 익명 클래스가 아니기 때문에 언어를 쓰는 사용자에게 가장 드러나는 차이는 this 키워드의 의미다.\npublic class ThisDifference { //네이버를 만든 기술 - 자바편 p107  public static void main(String[] args) { new ThisDifference().print(); } public void print() { Runnable anonClass = new Runnable() { @Override public void run() { verifyRunnable(this); } }; anonClass.run(); Runnable lambda = () -\u0026gt; verifyRunnable(this); lambda.run(); } private void verifyRunnable(Object obj) { System.out.println(obj.getClass()); } } 결과 class java8.ThisDifference$1 //익명 클래스 class java8.ThisDifference 익명 클래스 내부에서 전달한 this는 Runnable을 구현한 익명 클래스 그 자체인데 반해 람다 표현식을 썼을 때는 익명 클래스가 아닌 것이다. 람다 표현식 안에서 선언한 this의 타입은 이를 생성한 클래스인 ThisDifference다. 익명 클래스 안에서 이를 생성한 객체를 전달하려면 \u0026lsquo;ThisDifference.this\u0026rsquo; 처럼 직접 타입을 지정하면 된다.\n이렇듯 람다 표현식은 익명 클래스와 다르다. 다른 JVM 언어처럼 람다 표현식을 익명 클래스로 바꾸는 것이 적절하고 쉬운 방법으로 보인다. 하지만 익명 클래스로는 매번 새로운 인스턴스를 생성하고 단순한 바이트코드 명세로 표현되지 않는 등의 단점이 있다. 결과적으로 자바8에서 람다 표현식은 invokedynamic이라는 바이트코드로 변환된다.\n원래 invokedynamic은 자바 언어가 아닌 JRuby, Jython, Groovy와 같은 동적 타입 언어를 위한 명세였다. 동적 타입 언어는 컴파일 시점에 타입이 확정되지 않은 메서드를 런타임에 호출할 수 있는데 이를 효율적으로 지원하기 위해 자바7부터 invokedynamic 명세가 포함됐다.\ncf) 람다 표현식을 쓴 코드를 자바6과 자바7에서도 실행 할 수 있도록 컴파일 하는 Retrolambda라는 프로젝트도 있다. 메이븐이나 그래들의 플러그인으로 설정하면 익명 클래스를 생성하는 방식으로 람다 표현식을 컴파일한다. 자바8의 문법을 지원하지 않는 안드로이드 환경에서도 활용할 만하다.\n5. JVM 이해하기 JVM의 역할은 자바 애플리케이션을 클래스 로더를 통해 읽어 들여 자바 API와 함께 실행하는 것이다.\n가상머신이란 프로그램을 실행하기 위해 물리적 머신(컴퓨터)과 유사한 머신을 소프트웨어로 구현한 것이라고 정의한다.\nJVM의 특징\n스택 기반의 가상 머신(대표적인 컴퓨터 아키텍처인 인텔x86 아키텍처나 ARM 아키텍처가 레지스터 기반으로 작동하는데 비해 JVM은 스택 기반으로 작동한다).\n심벌릭 레퍼런스\n가바지 컬렉션\n기본 자료형을 명확하게 정의해 플랫폼 독립성 보장한다(플랫폼에 따라 기본 자료형 크기가 변하지 않는다).\n네트워크 바이트 순서(자바 클래스 파일은 네트워크 바이트 순서를 사용한다).\n안드로이드에 탑재된 달빅 VM은 JVM이긴 하지만 JVM 명세를 따르지 않는다. 스택 머신인 다른 JVM과 달리 달빅 VM은 레지스터 머신이다.\nJVM 구조\n클래스 로더가 컴파일된 자바 바이트코드를 런타임 데이터 영역에 로드하고 실행엔진이 자바 바이트코드를 실행한다.\n클래스 로더 : 자바는 동적코드, 컴파일 타임이 아니라 런타임에 클래스를 처음으로 참조할 때 해당 클래스를 로드하고 링크하는 특징이 있다. 이 동적 코드를 담당하는 부분이 JVM의 클래스 로더다(WAS 제조사마다 조금씩 다른 형태의 계층 구조를 갖고 있다).\n런타임 데이터 영역 : JVM이라는 프로그램이 OS위에서 실행되면서 할당받는 메모리 영역.\nMethod Area와 Heap은 모든 스레드가 공유해서 사용한다.\n실행엔진 : 클래스로더를 통해 JVM내의 런타임 데이터 영역에 배치된 바이트코드는 실행엔진에 의해 실행된다.\n바이트 코드 \u0026ndash;\u0026gt; 기계어\n인터프리터 : 바이트코드 명령어를 하나씩 읽어서 해석하고 실행. 그래서 느려.\nJIT 컴파일러 : 느림을 보완하기 위해 인터프리터 방식으로 실행하다가 적절한 시점에 바이트코드 전체를 컴파일해 네이티브 코드로 변경하고 직접 실행하는 방식(네이티브 코드를 캐시에 보관하기 때문에 빠름).\n한번만 실행되는 코드라면 컴파일 하지 않고 인터프리팅하는게 훨씬 유리\n10. 자바 가비지 컬렉션의 작동과정 stop the world : 가비지컬렉션을 실행하기 위해 JVM이 애플리케이션 실행을 멈추는것.(GC 실행하는 스레드 말고 나머지 스레드 작업 멈춰) GC 튜닝이랑 stop the world 시간을 줄이는것.\n오라클 JVM인 HOTSPOT VM 에서는 물리적 공간을 둘로 나눔\nYoung 영역의 구성\n새로 생성한 대부분의 객체는 Eden에 쌓인다. GC 한번 발생 후 살아남은 객체들은 Survivor로 옮겨가고 가득 차면 비어있는 Survivor로 이동한다. 그리고 가득찼던 Survivor 영역은 아무 데이터도 없는 상태가 된다. 이 과정을 반복하다 계속해서 살아남는 객체는 old 영역으로 이동한다. Survivor 영역 중 하나는 반드시 비어 있는 상태로 남아 있어야 한다. 만약 두 Survivor 영역에 모두 데이터가 존재하거나 두 영역 모두 사용량이 0이라면 시스템이 정상적인 상황이 아니라고 생각하면 된다.\n참고로 HotSpot VM에서는 더욱 빠른 메모리 할당을 위해 두 가지 기술을 사용한다.\nbump the pointer : Eden영역에 할당된 마지막 객체를 추적해서 빠르게 메모리 할당 이루어지게 하는 방법.\nTLABS : 멀티스레드에서는 객체를 Eden에 넣으려면 스레드 세이프하기 위해 락이 발생할 수 밖에 없고, 락으로 인한 경합 때문에 성능이 떨어진다. 이를 해결 하기 위해, 스레드가 각각의 몫에 해당하는 Eden 영역의 작은 덩어리를 가질 수 있게 하는 기술이다.\n간단하게 Young 영역에 대한 GC를 알아봤다. 위에서 이야기한 두 가지 기술(bump the pointer, TLABs)을 반드시 기억하고 있을 필요는 없다. 그러나 Eden 영역에 최초로 객체가 만들어지고, Survivor 영역을 통해 Old 영역으로 오래 살아남은 객체가 이동한다는 사실은 꼭 기억하기 바란다.\nOld 영역 GC(JDK 7기준)\nOld 영역은 기본적으로 데이터가 가득 차면 GC를 실행한다.\n Serial GC : 운영서버에서 사용하면 안된다(데스크톱의 CPU 코어가 하나 만 있을 때 사용하기 위해 만든 방식이다). 이 방식은 mark-sweep-compact라는 알고리즘을 사용한다. 이 알고리즘의 첫 단계는 Old 영역에 살아 있는 객체를 식별(mark)하는 것이다. 그 다음에는 힙(heap)의 앞부분부터 확인해 살아 있는 것만 남긴다(sweep). 마지막 단계에서는 각 객체들이 연속으로 쌓이도록 힙의 맨 앞부분부터 채워서 객체가 존재하는 부분과 객체가 없는 부분으로 나눈다(compact). Serial GC는 적은 메모리와 CPU 코어 개수가 적을 때 적합한 방식이다. Parallel GC : Serial GC와 기본적인 알고리즘은 같다. 그러나 Serial GC가 가비지 컬렉션을 처리하는 스레드가 하나인 것에 비해 Parallel GC는 가비지 컬렉션을 처리하는 스레드가 여러개다. CMS GC : 초기 Initial Mark 단계에서는 클래스 로더에서 가장 가까운 객체 중 살아 있는 객체만 찾는 것으로 끝낸다. 따라서 멈추는 시간이 매우 짧다. 그리고 Concurrent Mark 단계에서는 방금 살아있다고 확인한 객체에서 참조하고 있는 객체를 따라가면서 확인하는데 이 단계의 특징은 다른 스레드가 실행 중인 상태에서 동시에 진행된다는 점이다. 그 다음 Remark 단계에서는 Concurrent Mark 단계에서 새로 추가되거나 참조가 끊긴 객체를 확인한다. 마지막으로 Concurrent Sweep 단계에서는 쓰레기를 정리하는 작업을 실행한다. 이 작업도 다른 스레드가 실행되고 있는 상황에서 진행한다. 이러한 단계로 진행되기 때문에 stop the world 시간이 매우 짧지만 다른 GC 방식보다 메모리와 CPU를 더 많이 사용하고 Compaction 단계가 기본적으로 제공되지 않는다. 따라서 조각난 메모리가 많아 Compaction 작업을 실행하면 오히려 stop the world 시간이 길어지기 때문에 신중하게 사용해야 한다.\n G1 GC : 바둑판의 각 영역에 객체를 할당하고 GC를 실행. 그러다가 해당 영역이 꽉 차면 다른 영역에 객체를 할당하고 GC를 실행한다. Young-\u0026gt;Old로 가는 이동단계가 사라진 방식\n  자바7부터 공식적으로 사용하게 된 G1 GC는 기존의 GC 개념을 획기적으로 발전시켜 놓았다. G1 GC는 멀티 프로세서 환경에서 대용량의 메모리가 사용되는 현대 애플리케이션을 목표로 새롭게 개발된 GC 메커니즘으로 간단히 말해 메모리 영역을 작은 단위(Region)로 나눠 CMS를 수행한다. 즉, 작은 영역별로 나뉘어진 메모리에 병렬로 GC를 수행해 지연이 최소화된 최적의 중단 없는 고성능 자바 실행 환경을 제공한다.\n13. 자바의 Reference 클래스와 가비지 컬렉션 자바의 가비지 컬렉터는 작동 방식에 따라 종류가 다양하지만 공통적으로 크게 다음 두 가지 작업을 실행한다고 볼 수 있다. 1. 힙(heap) 내의 객체 중에서 가비지(garbage)를 찾아낸다. 2. 찾아낸 가비지를 처리해 힙의 메모리를 회수한다.\n최초 버전의 자바는 이러한 가비지 컬렉션 작업에 사용자 코드가 관여하지 않도록 구현됐다. 하지만 JDK1.2부터는 java.lang.ref 패키지를 추가해 제한적이나마 사용자 코드와 가비지 컬렉터가 상호작용할 수 있게 했다.\njava.lang.ref 패키지는 전형적인 객체 참조인 strong reference 외에도 soft reference, weak reference, phantom reference라는 3가지 새로운 참조 방식을 각 Reference 클래스로 제공한다. 이 3가지 Reference 클래스를 애플리케이션에 사용하면 가비지 컬렉션에 일정 부분 관여할 수 있고, LRU(least recently used) 캐시같이 특별한 작업을 하는 애플리케이션을 더 쉽게 작성 할 수 있다.\n가비지 컬렉션과 접근 가능성\n가비지 컬렉터는 객체가 가비지인지 판별하기 위해 접근 가능성(reachability)이라는 개념을 사용한다. 어떤 객체에 유효한 참조가 있으면 접근 가능한(reachable) 상태로, 유효한 참조가 없으면 접근 불가능한(unreachable) 상태로 구별하고, 접근 불가능한 객체를 가비지로 간주해 가비지 컬렉션을 실행한다. 한 객체는 여러 다른 객체를 참조하고 참조된 다른 객체도 마찬가지로 또 다른 객체를 참조할 수 있으므로 객체들은 참조 사슬을 이룬다. 이런 상황에서 유효한 참조 여부를 파악하려면 항상 유효한 최초의 참조가 있어야 하는데 이를 객체 참조의 루트 세트(root set)라 한다.\nJVM에서 런타임 데이터 영역의 구조를 단순화하면 위와 같다. 런타임 데이터 영역은 스레드가 차지하는 영역과 객체를 생성 및 보관하는 하나의 큰 힙 영역, 클래스 정보가 차지하는 메서드 영역으로 크게 3부분으로 나눌 수 있다. 위 그림에서 객체에 대한 참조는 화살표로 표시된다.\n힙에 있는 객체에 대한 참조는 다음 4가지 종류 중 하나다.\n 힙 내의 다른 객체에 의한 참조 자바 스택, 즉 자바 메서드 실행 시 사용하는 지역 변수와 파라미터에 의한 참조 네이티브 스택, 즉 JNI(java native interface)에 의해 생성된 객체에 대한 참조 메서드 영역의 정적 변수에 의한 참조  이들 중 힙 내의 다른 객체에 의한 참조를 제외한 나머지 세 개가 루트 세트로, 접근 가능성을 판가름하는 기준이 된다. 접근 가능성을 더 자세히 설명하기 위해 루트 세트와 힙 내의 객체를 중심으로 다음과 같이 재구성했다.\n위에서 볼 수 있듯이 루트 세트에서 시작한 참조 사슬에 속한 객체는 접근 가능한 객체다. 이 참조 사슬과 무관한 객체가 접근 불가능한 객체로 가비지 컬렉션 대상이다. 오른쪽 아래 객체처럼 접근 가능한 객체를 참조하더라도 다른 접근 가능한 객체가 이 객체를 참조하지 않는다면 이 객체는 접근 불가능한 객체다. 참고로 이 그림에서 참조는 모두 java.lang.ref 패키지를 사용하지 않는 일반적인 참조로 이를 흔히 strong reference라 한다.\nsoft reference, weak reference, phantom reference\njava.lang.ref 패키지는 soft reference, weak reference, phantom reference를 클래스 형태로 제공한다. 예를 들면, java.lang.ref.WeakReference 클래스는 참조 대상인 객체를 캡슐화한 WeakReference 객체를 생성한다.\npublic class WeakReference\u0026lt;T\u0026gt; extends Reference\u0026lt;T\u0026gt; { public WeakReference(T referent) { super(referent); } public WeakReference(T referent, ReferenceQueue\u0026lt;? super T\u0026gt; q) { super(referent, q); } } 이렇게 생성된 WeakReference 객체는 다른 객체와 달리 가비지 컬렉터가 특별하게 취급한다. 캡슐화된 내부 객체는 weak reference에 의해 참조된다.\n다음은 WeakReference 클래스가 객체를 생성하는 예다.\nWeakReference\u0026lt;Sample\u0026gt; wr = new WeakReference\u0026lt;\u0026gt;(new Sample()); Sample ex = wr.get();; ... ex = null; 코드의 첫 번째 줄에서 생성한 WeakReference 클래스의 객체는 new() 메서드로 생성된 Sample 객체를 캡슐화한 것이다. 참조된 Sample 객체는 두 번째 줄에서 get() 메서드를 통해 다른 참조에 대입된다. 이 시점에서는 WeakReference 객체 내의 참조와 ex 참조, 두 개의 참조가 처음 생성된 Sample 객체를 가리킨다.\n앞 코드의 마지막 줄에서 ex 참조에 null을 대입하면 처음 생성한 Sample 객체는 오직 WeakReference 내부에서만 참조된다. 이 상태의 객체를 weakly reachable 객체라고 한다.\n자바 명세에는 SoftReference, WeakReference, PhantomReference라는 3가지 클래스에 의해 생성된 객체를 참조 객체(reference object)라 한다. 이는 흔히 strong reference로 표현되는 일반적인 참조나 다른 클래스의 객체와는 달리 위 3가지 Reference 클래스의 객체에 대해서만 사용하는 용어다. 또한 이들 참조 객체에 의해 참조된 객체는 \u0026lsquo;referent\u0026rsquo;라 한다. 위의 소스 코드에서 new WeakReference() 생성자로 생성된 객체는 참조 객체고, new Sample() 생성자로 생성된 객체는 referent다.\nReference 클래스와 접근 가능성\n원래 가비지 컬렉션 대상인지는 접근 가능성 여부로만 판단했고 이를 사용자 코드에서는 관여할 수 없었다. 그러나 java.lang.ref 패키지를 이용해 접근 가능한 객체를 strongly reachable, softly reachable, weakly reachable, phantomly reachable로 더 자세히 구별해 가비지 컬렉션이 실행될 때의 동작을 다르게 지정할 수 있게 됐다. 다시 말해, 가비지 컬렉션 대상 여부를 판별하는 부분에 사용자 코드가 개입할 수 있게 됐다.\n녹색으로 표시한 중간의 두 객체는 WeakReference로만 참조된 weakly reachable 객체이고, 파란색 객체는 strongly reachable 객체이다. GC가 동작할 때, unreachable 객체뿐만 아니라 weakly reachable 객체도 가비지 객체로 간주되어 메모리에서 회수된다. root set으로부터 시작된 참조 사슬에 포함되어 있음에도 불구하고 GC가 동작할 때 회수되므로, 참조는 가능하지만 반드시 항상 유효할 필요는 없는 LRU 캐시와 같은 임시 객체들을 저장하는 구조를 쉽게 만들 수 있다.\n위 그림에서 WeakReference 객체 자체는 weakly reachable 객체가 아니라 strongly reachable 객체다. 또한 그림에서 A로 표시한 객체와 같이 WeakReference에 의해 참조되면서 동시에 루트 세트에서 시작한 참조 사슬에 포함된 경우에는 weakly reachable 객체가 아니라 strongly reachable 객체다.\n가비지 컬렉터가 작동해 어떤 객체를 weakly reachable 객체로 판명하면 가비지 컬렉터는 WeakReference 객체에 있는 weakly reachable 객체에 대한 참조를 null로 설정한다. 이에 따라 weakly reachable 객체는 접근 불가능한 객체와 마찬가지 상태가 되고, 가비지로 판명된 다른 객체와 함께 메모리 회수 대상이 된다.\n접근 가능성의 세기\n접근 가능성 정도는 가비지 컬렉터가 객체를 처리하는 기준이 되는데, 자바 명세에서는 이를 접근 가능성의 세기(strengths of reachability)라 하고 정도에 따라 5가지 상태로 분류한다.\n strongly reachable : 루트 세트에서 시작해서 어떤 참조 객체도 중간에 끼지 않은 상태로 참조 가능한 상태. softly reachable : strongly reachable 객체가 아닌 객체 중에서 weak reference, phantom reference 없이 soft reference만 통과하는 참조 사슬이 하나라도 있는 상태. weakly reachable : strongly reachable 객체도, softly reachable 객체도 아닌 객체 중에서 phantom reference 없이 weak reference만 통과하는 참조 사슬이 하나라도 있는 상태. phantomly reachable : strongly reachable 객체, softly reachable 객체, weakly reachable 객체 모두 해당되지 않는 상태. 이 상태는 파이널라이즈(finalize)됐지만 아직 메모리가 회수되지 않은 상태다. unreachable : 루트 세트에서 시작되는 참조 사슬로 참조되지 않는 상태  위에서 예로 든 WeakReference 외에도 SoftReference나 PhantomReference 등을 이용해서도 접근 가능성을 지정할 수 있고 이에 따라 각 객체의 가비지 컬렉션 여부는 달라진다. 하나의 객체에 대한 참조의 개수나 참조 형태는 아무런 제한이 없으므로 하나의 객체는 다양한 조합으로 참조될 수 있다.\n가비지 컬렉터는 루트 세트에서 시작해 객체에 대한 모든 경로를 탐색하고 그 경로에 있는 참조 객체를 조사해 그 객체에 대한 접근 가능성을 결정한다. 다양한 참조 관계의 결과 하나의 객체는 앞서 언급한 5가지 접근 가능성 중 하나가 된다.\n위 그림에서 객체 B의 접근 가능성은 softly reachable이다. 루트 세트에서 SoftReference를 통해 B를 참조할 수 있기 때문이다. 만약 루트 세트의 SoftReference에 대한 참조가 없다면 객체 B는 phantomly reachable이 된다.\nsoftly reachable과 SoftReference\nsoftly reachable 객체, 즉 strong reachable이 아니면서 오직 SoftReference 객체로만 참조된 객체는 힙에 남아 있는 메모리 크기와 해당 객체의 사용 빈도에 따라 가비지 컬렉션 여부가 결정된다. 그래서 softly reachable 객체는 weakly reachable 객체와는 달리 가비지 컬렉터가 작동할 때마다 회수되지 않으며 자주 사용될수록 더 오래 살아남는다.\nsoftly reachable 객체를 가비지 컬렉션하기로 결정하면 앞서 설명한 WeakReference 경우와 마찬가지로 참조 사슬에 존재하는 SoftReference 객체 내의 softly reachable 객체에 대한 참조가 null로 설정되며, 이후 이 softly reachable 객체는 접근 불가능한 객체로 취급되어 가비지 컬렉터에 의해 메모리가 회수된다.\nsoftly reachable 객체는 힙에 남아 있는 메모리가 많을수록 회수 가능성이 낮기 때문에 다른 비지니스 로직 객체를 위해 어느 정도 비워 둬야 할 힙 공간이 softly reachable 객체에 의해 일정 부분 점유된다. 따라서 전체 메모리 사용량이 높아지고 가비지 컬렉션이 더 자주 일어나며 가비지 컬렉션에 걸리는 시간도 상대적으로 길어지는 문제가 있다.\nweakly reachable과 WeakReference\nweakly reachable 객체는 특별한 정책에 의해 가비지 컬렉션 여부가 결정되는 softly reachable 객체와는 달리 가비지 컬렉션을 실행할 때마다 회수 대상이 된다. 앞서 설명한 것처럼 WeakReference 내의 참조가 null로 설정되고 weakly reachable 객체는 접근 불가능한 객체와 같은 상태가 돼 가비지 컬렉터에 의해 메모리가 회수된다. 그러나 가비지 컬렉션 알고리즘에 따라 객체 회수 시기가 결정되므로 가비지 컬렉션이 실행될 때마다 메모리까지 회수되지는 않을 수 있다. 이는 softly reachable 객체는 물론 접근 불가능한 객체도 마찬가지다. 가비지 컬렉터가 가비지 컬렉션 대상인 객체를 찾는 작업과 가비지 컬렉션 대상인 객체를 처리해 메모리를 회수하는 작업은 즉각적인 연속 작업이 아니며, 가비지 컬렉션 대상 객체의 메모리를 한 번에 모두 회수하지도 않는다.\nLRU 캐시와 같은 애플리케이션에서는 softly reachable 객체보다는 weakly reachable 객체가 유리하므로 LRU 캐시를 구현할 때는 대체로 WeakReference를 사용한다.\nReferenceQueue\nphantomly reachable 객체의 동작 방식과 PhantomReference를 이해하려면 java.lang.ref 패키지에서 제공하는 ReferenceQueue 클래스를 알아야 한다.\n앞서 SoftReference 객체나 WeakReference 객체가 참조하는 객체가 가비지 컬렉션 대상이 되면 SoftReference 객체와 WeakReference 객체 내의 참조는 null로 설정된다고 설명했다. 이때 SoftReference 객체와 WeakReference 객체 자체는 ReferenceQueue의 큐에 추가된다.\nReferenceQueue의 큐에 추가하는 작업은 가비지 컬렉터에 의해 자동으로 실행된다. ReferenceQueue의 poll() 메서드나 remove() 메서드를 이용해 ReferenceQueue에 이들 참조 객체가 큐에 추가됐는지 확인하면 softly reachable 객체나 weakly reachable 객체의 가비지 컬렉션 여부를 파악할 수 있고, 이에 따라 관련 리소스나 객체에 대한 후속 작업을 진행할 수 있다. 어떤 객체가 더 이상 필요 없게 됐을 때 이와 관련한 후처리가 필요한 애플리케이션에서 이 ReferenceQueue를 유용하게 사용할 수 있다. 자바의 Collections 클래스 중에서 간단한 캐시를 구현하는 용도로 자주 사용되는 WeakHashMap 클래스는 ReferenceQueue와 WeakReference를 사용해 구현했다.\nReference 추상 클래스 생성자 코드\n/* -- Constructors -- */ Reference(T referent) { this(referent, null); } Reference(T referent, ReferenceQueue\u0026lt;? super T\u0026gt; queue) { this.referent = referent; this.queue = (queue == null) ? ReferenceQueue.NULL : queue; } SoftReference와 WeakReference는 ReferenceQueue를 사용할 수도 있고 사용하지 않을 수도 있다. 이는 이들 클래스의 생성자 중에서 ReferenceQueue를 받는 파라미터로 받는 생성자를 사용할지 여부로 결정한다. 그러나 PhantomReference는 반드시 ReferenceQueue를 사용해야 한다. PhantomReference의 생성자는 단 하나이며 항상 ReferenceQueue를 파라미터로 받기 때문이다.\nSoftReference와 WeakReference는 객체 내부의 참조가 null로 설정된 이후에 ReferenceQueue의 큐에 추가되지만 PhantomReference는 객체 내부의 참조를 null로 설정하지 않고 참조된 객체를 phantomly reachable 객체로 만든 이후에 ReferenceQueue의 큐에 추가된다. 이를 통해 애플리케이션은 객체의 파이널라이즈 이후에 필요한 작업을 처리할 수 있게 된다.\nphantomly reachable과 PhantomReference\nphantomly reachable 객체의 작동 방식은 softly reachable 객체와 weakly reachable 객체의 작동 방식과는 많이 다르다. phantomly reachable 객체의 작동 방식을 이해하려면 먼저 가비지 컬렉션의 작동 방식을 알아야 한다. 가비지 컬렉션의 대상 객체를 찾는 작업과 가비지 컬렉션의 대상 객체를 처리하는 작업이 연속적이지 않듯이 가비지 컬렉션의 대상 객체를 처리하는 작업과 할당된 메모리를 회수하는 작업도 연속된 작업이 아니다. 메모리 회수 작업은 가비지 컬렉션의 대상 객체를 처리하는 작업, 즉 객체의 파이널라이즈 이후에 가비지 컬렉션의 알고리즘을 기반으로 실행된다.\n가비지 컬렉션 대상 여부를 결정하는 부분에 관여하는 softly reachable, weakly reachable과는 달리 phantomly reachable은 파이널라이즈와 메모리 회수 사이에 관여한다. strongly reachable, softly reachable, weakly reachable에 해당하지 않고 PhantomReference로만 참조되는 객체는 먼저 파이널라이즈된 이후에 phantomly reachable로 간주된다. 다시 말해, 객체에 대한 참조가 PhantomReference만 남게 되면 해당 객체는 바로 파이널라이즈된다. 가비지 컬렉터가 객체를 처리하는 순서는 항상 다음과 같다.\n soft reference weak reference 파이널라이즈 phantom reference 메모리 회수  즉, 어떤 객체에 대해 가비지 컬렉션 여부를 판별할 때 먼저 대상 객체의 접근 가능성을 strongly, softly, weakly 순서로 판별한다. 판별 과정을 모두 거쳐도 해당되는 접근 가능성이 없으면 가비지 컬렉션 대상이 돼 위의 순서에 의해 처리된다. 가비지 컬렉터는 해당 객체에 대해 파이널라이즈를 진행한 이후에 phantomly reachable 여부를 판별한다. 대상 객체를 참조하는 PhantomReference가 있다면 phantomly reachable로 간주해 PhantomReference를 ReferenceQueue에 넣고 파이널라이즈 이후 작업을 애플리케이션이 실행하게 하고 메모리 회수를 지연시킨다.\n이처럼 PhantomReference를 사용하면 어떤 객체가 파이널라이즈된 이후에 할당된 메모리가 회수되는 시점에 사용자 코드가 관여할 수 있게 된다. 파이널라이즈 이후에 처리해야 하는 리소스 정리 등의 작업이 있다면 유용하게 사용할 수 있다.\n"
},
{
	"uri": "/%E1%84%83%E1%85%A2%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%85%E1%85%A3%E1%86%BC_%E1%84%8B%E1%85%A1%E1%84%8F%E1%85%B5%E1%84%90%E1%85%A6%E1%86%A8%E1%84%8E%E1%85%A5%E1%84%8B%E1%85%AA_%E1%84%89%E1%85%A5%E1%86%BC%E1%84%82%E1%85%B3%E1%86%BC_%E1%84%90%E1%85%B2%E1%84%82%E1%85%B5%E1%86%BC/",
	"title": "대용량 아키텍처와 성능 튜닝",
	"tags": [],
	"description": "",
	"content": " 대용량 아키텍처와 성능 튜닝 "
},
{
	"uri": "/%E1%84%86%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%87%E1%85%A1%E1%84%90%E1%85%B5%E1%84%89%E1%85%B3%E1%84%85%E1%85%B3%E1%86%AF_%E1%84%89%E1%85%A1%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%92%E1%85%A1%E1%86%AB_%E1%84%8C%E1%85%A1%E1%84%87%E1%85%A1_%E1%84%91%E1%85%A5%E1%84%89%E1%85%B5%E1%84%89%E1%85%B3%E1%84%90%E1%85%A5%E1%86%AB%E1%84%89%E1%85%B3_%E1%84%80%E1%85%A2%E1%84%87%E1%85%A1%E1%86%AF/",
	"title": "마이바티스를 사용한 자바 퍼시스턴스 개발",
	"tags": [],
	"description": "",
	"content": " Spring 프로젝트에서 연동하기 먼저 의존성 추가\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.3.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-spring\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; mybatis-spring 모듈을 사용하면, 스프링의 ApplicationContext에 마이바티스 빈을 설정할 수 있다.\n\u0026lt;bean id=\u0026#34;sqlSessionFactory\u0026#34; class=\u0026#34;org.mybatis.spring.SqlSessionFactoryBean\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;dataSource\u0026#34; ref=\u0026#34;dataSource\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;configLocation\u0026#34; value=\u0026#34;classpath:/mybatis-config.xml\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;mapperLocations\u0026#34; value=\u0026#34;classpath:/sql-map/*.xml\u0026#34;/\u0026gt; \u0026lt;!-- statement 선언의 오류를 좀 더 빠르게 파악하기 위해서 true로 설정 --\u0026gt; \u0026lt;property name=\u0026#34;failFast\u0026#34; value=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;sqlSessionTemplate\u0026#34; class=\u0026#34;org.mybatis.spring.SqlSessionTemplate\u0026#34;\u0026gt; \u0026lt;constructor-arg index=\u0026#34;0\u0026#34; ref=\u0026#34;sqlSessionFactory\u0026#34;\u0026gt;\u0026lt;/constructor-arg\u0026gt; \u0026lt;constructor-arg index=\u0026#34;1\u0026#34; value=\u0026#34;BATCH\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; 스프링에서 SqlSessionFactory빈을 만들고 SqlSessionTemplate빈을 만들어서 생성자로 넣어준다. SqlSessionTemplate빈은 thread safe하게 SqlSession 객체를 제공하기 때문에, 여러 개의 스프링 빈에서 동일한 SqlSessionTemplate 객체를 공유할 수 있다. 개념적으로는 SqlSessionTemplate이 스프링 DAO 모듈의 JdbcTemplate과 동일하다.\nmapper interface가 있는 패키지를 체크하고 자동으로 mapper interface를 mapper bean으로 등록하기 위해 MapperScannerConfigurer를 사용할 수 있다.\n\u0026lt;bean class=\u0026#34;org.mybatis.spring.mapper.MapperScannerConfigurer\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;basePackage\u0026#34; value=\u0026#34;com.test.mapper\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;processPropertyPlaceHolders\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; java config code\n@Configuration @MapperScan(\u0026#34;com.test.mapper\u0026#34;) public class TestConfig { @Autowired ApplicationContext applicationContext; @Bean public SqlSessionFactory sqlSessionFactory() throws Exception { SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); sqlSessionFactoryBean.setDataSource(dataSource()); sqlSessionFactoryBean.setConfigLocation(new ClassPathResource(\u0026#34;mybatis-config.xml\u0026#34;)); sqlSessionFactoryBean.setMapperLocations(applicationContext.getResources(\u0026#34;classpath:/sql-map/*.xml\u0026#34;)); return sqlSessionFactoryBean.getObject(); } @Bean public SqlSessionTemplate sqlSessionTemplate() throws Exception { SqlSessionTemplate sqlSessionTemplate = new SqlSessionTemplate(sqlSessionFactory()); return sqlSessionTemplate; } } MapperScanner를 사용하면 mapper namespace로 맵핑시켜서 사용하면 된다.\n@Repository(value = \u0026#34;TestMapper\u0026#34;) public interface TestMapper { }\u0026lt;mapper namespace=\u0026#34;com.test.TestMapper\u0026#34;\u0026gt; 만약 MapperScanner를 사용안한다면 sqlSessionTemplate을 직접 DI받아서 사용하면 된다.\n@Repository public class TestDaoImpl implements TestDao { @Autowired private SqlSessionTemplate sqlSessionTemplate; } 스프링을 사용한 트랜잭션 관리\n\u0026lt;tx:annotation-driven\u0026gt;\u0026lt;/tx:annotation-driven\u0026gt; \u0026lt;bean id=\u0026#34;transactionManager\u0026#34; class=\u0026#34;org.springframework.jdbc.datasource.DataSourceTransactionManager\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;dataSource\u0026#34; ref=\u0026#34;dataSource\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; 트랜잭션매니저에서 사용한 dataSource는 sqlSessionFactory 빈이 사용하는 것과 동일한 dataSource여야 한다.\nXML을 사용한 SQL 매퍼 ResultMap 확장이 가능하다.\n\u0026lt;resultMap type=\u0026#34;Student\u0026#34; id=\u0026#34;StudentResult\u0026#34;\u0026gt; \u0026lt;result property=\u0026#34;name\u0026#34; column=\u0026#34;name\u0026#34;/\u0026gt; \u0026lt;result property=\u0026#34;email\u0026#34; column=\u0026#34;email\u0026#34;/\u0026gt; ... \u0026lt;/resultMap\u0026gt; \u0026lt;resultMap type=\u0026#34;Student\u0026#34; id=\u0026#34;StudentWithAddressResult\u0026#34; extends=\u0026#34;StudentResult\u0026#34;\u0026gt; \u0026lt;result property=\u0026#34;address.addrId\u0026#34; column=\u0026#34;addr_id\u0026#34;/\u0026gt; \u0026lt;result property=\u0026#34;address.street\u0026#34; column=\u0026#34;street\u0026#34;/\u0026gt; ... \u0026lt;/resultMap\u0026gt; 동적 SQL 마이바티는 \u0026lt;if\u0026gt;, \u0026lt;choose\u0026gt;, \u0026lt;where\u0026gt;, \u0026lt;foreach\u0026gt;, \u0026lt;trim\u0026gt;과 같은 엘리먼트를 사용해서 동적인 SQL 쿼리를 만들도록 지원한다.\nif 조건 if 엘리먼트는 test 조건이 true가 될 때만 해당되는 SQL이 쿼리에 추가된다.\n\u0026lt;resultMap type=\u0026#34;Course\u0026#34; id=\u0026#34;CourseResult\u0026#34;\u0026gt; \u0026lt;id property=\u0026#34;courseId\u0026#34; column=\u0026#34;course_id\u0026#34;/\u0026gt; \u0026lt;result property=\u0026#34;name\u0026#34; column=\u0026#34;name\u0026#34;/\u0026gt; \u0026lt;result property=\u0026#34;description\u0026#34; column=\u0026#34;description\u0026#34;/\u0026gt; \u0026lt;result property=\u0026#34;start_date\u0026#34; column=\u0026#34;startDate\u0026#34;/\u0026gt; \u0026lt;result property=\u0026#34;end_date\u0026#34; column=\u0026#34;endDate\u0026#34;/\u0026gt; \u0026lt;/resultMap\u0026gt; \u0026lt;select id=\u0026#34;searchCourses\u0026#34; parameterType=\u0026#34;hashmap\u0026#34; resultMap=\u0026#34;CourseResult\u0026#34;\u0026gt; \u0026lt;![CDATA[ select * from courses where tutor_id=#{tutorId} \u0026lt;if test=\u0026#34;courseName != null\u0026#34;\u0026gt; and name like #{courseName} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;startDate != null\u0026#34;\u0026gt; and start_date \u0026gt;= #{startDate} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;endDate != null\u0026#34;\u0026gt; and end_date \u0026lt;= #{endDate} \u0026lt;/if\u0026gt; ]]\u0026gt; \u0026lt;/select\u0026gt; choose, when, otherwise 조건 마이바티스는 \u0026lt;choose\u0026gt;의 test 조건을 확인해서 가장 먼저 true가 되는 조건을 사용한다. 어느 조건도 true가 되지 못하면, \u0026lt;otherwise\u0026gt;절이 사용된다.\nselect * from courses \u0026lt;choose\u0026gt; \u0026lt;when test=\u0026#34;searchBy == \u0026#39;Tutor\u0026#39;\u0026#34;\u0026gt; where tutor_id = #{tutorId} \u0026lt;/when\u0026gt; \u0026lt;when test=\u0026#34;searchBy == \u0026#39;CourseName\u0026#39;\u0026#34;\u0026gt; where name like #{courseName} \u0026lt;/when\u0026gt; \u0026lt;otherwise\u0026gt; where tutor start_date \u0026amp;gt; = now() \u0026lt;/otherwise\u0026gt; \u0026lt;/choose\u0026gt; where 조건 가끔은 모든 검색 조건 중 하나도 선택하지 않을 수 있다 마이바티스는 이러한 SQL문을 만들기 위해 \u0026lt;where\u0026gt; 엘리먼트를 제공한다. 내부조건을 나타내는 엘리먼트에 의해 리턴되는 내용이 있을 때에만 where를 추가한다(모든 검색 조건이 필수가 아니라 선택할 수 있을 때 사용된다).\nselect * from courses \u0026lt;where\u0026gt; \u0026lt;if test=\u0026#34;tutorId != null\u0026#34;\u0026gt; tutor_id=#{tutorId} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;courseName != null\u0026#34;\u0026gt; and name like #{courseName} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;startDate != null\u0026#34;\u0026gt; and start_date \u0026gt;= #{startDate} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;endDate != null\u0026#34;\u0026gt; and end_date \u0026lt;= #{endDate} \u0026lt;/if\u0026gt; \u0026lt;/where\u0026gt; trim 조건 \u0026lt;trim\u0026gt; 엘리먼트는 \u0026lt;where\u0026gt; 엘리먼트와 유사하지만 접두사/접미사를 추가하거나 제거하는 기능을 추가로 제공한다. \u0026lt;if\u0026gt;조건이 true이면 where절을 추가하고 where 뒤에 접두사 AND나 OR가 있으면 제거한다.\nselect * from courses \u0026lt;trim prefix=\u0026#34;where\u0026#34; prefixOverrides=\u0026#34;AND | OR\u0026#34;\u0026gt; \u0026lt;if test=\u0026#34;tutorId != null\u0026#34;\u0026gt; tutor_id=#{tutorId} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;courseName != null\u0026#34;\u0026gt; and name like #{courseName} \u0026lt;/if\u0026gt; \u0026lt;/trim\u0026gt; foreach 루프 배열이나 리스트를 통해 반복적인 처리를 하고 AND나 OR 조건을 붙이거나 IN 절을 처리하는 공통적인 요구사항을 담당한다.\ntutor_id의 아이디가 1,3,6인 교사가 가르치는 모든 교육과정을 찾는다고 해보자. tutor_id의 아이디 목록을 매핑 구문에 전달하고 \u0026lt;foreach\u0026gt; 엘리먼트를 사용해서 리스트를 반복 처리해서 동적 쿼리를 만들 수 있다.\n\u0026lt;select id=\u0026#34;searchCoursesByTutors\u0026#34; parameterType=\u0026#34;map\u0026#34; resultMap=\u0026#34;CourseResult\u0026#34;\u0026gt; select * from courses \u0026lt;if test=\u0026#34;tutorIds != null\u0026#34;\u0026gt; \u0026lt;where\u0026gt; \u0026lt;foreach item=\u0026#34;tutorId\u0026#34; collections=\u0026#34;tutorIds\u0026#34;\u0026gt; OR tutor_id=#{tutorId} \u0026lt;/foreach\u0026gt; \u0026lt;/where\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;/select\u0026gt; IN절을 만드는법을 알아보자.\n\u0026lt;select id=\u0026#34;searchCoursesByTutors\u0026#34; parameterType=\u0026#34;map\u0026#34; resultMap=\u0026#34;CourseResult\u0026#34;\u0026gt; select * from courses \u0026lt;if test=\u0026#34;tutorIds != null\u0026#34;\u0026gt; \u0026lt;where\u0026gt; tutor_id IN \u0026lt;foreach item=\u0026#34;tutorId\u0026#34; collections=\u0026#34;tutorIds\u0026#34; open=\u0026#34;(\u0026#34; seperator=\u0026#34;,\u0026#34; close=\u0026#34;)\u0026#34;\u0026gt; #{tutorId} \u0026lt;/foreach\u0026gt; \u0026lt;/where\u0026gt; \u0026lt;/if\u0026gt; \u0026lt;/select\u0026gt; set 조건 \u0026lt;where\u0026gt; 엘리먼트와 유사하고 내부 조건이 리턴하는 내용이 있을 경우 SET을 추가할 것이다.\n\u0026lt;update id=\u0026#34;updateStudent\u0026#34; parameterType=\u0026#34;Student\u0026#34;\u0026gt; update students \u0026lt;set\u0026gt; \u0026lt;if test=\u0026#34;name != null\u0026#34;\u0026gt;name=#{name},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;email != null\u0026#34;\u0026gt;email=#{email},\u0026lt;/if\u0026gt; \u0026lt;if test=\u0026#34;phone != null\u0026#34;\u0026gt;phone=#{phone},\u0026lt;/if\u0026gt; \u0026lt;/set\u0026gt; where stud_id=#{id} \u0026lt;/update\u0026gt; 여기서 \u0026lt;set\u0026gt; 엘리먼트는 \u0026lt;if\u0026gt;조건이 텍스트를 리턴한다면 set 키워드를 추가하고 마지막에 콤마(,)를 제거한다.\n"
},
{
	"uri": "/%E1%84%89%E1%85%A9%E1%84%91%E1%85%B3%E1%84%90%E1%85%B3%E1%84%8B%E1%85%B0%E1%84%8B%E1%85%A5_%E1%84%91%E1%85%AE%E1%86%B7%E1%84%8C%E1%85%B5%E1%86%AF%E1%84%80%E1%85%AA%E1%86%AB%E1%84%85%E1%85%B5_nhn%E1%84%8B%E1%85%B3%E1%86%AB_%E1%84%8B%E1%85%B5%E1%84%85%E1%85%A5%E1%87%82%E1%84%80%E1%85%A6%E1%84%92%E1%85%A1%E1%86%AB%E1%84%83%E1%85%A1/",
	"title": "소프트웨어 품질관리(NHN은 이렇게한다)",
	"tags": [],
	"description": "",
	"content": " SW 개발의 특징(경험적 프로세스) 어떤 서비스나 재화를 생산하는 과정은 ‘정의된 프로세스’를 따르는 경우와 ‘경험적 프로세스’를 따르는 경우로 나뉜다. 정의된 프로세스는 공장의 생산 라인과 같이 반복할 수 있는 과정을 의미한다. 반면 경험적 프로세스는 어머니가 음식을 만드는 과정과 유사하다. 음식이 완성될 때까지 양념을 넣고 간을 보고 다시 양념을 넣는 과정을 반복한다. 이렇게 피드백을 자주 받는 방식으로 제품을 생산하는 방식을 경험적 프로세스라고 한다.\n피드백은 현재까지 구현된 SW가 사용자의 요구 사항과 일치하는 지를 확인하는 과정이다. 전통적인 개발 방법론에서는 이런 사실을 SW 개발 프로젝트 후반부에서야 확인할 수 있다. 이런 문제를 프로젝트 후반부가 아닌 초기부터 자주 드러내어 문제를 일찍 해결하려는 방법이 품질 혁신 활동이다.\nQP(Quality Practice) 품질 혁신 활동\n코딩 컨벤션, 코드 리뷰, 코드 커버리지, 정적 분석, 사이클로매틱 복잡도 5가지 품질의 각 수행 활동에 대한 품질 지표를 측정할 수 있는 방법과 품질 기준을 정의했다. 현재는 서스테이닝 품질을 개선하기 위해 \u0026lsquo;중복 코드 분석 활동\u0026rsquo;을 추가하고 \u0026lsquo;사이클로매틱 복잡도\u0026rsquo;와 \u0026lsquo;코드 리뷰\u0026rsquo;는 자율적으로 적용하도록 정책을 변경했다.\n코딩 컨벤션\n코딩 컨벤션은 언어별 네이밍 규칙, 코드 스타일, 주석, 보안 영역을 포괄한다. 여기엔 클래스나 메서드, 변수의 이름을 짓는 방법, 공백이나 줄 바꿈, 들여쓰기의 정도, 파일, 클래스, 메서드, 상수 등의 주석 작성 방법, 주요 공격 유형별 방어 코드 작성 방법 등이 포함된다. (ex 자바 Checkstyle)\n코드 리뷰\n코드 리뷰 수행 시점은 조직에 따라 형상 관리 시스템에 커밋하기 전이나 커밋한 후에 결정하며 신규/개편 개발 과제는 최소한 반복 개발 주기별로, 서스테이닝은 2주 ~ 2개월 간격으로 1 시간씩 진행할 것을 권장한다.\ncf) Sustaining : 운영 중인 서비스 또는 서비스 관리 시스템의 운영 품질 개선을 위한 소규모 개발 업무를 의미한다.\n사이클로매틱 복잡도\n위의 그래프에 나타난 제어 흐름은 먼저 A의 조건에 따라 작업 B,C,D가 수행된다. 작업 B 뒤에는 항상 E가 수행되며, 이 두 작업은 이중으로 중첩된 반복 구조의 일부이다.\n사이클로매틱 복잡도는 그래프에 있는 리전(그래프 평면 상의 밀폐된 영역)의 수로 정의한다. 따라서 위의 그래프에서는 R1부터 R5까지 다섯 개의 리전이 있으며, 사이클로매틱 복잡도는 5이다.\n효과적인 명세 작성 SW의 품질 관리는 사용자의 요구 사항을 수집하고 기록하는 단계에서부터 시작된다고 할 수 있다. 전통적인 SW개발 과정을 살펴보면 기획자가 \u0026lsquo;요구 사항 명세서\u0026rsquo;, \u0026lsquo;기획 명세서\u0026rsquo; 등 다양한 이름의 문서를 작성해서 개발자에게 전달하면 개발자는 이를 기반으로 설계 명세서, 개발 명세서, 기능 명세서 등을 작성한다. 개발이 완료되면 QA나 테스터는 테스트 계획서, 테스트 설계서 등 각종 문서를 작성하기 시작한다. 물론 언제든 요구 사항이나 설계 내용은 변경될 수 있기 때문에 의사소통의 어려움을 겪게 된다. 따라서 품질을 높이기 위해서는 혼잡해진 언어들 간에 소통의 코드가 필요하다.\n예제를 이용한 명세 작성 기법 (가능한 모든 조합을 열겨하고, 예외 케이스까지 고려)\nex) 계산기 프로그램\n계산기의 사칙 연산에 대한 명세는 테이블로 표현할 수 있다. 테이블로 명세를 작성할 때 특별한 형식이나 규칙이 있는 것은 아니다. 그러나 테이블을 작성할 때도 역시 언어의 중의성과 모호성의 함정을 주의해야 한다.\n정상적인 사용\n| left | operator | right | equal | result? | | \u0026ndash; | \u0026ndash; | \u0026ndash; | \u0026ndash; | \u0026ndash; | | 6 | + | 3 | = | 9 | | 6 | - | 3 | = | 3 | | 6 | * | 3 | = | 18 | | 6 | / | 3 | = | 2 |\n비정상적이지만 합당한 사용\n| left | operator | right | equal | result? | | \u0026ndash; | \u0026ndash; | \u0026ndash; | \u0026ndash; | \u0026ndash; | | 0.0000000000003 | * | 0.00000000004 | = | 1.2e-59 | | 5555555555555555 | * | 111111111111 | = | 6.1728395061727e+62 | | 0.000000000004 | + | 0.000000000003 | = | 0.000000000007 | | 5 | / | 3 | = | 1.66 \u0026hellip; 667 |\n비정상적이고 예외적인 사용\n| left | operator | right | equal | result? | | \u0026ndash; | \u0026ndash; | \u0026ndash; | \u0026ndash; | \u0026ndash; | | 5 | + | | = | 5 | | | - | 5 | = | -5 | | 5 | / | 0 | = | error |\n단계적 빌드 지속적인 통합이란 통합 과정을 자동화하고 주기적인 빌드, 테스트, 분석을 통해 피드백을 받는 과정이다. 개발자가 형상 관리 시스템에 변경한 코드를 커밋하면 CI 서버는 빌드를 수행하여 결과를 제공하며 설정한 주기에 따라 주기적으로 빌드를 수행하기도 한다.\n[기존 개발 프로세스] 단계적 빌드\n 개발자 빌드 : 로컬 PC에서 변경한 코드를 형상 관리 시스템에 커밋하기 전에 수행 / 빌드환경: 로컬 PC / 테스트 범위 : 다른 모듈에 의존하지 않는 단위 테스트 커밋 빌드 : 형상 관리 시스템에 저장된 코드가 변경되었을 때 해당 코드가 다른 코드와 충돌하지 않는지 확인하기 위해 수행 / 빌드환경 : CI 서버 / 테스트 범위 : 여러 명의 단위 테스트를 모아 수행하는 테스트(미들웨어에 의존하지 않는 테스트) 통합 빌드 : 정해진 시간 주기마다 수행. 주기는 일반적으로 24시간이며, 밤에 수행하는 것을 권장. 최종 통합 빌드 완료 후에는 코드 완료를 선언 / 빌드환경 : CI 서버 / 테스트 범위 : DB, 플랫폼, 네트워크 등의 미들웨어에 의존하는 테스트 릴리스 빌드 : 사용자에게 소프트웨어를 배고하기 위해 수행. 빌드 라벨을 붙이면 의사소통에 유용 / 빌드환경 : 빌드 배포 시스템 / 테스트 범위 : 기능 테스트, 성능 테스트, 부하 테스트  단계적 빌드에 필요한 것 : 형상 관리 시스템, 빌드 자동화 스크립트, CI 서버\n[CI 서버 구성] CI 서버란 ‘빌드 자동화 서버’다. 좀 더 구체적으로 말하자면 ‘정해진 스케줄에 따라 빌드를 수행하는 서버’라고 할 수 있다. CI 서버는 주기적으로 또는 형상 관리 시스템에 변화가 발생했을 때 자동으로 빌드를 수행하고 결과를 보고한다.\ncf) Continuous Inspection(코드 품질용 ex 소나) 코드만 점검하고 빌드나 배포 작업은 안함. 지속적으로 코드품질을 유지하려는 목적\n코드 커버리지 새로 작성하거나 수정된 코드를 어느 정도 테스트했는지 개발자 테스트 수행 정도를 파악하기 위한 품질 지표로 코드 커버리지를 측정했다. 커버리지를 측정하지 않고 테스트를 수행할 때는 일반적으로 코드의 일부분만을 실행하는데 커버리지를 측정하면 테스트를 그만해야 하는지, 추가할 테스트는 없는 지 확인할 수 있으며 개발자가 의무적으로 테스트를 수행하게 된다는 점에서 효과적이다. (가장 중요한 수행 활동)\n정적 분석 정적 분석이란 SW를 실행하지 않고 도구를 이용해서 소스 코드나 바이너리를 분석해서 잠재적인 결함을 찾아내는 것을 말한다.\n중복 코드 분석 "
},
{
	"uri": "/%E1%84%89%E1%85%B5%E1%86%AF%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%8C%E1%85%AE%E1%84%8B%E1%85%B4%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%80%E1%85%B3%E1%84%85%E1%85%A2%E1%84%86%E1%85%A5_%E1%84%8B%E1%85%B5%E1%86%A8%E1%84%89%E1%85%B3%E1%84%90%E1%85%B3%E1%84%85%E1%85%B5%E1%86%B7%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%80%E1%85%B3%E1%84%85%E1%85%A2%E1%84%86%E1%85%B5%E1%86%BC/",
	"title": "실용주의프로그래머 익스트림프로그래밍",
	"tags": [],
	"description": "",
	"content": " 1.자신의 기술에 관심과 애정을 가져라 2.자신의 일에 대해 생각하면서 일하라\n- 모든 개발 과정에서, 매일, 내가 내리는 모든 결정을 지속적이고 비판적으로 평가 - 일하면서 동시에 자신의 일을 비평하고 분석  3.DRY 원칙을 지켜라 (Don’t Repeat Yourself) 4.프로토타입을 통해 학습하라 5.리팩터링은 어떤 것이든 ‘잘못’되었다고 생각될 때, 그것을 변경하는 일을 주저하면 안된다. 언제나 바로 지금이 최적기다. (일찍 리팩터링하고 자주 리팩터링하자) 6.풀기 어려운 문제에 맞닥뜨렸을때 한걸음 뒤로 물러서서 다음 질문을 스스로에게 하라\n- 더 쉬운 방법이 존재하는가? - 진짜 문제를 풀려고 노력하고 있나. 그렇지 않다면 중요하지 않은 기술적 문제에 정신 팔려있는 것인가? - 왜 이것이 문제인가? - 문제를 이렇게 풀기 어렵게 만드는 것이 무엇인가? - 반드시 이 방법으로 해야 하는가? - 반드시 해야 하는 일이긴 한가?  7.프로젝트를 시작할 때 이름을 지어주자 (팀의 정체성 확립의 기반을 얻는 것) 8.문서가 애초부터 전체의 일부가 되게 하고, 나중에 집어넣으려고 하지 말라.\n익스트림 프로그래밍  XP는 오늘 내가 기울인 모든 노력에 대해 자신을 인정해 주는 것이다. XP는 내일은 좀 더 잘해보려고 애쓰는 것이다. ‘받아들인 책임’의 원칙. 스토리를 구현할 책임을 진 사람은 궁극적으로 스토리의 설계, 구현, 테스트까지 책임을 진다. 소프트웨어 개발은 통찰력 싸움이다. 그리고 통찰력은 준비되고, 잘 쉬고, 긴장이 풀린 마음에서 생겨난다. 점진적 설계. 시스템 설계에 매일 투자해라 짝 프로그래밍은 팀 동료들이 서로에게 품질에 대한 자신의 헌신을 보여주고 좋은 품질을 구성하는 것이 무엇 인가에 대한 서로의 기대치를 통일 시키는 일에 도움이 된다. 설계하기. 설계 개선을 멀리 까지 앞서 나가게 하고 싶은 유혹에 저항하라. 오늘 여러분에게 영향을 미치는 설계만 개선하는 습관을 길러라. 팀 전체의 생산성과 내 오늘의 작업에 균형을 맞춰라(지금 당장 설계를 수정함으로써 오늘 내가 할 일을 못한다 하더라도 해야만 하는 일이다)  "
},
{
	"uri": "/%E1%84%8B%E1%85%A2%E1%84%8C%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AF%E1%84%8C%E1%85%A5%E1%86%A8%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%92%E1%85%AE%E1%84%80%E1%85%B5/",
	"title": "애자일적용후기",
	"tags": [],
	"description": "",
	"content": " 불확실성과 화해하는 프로젝트 추정과 계획 애자일 핵심\n1.정확 하려고 하다 틀리는 것보다는 대충 이라도 맞는 것이 낫다.\n2.스토리 점수 추정 / 예상 소요 시간 추정 등에 있어서 논쟁은 의미 없다.\n3.한 팀이라는 소속감과 항상 같이 작업한다는 의식 중요\n4.계획에 대해 자주 의견을 나누는 것이 중요 5.속도는 all or nothing( 다 완료하지 못하면 무조건 0점)\n6.얼마나 많은 일을 했는지 아는것보다 얼마나 많은 일들이 남아있는지 살피는것이 핵심\n7.진행 중인 일들은 다음 이터레이션으로 넘기지 않는다.\n- 이터레이션이 끝날때, 진행중인 작업들은 전부 제거. 어떤 기능의 구현을 완전히 끝내지 못했다손 치더라도, 그 기능 구현을 다음 이터레이션에 반드시 계속할 필요는 없다는 뜻.(계속해야 할 경우도 가끔 있을수 있지만)\n8.빈틈을 두라. 주어진 시간을 100% 프로젝트에 쏟아 부을 것이라는 가정 하지 않는다.\n애자일 기법의 목적\n어떤 자원을 가지고 어떤 기능을 어떻게 개발할 것인가 하는 질문에 대한 최적의 답을 반복적이고 점진적으로 찾아나가는 것.\n애자일 기법을 적용하기 위한 단계\n1.종이 카드에 스토리들을 적는다.\n- `\u0026lt;사용자 유형\u0026gt;`은 `\u0026lt;방법\u0026gt;`을 하여 `\u0026lt;효과\u0026gt;`를 할 수 있다.  2.각각의 스토리들에 대한 규모를 추정하여 점수화한다.(p54) - 점수화 할때 1,2,3,5,8식의 피보나치 수열 이용\n3.각각의 스토리들에 대한 우선순위를 부여한다.\n- 위험성과 가치를 동시에 고려하여 기능 간 우선순위를 결정 - 어떤 기능의 위험성과 가치에 대한 평가는 시간의 흐름에 따라 달라짐을 유의 - ![](/agaile_우선순위.png) - 고객 만족에 따른 카노 모델 - ![](/agaile_konomodel.PNG) - 우선순위1 : 필수기능(성공적인 제품을 위해 반드시 포함되어야 하는 기능) - 우선순위2 : 선형기능(더 많을수록 좋은 기능) - 우선순위3 : 감동요인(예상하지 못한 좋은 추가적인 좋은 기능들) - 필수 / 선형 / 감동인지 파악하기 위한 설문지 - ![](/agaile_설문지.PNG) - 설문지에 따른 필수 / 선형 / 감동 분석 - ![](/agaile_설문지분석법.PNG)  4.우선순위가 부여된 스토리들 중에 이번 이터레이션 동안 작업할 스토리들을 찾는다.\n5.스토리들을 작업 목록으로 확장시킨다(구체적으로 작업단위를 쪼갬).\n6.이번 이터레이션 동안 실제 코딩을 완료지을 거라 서약 할 수 있는지 묻는다.\n7.최대로 서약할 수 있을때까지 계속하고 계획이 다 차면 이터레이션 계획완료.\n8.나머지 스토리들은 한 이터레이션이 끝난 후 검토, 회고를 거친 후 다시 작업\n릴리스 소멸 차트 예시\n(중간에 그래프가 올라간 이유는 계획대로 마쳐도 이터레이션이 도는 동안 스토리 규모가 생각보다 더 크다는 것을 발견해서 그와 관련된 모든 추정치를 수정)\n이터레이션 동안 사용하는 작업 보드 예시\n한 개발자가 한번에 두 카드를 고르는 것은 금지 개발자들은 작업 카드에 적힌 추정치를 언제든 수정 할 수 있어야 함\n실제 적용\n종이 카드에 스토리 적기 점수 추정 이번 이터레이션 동안 할 작업 선정 애자일 작업보드 이터레이션 소멸 차트 후기\n1.2주 단위 이터레이션 보고활동은 휴학상태 아니면 현실적으로 지키기 어려움\n2.형식적인 일정짜기를 안해도 되는 장점\n3.팀원 모두 애자일이 처음이라 특수한 상황에 대처가 쉽지 않았음\n4.주기적인 고객의 피드백 수용가능\n5.개발자 3명이서 모든 프로젝트를 담당하다 보니 한계점 존재\n6.계획에 없던 디자이너가 추가됨에 따라 스토리가 \u0026lsquo;사용자 중심\u0026rsquo;에서 \u0026lsquo;기능 중심\u0026rsquo;으로 바뀔수 밖에 없는 문제 발생\nex) \u0026lsquo;사용자는 내가 수강한 강의 목록을 확인 할 수 있다.\u0026rsquo; 이 스토리를 실제로 구현하기 위해서는 기능 + 테스트 + 디자인 까지 한번에 완료되어야 한다. 그런데 우리 프로젝트는 디자이너가 후반에 참가하게 됐다. 그에 따라 개발 속도와 디자인 속도가 다를 수 밖에 없게 되고 선 기능구현 후 디자인 적용으로 갈수밖에 없었다. 결국 스토리도 \u0026lsquo;Q\u0026amp;A 댓글 기능 구현\u0026rsquo; , \u0026lsquo;메인페이지 디자인 적용\u0026rsquo; 이렇게 기능중심적으로 갈수 밖에 없었다.\n7.나태해지지 않게 잡아주는 장점\n"
},
{
	"uri": "/",
	"title": "양봉수 개발 블로그",
	"tags": [],
	"description": "",
	"content": " Blog Email : goodbs1000@gmail.com\n"
},
{
	"uri": "/%E1%84%8B%E1%85%B0%E1%86%B8%E1%84%8B%E1%85%B3%E1%86%AF_%E1%84%8C%E1%85%B5%E1%84%90%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB_%E1%84%80%E1%85%B5%E1%84%89%E1%85%AE%E1%86%AF/",
	"title": "웹을 지탱하는 기술",
	"tags": [],
	"description": "",
	"content": " HTTP는 원래 하이퍼텍스트를 전송하기 위한 프로토콜이었지만, 실제로는 하이퍼텍스트 이외의 다양한 것들을 전송하고 있다. 그것이 무엇인가 하면, 리소스 상태(Resource State)의 표현(Representation)이라는 것이 필딩의 주장이다(REST 창시자).\n리소스\nREST에 있어서 중요한 개념의 하나로 리소스가 있다. 우선 웹에서 리소스의 예를 보자.\n서울의 일기예보 청량리역의 사진 다음 웹 페이지 Dijkstra의 논문 'Go To Statement Considered Harmful'  웹 상에서는 이 밖에도 다양한 리소스가 존재한다. 리소스를 한마디로 설명하면, \u0026lsquo;웹상에 존재하는 이름을 가진 모든 정보\u0026rsquo;가 된다.\n리소스 명칭으로서의 URI\n서울의 일기 예보 http://weather.daum.net/rgn/cityWetrWarea 청량리역의 사진 http://wwwflickr.com/photos/nala2sky/2121321/ Dijkstra의 논문 'Go To Statement Considered Harmful' http://www.ecn.purdue.edu/ParaMount/papers/diijkstra68goto.pdf cf) 복합한 URI의 예 http://yohei:pass@blog.example.com:8000/search?q=test\u0026amp;debug=true#n10 URI 스키마(hhtp) 다음에 사용자 정보가 들어가 있다. 사용자 정보는 이 리소스에 접근할 때 이용할 사용자 이름과 패스워드로 구성된다.  즉, 리소스란 웹상의 정보이다. 전 세계 무수한 리소스는 각각 URI로 의미 있는 이름을 가진다. URI를 이용함으로써, 프로그램은 리소스가 표현하는 정보에 접근할 수 있다.\n클라이언트/서버\n웹은 HTTP라는 프로토콜을 이용해 클라이언트와 서버가 서로 통신하는 클라이언트/서버의 아키텍처 스타일을 채용하고 있다. 클라이언트/서버의 이점은 단일 컴퓨터 상에서 모든 것을 처리하는 것이 아니라, 클라이언트와 서버로 분리해서 처리할 수 있다는 점이다.\nURI, URL, URN\nURI와 비슷한 이름으로 URL과 URN이 있다. 정확히 말하지면 URI는 URL과 URN을 총칭하는 이름이다. URL에는 도메인을 갱신하지 않았거나 서버가 어떤 장애로 인해 변경되면 액세스 할 수 없다는 문제가 있다. 이 문제에 대응하기 위해 도메인명과는 독립적으로 리소스에 항구적인 ID를 할당하기 위한 스펙이 검토되었고 그 결과가 URN이다. URN을 이용하면 리소스에 도메인명과는 독립된 이름을 붙일 수 있다. 예를 들어 서적은 ISBN이라는 세계적으로 통일된 ID를 갖고 있다. urn:isbn:924483858493 이렇게 URN은 도메인명에 의존하지 않는다. 이런 특성을 가진 URL과 URN을 합해 URI라고 부르게 되었다. 즉, URI는 2개의 ID체계를 합한 총칭이다.\nHTTP의 기본 HTTP란 이름대로라면 하이퍼텍스트 전송용 프로토콜이지만, 실제로는 HTML과 XML 같은 하이퍼텍스트뿐만 아니라 이미지, 음성, 동영상, JavaScript 프로그램, PDF와 각종 오피스 도큐먼트 파일 등 컴퓨터에서 다룰 수 있는 데이터라면 무엇이든 전송할 수 있다.\n미디어 타입\nHTTP는 많은 데이터 타입을 다루기 때문에 웹에서 전송되는 객체 각각에 신중하게 MIME 타입이라는 데이터 포맷 라벨을 붙인다(Multipurpose Internet Mail Extensions). 원래 각기 다른 전자메일 시스템 사이에서 메세지가 오갈 때 겪는 문제점을 해결하기 위해 설계되는데 HTTP에서도 멀티미디어 콘텐츠를 기술하고 라벨을 붙이기 위해 채택되었다.\nContent-Type: ( MIME 타입 ) HTML 텍스트 문서 : text/hml plain ASCII 텍스트 문서 : text/plain JPEG 이미지 : image/jpeg GIF 이미지 : image/gif MS ppt : application/vnd.ms-powerpoint JSON : application/json  TCP/IP\nHTTP는 자신의 메세지 데이터를 전송하기 위해 TCP를 사용한다. HTTP 클라이언트가 서버에 메세지를 전송할 수 있게 되기 전에, IP주소와 포트번호를 사용해 클라이언트와 서버 사이에 TCP/IP 커넥션을 맺어야 한다.\n 브라우저는 서버의 URL에서 호스트 명을 추출한다. 브라우저는 서버의 호스트 명을 IP로 변환한다. 브라우저는 URL에서 포트번호를 추출한다. 브라우저는 추출한 IP와 포트번호로 TCP 커넥션을 맺는다. 브라우저는 서버에 HTTP 요청을 보낸다. 서버는 브라우저에 HTTP 응답을 돌려준다. 커넥션이 닫히면, 브라우저는 문서를 보여준다.  HTTP 메세지\n요청 메세지 GET /search?q=test\u0026amp;debug=true#n10 HTTP/1.1 Host : example.com:8080 -------- 바디 --------  요청 메세지의 둘째 줄 부터 헤더가 이어진다. 헤더는 메세지의 메타 데이터이다. 그리고 하나의 메세지는 복수의 헤더를 가질 수 있다. 마지막으로 바디에는 그 메세지를 나타내는 본질적인 정보가 들어간다.\n응답 메세지 HTTP/1.1 200 OK Content-Type : application/xhtml+xml; charset=utf-8 \u0026lt;html\u0026gt; ... \u0026lt;/html\u0026gt;  응답 메세지의 첫째 줄은 status line이라고 하며 프로토콜 버전(HTTP.1,1), status code(200), 테스트 구문(OK)으로 구성된다.\nHTTP 메서드 GET : 리소스 취득 POST : 서브 리소스의 작성, 리소스 데이터의 추가, 그밖의 처리 PUT : 리소스 갱신, 리소스 작성 DELETE : 리소스 삭제 HEAD : 리소스의 헤더(메타 데이터) 취득 OPTIONS : 리소스가 서포트하는 메서드의 취득 TRACE : 자기 앞으로 요청 메세지를 반환(루프 백) 시험 CONNECT : 프록시 동작의 터널 접속으로 변경 대표적인 CRUD 메서드 GET : 리소스 취득 POST : 서브 리소스의 작성, 리소스 데이터의 추가, 그밖의 처리 PUT : 리소스 갱신, 리소스 작성 DELETE : 리소스 삭제  POST, PUT 두개 다 리소스를 작성할 수 있다. 그럼 이 두 가지를 어떻게 구분해서 사용하면 좋을까? 정답은 없지만 설계상의 지침으로 다음과 같은 사실이 있다. POST로 리소스를 작성할 경우, 클라이언트는 리소스의 URI를 지정할 수 없다. URI의 결정권은 서버 측에 있다. 반대로 PUT으로 리소스를 작성할 경우, 리소스의 URI는 클라이언트가 결정한다.\n예를 들어, Twitter와 같이 포스팅한 트윗의 URI를 서버 측이 자동적으로 결정하는 웹 서브시의 경우는 POST를 이용하는 것이 일반적이다. 반대로, Wiki 처럼 클라이언트가 결정한 타이틀이 그대로 URI가 되는 웹 서비스는 PUT을 사용하는 편이 적합하다.\n특별한 이유가 없는 한, 리소스의 작성은 POST로 수행하여 URI를 서버 측에서 결정하는 설계가 바람직하다.\nOPTIONS는 그 리소스가 지원하고 있는 메서드 목록을 반환한다. 리소스마다 대응하는 메서드를 반환하도록 직접 구현해야 되며 Apache와 같은 WebDAV에 대응하는 웹 서버에서는 설정파일로 OPTIONS의 동작을 설정할 수 있다.\n요청 OPTIONS /list HTTP/1.1 Host: example.com 응답 HTTP/1.1 200 OK Allow: GET, HEAD, POST  조건부 요청\nHTTP 메서드와 갱신일자 등으로 헤더를 구성하면 메서드의 실행 여부를 리소스의 갱신일자를 조건으로 서버가 선택할 수 있다. 예를 들어, GET에 리소스의 갱신일자를 조건으로 넣기 위해서는 If-Modified-Since헤더를 사용한다. 이 헤더가 들어간 GET은 리소스가 이 시간 이후 갱신되어 있으면 GET한다는 의미가 된다. 마찬가지로 PUT과 조합하면 이 시간 이후로 갱신되어 있지 않으면 리소스를 갱신한다는 의미가 된다.\nHTTP 헤더 리소스에 대한 접근권한을 설정하는 인증이나 클라이언트와 서버의 통신횟수와 양을 감소시키는 캐시 같은 HTTP의 기능을 헤더로 실현한다.\n날짜와 시간\nDate 헤더 Date: Tue, 06 Jul 2010 03:21:05 GMT  MIME 미디어 타입\nContent-Type: text/plain; charset=utf-8  미디어 타입은 charset 파라미터를 가질 수 있다. charset 파라미터는 생략 가능하지만 타입이 text인 경우에는 주의가 필요하다. HTTP에서 text타입 디폴트 문자 인코딩은 ISO 8859-1로 정의하고 있다. 그렇기 때문에 다음과 같은 메세지는 한글 텍스트가 들어가 있음에도 불구하고, 클라이언트가 ISO 8859-1로 해석해 문자가 깨질 가능성이 있다.\n한글 텍스트임에도 불구하고 ISO 8859-1이 적용되는 예 HTTP/1.1 200 OK Content-Type: text/plain 한글 텍스트  더욱 까다로운 것은 XML 처럼 문서 자체에서 문자 인코딩 방식을 선언할 수 있는 경우라도, text 타입의 경우에는 Content-Type 헤더의 charset 파라미터를 우선한다는 것이다.\nXML이 선언한 문자 인코딩 지정을 무시하는 예 HTTP/1.1 200 OK Content-Type: text/html \u0026lt;?xml version=“1.0” encoding=“utf-8”?\u0026gt; \u0026lt;test\u0026gt;한글 텍스트\u0026lt;/test\u0026gt;  이 문제는 text타입인 경우에 반드시 charset 파라미터를 붙이도록 하면 해결된다. 또한 XML 문서의 경우에는 text/html을 사용하지 않고, application/xml이나 application/xhtml+xml과 같은 파라미터를 이용하고, 반드시 charset 파라미터를 붙이는 것이 현시점에서는 가장 바람직한 운용방법이다.\n바르게 문자 인코딩을 지정한 예 HTTP/1.1 200 OK Content-Type: application/xml; charset=utf-8 \u0026lt;?xml version=“1.0” encoding=“utf-8”?\u0026gt; \u0026lt;test\u0026gt;한글 텍스트\u0026lt;/test\u0026gt;  주요 서브타입\ntext/plain text/csv text/css text/html text/xml XML 문서(비추천) image/jpeg image/gif image/png application/xml application/xhtml+xml application/atom+xml Atom 문서 application/atomsvc+xml Atom의 서비스 문서 application/atomcat+xml Atom의 카테고리 문서 application/javascript application/json application/msword application/vnd.ms-excel application/vns.ms-powerpoint application/pdf application/zip application/x-shockwave-flash application/x-www-form-urlencoded HTML 폼 형식  Content Negotiation\n지금까지 설명했던 미디어 타입과 문자 인코딩, 언어 태그는 서버가 일방적으로 결정하는 것 뿐만 아니라, 클라이언트와 교섭해서 정할 수도 있다. Accept - 처리할 수 있는 미디어 타입을 전달한다.\nAccept: text/html, application/xhtml+xml, application/xml; q=0.9,*/*;q=0.8  q=이라는 파라미터의 값을 qvalue라고 하며, 그 미디어 타입의 우선순위를 나타낸다. qvalue는 소수점 이하 세 자리 이내의 0~1까지의 수치이며 수치가 더 큰 쪽을 우선한다. 이 예의 경우, text/html, application/xhtml+xml이 디폴트인 1, application/xml이 0.9, 그 밖의 모든 미디어 타입(*/*)이 0.8이라는 우선도를 가진다.\n클라이언트가 Accept 헤더에 지정한 미디어 타입에 서버가 대응하고 있지 않다면 406 Not Acceptable이 반환된다.\nContent-Length와 청크(chunk) 전송\n메세지의 바디가 있는 경우 기본적으로 Content-Length 헤더를 이용해 그 사이즈를 10진수의 바이트로 나타낸다. 미리 사이즈를 알고 있는 리소스인 정적인 파일 등을 전송할 때는 Content-Length 헤더를 이용하는 것이 간단하다.\n하지만 동적으로 이미지를 생성하는 웹 서비스의 경우, 파일 사이즈가 정해질 때까지 응답할 수 없기 때문에 응답성능이 저하된다. 이때 사용하는 것이 Transfer-Encoding 헤더다.\nTransfer-Encoding: chunked  Transfer-Encoding 헤더에 Chunked를 지정하면 최종적으로는 사이즈를 모르는 바디를 조금씩 전송할 수 있다. 다음 예에서는 ‘The brown fox jumps quickly over the lazy dog’이라는 46바이트의 문자열을 16바이트 청크 2개와 14바이트 청크 1개로 분할하여 POST한다.\nPOST /test HTTP/1.1 Host: example.com Transfer-Encoding: chunked Content-Type: Text/plain; charset=utf-8 10 The brow fox ju 10 maps quickly over e the lazy dog. 0 (여기에도 빈 줄)  마지막에는 반드시 길이가 0인 청크와 빈 줄을 붙이도록 스펙에서 규정하고 있다.\n인증\n현재 주류인 HTTP 인증 방식에는 HTTP 1.1이 규정하고 있는 Basic 인증과 Digest 인증이 있다. 또한 웹 API에서는 WSSE(WS-Security Extension)라는 HTTP 인증의 확장 스펙을 이용하는 경우도 있다.\n어떤 리소스에 액세스 제어가 걸려 있는 경우, status code 401 Unauthorized(이 리소스에 접근하려면 적절한 인증이 필요)와 WWW-Authenticate 헤더를 이용해 클라이언트에 리소스 접근에 필요한 인증정보를 통지할 수 있다.\n요청 DELETE /test HTTP/1.1 Host: example.com 응답 HTTP/1.1 401 Unauthorized WWW-Authenticate: Basic realm=“Example.com\u0026quot;  WWW-Authenticate 헤더에 의해 클라이언트는 서버가 제공하는 인증 방식을 이해할 수 있게 되고 그 방식을 따른 형식으로 인증 정보를 보낼 수 있다. 위의 예에서는 이 서버가 Basic 인증을 지원하고 있다는 것을 알 수 있다. ‘realm’은 서버 상에서 이 리소스가 속한 URI 공간의 이름이 된다.\ncf) Basic, Digest 인증 모두 패스워드만 암호화할 뿐이기 때문에 메세지 자체는 평문으로 네트워크를 흘러간다. 따라서 메세지도 암호화하고 싶을 때는 HTTPS를 이용해야 한다.\n캐시\n클라이언트는 서버에서 가져온 리소스의 캐시 가능 여부를 조사하고 가능한 경우는 로컬 스토리지에 저장한다. 어떤 리소스가 캐시 가능한지는 그 리소스를 취득했을 때의 헤더로 판단한다. 리소스가 캐시 가능한지, 그 유효기간이 언제까지인지는 Pragma, Expire, Cche-Control 헤더를 이용해 서버가 지정한다.\nPragma - 캐시를 억제한다 HTTP/1.1 200 OK Content-Type: application/xhtml+xml, charset=utf-8 Pragma: no-cache  Expires - 캐시의 유효기간을 나타낸다 HTTP/1.1 200 OK Content-Type: application/xhtml+xml, charset=utf-8 Expires: Thu, 11 May 2010 16:00:00 GMT  이 응답에는 2010년 5월 11일 16시까지는 캐시가 유효하다는 것을 서버가 보증하고 있다. 리소스가 변경할 가능성이 없는 경우는 캐시의 유효기간을 무한으로 설정하고 싶겠지만 그런 경우라도 최장 약 1년 이내로 일시를 넣을 것을 스펙에서는 권장한다.\nPragma 헤더와 Expires 헤더는 HTTP 1.0이 정의한 헤더다. 간단한 캐시는 이들로 구현할 수 있지만 복잡한 지정은 할 수 없다. 그래서 HTTP 1.1에서는 Cache-Control 헤더를 추가했다. 따라서 Pragma 헤더와 Expires 헤더의 기능은 Cache-Control 헤더로 완전히 대응할 수 있다.\nPragma: no-cache 와 Cache-Control: no-cache 는 같다.  캐시를 시키지 않을 경우는 Pragma와 Cache-Control의 no-cache를 동시에 지정한다.\n또한 Expires에서는 절대시간으로 유효기간을 표시했는데 Cache-Control에서는 현재로부터의 상대시간으로 유효기간을 설정할 수 있다. 아래의 예는 86400초, 즉 현재로부터 24시간 캐시가 유효하다는 것을 의미한다.\nCache-Control: max-age: 86400  조건부 GET\nGET /test HTTP/1.1 Host: example.com If-Modified-Since: Thu, 11 May 2010 16:00:00 GMT  서버의 리소스가 Thu, 11 May 2010 16:00:00 GMT 이후로 변경되지 않았다면 다음과 같은 응답을 보낸다.\nHTTP/1.1 304 Not Modified Content-Type: application/xhtml+xml, charset=utf-8 Last-Modified: Thu, 11 May 2010 16:00:00 GMT  이 응답에는 바디가 포함되지 않기 때문에 그만큼 네트워크 대역을 절약할 수 있다.\nIf-Modified-Since 헤더와 Last-Modified 헤더에 의한 조건부 GET은 편리하지만, 시계를 가지고 있지 않은 서버와 밀리 초 단위로 변경될 가능성이 있는 리소스에는 이용할 수 없다. 그 경우 이용하는 것이 If-None-Match 헤더와 ETag(엔티티 태그)헤더다.\nGET /test2 HTTP/1.1 Host: example.com If-None-Match: ab3322028  If-None-Match 헤더는 ‘지정한 값과 매치하지 않으면’이라는 조건이 된다. If-None-Match 헤더에 지정하는 값은 캐시하고 있는 리소스의 ETag 헤더의 값이다. 서버상의 리소스가 변경되어 있지 않으면 다음의 응답을 반환한다.\nHTTP/1.1 304 Not Modified Content-Type: application/xhtml+xml, charset=utf-8 ETag: ab3322028  ETag는 리소스의 갱신 상태를 비교하기 위해서만 사용하는 문자열이다. 리소스를 갱신했을 때 다른 값이 되는 것이면 어떤 문자라도 상관없다.\nJSON JavaSript Object Notation의 약자로 데이터 표현 형식 중 하나이다.\nJSON의 미디어 타입은 application/json이다. JSON은 스펙 상 UTF-8, UTF-16, UTF-32 중 하나로 인코딩하도록 되어 있다. 따라서 HTTP 헤더 등의 미디어 타입에서 파라미터로 지정할 수 있다.\nContent-Type: application/json; charset=utf-8  cf) front에서 AJAX 통신할 때\n$.ajax({ type: 'get', url: '/message/random', contentType: 'application/json', dataType: 'json', success: function (data) { }, error: function(data){ } });  contentType 을 통해서 json형식이라는 것을 알리고 response로 받아오는 데이터도 json이라는 것을 dataType을 통해 명시한다.\nJSON 자료형은 object, array, string, number, boolean, null 이렇게 총 6가지가 있다. JSON의 문자열은 반드시 이중인용부호(\u0026ldquo;)로 감싸준다.\nJSON에 의한 크로스 도메인 통신\nJSON으로 리소스 표현을 제공하는 부차적 효과로서, JSONP(JSON with PAdding)을 이용할 수 있다. JSONP가 필요하게 된 배경부터 설명하면, Ajax에서 이용하는 XMLHttpRequest라는 JavaScript의 모듈은 보안상의 제한으로 인해 JavaScript 파일을 가져왔던 동일한 서버하고만 통신할 수 있다. JavaScript가 있는 서버와 다른 서버가 통신할 수 있다면 브라우저에서 입력한 정보를 사용자가 모르는 사이에 부정한 서버로 전송할 수 있게 되기 때문이다.\n이와 관련해, 이렇게 불특정 다수의 도메인에 속하는 서버에 액세스하는 것을 \u0026lsquo;크로스 도메인 통신\u0026rsquo;이라고 부른다. 복수 도메인의 서버와 통신할 수 없고 단일 도메인과만 통신해야 한다는 것은 커다란 제약이다. 예를 들어, 우리 서비스에서 데이터를 직접 들고 있지 않고 다른 웹 API를 통해 받아올 수 없기 때문이다.\nXMLHttpRequest에서는 크로스 도메인 통신을 할 수 없지만 대체 수단이 있다.\n\u0026lt;html xmlns=\u0026quot;http://www.w3.org/1999/xhtml\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;script src=\u0026quot;http://example.jp/map.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026quot;http://example.jp/zip.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; ... \u0026lt;/head\u0026gt; \u0026lt;/html\u0026gt;  HTML의 script 요소를 이용하면 복수의 사이트에서 JavaScript 파일을 읽을 수 있다. script 요소는 역사적인 이유에서 일반적으로 브라우저의 보안제한을 받지 않는다.\nJSONP는 브라우저의 이런 성질을 이용해 크로스 도메인 통신을 구현하는 방법이다. JSONP에서는 오리지널 JSON을 클라이언트가 지정한 콜백 함수명으로 랩핑하여 도메인이 다른 서버로부터 데이터를 취득한다.\n\u0026lt;html xmlns=\u0026quot;http://www.w3.org/1999/xhtml\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;크로스 도메인 통신의 예\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;script type=\u0026quot;text/javascript\u0026quot;\u0026gt; function foo(zip){ alert(zip[\u0026quot;zipcode\u0026quot;]); } \u0026lt;/script\u0026gt; \u0026lt;script src=\u0026quot;http://zip.ricollab.jp/1120002.json?callback=foo\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  브라우저에서 이 html파일을 렌더링하면 두번째 script 요소인 JSONP의 URI를 자동적으로 GET하여 다음 통신이 수행된다.\n요청 GET /1120002.json?callback=foo HTTP/1.1 Host: zip.ricollab.jp  응답 HTTP/1.1 200 OK Content-Type: application/javascript foo({ \u0026quot;zipcode\u0026quot;: \u0026quot;1120002\u0026quot;, \u0026quot;address\u0026quot;: { \u0026quot;prefecture\u0026quot;: \u0026quot;도쿄도\u0026quot;, \u0026quot;city\u0026quot;: \u0026quot;분쿄구\u0026quot;, \u0026quot;town\u0026quot;: \u0026quot;코이시카와\u0026quot; }, \u0026quot;yomi\u0026quot;:{ \u0026quot;prefecture\u0026quot;: \u0026quot;토우쿄우토\u0026quot;, \u0026quot;city\u0026quot;: \u0026quot;분쿄우쿠\u0026quot;, \u0026quot;town\u0026quot;: \u0026quot;코이시카와\u0026quot; } });  요청한 URI에는 callback이라는 쿼리 파라미터에서 콜 백 함수로 foo를 지정하고 있기 때문에 응답의 바디에는 foo 함수를 호출하는 JavaScript의 코드가 들어 있다. foo 함수의 인수로는 요청 URI에서 지정한 우편번호인 1120002가 JSON으로 들어 있다. 이에 따라 첫 번째 script 요소에서 정의한 foo 함수를 1120002라는 우편번호 정보를 인수로 하여 호출하고, 결과로 브라우저가 1120002라는 알림창을 표시한다.\nfoo함수를 정의한 HTML 파일은 우편번호 정보를 zip.ricollab.jp에서 가져오고 있다는 점을 주목하자. 이것이 JSONP로 크로스 도메인 통신을 구현하는 방법이다. 이 예에서는 콜백 함수를 지정한 script 요소를 HTML에 직접 삽입하고 있지만, 보통은 사용자의 입력에 대응해 JavaScript로 HTML을 조적해서 동적으로 삽입한다.\n리다이렉트 / 포워딩 / 세션 / 쿠키 포워딩 : Web Container 차원에서 페이지 이동만 있다. 실제로 웹 브라우저는 다른 페이지로 이동했음을 알 수 없다. 그렇기 때문에 웹 브라우저에는 최초에 호출한 URL이 표시되고 이동한 페이지의 URL 정보는 볼 수 없다. 동일한 웹 컨테이너에 있는 페이지로만 이동할 수 있다.\n리다이렉트 : Web Container는 Redirect 명령이 들어오면 웹 브라우저에게 다른 페이지로 이동하라고 명령을 내린다.(response header인 location에 리다이렉트될 주소 적어서 보낸다) 그러면 웹 브라우저는 URL을 지시된 주소로 바꾸고 그 주소로 이동한다. 다른 Web Container에 있는 주소로 이동이 가능하다.\n세션 : 방문자의 요청에 따른 정보를 방문자 메모리에 저장하는 것이 아닌 웹 서버가 세션 아이디 파일을 만들어 서비스가 돌아가고 있는 서버에 저장하는 것이다. 즉 프로세스들 사이에서 통신을 하기 위해 메세지 교환을 통해 서로를 인식한 이후부터 통신을 마칠때까지의 기간 동안 서버에 잠시 방문자 정보를 저장 한다는 것. (웹사이트에 방문하여 계속 접속을 유지할 때 이전의 접속 정보를 이용할 수 있는 방법으로 많이 사용)\n쿠키 : 특정 웹 사이트를 방문 했을 때 만들어지는 정보를 담는 파일을 지칭(상태정보를 유지하는 기술). ex) 방문 했던 사이트에 다시 방문 하였을 때 아이디와 비밀번호 자동 입력, 팝업에서 “오늘 이 창을 다시 보지 않음” 체크\n"
},
{
	"uri": "/%E1%84%8B%E1%85%B0%E1%86%B8_%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%80%E1%85%B3%E1%84%85%E1%85%A2%E1%84%86%E1%85%A5%E1%84%85%E1%85%B3%E1%86%AF_%E1%84%8B%E1%85%B1%E1%84%92%E1%85%A1%E1%86%AB_%E1%84%89%E1%85%A5%E1%84%87%E1%85%B3%E1%86%AF%E1%84%85%E1%85%B5%E1%86%BA_%E1%84%8F%E1%85%A5%E1%86%AB%E1%84%90%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%82%E1%85%A5%E1%84%8B%E1%85%B4_%E1%84%8B%E1%85%B5%E1%84%92%E1%85%A2/",
	"title": "웹프로그래머를 위한 서블릿 컨테이너의 이해",
	"tags": [],
	"description": "",
	"content": " WAS는 클라이언트와 서버 간의 소켓 통신에 필요한 TCP/IP 연결 관리와 HTTP 프로토콜 해석 등의 네트워크 기반 작업을 추상화해 일종의 실행 환경을 제공한다. 따라서 웹 프로그래머는 TCP/IP 연결을 직접 생성하고 HTTP 프로토콜을 해석하는 과정을 생략해 웹을 쉽게 구현할 수 있다. 결국 관련 기술을 깊이 알지 못한 채로 WAS가 제공하는 추상화된 API로 네트워크에 접근한다.\nWAS가 \u0026ldquo;복잡한 실제 작업을 적절히 추상화해 사용하기 편하게 한다\u0026rdquo; 개념을 성공적으로 충족하면서, 이를 사용하는 웹 기반 프로그래밍은 오히려 별것 아니다는 평판을 얻었다. 하지만 웹 기반으로 제공되는 서비스의 영역은 지속적으로 넓어지고 있으며, 규모는 거대해지고 있다. WAS의 내부구조와 동작 원리를 이해하지 못하면 고성능, 고가용성에 대한 요구를 충족시킬 수 없다.\n서블릿의 이해 원칙적으로 javax.servlet.Servlet 인터페이스를 구현한 것이 서블릿이다. 서블릿은 서블릿 컨테이너 내에 등록된 후 서블릿 컨테이너에 의해 생성, 호출, 소멸이 이뤄진다. 다시 말해, 서블릿은 독립적으로 실행되지 않고 main 메서드가 필요하지 않으며 서블릿 컨테이너에 의해 서블릿의 상태가 바뀐다.\n때때로 서블릿은 자신의 상태 변경 시점을 알아내 적절한 리소스 획득/반환 등의 처리를 해야 하므로 Servlet 인터페이스에 init/destroy 메서드가 정의된다. GenericServlet public abstract class GenericServlet implements Servlet, ServletConfig, java.io.Serializable { } 서블릿 인터페이스만 구현하면 서블릿 컨테이너가 생성, 소멸 등의 생명주기 관리작업을 수행할 수 있다. 그런데 서블릿 컨테이너가 서블릿 관리를 위해 필요한 기능은 서블릿 스펙에 모두 정의돼 있으므로 서블릿 명세는 서블릿에 필요한 구현을 미리 작성해 GenericServlet이란 이름으로 제공한다. 이 GenericServlet 클래스는 추상 클래스지만, service 메서드를 제외하고는 모두 구현된 일종의 서블릿을 위한 어댑터 역할을 제공한다. 따라서 서블릿을 작성하는 프로그래머들은 반복적으로 동일한(서블릿 컨테이너의 관리를 받으려고) 서블릿 인터페이스를 구현하는 대신 GenericServlet을 상속해서 사용한다.\nHttpServlet public abstract class HttpServlet extends GenericServlet { } 일반적으로 서블릿이라 하면 거의 대부분 이 HttpServlet을 상속받은 서블릿을 의미한다. HttpServlet은 GenericServlet을 상속받으며, GenericServlet의 유일한 추상 메서드인 service를 HTTP 프로토콜 요청 메서드에 적합하게 재구현한 것이다. 서블릿 컨테이너는 받은 요청에 대해 서블릿을 선택한 후 Servlet 인터페이스에 정의된 service(ServletRequest, ServletResponse)를 호출한다. 그러면 클래스 상속 위계에 따라 그 처리가 부모 클래스인 GenericServlet에서 자식 클래스인 HttpServlet으로 넘어온다. HttpServlet의 service 메서드 내에서는 HTTP 요청 메서드에 의해 여러 doXXX 메서드로 분기돼 처리된다.\nprotected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { String method = req.getMethod(); if (method.equals(METHOD_GET)) { long lastModified = getLastModified(req); if (lastModified == -1) { // servlet doesn\u0026#39;t support if-modified-since, no reason  // to go through further expensive logic  doGet(req, resp); } else { long ifModifiedSince = req.getDateHeader(HEADER_IFMODSINCE); if (ifModifiedSince \u0026lt; lastModified) { // If the servlet mod time is later, call doGet()  // Round down to the nearest second for a proper compare  // A ifModifiedSince of -1 will always be less  maybeSetLastModified(resp, lastModified); doGet(req, resp); } else { resp.setStatus(HttpServletResponse.SC_NOT_MODIFIED); } } } else if (method.equals(METHOD_HEAD)) { long lastModified = getLastModified(req); maybeSetLastModified(resp, lastModified); doHead(req, resp); } else if (method.equals(METHOD_POST)) { doPost(req, resp); } else if (method.equals(METHOD_PUT)) { doPut(req, resp); } else if (method.equals(METHOD_DELETE)) { doDelete(req, resp); } else if (method.equals(METHOD_OPTIONS)) { doOptions(req,resp); } else if (method.equals(METHOD_TRACE)) { doTrace(req,resp); } else { //  // Note that this means NO servlet supports whatever  // method was requested, anywhere on this server.  //  String errMsg = lStrings.getString(\u0026#34;http.method_not_implemented\u0026#34;); Object[] errArgs = new Object[1]; errArgs[0] = method; errMsg = MessageFormat.format(errMsg, errArgs); resp.sendError(HttpServletResponse.SC_NOT_IMPLEMENTED, errMsg); } } Apache Tomcat Apache Tomcat은 오픈소스 서블릿 컨테이너다.\ncf) 자바고양이 톰캣이야기(최진식 저) 초창기 Tomcat은 Apache Jakarta 프로젝트 하위에 있었기 때문에 Jakarta Tomcat으로 불렸다(Jakarta 라는 이름은 과거 Sun Microsystems의 회의실 명에서 유래했다는 설이 있다). Catalina는 과거 Tomcat 코드네임이었고 지금은 Tomcat 코어 엔진을 뜻하는 단어다. Tomcat에서 가장 중요한 환경 변수 또한 $CATALINA_HOME과 $CATALINA_BASE다.\ncatalina.sh\n# Add on extra jar files to CLASSPATH if [ ! -z \u0026quot;$CLASSPATH\u0026quot; ] ; then CLASSPATH=\u0026quot;$CLASSPATH\u0026quot;: fi CLASSPATH=\u0026quot;$CLASSPATH\u0026quot;\u0026quot;$CATALINA_HOME\u0026quot;/bin/bootstrap.jar if [ -z \u0026quot;$CATALINA_OUT\u0026quot; ] ; then CATALINA_OUT=\u0026quot;$CATALINA_BASE\u0026quot;/logs/catalina.out fi if [ -z \u0026quot;$CATALINA_TMPDIR\u0026quot; ] ; then # Define the java.io.tmpdir to use for Catalina CATALINA_TMPDIR=\u0026quot;$CATALINA_BASE\u0026quot;/temp fi # Add tomcat-juli.jar to classpath # tomcat-juli.jar can be over-ridden per instance if [ -r \u0026quot;$CATALINA_BASE/bin/tomcat-juli.jar\u0026quot; ] ; then CLASSPATH=$CLASSPATH:$CATALINA_BASE/bin/tomcat-juli.jar else CLASSPATH=$CLASSPATH:$CATALINA_HOME/bin/tomcat-juli.jar fi  톰캣이 시작될 때 jar 파일 두 개만 클래스패스에 지정돼 있으므로 우리가 만든 XXXServlet을 찾을 방법이 필요하며 그것을 배치(deploy)라 한다. 다시말해 배치(deploy)는 서블릿을 포함한 웹 애플리케이션을 서블릿 컨테이너에 알려주는 과정이다.\n톰캣 서버는 시작할 때 webapps 디렉토리 아래에서 새로운 웹 애플리케이션을 탐색한다.\ncf)\n\u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-war-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;webappDirectory\u0026gt;deploy\u0026lt;/webappDirectory\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 위와 같이 webapps 디렉토리 안에 deploy 디렉토리를 넣어주면 톰캣 서버는 디렉토리 안에 있는 웹 애플리케이션 구조를 자동으로 인식하므로 톰캣이 구동될 때 톰캣 서버에 배치(deploy)된다.\n웹 애플리케이션은 서블릿 스펙에 정의된 특정한 구조를 가진 디렉토리 혹은 디렉토리 압축 파일이므로 서블릿 컨테이너는 해당 웹 애플리케이션이 가진 서블릿의 위치를 알 수 있다.\n서블릿 컨테이너 부팅 과정에서 벌어지는 일들 톰캣 서블릿 컨테이너 시작 클래스인 Bootstrap의 main 메서드이다.\n/** * Main method and entry point when starting Tomcat via the provided * scripts. * * @param args Command line arguments to be processed */ public static void main(String args[]) { if (daemon == null) { // Don\u0026#39;t set daemon until init() has completed  Bootstrap bootstrap = new Bootstrap(); try { bootstrap.init(); } catch (Throwable t) { handleThrowable(t); t.printStackTrace(); return; } daemon = bootstrap; } else { // When running as a service the call to stop will be on a new  // thread so make sure the correct class loader is used to prevent  // a range of class not found exceptions.  Thread.currentThread().setContextClassLoader(daemon.catalinaLoader); } try { String command = \u0026#34;start\u0026#34;; if (args.length \u0026gt; 0) { command = args[args.length - 1]; } if (command.equals(\u0026#34;startd\u0026#34;)) { args[args.length - 1] = \u0026#34;start\u0026#34;; daemon.load(args); daemon.start(); } else if (command.equals(\u0026#34;stopd\u0026#34;)) { args[args.length - 1] = \u0026#34;stop\u0026#34;; daemon.stop(); } else if (command.equals(\u0026#34;start\u0026#34;)) { daemon.setAwait(true); daemon.load(args); daemon.start(); } else if (command.equals(\u0026#34;stop\u0026#34;)) { daemon.stopServer(args); } else if (command.equals(\u0026#34;configtest\u0026#34;)) { daemon.load(args); if (null==daemon.getServer()) { System.exit(1); } System.exit(0); } else { log.warn(\u0026#34;Bootstrap: command \\\u0026#34;\u0026#34; + command + \u0026#34;\\\u0026#34; does not exist.\u0026#34;); } } catch (Throwable t) { // Unwrap the Exception for clearer error reporting  if (t instanceof InvocationTargetException \u0026amp;\u0026amp; t.getCause() != null) { t = t.getCause(); } handleThrowable(t); t.printStackTrace(); System.exit(1); } } Bootstrap 클래스를 생성하고 init 메서드를 호출해 초기화한다. 멤버 변수인 daemon에 방금 생성한 Bootstrap 인스턴스를 할당한다. 이후 main 메서드의 args 배열로 전달받은 명령행 인자 값에 따라 Bootstrap 클래스의 인스턴스인 daemon의 load, start, stop 등의 메서드가 호출된다.\n만약 예외가 발생하지 않았다면 main 메서드는 종료된다. 따라서 프로그램은 종료돼야 한다. 하지만 수많은 웹 사이트가 톰캣 서블릿 컨테이너로 서비스한다. 지금까지 지나쳐 온 여러 메서드(init, load, start 등)에 서블릿 컨테이너를 종료하지 않고 HTTP 요청을 받아들일 수 있게 소켓을 열고, 서블릿을 초기화하며 스레드를 관리하는 등 웹 서비스를 동작하게 하는 기능이 있으리라 짐작할 수 있을 것이다. 먼저 init 메서드를 알아보자.\n/** * Initialize daemon. * @throws Exception Fatal initialization error */ public void init() throws Exception { initClassLoaders(); Thread.currentThread().setContextClassLoader(catalinaLoader); SecurityClassLoad.securityClassLoad(catalinaLoader); // Load our startup class and call its process() method  if (log.isDebugEnabled()) log.debug(\u0026#34;Loading startup class\u0026#34;); Class\u0026lt;?\u0026gt; startupClass = catalinaLoader.loadClass (\u0026#34;org.apache.catalina.startup.Catalina\u0026#34;); Object startupInstance = startupClass.newInstance(); // Set the shared extensions class loader  if (log.isDebugEnabled()) log.debug(\u0026#34;Setting startup class properties\u0026#34;); String methodName = \u0026#34;setParentClassLoader\u0026#34;; Class\u0026lt;?\u0026gt; paramTypes[] = new Class[1]; paramTypes[0] = Class.forName(\u0026#34;java.lang.ClassLoader\u0026#34;); Object paramValues[] = new Object[1]; paramValues[0] = sharedLoader; Method method = startupInstance.getClass().getMethod(methodName, paramTypes); method.invoke(startupInstance, paramValues); catalinaDaemon = startupInstance; } 주목해야 하는 곳은 initClassLoaders 메서드다.\nprivate void initClassLoaders() { try { commonLoader = createClassLoader(\u0026#34;common\u0026#34;, null); if( commonLoader == null ) { // no config file, default to this loader - we might be in a \u0026#39;single\u0026#39; env.  commonLoader=this.getClass().getClassLoader(); } catalinaLoader = createClassLoader(\u0026#34;server\u0026#34;, commonLoader); sharedLoader = createClassLoader(\u0026#34;shared\u0026#34;, commonLoader); } catch (Throwable t) { handleThrowable(t); log.error(\u0026#34;Class loader creation threw exception\u0026#34;, t); System.exit(1); } } 이 메서드는 모두 세 개의 클래스로더를 생성한다. 생성하는 클래스로더는 common, server, shared다. common 클래스로더는 루트 클래스로더로, 부모가 없는 최상위 클래스로더다. server와 shared 클래스로더는 common 클래스로더를 부모 클래스로더로 가진다(shared나 server 클래스로더에 로딩된 클래스는 상위 클래스로더인 common 클래스로더에 로딩된 클래스에 접근할 수 있다). common, shared, server 클래스로더는 catalina.properties 파일에 정의된 디렉토리의 jar 파일을 읽어들여, 파일 안에 포함된 클래스를 로딩한다.\ncommon.loader=${catalina.base}/lib,${catalina.base}/lib/*.jar,${catalina.home}/lib,${catalina.home}/lib/*.jar ... server.loader= ... shared.loader= ...  기본으로 제공되는 catalina.properties에는 common 클래스로더만 설치 디렉토리 아래 lib 디렉토리로 지정되어 있고, shared, server 클래스로더는 위치가 지정되어 있지 않다. 따라서 설정을 변경하지 않으면 shared나 server 클래스로더에 아무런 영향이 없다.\nThread.currentThread().setContextClassLoader(catalinaLoader)는 지금까지 설정한 클래스로더를 현재 클래스로더로 바꾼다. 이부분은 특별히 강조할 만한 가치가 있다. 앞서 살펴본 톰캣 구동 스크립트를 다시 한번 살펴보면 클래스 패스에 jar 파일 두 개만 설정됐었다(catalina.sh에서 bootstrap.jar와 tomcat-juli.jar).\n그렇다면 jar 파일 이외의 라이브러리는 어떻게 사용할 수 있을까? 그보다 먼저 서블릿 인터페이스는 lib 디렉토리 아래 servlet-api.jar에 포함되어 있다. 클래스패스에 포함되어 있지 않다면 서블릿 컨테이너는 서블릿 인터페이스를 어떻게 알고 사용할 수 있을까?\n웹 애플리케이션 하나가 서블릿 컨테이너 안으로 배치(deploy)되면 서블릿 컨테이너는 먼저 해당 웹 애플리케이션 전용 클래스로더를 생성한다. 그후 WEB-INF/classes 디렉토리와 WEB-INF/lib 디렉토리 내에 있는 클래스파일과 .jar 아카이브 파일들을 해당 클래스로더를 사용해 로딩한다. 그리고 Bootstrap 클래스의 initClassLoaders() 메서드를 통해 catalina.properties 파일에 정의된 디렉토리의 jar 파일들을 읽어들여 common 클래스로더를 로딩한다(여기에 servlet-api.jar가 있다). 그리고 웹 애플리케이션을 호출하는 HTTP 요청이 들어왔을 때 WEB-INF/web.xml에 정의된 서블릿 매핑에 따라서 웹 애플리케이션 클래스로더에서 서블릿을 찾아 요청을 전달(해당 인스턴스의 service 메서드 호출)한다.\ncf) Understanding The Tomcat Classpath\nhttps://www.mulesoft.com/tcat/tomcat-classpath 톰캣이 어떻게 classpath를 reslove하는지 이해하기 위해 startup process를 살펴보자.\n JVM bootstrap loader가 코어 자바 라이브러리들을 로드한다(JVM은 JAVA_HOME 변수를 사용하여 코어 라이브러리들을 찾는다).\n Startup.sh는 \u0026ldquo;start\u0026rdquo; 파라미터와 함께 Catalina.sh를 호출해서 system classpath를 overwrites하고 bootstrap.jar와 tomcat-juli.jar를 로드한다. 이러한 리소스들은 톰캣에서만 볼 수 있다.\n Class loader들은 각각 deployed Context로 만들어진다. deployed Context는 각 web 애플리케이션의 WEB-INF/classes 와 WEB-INF/lib에 있는 모든 클래스들과 JAR 파일들을 순서대로 로드한다. 이러한 리소스들은 그것들을 로드한 웹 애플리케이션에서만 볼 수 있다.\n The Common class loader는 $CATALINA_HOME/lib에 있는 모든 클래스들과 JAR 파일들을 로드한다. 이러한 리소스들은 톰캣과 모든 애플리케이션에서 볼 수 있다.\n  cf) 컴파일 때는 직접 의존성을 참조하고, 런타임 때는 톰캣에 있는 servlet-api.jar를 참조하도록 provided 스코프를 지정한다.\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.servlet\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;servlet-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0.1\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 이제 실질적인 톰캣 서버 클래스인 카탈리나 클래스를 찾아 로딩을 시작한다.\npublic void init() throws Exception { // 생략  Class\u0026lt;?\u0026gt; startupClass = catalinaLoader.loadClass (\u0026#34;org.apache.catalina.startup.Catalina”); 이후 Bootstrap 클래스의 load, start, stop 메서드가 불리지만 내부적으로는 catalinaDaemon, 즉 Catalina 클래스에 있는 같은 이름의 메서드가 호출된다. 카탈리나 클래스를 클래스로더에서 로딩한 후 startup 인스턴스를 만든다.\nClass\u0026lt;?\u0026gt; startupClass = catalinaLoader.loadClass (\u0026#34;org.apache.catalina.startup.Catalina\u0026#34;); Object startupInstance = startupClass.newInstance();public class Catalina { /** * Start a new server instance. */ public void start() { if (getServer() == null) { load(); } if (getServer() == null) { log.fatal(\u0026#34;Cannot start server. Server instance is not configured.\u0026#34;); return; } long t1 = System.nanoTime(); // Start the new server  try { getServer().start(); } catch (LifecycleException e) { log.fatal(sm.getString(\u0026#34;catalina.serverStartFail\u0026#34;), e); try { getServer().destroy(); } catch (LifecycleException e1) { log.debug(\u0026#34;destroy() failed for failed Server \u0026#34;, e1); } return; } 이렇게 부팅 과정을 관리하는 클래스(Bootstrap)의 서버 역할을 수행하는 클래스(Catalina)를 분리해 놓으면 추후 서버 클래스 개선이 필요할 때 Bootstrap 클래스의 변경을 최소화하면서 서버 역할 수행 클래스를 교체할 수 있다.\n생명주기 관리 톰캣 서블릿 컨테이너를 사용한 경험이 있는 웹 프로그래머라면 한 번쯤 config 디렉토리 안에 있는 XML 파일이 어떤 의미가 있으며, 어떤 시점에 어떻게 로딩되는지 의문을 가졌을 것이라 생각한다. 이런 설정 값을 읽어들이는 과정은 바로 Catalina 클래스의 load 메서드에서 찾아볼 수 있다.\n/** * Start a new server instance. */ public void load() { long t1 = System.nanoTime(); initDirs(); // Before digester - it may be needed  initNaming(); // Create and execute our Digester  Digester digester = createStartDigester(); // 설정 파일을 개체화해 접근할 수 있도록 한다.  InputSource inputSource = null; InputStream inputStream = null; File file = null; try { try { file = configFile(); //conf/server.xml  inputStream = new FileInputStream(file); inputSource = new InputSource(file.toURI().toURL().toString()); } catch (Exception e) { … 이하 생략 톰캣 서블릿 컨테이너는 Digester를 사용해 부팅 시 설정 파일을 객체화해 접근하는 방식을 지원한다. 그러므로 server.xml 파일이 로딩되면 XML 태크게 해당하는 객체가 생성된다. 톰캣 서블릿 컨테이너는 설정 파일에 지정된 객체들을 시동 시, 자동으로 생성될 뿐만 아니라 유지, 관리, 소멸 등의 생명주기를 관리함으로써 동작 중인 서버를 재시동하지 않고서 기능 변경을 하는 방법을 제공한다.\n정리하면 사용자가 설정 파일에 정의한 각 XML element는 Digester에 의해 서버 객체로 변경돼 로딩되며, 이런 객체는 Lifecycle 인터페이스를 구현했으므로 프로그래밍적으로 초기화, 시작, 종료, 소멸 등을 컨트롤할 수 있다는 의미가 된다.\n"
},
{
	"uri": "/%E1%84%8C%E1%85%A1%E1%84%87%E1%85%A1%E1%84%8B%E1%85%B4_%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%89%E1%85%A5%E1%86%A8/",
	"title": "자바의 정석",
	"tags": [],
	"description": "",
	"content": " Chapter 1 자바를 시작하기 전에 동적 로딩(Dynamic Loading)을 지원한다.\n자바로 작성된 애플리케이션은 여러 개의 클래스로 구성되어 있다. 자바는 동적 로딩을 지원하기 때문에 실행 시에 모든 클래스가 로딩되지 않고 필요한 시점에 클래스를 로딩하여 사용할 수 있다는 장점이 있다. 또한 일부 클래스가 변경되어도 전체 애플리케이션을 다시 컴파일 하지 않아도 되며, 애플리케이션의 변경사항이 발생해도 비교적 적은 작업만으로도 처리할 수 있다.\njavac.exe\n자바 컴파일러, 자바소스코드를 bytecode로 컴파일한다.\njava.exe(JIT 컴파일러)\n자바 인터프리터, 컴파일러가 생성한 bytecode를 해석하고 실행한다.\nJRE(자바실행환경) = JVM + Java API(클래스 라이브러리)\nJDK(자바개발도구) = JRE + 개발에 필요한 실행파일(javac.exe 등)\nChapter 2 변수 리터럴\n그 자체로 데이터인 것을 리터럴(literal)이라고 한다. 상수(constant)와 의미가 같지만 프로그래밍에서는 상수를 \u0026lsquo;값을 한번 저장하면 변경할 수 없는 저장공간\u0026rsquo; 으로 정의하기 때문에 이와 구분하기 위해 \u0026lsquo;리터럴\u0026rsquo;이라는 용어를 사용한다.\nChapter 3 연산자 연산자\n값의 범위가 작은 타입에서 큰 타입으로의 형변환은 생략할 수 있다. 그러나 큰 자료형에서 작은 자료형으로의 형변환에 캐스트 연산자를 사용하지 않으면 컴파일시 에러가 발생한다.\nlong은 8byte고 float은 4byte지만 실수형이 정수형보다 훨씬 더 큰 범위를 갖기 때문에 float이 더 크다고 할 수 있다. 또한 char와 short 모두 2byte지만 char는 음수를 갖지 않으므로 서로 범위가 달라서 자동적으로 형변환이 수행되지 않는다.\n사칙연산\n사칙 연산에서 int형 보다 크기가 작은 자료형은 int형으로 형변환 후에 연산을 수행한다.\nbyte + short -\u0026gt; int + int -\u0026gt; int\n두개의 피연산자 중 자료형의 표현범위가 큰 쪽에 맞춰서 형변환 된 후 연산을 수행한다.\nfloat + long -\u0026gt; float + float -\u0026gt; float 쉬프트 연산자\n쉬프트 연산자는 정수형 변수에만 사용할 수 있는데 \u0026lt;\u0026lt;연산자의 경우, 피연산자의 부호에 상관없이 자리를 왼쪽으로 이동시키며 빈칸을 0으로만 채우면 되지만 \u0026gt;\u0026gt;연산자는 오른쪽으로 이동시키기 때문에 음수인 경우 부호를 유지시켜주기 위해 빈자리를 1로 채우게 된다. 반면에 \u0026gt;\u0026gt;\u0026gt;연산자는 부호에 상관없이 항상 0으로 빈자리를 채운다. 그렇기 대문에 10진 연산보다는 비트연산(2진 연산)에 주로 사용된다.\nChapter 4 조건문과 반복문 이름 붙은 반복문 Loop1 : for(int i=0; i\u0026lt;9; i++){ for(int j=1; j\u0026lt;9; j++){ if(j==5) break Loop1; } } 위와 같이 break를 설정하면 바로 빠져나오게 할 수 있다.\nChapter 5 배열 배열의 복사\nSystem클래스의 arraycopy()를 사용하면 보다 간단히 배열을 복사할 수 있다.\nSystem.arraycopy(arr1, 0, arr2, 0, arr1.length); arr1배열의 0번째부터 arr1.length까지의 내용을 arr2의 0번째부터 복사하겠다는 뜻\nChapter 6 객체지향 프로그래밍1 class\n프로그래밍 언어에서 데이터 처리를 위한 저장형태의 발전과정은 다음과 같다. 그동안 데이터와 함수가 서로 관계가 없는 것처럼 따로 다루어져 왔지만, 사실 함수는 주로 데이터를 가지고 작업을 하기 때문에 많은 경우에 있어서 데이터와 함수는 관계가 깊다. 예를들어 C언어에서는 문자열을 문자의 배열로 다루지만, 자바에서는 String이라는 클래스로 문자열을 다룬다. 문자열을 단순히 문자의 배열로 정의하지 않고 클래스로 정의한 이유는 문자열과 문자열을 다루는데 필요한 함수들을 함께 묶기 위해서이다.\nparameter\n메서드의 매개변수가 있는 경우, 본격적인 작업을 시작하기에 앞서 넘겨받은 매개변수의 값이 유효한 것인지 꼭 확인 하는것이 중요하다.\nreturn\n아래 왼쪽같이 메서드 내에서 return문을 여러 번 쓰는 것보다 가능하면 오른쪽처럼 마지막에 한번만 사용하는 것이 좋다.\nint max(int a, int b) int max(int a, int b) { { if(a\u0026gt;b) int result = 0; return a; if(a\u0026gt;b) else result = a; return b; else } result = b; return result; } 리턴값이 있는 메서드를 리턴값이 없는 메서드로 바꾸는 방법\npublic static void main(String[] args) { ReturnTest r = new ReturnTest(); int[] result = {0}; r.add(3,5,result); System.out.println(result[0]); } void add(int a, int b, int[] result) { result[0] = a + b; } 메서드는 단 하나의 값만을 리턴할 수 있지만 이것을 응용하면 여러 개의 값을 리턴받는 것과 같은 효과를 얻을 수 있다. (임시적으로 간단히 처리할 때는 별도의 클래스를 선언하는 것보다 이처럼 배열을 이용하는 것이 좋다)\nJVM 메모리 구조\n1.메소드 영역(method area)\n- 프로그램 실행 중 어떤 클래스가 사용되면, JVM은 해당 클래스의 클래스파일(*.class)을 읽어서 분석하여 클래스에 대한 정보(클래스 데이터)를 이곳에 저장한다. 이때 그 클래스의 클래스변수도 이 영역에 함께 생성된다.  2.호출스택(call stack)\n- 호출스택은 메서드 작업에 필요한 메모리 공간을 제공한다. 메서드가 호출되면 호출스택에 메모리가 할당되며 이 메모리는 메서드가 작업을 수행하는 동안 지역변수(매개변수 포함) 연산의 중간결과 등을 저장하는데 사용된다. 그리고 메서드가 작업을 마치면 할당되었던 메모리공간은 반환되어 비워진다.  3.힙(heap)\n- 인스턴스가 생성되는 공간. 프로그램 실행 중 생성되는 인스턴스는 모두 이곳에 있다.  초기화 블럭\n클래스 초기화 블럭 - 클래스 변수의 복잡한 초기화에 사용된다.\n인스턴스 초기화 블럭 - 인스턴스 변수의 복잡한 초기화에 사용된다.\n생성자 보다 인스턴스 초기화 블럭이 먼저 수행된다. 클래스 초기화는 클래스가 처음 로딩될 때 클래스 변수들이 자동으로 메모리에 만들어지고, 바로 클래스 초기화 블럭에서 클래스 변수들을 초기화하게 되는 것이다.\nclass InitBlack { static { //클래스 초기화 블럭  } { //인스턴스 초기화 블럭  } } 초기화 블럭 내에는 메서드 내에서와 같이 조건문, 반복문, 예외처리 구문 등을 자유롭게 사용할 수 있으므로, 초기화 작업이 복잡하여 명시적 초기화만으로는 부족한 경우 초기화 블럭을 사용한다.\nChapter 7 객체지향 프로그래밍2 final\n생성자를 이용한 final 멤버변수 초기화\nfinal이 붙은 변수는 상수이므로 일반적으로 선언과 초기화를 동시에 하지만, 인스턴스 변수의 경우 생성자에서 초기화 되도록 할 수 있다.\nclass Card{ final int NUMBER; final String KIND; Card(int num, String kind){ NUMBER = num; KIND = kind; } } 이 기능을 활용하면 각 인스턴스마다 final이 붙은 멤버변수가 다른 값을 갖도록 하는것이 가능하다.\n생성자의 접근 제어자\n생성자에 접근 제어자를 사용함으로써 인스턴스의 생성을 제한할 수 있다. 보통 생성자의 접근 제어자는 클래스의 접근 제어자와 같지만, 다르게 지정할 수도 있다.\n생성자의 접근 제어자를 private으로 지정하면, 외부에서 생성자에 접근 할 수 없으므로 인스턴스를 생성할 수 없게 된다. 그래도 클래스 내부에서는 인스턴스의 생성이 가능하다.\nclass Singleton{ private static Singleton s = new Singleton(); private Singleton(){ //...  } //인스턴스를 생성하지 않고도 호출할 수 있어야 하므로 static이어야 한다.  public static Singleton getInstance(){ return s; } } 위의 경우처럼 생성자를 통해 직접 인스턴스를 생성하지 못하게 하고 public 메서드를 통해 인스턴스에 접근하게 함으로써 사용할 수 있는 인스턴스의 개수를 제한 할 수 있다.\n또한 생성자가 private인 클래스는 다른 클래스의 조상이 될 수 없으므로 클래스 앞에 final을 더 추가하여 상속할 수 없는 클래스라는 것을 알리는 것이 좋다.\npublic final class Math{ private Math(){ //...  } } 정리\n접근지정을 할 수 있는 곳은 클래스, 멤버변수, 메서드, 생성자 4곳이다.\n클래스\nprivate, protected은 내부 클래스만 가능.\n클래스 접근 지정자가 default일 경우에는, 다른 패키지에서 객체 생성이 안된다.\n멤버변수와 메서드\nprivate : 같은 클래스만 접근 가능\ndefault : 같은 패키지만 접근 가능\nprotected : 같은 패키지와 상속관계에서는 접근 가능\npublic : 어디서나 접근 가능\n생성자\nprivate : 외부에서 객체 생성을 못함. 상속도 불가능.\ndefault : 같은 패키지면 객체생성, 상속 가능하지만 다른 패키지면 객체생성, 상속 못함\nprotected : 같은 패키지면 객체생성, 상속 가능하지만 다른 패키지면 상속은 가능한데 객체생성은 못함\npublic : 같은, 다른 패키지 객체생성, 상속 가능\n참조변수와 인스턴스의 연결\n조상 클래스에 선언된 멤버변수와 같은 이름의 인스턴스변수를 자손 클래스에 중복으로 정의했을 때, 1. 조상 타입의 참조변수를 사용했을 때는 조상 클래스에 선언된 멤버변수가 사용되고, 자손타입의 참조변수를 사용했을 때는 자손 클래스에 선언된 멤버변수가 사용된다. 2. 메서드의 경우 참조 변수의 타입에 관계없이 항상 실제 인스턴스의 메서드(오버라이딩된 메서드)가 호출된다.\npublic static void main(String[] args){ Parent p = new Child(); Child c = new Child(); System.out.println(\u0026#34;p.x = \u0026#34;+p.x); p.method(); System.out.println(\u0026#34;c.x = \u0026#34;+c.x); c.method(); } class Parent{ int x = 100; void method(){ System.out.println(\u0026#34;Parent Method\u0026#34;); } } class Child extends Parent{ int x = 200; void method(){ System.out.println(\u0026#34;Child Method\u0026#34;); } } 실행결과\np.x = 100 Child Method c.x = 200 Child Method  그러나 멤버변수들은 주로 private으로 접근을 제한하고, 외부에서는 메서드를 통해서만 멤버변수에 접근할 수 있도록 하지, 다른 외부 클래스에서 참조변수를 통해 직접적으로 인스턴스변수에 접근할 수 있게 하지 않는다.\ninstanceof 연산자\ninstanceof를 이용한 연산결과로 실제 인스턴스와 같은 타입 뿐만 아니라 조상타입에도 true를 얻는다. 즉, 참조변수가 검사한 타입으로 형변환이 가능하다는 것을 뜻한다.\n인터페이스의 상속\n인터페이스는 인터페이스로부터만 상속받을 수 있으며, 클래스와는 달리 다중상속, 즉 여러개의 인터페이스로부터 상속을 받는 것이 가능하다.\ninterface Movable{ void move(int x, int y); } interface Attackable{ void attack(Unit u); } interface Fightable extends Movable, Attackable{ } Fightable 자체에는 정의된 멤버가 하나도 없지만 조상 인터페이스로부터 상속받은 두개의 추상 메서드를 멤버로 갖게 된다.\n인터페이스의 이해\n인터페이스의 규칙이나 활용이 아닌 본질적인 측면에 대해서 살펴보자.\n 클래스는 사용하는 쪽(User)과 클래스를 제공하는 쪽(Provider)이 있다. 메서드를 사용(호출)하는 쪽(User)에서는 사용하려는 메서드(Provider)의 선언부만 알면 된다.(내용은 몰라도 된다.)  class A{ public void methodA(B b){ b.methodB(); } } class B{ public void methodB(){ System.out.println(\u0026#34;methodB()\u0026#34;); } } class InterfaceTest{ public static void main(String args[]){ A a = new A(); a.methodA(new B()); } } 위와 같이 클래스 A와 클래스 B가 있을 때 클래스 A(User)는 클래스 B(Provider)의 인스턴스를 생성하고 메서드를 호출한다. 이 두 클래스는 서로 직접적인 관계에 있다. 이것을 간단히 \u0026lsquo;A-B\u0026rsquo;라고 표현하자.\n이경우 클래스 A를 작성하기 위해서는 클래스 B가 이미 작성되어 있어야 한다. 그리고 클래스 B의 methodB()의 선언부가 변경되면, 이를 사용하는 클래스 A도 변경되어야 한다. 즉 직접적인 관계의 두 클래스는 한 쪽(Provider)이 변경되면 다른 한 쪽(User)도 변경되어야 한다는 단점이 있다.\n그러나 클래스 A가 클래스 B를 직접 호출하지 않고 인터페이스를 매개체로 해서 클래스 A가 인터페이스를 통해서 클래스 B의 메서드에 접근하도록 하면, 클래스 B에 변경사항이 생기거나 클래스 B와 같은 기능의 다른 클래스로 대체 되어도 클래스 A는 전혀 영향을 받지 않도록 하는 것이 가능하다.\n두 클래스간의 관계를 직접적으로 변경하기 위해서는 먼저 인터페이스를 이용해서 클래스 B(Provider)의 선언과 구현을 분리 해야한다.\n먼저 다음과 같이 클래스 B에 정의된 메서드를 추상메서드로 정의하는 인터페이스 I를 정의한다.\ninterface I{ public abstract void methodB(); } 그 다음에는 클래스 B가 인터페이스 I를 구현하도록 한다.\nclass B implements I{ public void methodB(){ System.out.println(\u0026#34;methodB in B class\u0026#34;); } } 이제 클래스 A는 클래스 B 대신 인터페이스 I를 사용해서 작성할 수 있다.\nclass A{ public void methodA(I i){ i.methodB(); } } 클래스 A를 작성하는데 있어서 클래스 B가 사용되지 않았다는 점에 주목하자. 이제 클래스 A와 클래스 B는 \u0026lsquo;A-B\u0026rsquo;의 직접적인 관계에서 \u0026lsquo;A-I-B\u0026rsquo;의 간접적인 관계로 바뀐 것이다.\n결국 클래스 A는 여전히 클래스 B의 메서드를 호출하지만, 클래스 A는 인터페이스 I하고만 직접적인 관계에 있기 때문에 클래스 B의 변경에 영향을 받지 않는다. 클래스 A는 인터페이스를 통해 실제로 사용하는 클래스의 이름을 몰라도 되고 심지어는 실제로 구현된 클래스가 존재하지 않아도 문제되지 않는다. 클래스 A는 오직 직접적인 관계에 있는 인터페이스 I의 영향만 받는다.\n인터페이스 I는 실제구현 내용(클래스 B)을 감싸고 있는 껍데기이며, 클래스 A는 껍데기 안에 어떤 알맹이(클래스)가 들어 있는지 몰라도 된다.\nChapter 8 예외처리 예외 클래스들은 다음과 같이 두 개의 그룹으로 나눠질 수 있다. (모든 예외의 최고 조상은 Exception 클래스이다.) - RuntimeException 클래스와 그 자손클래스들 (프로그래머의 실수로 발생하는 예외) - ArithmeticException - ClassCastException - NullPointerException - IndexOutOfBoundsException - Exception 클래스와 그 자손 클래스들 (사용자의 실수와 같은 외적인 요인에 의해 발생하는 예외) - IOException - ClassNotFoundException - FileNotFoundException - DataFormatException\nRuntimeException 클래스들 그룹에 속하는 예외가 발생할 가능성이 있는 코드에는 예외처리를 해주지 않아도 컴파일 시에 문제가 되지 않지만, Exception 클래스들 그룹에 속하는 예외가 발생할 가능성이 있는 예외는 반드시 처리를 해주어야 하며, 그렇지 않으면 컴파일 시에 에러가 발생한다.\nSystem.err\nSystem.err는 setErr 메서드를 이용해서 출력방향을 바꾸지 않는 한 err에 출력하는 내용은 모두 화면에 나타나게 된다.\nPrintStream ps =null; FileOutputStream fos = null; try{ //error.log파일에 출력할 준비를 한다.  fos = new FileOutputStream(\u0026#34;error.log\u0026#34;,true); ps = new PrintStream(fos); //error의 출력을 화면이 아닌, error.log 파일로 변경한다.  System.setErr(ps); } 출력 방향이 변경되었기 때문에 System.err.println(\u0026quot;\u0026quot;)을 이용해서 출력하는 내용은 error.log파일에 저장된다.\n예외 되던지기(exception re-throwing)\n단 하나의 예외에 대해서 예외가 발생한 메서드와 호출한 메서드 양쪽에서 처리할 수 있다.\nclass ExceptionEx23{ public static void main(String[] args){ try{ method1(); }catch(Exception e){ System.out.println(\u0026#34;main메서드에서 예외가 처리되었습니다.\u0026#34;); } } static void method1() throws Exception{ try{ throw new Exception(); }catch(Exception e){ System.out.println(\u0026#34;method1메서드에서 예외가 처리되었습니다.\u0026#34;); throw e; // 다시 예외를 발생시킨다.  } } } method1()의 catch블럭에서 예외를 처리하고도 throw문을 통해 다시 예외를 발생시켰다. 그리고 이 예외를 method1을 호출한 main 메서드에서 한번 더 처리하였다.\nChapter 9 java.lang 패키지 String 클래스 String클래스에는 문자열을 저장하기 위해서 문자형 배열 변수(char[]) value를 인스턴스 변수로 정의해놓고 있다.\n한번 생성된 String 인스턴스가 갖고 있는 문자열은 읽어 올 수만 있고, 변경할 수는 없다.\n예를 들어 ‘+’연산자를 이용해서 문자열을 결합하는 경우 인스턴스내의 문자열이 바뀌는 것이 아니라 새로운 문자열이 담긴 String인스턴스가 생성되는 것이다. 이처럼 덧셈연산자(+)를 사용해서 문자열을 결합하는 것은 매 연산 시마다 새로운 문자열을 가진 String인스턴스가 생성되어 메모리공간을 차지하게 되므로 가능한 한 결합횟수를 줄이는 것이 좋다. 그래서 문자열간의 결합이나 추출 등 문자열을 다루는 작업이 많이 필요한 경우에는 String클래스 대신 StringBuffer클래스를 사용하는 것이 좋다. String인스턴스와는 달리 StringBuffer인스턴스에 저장된 문자열은 변경이 가능하므로 하나의 StringBuffer인스턴스만으로도 문자열을 다루는 것이 가능하다.\ncf) StringBuilder가 JDK1.5부터 새롭게 추가되었다. StringBuffer와 완전히 동일한 클래스이다. 다만 동기화 처리를 하지 않기 때문에 멀티스레드 프로그래밍에서는 사용하면 안되지만 그 외의 경우에는 StringBuffer보다 빠른 성능을 보장한다.\n문자열을 만들 때 두 가지 방법, 문자열 리터럴을 지정하는 방법과 String클래스의 생성자를 사용해서 만드는 방법이 있다.\nString str1 = “str1”; String str2 = “str1”; String str3 = new String(“str1”); equals(String s)를 사용했을 때는 문자열간의 내용으로 비교하기 때문에 str1,str2,str3 비교했을 때 모두 true로 나온다. 하지만 각 String인스턴스의 주소값을 등가비교연산자(==)로 비교했을 때는 결과가 다르다. 리터럴로 문자열을 생성했을 경우, 같은 내용의 문자열들은 모두 하나의 String인스턴스를 참조하도록 되어 있다. 그러나 String클래스의 생성자를 이용한 String인스턴스의 경우에는 new연산자에 의해서 메모리할당이 이루어지기 때문에 항상 새로운 String인스턴스가 생성된다.\n일반적으로 문자열들을 비교하기 위해서 equals메서드를 사용하지만, equals메서드로 문자열의 내용을 비교하는 것보다는 등가비교연산자(==)를 이용해서 주소(4byte)를 비교하는 것이 더 빠르다. 그래서 비교해야할 문자열의 개수가 많은 경우에는 보다 빠른 문자열 검색을 위해서 intern메서드와 등가비교연산자(==)를 사용하기도 한다.\nString클래스의 intern()은 String인스턴스의 문자열을 ‘constant pool’에 등록하는 일을 한다. 등록하고자 하는 문자열이 ‘constant pool’에 이미 존재하는 경우에는 그 문자열의 주소값을 반환한다.\nString클래스의 생성자와 메서드\nString file = “Hello.txt”; boolean b = file.endsWith(“txt”); //trueString s = “java.lang.Object”; boolean b = s.startsWith(“java”); // true boolean b2 = s.startWith(“lang”);// falseboolean equalsIgnoreCase(String str) //대소문자 구분없이 비교한다.String[] split(String regex) 기본형 -\u0026gt; 문자열\nString a = String.valueof(‘a’); String b = String.valueof(100); String c = String.valueof(true); 문자열 -\u0026gt; 기본형\nboolean Boolean.getBoolean(String s) byte Byte.parseByte(String s) short Short.parseShort(String s) int Integer.parseInt(String s) long Long.parseLong(String s) float Float.parseFloat(String s) double Double.parseDouble(String s) Chapter 10 내부 클래스 내부 클래스는 마치 변수를 선언하는 것과 같은 위치에 선언할 수 있으며, 변수의 선언위치에 따라 인스턴스변수, 클래스변수, 지역변수로 구분되는 것과 같이 내부 클래스도 선언위치에 따라 인스턴스 클래스, 스태틱 클래스, 지역 클래스로 나뉜다.\nclass Outer{ class InstanceInner{} static class StaticInner {} void myMethod(){ class LocalInner{} } } Chapter 11 컬렉션 프레임워크와 유용한 클래스 List : 순서가 있는 데이터의 집합. 데이터의 중복을 허용한다.(ArrayList, LinkedList, Stack, Vector 등)\nSet : 순서를 유지하지 않는 데이터의 집합. 데이터의 중복을 허용하지 않는다.(HashSet, TreeSet 등)\nMap : 키와 값의 쌍으로 이루어진 데이터의 집합. 순서는 유지되지 않으며, 키는 중복을 허용하지 않고, 값은 중복을 허용한다. (HashMap, TreeMap, Hashtable, Properties 등)\nMap.Entry 인터페이스\nMap.Entry 인터페이스는 Map 인터페이스의 내부 인터페이스이다. 내부 클래스와 같이 인터페이스도 이처럼 인터페이스 안에 인터페이스를 정의할 수있다.\npublic interface Map{ … interface Entry{ Object getKey(); Object getValue(); ... } } cf) Map 인터페이스 메서드중 Set entrySet()이 있다. Map에 저장되어 있는 key-value쌍을 Map.Entry타입의 객체로 저장한 Set으로 반환한다.\n동기화\n멀티스레드 프로그래밍에서는 하나의 객체를 여러 쓰레드가 동시에 접근할 수 있기 때문에 데이터의 일관성을 유지하기 위해서는 동기화가 필요하다. Vector와 Hashtable과 같은 구버전(JDK1.2 이전)의 클래스들은 자체적으로 동기화 처리가 되어 있는데, 멀티스레드 프로그래밍이 아닌 경우에는 불필요한 기능이 되어 성능을 떨어트리는 요인이 된다. 그래서 새로 추가된 ArrayList와 HashMap과 같은 컬렉션은 동기화를 자체적으로 처리하지 않고 필요한 경우에만 java.util.Collections 클래스의 동기화 메서드를 이용해서 동기화처리가 가능하도록 변경하였다. 이들을 사용하는 방법은 다음과 같다.\nList list = Collections.synchronizedList(new ArrayList(…)); ArrayList\nList list = new ArrayList(10); ArrayList를 생성 할 때, 저장할 요소의 갯수를 고려해 초기화 시키는게 좋다. 생성할 때 지정한 크기보다 더 많은 객체를 저장하면 자동적으로 크기가 늘어나기는 하지만 이 과정에서 처리시간이 많이 소요된다. 다시 말해 배열은 크기를 변경할 수 없으므로 새로운 배열을 생성해 데이터를 복사해야하기 때문에 효율이 많이 떨어진다.\nArrayList remove를 통해 객체를 삭제할때는\nfor(i = list2.size2()-1; i\u0026gt;=0; i--){ if(list1.contains(list2.get(i))) list2.remove(i); } 위와 같이 끝에서부터 인덱스를 감소시키면서 삭제를 진행한다. 그 이유는 배열의 한 요소가 삭제될때마다 나머지 요소들이 한칸씩 앞으로 자리이동을 해야되는데 뒤에서부터하면 이동을 최소화 시킬수 있다.\n실제 ArrayList remove 메서드 일부\nprivate void fastRemove(int index){ modCount++; int numMoved = size - index -1; if(numMoved \u0026gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; } 내가 생성한 객체 size가 5이고 지우려고하는 인덱스가 마지막이라면(4) numMoved는 0이되므로 System.arraycopy를 호출하지 않아 작업시간이 짧아진다. 배열의 중간에 위치한 객체를 추가하거나 삭제하는 경우 System.arraycopy()를 호출해서 다른 데이터의 위치를 이동시켜 줘야하기 때문에 다루는 데이터의 개수가 많을수록 작업시간이 오래걸린다.\nLinkedList\n실제로 LinkedList 클래스는 이름과 달리 더블 원형 링크드리스트로 구현되어있다.\n순차적으로 추가/삭제하는 경우에는 ArrayList가 LinkedList보다 빠르다. 중간 데이터를 추가/삭제 하는 경우에는 LinkedListk가 ArrayList보다 빠르다. 두 클래스의 장점을 이용해서 두 클래스를 혼합해서 사용하는 방법도 있다.\nArrayList al = new ArrayList(1000000); for(int i=0; i\u0026lt;100000;i++) al.add(i+\u0026#34;\u0026#34;); LinkedList ll = new LinkedList(al); for(int i=0; i\u0026lt;1000; i++) ll.add(500, \u0026#34;X\u0026#34;); 컬렉션 프레임워크에 속한 대부분의 컬렉션 클래스들은 이처럼 서로 변환이 가능한 생성자를 제공한다.\nStack \u0026amp; Queue\n순차적으로 데이터를 추가하고 삭제하는 스택에는 ArrayList와 같은 배열기반의 컬렉션 클래스가 적합하지만, 큐는 데이터를 꺼낼 때 항상 첫번째 저장된 데이터를 삭제하므로, ArrayList와 같은 배열기반의 컬렉션 클래스를 사용한다면 데이터를 꺼낼 때마다 빈 공간을 채우기 위해 데이터의 복사가 발생하므로 비효율적이다. 그래서 큐는 ArrayList보다 데이터의 추가/삭제가 쉬운 LinkedList로 구현하는 것이 더 적합하다.\nHashMap\nHashMap map = new HashMap(); map.put(\u0026#34;김자바\u0026#34;, new Integer(90)); map.put(\u0026#34;김자바\u0026#34;, new Integer(100)); map.put(\u0026#34;이자바\u0026#34;, new Integer(100)); map.put(\u0026#34;강자바\u0026#34;, new Integer(80)); map.put(\u0026#34;안자바\u0026#34;, new Integer(90)); Map에서 키가 중복되면 기존의 값을 덮어쓴다.\nSet set = map.entrySet(); Iterator it = set.iterator(); while(it.hasNext()){ Map.Entry e = (Map.Entry)it.next(); System.out.println(e.getKey() + e.getValue()); } Map은 Iterator가 없기 때문에 entrySet() 메서드를 통해 Set에 key와 value 결합한 형태로 저장시켜. iterator를 통해 하나씩 읽어온다. 그리고 Map의 내부 인터페이스인 Map.Entry를 통해 key와 value를 얻어온다.\ncf) entrySet()을 이용해서 key와 value를 함께 읽어 올수도 있고 keySet()이나 values()를 이용해서 키와 값을 따로 읽어 올 수 있다. (key는 중복을 허용하지 않으니까 Set타입으로 반환하고 value는 중복을 허용하니까 Collection 타입으로 반환한다.)\nSet set = map.entrySet(); Iterator iterator = set.iterator(); while(iterator.hasNext()){ Map.Entry e = (Map.Entry)iterator.next(); System.out.println(e.getKey() + \u0026#34; : \u0026#34; + e.getValue()); } Set set = map.keySet(); Iterator iterator = set.iterator(); while(iterator.hasNext()){ System.out.println(iterator.next()); } Collection values = map.values(); Iterator iterator = values.iterator(); while(iterator.hasNext()){ System.out.println(iterator.next()); } HashSet\nHashSet은 내부적으로 HashMap을 이용해서 만들어졌으며, HashSet이란 이름은 해싱을 이용해서 구현했기 때문에 붙여진 것이다.\n저장한 순서를 유지하고자 한다면 LinkedHashSet을 사용해야한다.\nString클래스는 문자열의 내용으로 해시코드를 만들어 내기 때문에 내용이 같은 문자열에 대한 hashCode()호출은 항상 동일한 해시코드를 반환한다. 반면에 Object클래스는 객체의 주소로 해시코드를 만들어 내기 때문에 실행 할 때마다 해시코드 값이 달라질 수 있다.\nComparator와 Comparable\nComparable - 기본 정렬기준을 구현하는데 사용\nComparator - 기본 정렬기준 외에 다른 기준으로 정렬하고자 할 때 사용\n둘다 인터페이스로 Comparable을 구현하고 있는 클래스들은 같은 타입의 인스턴스끼리 서로 비교할 수 있다. 그래서 Comparable을 구현한 클래스는 정렬이 가능하다는 것을 의미한다.\n해싱\n해싱이란 해시함수를 이용해서 데이터를 해시테이블에 저장하고 검색하는 기법을 말한다. 해시함수는 데이터가 저장되어 있는 곳을 알려 주기 때문에 다량의 데이터 중에서도 원하는 데이터를 빠르게 찾을 수 있다.\n제네릭\nList myIntList = new LinkedList(); myIntList.add(new Integer(0)); Integer i = (Integer)myIntList.iterator().next(); 리스트에 어떤 타입이 들어갈지 알고 있지만 캐스팅은 필수다. 컴파일러는 iterator에 의해 Object가 리턴될것이라는 것까지 밖에 보장못한다. 그래서 리스트에 특정한 타입만 들어갈 수 있도록 강제해서 캐스팅도 안해도 되는 제네릭 !!\nList\u0026lt;Integer\u0026gt; myIntList = new LinkedList\u0026lt;\u0026gt;(); myIntList 변수에 타입에 대한 정의를 해서 인자의 정확성을 컴파일 타임에 알 수 있게 되었다.\nList\u0026lt;String\u0026gt; ls = new ArrayList\u0026lt;String\u0026gt;(); // 1 List\u0026lt;Object\u0026gt; lo = ls; // 2 lo.add(new Object()); // 3 lo에 String 리스트를 대입하고 새로운 Object를 추가시켰다. 그러니 lo에는 이제 String만 있는게 아니니까 이런 문제를 방지하기 위해 컴파일러는 2에서 에러를 발생시킨다.\n컬렉션에 저장될 객체에도 다형성이 필요하다 =\u0026gt; 와일드 카드 \u0026lsquo;?\u0026rsquo;\npublic static void printAll(ArrayList\u0026lt;? extends Product\u0026gt; list, ArrayList\u0026lt;? extends Product\u0026gt; list2){ ... } //타입을 별도로 선언함으로써 코드 간략화 public static \u0026lt;T extends Product\u0026gt; void printAll(ArrayList\u0026lt;T\u0026gt; list, ArrayList\u0026lt;T\u0026gt; list2){ ... } T라는 타입이 Product의 자손 타입이라는 것을 미리 정의해놓고 사용.\ncf) Product가 인터페이스임에도 키워드를 extends로 사용함에 주의해라.\n\u0026lt;? extends T\u0026gt; - T또는 T의 자손타입을 의미 \u0026lt;? super T\u0026gt; - T또는 T의 조상타입을 의미\nCollections.sort()에 적용된 제네릭 public static \u0026lt;T extends Comparable\u0026lt;? super T\u0026gt;\u0026gt; void sort(List\u0026lt;T\u0026gt; list)\n List 인터페이스를 구현한 컬렉션을 매개변수의 타입으로 정의하고 있다. 그리고 그 컬렉션에는 \u0026rsquo;T\u0026rsquo;라는 타입의 객체를 저장하도록 선언되어 있다. \u0026rsquo;T\u0026rsquo;는 Comparable 인터페이스를 구현한 클래스의 타입이어야 하고, 그 Comparable 인터페이스는 \u0026rsquo;T\u0026rsquo;또는 그 조상타입을 비교하는 Comparable이어야 한다.  Comparable과 Comparator에 대해서 정확히 알자\nComparable 인터페이스 : 자기 자신과 같은 클래스 타입의 다른 객체와 비교하기 위해 사용\npublic interface Comparable\u0026lt;T\u0026gt;{ public int compareTo(T o); } 객체 비교를 위해서 compareTo 메서드를 오버라이딩해서 비교한다.\n현재의 객체가 다른 객체와 비교하여 최종 반환되는 값이 0이면 순서가 같은것, 음수면 순서가 앞에 있는것, 양수면 순서가 뒤에 있는것.\nComparator 인터페이스 : 다른 두개의 객체를 비교, 즉 Comparator를 구현한 객체가 다른 두개의 객체를 비교하는 기준이 되어 두개의 객체를 비교한다.\npublic interface Comparator\u0026lt;T\u0026gt;{ int compare(T o1, T o2); // o1이 비교하는 주체자, o2가 비교대상자 } Chapter 12 스레드 모든 스레드는 독립적인 작업을 수행하기 위해 자신만의 호출스택을 필요로 하기 때문에, 새로운 스레드를 생성하고 실행시킬 때마다 새로운 호출스택이 생성되고 스레드가 종료되면 작업에 사용된 호출스택은 소멸한다.\n스레드 그룹\n모든 스레드는 반드시 스레드 그룹에 포함되어 있어야 하기 때문에, 스레드 그룹을 지정하는 생성자를 사용하지 않은 스레드는 기본적으로 자신을 생성한 스레드와 같은 스레드 그룹에 속하게 된다.\n자바 애플리케이션이 실행되면, JVM은 main과 system이라는 스레드 그룹을 만들고 JVM운영에 필요한 스레드들을 생성해서 이 스레드 그룹에 포함시킨다. 예를 들어 main 메서드를 수행하는 main이라는 이름의 스레드는 main스레드 그룹에 속하고, 가비지컬렉션을 수행하는 Finalizer스레드는 system스레드 그룹에 속한다. 우리가 생성하는 모든 스레드 그룹은 main스레드 그룹의 하위 스레드 그룹이 되며, 스레드 그룹을 지정하지 않고 생성한 스레드는 자동적으로 main스레드 그룹에 속하게 된다.\n데몬스레드\n다른 일반 스레드의 작업을 돕는 보조적인 역할을 수행하는 스레드이다. 데몬 스레드는 무한루프와 조건문을 이용해서 실행 후 대기하고 있다가 특정 조건이 만족되면 작업을 수행하고 다시 대기하도록 작성한다. 데몬 스레드의 예로는 가비지 컬렉터, 워드프로세서의 자동저장, 화면자동갱신 등이 있다.\n데몬스레드는 일반 스레드의 작성방법과 실행방법이 같으며 다만 스레드를 생성한 다음 실행하기 전에 setDaemon(true)를 호출하기만 하면 된다. 그리고 데몬 스레드가 생성한 스레드는 자동적으로 데몬 스레드가 된다.\nThread t = new Thread(new ThreadEx8()); t.setDaemon(true); t.start(); setDaemon 메서드는 반드시 start()를 호출하기 전에 실행되어야 한다.\n스레드 실행제어 / 동기화\nsuspend(), resume(), stop()은 스레드를 교착상태에 빠뜨릴 가능성이 있기 때문에 deprecated되었으므로 사용하지 않는 것이 좋다.(suspend() 대신 wait()을, resume() 대신 notify()를 사용한다.)\nwait()과 notify()는 동기화 블록 내에서만 사용할 수 있으며 notify()는 객체의 waiting pool에 있는 스레드 중의 하나만 깨우고 notifyAll()은 모든 스레드를 깨운다. 어차피 한 번에 하나의 스레드만 객체를 사용할 수 있기 때문에 notify()를 사용하나 notifyAll()을 사용하나 별차이는 없다. 그러나 notify()에 의해 어떤 스레드가 깨워지게 될지는 알수 없기 때문에 다시 객체의 waiting pool에 들어가더라도 notifyAll()을 이용해서 모든 스레드를 깨워놓고 JVM의 스레드 스케줄링에 의해서 처리되도록 하는 것이 안전하다.\nChapter 14 입출력(I/O) 직렬화 : 객체를 데이터 스트림으로 만드는 것. 다시 얘기하면 객체에 저장된 데이터를 스트림에 쓰기위해 연속적인 데이터로 변환하는 것. 역직렬화 : 스트림으로부터 데이터를 읽어서 객체를 만드는것\n객체는 클래스에 정의된 인스턴스변수의 집합이다. 객체에는 클래스변수나 메서드가 포함되지 않는다. 객체는 오직 인스턴스변수들로만 구성되어 있다. 인스턴스변수는 인스턴스마다 다른 값을 가질 수 있어야하기 때문에 별도의 메모리공간이 필요하지만 메서드는 변하는 것이 아니라서 메모리를 낭비해 가면서 인스턴스마다 같은 내용의 코드를 포함시킬 이유는 없다.\n직렬화(객체 \u0026ndash;\u0026gt; 스트림) : 객체를 스트림에 출력 ObjectOutputStream 역직렬화(스트림 \u0026ndash;\u0026gt; 객체) : 스트림으로부터 객체에 입력 ObjectInputStream\n직렬화가 가능한 클래스 만들기\n직렬화하고자 하는 클래스가 java.io.Serializable인터페이스를 구현하도록 하면 된다.\npublic class UserInfo implements java.io.Serializable{ String name; String password; int age; } 아래는 직렬화할 수 없는 클래스의 객체를 인스턴스변수가 참조하고 있어서 직렬화에 실패한다. 모든 클래스의 최고조상인 Object는 Serializable을 구현하지 않았기 때문에 직렬화할 수 없다.\npublic class UserInfo implements java.io.Serializable{ String name; String password; int age; Object obj = new Object(); } 아래와 같은 경우는 직렬화가 가능하다. 인스턴스변수 obj의 타입이 직렬화가 안되는 Object이긴 하지만 실제로 저장된 객체는 직렬화가 가능한 String인스턴스이기 때문에 직렬화가 가능하다. 인스턴스변수의 타입이 아닌 실제로 연결된 객체의 종류에 의해서 결정된다.\npublic class UserInfo implements java.io.Serializable{ String name; String password; int age; Object obj = new String(\u0026#34;abc\u0026#34;); } 제어자 transient를 붙여서 직렬화 대상에서 제외되도록 할 수 있다. 또한 password와 같이 보안상 직렬화되면 안되는 값에 대해 transient를 사용할 수 있다.\npublic class UserInfo implements java.io.Serializable{ String name; transient String password; int age; transient Object obj = new Object(); } 추가적인 내용 JDK7에서 새롭게 소개된 Invokedynamic\n람다는 내부적으로 Invokedynamic을 활용한다. 자바는 static type 언어라고 불리며, 이는 컴파일 타임에서 이미 멤버 변수들이나 함수 변수들의 타입이 반드시 명시적으로 지정돼야 함을 의미한다. 그에 반해 루비나 자바스크립트는 이른바 ‘duck-typing’이라고 하는 타입 시스템을 사용함으로써 컴파일 타임에서의 타입을 강제하지 않는다. Invokedynamic은 이러한 duck-typing을 JVM레벨에서 기본적으로 지원하면서 자바 외에 다른 언어들이 JVM이라는 플랫폼 위에서 최적화된 방식으로 실행될 수 있는 토대를 제공한다.\n초창기 JVM은 항상 바이트코드를 해석했다. 따라서 루프문과 같이 코드 실행 과정에서 반복이 많은 경우 불필요한 해석 시간이 늘어나므로 C와 같은 프로그래밍 언어를 사용해 개발한 애플리케이션과의 성능 격차가 컸다. 이런 성능 문제를 해결하기 위해 바이트코드를 기계어 코드로 컴파일하는 방법을 사용해 실행 시간을 대폭적으로 높이는 JIT 컴파일이라 알려진 기술이 등장했다. 초기의 JIT 컴파일러는 모든 바이트코드를 한번에 기계어로 변환했기 때문에 컴파일 비용이 높았다. 하지만 연이어 등장한 핫스팟은 성능 향상을 위한 동적 변환 기능을 탑재해 자주 실행되는 코드나 반복되는 코드를 분석해 핫 스팟을 찾아낸다. 그리고 해당 부분만 기계어로 변환해 컴파일 비용을 줄이고 동적으로 상황에 맞춰 최적화를 할 수 있게 됐다. 즉, 성능이 덜 중요한 코드의 경우에는 변환에 따른 비용을 줄인다는 의미다.\n자바9\n자바9의 변화 중에서도 가장 손꼽을 만한 변화가 바로 프로젝트 직소다. 단어 그대로 직소 퍼즐처럼 자바의 내부 API들을 모듈화해서 관리한다는 의미다. 이러한 모듈은 jar파일이 아닌 새롭게 소개된 jimage 포맷 안에 담긴다. SE9의 기본 API들은 bootmodules.jimage, extmodules.jimage, appmodules.jimage 등의 이미지로 배포된다. jimage 파일 포맷은 jar 포맷을 장기적으로 대체하기 위한 기술이다. 대략 클래스를 읽는 속도만 5배 향상됐다. 용량으로 비교하면 zip보다 15~16%더 작다고 한다. 내부적으로 해시 충돌을 막기 위한 새로운 해시함수를 사용한다.\n자바 환경변수\nJDK에서 제공하는 명령어들을 환경 변수에 지정하면 시스템의 모든 곳에서 JDK 명령어를 쉽게 실행할 수 있다.\nJAVA_HOME : JDK가 설치된 홈 디렉토리를 설정하기 위한 환경 변수다. C:\\Program Files\\Java\\jdk1.7.0_75\nPATH : OS에서 명령어를 실행할 때 명령어를 찾아야 하는 폴더의 순위를 설정하는 환경 변수다. 편리한 개발을 위해 Path 환경 변수에 JDK 개발 툴의 경로를 등록한다.\n;%JAVA_HOME%\\bin(bin 디렉토리에는 JDK에서 제공하는 개발 툴 명령어들이 있다.)\nCLASSPATH : JVM이 시작될 때 JVM의 클래스 로더는 이 환경 변수를 호출한다. 그래서 환경 변수에 설정되어 있는 디렉토리가 호출되면 그 디렉토리에 있는 클래스들을 먼저 JVM에 로드한다. 그러므로 CLASSPATH 환경 변수에는 필수 클래스들이 위치한 디렉토리를 등록하도록 한다.%JAVA_HOME%\\lib\\\n클래스 로더 JVM에서 클래스가 동작하기 위해서는 클래스 로더가 클래스를 JVM에 올려놓는 과정이 반드시 필요하다. 클래스 로더에 의해서 로딩된 클래스만이 실행 가능한 상태이기 때문이다. 물론 CLASSPATH 경로에 위치한 클래스를 자동으로 로딩할 수 있지만, 개발자가 클래스를 직접 로딩할 수도 있다.\n자바는 동적으로 클래스를 읽어온다\n실행 시 모든 클래스 파일들이 한 번에 JVM 메모리에 로딩되지 않고 요청되는 순간 로딩된다. 자바의 클래스 로더가 이런 역할을 수행한다. 클래스 로더란 \u0026lsquo;.class\u0026rsquo; 바이트 코드를 읽어 들여 class 객체를 생성하는 역할을 담당한다.\n클래스 로더에 의해서 분석된 클래스의 정보를 개발자가 실행하거나 참조할 수 있다. 이와 같이 클래스의 내부 정보를 보는 기법을 리플렉션이라고 한다.\n리플렉션 리플렉션의 핵심은 클래스 정보 확인이 아니라 동적인 프로그래밍이다. 리플렉션 기법이 사용된 가장 대표적인 예로는 이클립스 개발 도구의 자동 완성 기능이다.\n지금까지 배운 내용에 의하면 객체를 생성하기 위해서는 클래스를 프로그래밍하는 시점에서 new 키워드와 함께 생성자를 호출해야 한다. 즉 클래스를 인스턴스하기 전에 사람이 직접 클래스를 코딩해서 컴파일 시점에서만 객체를 생성할 수 있음을 의미한다. 하지만 리플렉션은 런타임 시점에서 동적으로 클래스의 정보를 추출하고 실행하는 환경을 제공해줄 수 있다.\njava.lang.Class클래스를 통해서 클래스들의 정보를 얻을 수 있다. 보통의 클래스와 달리 Class 클래스에서는 Class 객체를 생성하는 생성자가 없다. 그러므로 new 키워드를 사용해서 객체를 생성할 수 없고, 정보를 얻고자 하는 대상으로부터 Class 객체를 생성해야 한다. 리플렉션의 단어 뜻처럼, 거울로 비춰보기 위한 원래 대상 객체가 필요하다.\nClass 객체 생성하는 3가지 방법\n//1. 대상 객체에서 제공하는 getClass() 메서드 이용하는 방법  String str = new String(); Class class1 = str.getClass(); //2. 대상 클래스를 이용하여 Class 객체 받아오는 방법  Class class2 = String.class; //3. 대상 클래스의 이름을 이용하여 Class 객체 받아오는 방법  try{ Class class3 = Class.forName(\u0026#34;java.lang.String\u0026#34;); //반드시 패키지 경로 포함  }cathch(ClassNotFoundException e){} 1번 2번이 명시적인 방법이라면 3번은 forName() 메서드를 동적으로 처리할 수 있다는 장점이 있다.\n다음과 같은 리플렉션 기법을 통해 클래스의 생성자 정보, 메서드정보, 필드 정보를 얻을 수 있다.\nBong bong = new Bong(); Class class1 = bong.getClass(); //생성자 정보 얻기  //Constructor[] constructors = class1.getDeclaredConstructors(); //명시적으로 선언된 생성자를 받는 메서드  Constructor[] constructors = class1.getConstructors(); for(int i=0; constructors != null \u0026amp;\u0026amp; i\u0026lt; constructors.length; i++){ System.out.println(constructors[i].toString()); } //메서드 정보 얻기  //Method[] methods = class1.getDeclaredMethods();  Method[] methods = class1.getMethods(); //상속 받은 메서드도 알 수 있음.  for(int i=0; methods != null \u0026amp;\u0026amp; i\u0026lt;methods.length; i++){ System.out.println(methods[i].toString()); } //필드 정보 얻기  Field[] fields = class1.getDeclaredFields(); for(int i=0; fields != null \u0026amp;\u0026amp; i\u0026lt; fields.length;i++){ System.out.println(fields[i].toString()); } 1. 생성자를 의미하는 Constructor 클래스\nClass\u0026lt;Bong\u0026gt; clazz = Bong.class; try { //String형 매개변수와 int형 매개변수를 받는 생성자를 의미하는 Constructor객체 받아온다.  Constructor\u0026lt;Bong\u0026gt; paramCons = clazz.getConstructor(String.class, Integer.TYPE); //newInstacne() 메서드에 매개변수로 넣기 위한 배열  Object[] params = new Object[]{ new String(\u0026#34;Lodoss\u0026#34;), Bong.NUMBER }; try { Bong bongVo = paramCons.newInstance(params); System.out.println(bongVo.toString()); } catch (InstantiationException | IllegalAccessException | IllegalArgumentException | InvocationTargetException e) { // TODO Auto-generated catch block  e.printStackTrace(); } } catch (NoSuchMethodException e) { // TODO Auto-generated catch block  e.printStackTrace(); } catch (SecurityException e) { // TODO Auto-generated catch block  e.printStackTrace(); } 직접 new 키워드를 사용해서 객체를 생성하지 않고 리플렉션 기법으로 동적으로 객체를 생성했다.\n2. 특정 메서드를 가리키는 Method 클래스\nWorkerValue benVo = new WorkerValue(\u0026#34;Benjamin Kim\u0026#34;, WorkerValue.POSITION_MANAGER); WorkerValue hamVo = new WorkerValue(\u0026#34;Hamzani\u0026#34;, WorkerValue.POSITION_MANAGER); Class\u0026lt;WorkerValue\u0026gt; clazz1 = WorkerValue.class; try{ Method m1 = clazz1.getMethod(\u0026#34;getName\u0026#34;, new Class[] {}); Object rt1 = m1.invoke(benVo, new Obejct[] {}); Object rt1 = m1.invoke(hamVo, new Obejct[] {}); } invoke 메서드가 두번 호출 됐는데 첫번째는 benVo 객체의 getName() 메서드가 실행되어 그 값이 Object rt1에 대입된다. 두번째는 hamVo 객체의 getName() 메서드가 실행된다.\n3. 클래스 변수를 의미하는 Field 클래스\nWorkerValue benVo = new WorkerValue(\u0026#34;Benjamin Kim\u0026#34;, WorkerValue.POSITION_MANAGER); Class\u0026lt;WorkerValue\u0026gt; clazz1 = WorkerValue.class; try{ Field f = clazz.getDeclaredField(\u0026#34;position\u0026#34;); //position은 필드명  f.setAccessible(true); Object vlu = f.get(benVo); } 필드는 보통 private 제어자로 외부에서 접근할 수 없다. 그래서 getDeclared* 로 시작하는 메서드를 사용해야 해당 자원에 대한 정보를 획득할 수 있다.\n자바 수정자(제어자) :\n접근 제어자 : public protected default, private\n그외 : static, final, synchronized, transient, volatile, native abstract 등등\ntransient는 직렬화 가능한 객체에서 멤버변수 중 직렬화 대상에 포함시키지 않을 때, 기본값으로 직렬화 되게 한다.(객체 직렬화시에 데이터의 보존여부를 결정. 멤버변수만 사용 가능하다.) ex) password\nvolatile과 synchronized\nhttp://kwanseob.blogspot.kr/2012/08/java-volatile.html\n조금 더 엄밀히 정의를 하자면, (1) 특정 최적화에 주의해라, (2) 멀티 쓰레드 환경에서 주의해라, 정도의 의미를 준다고 보면 된다.\nJava에서는 어떤 의미를 가질까? volatile을 사용한 것과 하지 않은것의 차이는 뭘까?\nvolatile을 사용하지 않은 변수: 마구 최적화가 될 수 있다. 재배치(reordering)이 될 수있고, 실행중 값이 캐쉬에 있을 수 있다.\nvolatile을 사용한 변수 (1.5미만): 그 변수 자체에 대해서는 최신의 값이 읽히거나 쓰여진다.\nvolatile을 사용한 변수 (1.5이상): 변수 접근까지에 대해 모든 변수들의 상황이 업데이트 되고, 변수가 업데이트된다.\nsynchronziation을 사용한 연산: synch블락 전까지의 모든 연산이 업데이트 되고, synch안의 연산이 업데이트된다.\n"
},
{
	"uri": "/clean_coders/",
	"title": "클린코더스 강의 정리",
	"tags": [],
	"description": "",
	"content": " Function 함수는 한 가지 일만 해야 한다.\n함수의 크기는 4줄 짜리여야 한다.\n잘 지어진 서술적인 긴 이름을 갖는 많은/작은 함수들로 유지해야한다.\n함수의 Role : 더 이상 작아질 수 없을 만큼 작아야한다.(if, else, while 문장 내부 블록은 한줄이어야 함, 중괄호없고 함수 호출일 것) 큰 함수를 보면 클래스로 추출할 생각을 해라.(큰 함수의 기준은 20줄 정도, 한눈에 이해할 수 없는 정도)\ncf) 메서드와 함수의 차이(객체지향의 사실과 오해)\n메시지를 처리하기 위해 내부적으로 선택하는 방법을 메서드라고 한다. 메시지를 처리할 수 있다고 판단되면 자신에게 주어진 책임을 다하기 위해 메시지를 처리할 방법인 메서드를 선택하게 된다. 객체지향 프로그래밍 언어에서 메서드는 클래스안에 포함된 함수 또는 프로시저를 통해 구현된다. 즉, 어떤 객체에게 메시지를 전송하면 결과적으로 메시지에 대응되는 특정 메서드가 실행된다.\n우리는 객체를 일종의 데이터처럼 사용하지만 객체는 데이터가 아니다. 객체에서 중요한 것은 ‘객체의 행동’이다. 상태는 행동의 결과로 초래된 부수효과를 쉽게 표현하기 위해 도입한 추상적인 개념이다.\n클래스 : 일련의 변수들에 동작하는 기능의 집합. (큰 함수는 항상 하나 이상의 클래스로 분리할 수 있다.)\n멤버변수 중 한곳에서만 사용되면(전체가 사용되지 않고) 로컬변수나 파라미터로 바꿔라. 인텔리제이를 기준으로 했을 때 보라색 변수(멤버변수)가 사용된 곳을 파악하고 작업하면 된다.\n함수는 한 가지 일만 해야 한다고 했을 때 ‘한 가지 일’이 되기 위해서는 주요 섹션들을 다른 함수로 추출한다. 함수를 서로 다른 추상화 레벨로 분리(extract till you drop)해야 하는데 사람들마다 느끼는 추상화 레벨이 달라서 매우 어렵다.\nFunction Structure Argument(인자)는 최대 3개를 넘지 마라.\n생성자에 많은 인자가 필요할 땐 builder 패턴\nBoolean 인자 사용금지(true일 때, false일 때 두가지 이상의 일을 하기 때문에 함수를 나눠야 한다)\nInnies not Outies(파라미터는 입력으로 작용하는 거지 output으로 작용하면 안된다)\nprivate String toSimpleText(Parse table, StringBuffer returnText){ if(table.parts == null){ SimpleTextOfLeave(table, returnText); SimpleTextOfMore(table, returnText); retrun returnText.toString(); } } 위 예제를 보면 returnText 파라미터가 다른 메서드의 파라미터로 간다. 그리고 returnText.toString 으로 리턴된다. 이 얘기는 파라미터 returnText가 toSimpleText 메서드 안에서 변경됐다는 것이다. input으로 들어와서 변경되서 return 되는 구조는 안좋다. 로컬 변수로 만들어서 그 로컬변수에 담고 그걸 리턴하는게 좋다.\nNull\nnull을 전달/기대하는 함수는 없어야 한다. boolean을 전달하는 만큼 잘못된 것이다. null의 경우의 행위와 null이 아닌 경우의 행위 2개의 함수를 만드는 것이 좋다.\ncf) null값 조사(체크)가 괜찮을 때가 있는데, public api를 사용할 경우에는 defensive하게 프로그래밍 하는게 좋다.\nThe Stepdown Rule\n모든 public은 위에 private은 아래에 둔다.\n중요한 부분을 위로, 상세한 부분을 아래로 둔다.\nSwitches and Cases\n제일 중요하다. Switch 문장 사용을 왜 꺼리나? 객체지향의 가장 큰 장점은 ‘의존성 관리 능력’이다.\n예를 들어 DIP B가 거꾸로 I에 의존성이 있어서 inversion이란 말을 쓴다. B의 소스코드 의존성은 runtime 의존성과 반대가 된다.(이게 좋은것)\n스프링을 쓰면 좋은점은 레코드가 위와 같은 구조를 준수하게 도와준다.\nSwitch 문장은 독립적 배포에 방해가 된다. 각 Case 문장은 외부 모듈에 의존성을 갖는다. 다수의 다른 모듈에 의존성을 가질 수 있어서 fan-out problem을 유발한다.\napplication / main partition\nFunction Structure2 Temporal Coupling - 함수들이 순서를 지키며 호출되어 한다.\n예) open, execute, done\n // file should be opened before processing fileCommand.process(file); // file should be closed after processing  이 방법은 실수할 여지도 많고 좋지 않다.(누군가는 open 안하고 실행하거나 실행하고 close를 안하는 등)\nSo 전략패턴\nfileCommandTemplate.process(myfile, new FileCommand(){ public void process(File f){ // file processing codes here  } }); class FileCommandTemplate{ public void process(File file, FileCommand command){ file.open(); command.process(file); file.close(); } } 전략패턴과 컨텍스트를 템플릿이라 부르고, 익명 내부 클래스로 만들어지는 오브젝트를 콜백이라 부른다.\n콜백 : 실행되는 것을 목적으로 다른 오브젝트의 메서드에 전달되는 오브젝트. 파라미터로 전달되지만 값을 참조하기 위한 것이 아니라 특정 로직을 담은 메서드를 실행시키기 위해 사용한다.\nTemplate/Callback 패턴은 보통 단일 메소드 인터페이스를 사용한다. 템플릿의 작업 흐름 중 특정 기능을 위해 한 번 호출되는 경우가 일반적이기 때문이다.\nCQS(Command Query Separation)\n정의 : 상태를 변경하는 함수는 값을 반환하면 안된다. 값을 반환하는 함수는 상태를 변경하면 안된다.\nCommand : 시스템의 상태변경 가능. side effect를 갖는다. 아무것도 반환하지 않는다.\nQuery : side effect가 없다. 계산값이나 시스템의 상태를 반환한다.\nCQS는 신뢰를 기반으로 한다.(다음 행동이 예측 가능하다라는 뜻)\nTell, Don’t ask\nWhat에 대해서 생각하라. How에 대해서 생각하지 마라. 예를 들어 차의 내구도가 0 이하가 되면 자동차 상태를 BROKEN으로 변경한다고 해보자.\nif (car.getDurability() \u0026lt; 0) car.setStatus(BROKEN); 위와 같이 직접 상태를 바꾸는것보단 아래와 같이 Car 객체에 위임해서 시키는게 좋다. Tell(시켜라), Don\u0026rsquo;t ask(구체적인 방법을 직접 쓰지말고)\nif (car.getDurability() \u0026lt; 0) car.changeStatus(BROKEN); // Car 클래스 메서드 public void changeStatus(String status) { car.setStatus(status); } Law of Demeter\n함수가 시스템의 전체를 알게 하면 안된다. 개별 함수는 아주 제한된 지식만 가져야 한다. 객체는 요청된 기능 수행을 위해 이웃객체에게만 요청해야 한다. 요청을 수신하면 적절한 객체가 수신할때가지 전파되야 한다.\nEarly returns\n최대한 리턴은 빠르게.\nError handling\nSpring의 default는 Runtime-exception이 발생하면 롤백. Checked-exception이 발생하면 롤백 아님.\nSpecial Cases\nsize 0일때.\nNull is not error\nNull is a value\ntry도 하나의 역할/기능이다\nForm Comment는 특별한 경우에만 작성되야 한다.\nBad Comments\n Closing Brace Comments (중괄호 닫는거 알리는 주석) Big Banner Comments attribution Comments(ex add by yangbongsoo)  Commetns와 해당 코드는 항상 붙어있어라.\nVertical Formatting\n공란을 함부로 사용하지 마라. 공란은 메서드 사이, private 변수들과 public 변수들 사이, 변수 선언과 메서드 실행의 나머지 부분 사이, if / while 블록과 다른 코드 사이에 둔다.\n서로 관련된 것들은 vertical하게 근접해야 한다.(vertical의 거리가 그들간의 관련성을 나타낸다)\nclasses\n안 좋은 설계 방식이 getter/setter 자바빈 규약(예전에는 애플릿으로 네트워크 통신할 때 필요했었던 \u0026hellip;)\n변수를 private로 해놓고 왜 getter/setter를 제공하는가?\nTell, Don’t ask를 다시 생각해라. getter/setter가 많으면 get, get, get 해서 요청하게 되고 set 시킬 수 있다고 생각하게 된다. getter, setter가 없으면 Ask를 안한다. 그냥 시키게 된다. 이런 규칙을 따라야 한다.\nMax Cohesive\n응집도가 높아야 된다. 좀 더 구체적으로 말하면\nmethod1은 굉장히 Cohesive하다. 왜? 이 클래스의 변수를 다 사용하기 때문이다. 변수들 중 하나라도 바뀌면 method1은 영향을 받는다.\nmethod1, method2 둘 다 2개의 변수 모두 사용한다. 변수 하나의 변경은 모두에게 전파가 된다. (마찬가지로 high cohesion)\ngetter/setter는 cohesion이 낮다. 왜? getter/setter는 변수 하나만 사용하기 때문이다. getter/setter가 없을 수는 없다. 하지만 최소화 해야 된다.\n추가적으로 다음과 같은 경우를 살펴보자. Car 객체에 gallonsOfGas 속성이 있는데, 문제는 디젤차, 전기차 등으로 확장했을 때 gallonsOfGas는 올바른 변수명이 될 수 없다. 따라서 오른쪽 그림과 같이 getPercentFuelRemaining이란 변수명으로 바꾸면 디젤차, 전기차에서도 문제 없이 사용할 수 있다.\n만약 디젤차라면, 런타임의 flow는 CarDriver -\u0026gt; Car(인터페이스) -\u0026gt; DisielCar 이렇게 흘러간다. 그러나 소스코드 의존성은 DisielCar -\u0026gt; Car 이렇게 거꾸로 되고 있다.(IoC)\n객체 지향의 핵심 : IoC를 통해 High Level Policy(클라이언트, 비지니스 로직)를 Low Level Detail로부터 보호하는것이다. 다형성은 클라이언트 코드를 서버 코드의 구현 변경으로부터 보호해준다.\n내부 변수를 hide했을 때, 상세 구현을 덜 노출 할 수록 다형성 클래스를 활용할 기회가 늘어난다.\nArchitecture Architecture : 전체적인 시스템 개발에 기반을 제공하는 변경 불가한 초기 결정사항의 집합.\n건축의 아키텍처가 해머, 못, 기욋장이 아니듯이 Java, Eclipse, MVC, Spring, Tomcat, Hibernate 들도 아키텍처가 아니고 도구이다. 아키텍처는 사용법을 드러내야 한다.\n시스템의 사용법을 보여주는 것은 Usecase가 되야 한다. Usecase는 일련의 단계를 나타낸다. 사용자가 ~한다. 그러면 시스템은 ~ 한다. 다시 사용자가 ~ 한다. 시스템은 ~ 한다(반복). 즉, 시스템과 Actor(사용자 집합) 간의 상호작용을 정의하는 일련의 절차이다.\nMVC로 구성된 Web 시스템만 가지고 아키텍처라고 많이 하는데, 이건 Usecase를 숨기고 Delivering 메커니즘(MVC를 말함. 사용자 요청을 시스템에 전달하고 시스템에서 가공된 결과를 사용자에게 전달하는 \u0026hellip;)만 노출한다. 문제는 그 부분만 자세히 설명하고 \u0026lsquo;그 시스템이 무엇을 하고 있다’ 라는건 보여주지 않는다. 중요한건 Usecase다. 그래서 Usecase가 Delivering 메커니즘에 의존성이 없어야 되고, UI, DB, Framework, Tool에 대한 결정들은 Usecase와 decouple 되야 한다. Usecase should stand alone\n좋은 아키텍처는 Framework, WAS, UI 등과 같은 stuff들에 대한 결정을 미룰 수 있어야 된다. 연기 될 수 있어야 되고, 연기 되어야만 한다.(시간이 지날수록 결정을 위한 정보가 더 풍부해진다)\n우린 뭔가 시작할 때 DB부터 생각한다. MySQL 써서 테이블 이렇게 저렇게 만들고 \u0026hellip; 앞으론 그러지 말자. 개발자 입장에서 data부터 생각하고 시작하면 꼬인다. 반드시 절차지향적으로 가게 된다. 아키텍처를 Usecase에 집중해라(시스템의 의도)\nex) Web기반 Accounting 시스템의 아키텍처는 Web이 아닌 Account 이슈에 대해서 잘 드러내야 한다(Web에 대해서 언급할 필요가 없다). 하지만 대부분은 Web MVC에 대해서 자세히 말하지만 실질적인 비지니스 로직은 언급하지 않는다.\nController, View는 html, http와 강하게 연관돼있다. 그런데 Controller가 사용하는 Moel이라는 것은 Controller에 의존적일 수 밖에 없다(Controller가 요구하는 기능들을 잘 제공 해야 되니까). 결국 View, Controller가 Model에 high coupling된다. Model이 순수하게 POJO가 되지 못하고 http, html와 관련된 코드가 들어가게 된다. 원래 MVC의 Model은 pure해야 되는데 Web MVC에서 Model은 pure할 수가 없다.\n위 그림을 보면 Model이 중심이 아니고, Web이 중심이어서 Web에 의해 Model이 오염되는 모습을 보인다. 시스템 아키텍처는 아키텍처 변경 없이 delivery 메커니즘을 변경할 수 있어야 한다. Usecase가 시스템에서 가장 중요하다(delivery 메커니즘이 변경되도 내 애플리케이션의 비지니스 로직이 보호받을 수 있어야 한다).\nUsecase는 사용자가 특정 목적을 이루기 위해 시스템과 어떻게 상호작용하는지에 대한 형식적 기술이다. Usecase는 입력 데이터를 해석하여 출력 데이터를 생성하는 필수 알고리즘이다.\n결론 : 아키텍처는 Tool이나 Framework에 기반/의존하지 않는다. 좋은 아키텍처는 Tool, Framework에 대한 결정을 아주 오랫동안 미룰 수 있어야 한다.(delivery 메커니즘에 의존하지 않고, 노출시키지 않고 숨김) 시스템의 모양을 보면 Web인지 App인지 몰라야 된다. 대신 어떤 기능을 제공하는지, 뭘 하는지 알 수 있어야 된다.\nSOLID Design Smells(내가 잘못하고 있다는 느낄수 있는 징후 3가지)\nRigidity :\n정의 : 시스템의 의존성으로 인해 변경하기 어려워지는 것.\n원인 : 조금해보고 변경하고 조금해보고 변경하려면 빌드나 테스트가 자동화되야 한다. 하지만 그렇지 못하고 많은 시간이 소요되면, 빌드나 테스트를 자주 못하게돼 결국 rigid해진다.\n해결 : 테스트와 리빌드 시간을 줄이면 Rigidity가 줄어들고 수정이 용이해진다.\nFragility: 한 모듈의 수정이 다른 모듈에 영향을 미칠 때 =\u0026gt; 모듈 간의 의존성을 제거해야 한다.\nImmobility: 모듈이 쉽게 추출되지 않고 재사용 되지 않는 경우 =\u0026gt; DB, UI, Framework 등과 결합도를 낮춰야 한다.\n상속, 다형성, 캡슐화 등등은 객체지향의 핵심이 아니라 메커니즘이다. 객체지향의 핵심은 IoC를 통해 상위레벨의 모듈을 하위 레벨의 모듈로부터 보호하는 것이다.\n객체지향 설계는 의존성을 잘 관리하는 것이다.(Isolate the high level policies from low level details)\nSRP\nsave / findById 는 같은 부류\n만약 CalculatePay 책임이 있는 경우, CalculateDeduction, CalculateSalary 추가해도 책임의 수는 변하지 않음.\n그러므로 같은 부류로 나눠서 책임이 몇개인가 보면 된다.\n그렇다면 어떻게 부류를 나눌 수 있냐에 대해서, “누가 해당 메서드의 변경을 유발하는 사용자인가”로 메서드를 그룹핑할 수 있다.\nSRP는 사용자에 관한 것이다. 책임은 SW의 변경을 요청하는 특정 사용자들에 대해 클래스나 함수가 갖는 것이다. 변경의 근원으로 책임을 볼 수 있는데 변경의 원인이 같은 것은 같은 책임으로 볼 수 있다.\n지금 여기에는 3개의 Actor가 있다. (Employee 클래스의 변경을 요구하는 사용자들)\nActor는 서로 다른 Needs와 Expectation을 가진다.\nUser들을 Role에 따라 나눠야 한다. 개별 User가 Actor가 아니라 User가 특정 Role을 수행할 때 Actor라 부른다. 결국 책임은 individual 한게 아니라 Actor와 연결되어 있다.\n책임이라는 것은 특정 Actor의 요구사항을 만족시키기 위한 일련의 함수의 집합이다. Actor의 요구사항 변경이 일련의 함수들의 변경의 근원이 된다.\nTwo values of SW\nSecondary value of SW is it’s behavior : 현재의 SW가 현재 사용자의 현재 요구사항을 만족하는가?\nPrimary value of SW : 지속적으로 변화하는 요구사항을 수용하는 것. 대부분의 SW는 현재의 요구사항을 잘 만족하지만 변경하긴 어렵다.\nSRP 하나의 모듈은 반드시 하나의 변경사유만 가져야 한다.\nSRP Solution\n정답은 없다. Create 3 interfaces for each responsibility\n3개의 인터페이스를 하나의 클래스로 구현\n장점 : Actor들을 완전히 decouple 시켰다.\n단점 : 어디에 구현되었는지 찾기 어렵다. 그리고 하나의 클래스에 구현되어 구현은 coupled 되어 있다.\nFacade 클래스가 3개의 다른 구현체들에게 위임하는 구조이다. 어디에 구현되어 있는지 찾기는 쉽지만, Actor들은 여젼히 coupled 되어 있다.\nActor를 구현 클래스에서 decouple 시켰다. 그러나 모든 Actor들이 하나의 인터페이스에 coupled 되어 있다. 그리고 하나의 클래스에 구현되어 구현도 coupled 되어 있다.\n레거시를 다룰때는 좋은 방법이다.\n결과 : Actor들은 분리된 3개의 클래스에 의존\n3개의 책임에 대한 구현은 분리\n하나의 책임의 변경에 따른 다른 책임에 영향을 안미침\n문제점 : transitive dependency가 존재한다. 다시 말해 Employee에서 변경이 일어 났을 때 EmployeeGateway / EmployeeReporter에 영향을 미칠 수 있다.\nOCP\n확장에 대해선 열려 있고, 변경에 대해선 닫혀있다.\n확장 : 새로운 type을 추가함으로써 새로운 기능을 추가 할 수 있다.\nOCP가 가능한가?\n이론적으론 가능한데 비실용적이다. 2가지 문제점이 있다.\n main partition : main에서 의존성 주입을 해줘야 하는 경우가 있으니까, 거기는 어차피 if / else가 있으니까. main은 OCP를 준수 할 수 없음(Spring에서 해결해줄수는 있어) Crystal ball problem : 확장을 위해 미리 인터페이스를 준비해 놓는다는게 현실적으로 불가능해.(고객은 자신이 원하는 걸 직접 만져봐야만 그때서야 알 수 있어)  cf) 모든 Design Smell 중 Fragility가 가장 먼저 제거해야 할 대상이다.\nCrystal ball problem을 해결하기 위한 방법\n Big Design Up Front(BDUF) : OCP가 가능하도록 고객의 요구사항을 예측하여 도메인 모델을 만든다. 변경 가능한 모든것들에 대한 청사진을 얻을 때까지 헛된 짓을 계속한다.\n 문제 : 머피의 법칙처럼 미리 추상화 시켜놓은 것엔 고객이 변경을 요구하지 않고 예상치 못한 곳에서 요구한다. 그리고 추상화로 도배된 설계는 직관적이지 않고 더 복잡해서 안하늬만 못한 결과를 초래한다.  Agile Design : 최대한 빨리 고객의 요구사항을 끌어낼 수 있는 가장 단순한 일을 한다. 그럼 고객은 그 결과물에 대해 요구사항 변경을 시작한다. 그럼 어떤 변경이 요구되는지 알게 된다.\n  우리는 실제로 BDUF와 Agile 두 극단 사이에 살고 있다. BDUF를 피해야 하지만 No DUF도 피해야 한다. 사전 설계하는 것은 가치있는 일이다. 그러나 목적은 시스템의 기본 모양을 수립하는 것이지 모든 작은 상세까지 수립하는 것이 아니다.(불필요한 추상화 초래)\nSo 빨리 자주 Deliver하고 고객의 요구사항 변화에 기반하여 리팩토링하라.\nLSP\n서브타입이 슈퍼타입을 행위적으로 대체 가능하다는 원칙\nOCP를 받쳐주는 다형성에 관한 원칙을 제공한다.\nLSP가 위반되면 OCP도 위반됨\ninstanceof / downCasting을 사용하는 것은 전형적인 LSP 위반의 징조\nSuper Type이 있고 Sub Type이 있을 때 어떤 Sub Type이든지 Super Type으로 대체 됐을 때 아무런 문제가 없어야 된다. 근데 아무것도 안하도록 override 하는 것은 LSP 위반이다.\n인터페이스에 모든 파생 클래스에 적용할 수 없는 메서드를 추가하는 것도 LSP 위반이다.\nISP\nDon’t depend on things that you don’t need\n사용하지 않지만 의존성을 갖고 있다면, 그 인터페이스가 변경되면 재컴파일 / 빌드 / 배포 해야 된다.\nSo 사용하는 기능만 제공하도록 인터페이스를 분리함으로써 한 기능에 대한 변경의 여파를 최소화 시켜라.\nFatClass를 만나면 인터페이스를 생성해서 FatClass를 Client로부터 Isolate 시켜야 한다. 인터페이스는 구현체보다는 Client와 논리적으로 결합되므로, Client가 호출하는 메서드만 interface에 정의 되었다는 것을 확신할 수 있다.\ncf) 인자로 HashMap을 넘기는 것은 굉장히 위험하다. 꼭 HashMap을 써야 한다면 Wrapping 해서 써야지, direct로 쓰면 HashMap이 무엇이든지 다 넣을 수 있기 때문에 위험해진다.\nDIP High Level policy should not depend on Low Level Details\nOO의 핵심은 IoC를 통해 상위 레벨의 모듈을 하위 레벨의 모듈로부터 보호하는 것이다.\nThe Inversion\nApplication이 Framework에 의존성을 갖는다. 하지만 Framework는 Application에 의존성을 갖지 않는다.\nFramework가 High Level policy가 되고 Application이 Low Level Detail이 되는 거다.\nOCP는 확장이 필요한 부분을 추상화 하는 거고 DIP는 Low Level의 의존성을 갖는 부분을 추상화 한다. 의도가 다르다.\n"
}]